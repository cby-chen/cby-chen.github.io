<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Ansible 安装并简单使用</title>
    <url>/2021/12/30/2021-12-30-Ansible_%E5%AE%89%E8%A3%85%E5%B9%B6%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>Ansible 简介</p>
<p>Ansible 是一款 IT 自动化工具。主要应用场景有配置系统、软件部署、持续发布及不停服平滑滚动更新的高级任务编排。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dc088adca8ce488482700e675f8717c3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>Ansible 本身非常简单易用，同时注重安全和可靠性，以最小化变动为特色，使用 OpenSSH 实现数据传输 ( 如果有需要的话也可以使用其它传输模式或者 pull 模式 )，其语言设计非常利于人类阅读，即使是针对不刚接触 Ansible 的新手来讲亦是如此。</p>
<p>我们坚信无论什么范围的环境，简单都是必须的，所以我们的设计尽可能满足各类型的繁忙人群：开发人员、系统管理员、发布工程师、IT 管理员等所有类型的人。同时， Ansible 适用于各种环境，小到几台多到成千上万台的企业实际环境都完全满足。</p>
<p>Ansible 不使用C&#x2F;S架构管理节点，即没有 Agent 。这样的架构使得 Ansible 不会存在如何升级远程 Agent 管理进程或者因为没有安装 Agent 而无法管理系统。因为 OpenSSH 是非常流行的开源组件，安全问题也非常少 。Ansible 的 去中心化 管理方式深受业内认可， 即它只依赖 OS 的 KEY 认证访问远程主机。如需， Ansible 可以便捷接入 Kerberos, LDAP 或者其它认证系统。</p>
<p>安装ansible工具</p>
<p>&#96;&#96;&#96;shell<br>root@Ansible:<del># apt update &amp;&amp; apt install ansible<br>root@Ansible:</del># apt install sshpass</p>
<p>&#96;&#96;&#96;shell</p>
<p>创建秘钥</p>
<p>&#96;&#96;&#96;shell<br>root@Ansible:<del># ssh-keygen<br>Generating public&#x2F;private rsa key pair.<br>Enter file in which to save the key (&#x2F;root&#x2F;.ssh&#x2F;id_rsa):<br>Enter passphrase (empty for no passphrase):<br>Enter same passphrase again:<br>Your identification has been saved in &#x2F;root&#x2F;.ssh&#x2F;id_rsa<br>Your public key has been saved in &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub<br>The key fingerprint is:<br>SHA256:ZlnekfYdDkp4AA2zZLysbtr8Epcp6tMgFB2TGEY&#x2F;zFU root@Ansible<br>The key’s randomart image is:<br>+—[RSA 3072]—-+<br>|.++oo.oE+.       |<br>|.o+oo o.o.o  .   |<br>|  .&#x3D;  …..o+. . |<br>| .  .  o +oo.oo..|<br>|.     . S … …|<br>| . . + *         |<br>|  . &#x3D; +          |<br>|   oo&#x3D;           |<br>|  .o+oo.         |<br>+—-[SHA256]—–+<br>root@Ansible:</del>#</p>
<p>批量拷贝脚本</p>
<p>root@Ansible:~# vim copy_ssh_id.sh</p>
<p>root@Ansible:~# cat copy_ssh_id.sh<br>#!&#x2F;bin&#x2F;bash<br>rm -f .&#x2F;authorized_keys; touch .&#x2F;authorized_keys<br>sed -i ‘&#x2F;StrictHostKeyChecking&#x2F;s&#x2F;^#&#x2F;&#x2F;; &#x2F;StrictHostKeyChecking&#x2F;s&#x2F;ask&#x2F;no&#x2F;‘ &#x2F;etc&#x2F;ssh&#x2F;ssh_config<br>sed -i “&#x2F;#UseDNS&#x2F; s&#x2F;^#&#x2F;&#x2F;; &#x2F;UseDNS&#x2F; s&#x2F;yes&#x2F;no&#x2F;“ &#x2F;etc&#x2F;ssh&#x2F;sshd_config</p>
<p>cat hostsname.txt | while read host ip pwd; do<br>  sshpass -p $pwd ssh-copy-id -f $ip 2&gt;&#x2F;dev&#x2F;null<br>  ssh -nq $ip “hostnamectl set-hostname $host”<br>  ssh -nq $ip “echo -e ‘y\n’ | ssh-keygen -q -f ~&#x2F;.ssh&#x2F;id_rsa -t rsa -N ‘’”<br>  echo “&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; Copy id_rsa.pub of $ip &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;”<br>  scp $ip:&#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub .&#x2F;$host-id_rsa.pub<br>  #cat .&#x2F;$host-id_rsa.pub &gt;&gt; .&#x2F;authorized_keys<br>  echo $ip $host &gt;&gt; &#x2F;etc&#x2F;hosts<br>done</p>
<p>root@Ansible:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p>添加主机信息</p>
<p>&#96;&#96;&#96;shell<br>root@Ansible:~# vim hostsname.txt</p>
<p>root@Ansible:~# cat hostsname.txt<br>node  192.168.1.2    123123<br>node  192.168.1.3    123123<br>node  192.168.1.4    123123<br>node  192.168.1.5    123123<br>node  192.168.1.6    123123<br>node  192.168.1.7    123123<br>node  192.168.1.8    123123<br>node  192.168.1.9    123123</p>
<hr>
<p>&#96;&#96;&#96;shell</p>
<p>fetch模块：</p>
<p>copy模块：</p>
<p>&#96;&#96;&#96;shell<br>1、从远程主机获取文件：</p>
<p>root@Ansible:~# ansible k8s -m fetch -a “src&#x3D;&#x2F;root&#x2F;node.sh dest&#x3D;&#x2F;root&#x2F;test”</p>
<p>2、从本地主机传到远程：<br>root@Ansible:~# ansible k8s -m copy -a “src&#x3D;&#x2F;root&#x2F;node.sh dest&#x3D;&#x2F;root”</p>
<p>3、远程复制或者本地上传，加上force&#x3D;yes，则会覆盖掉原来的文件，加上backup&#x3D;yes，在覆盖的时候会把原来的文件做一个备份：<br>root@Ansible:~# ansible k8s -m copy -a “src&#x3D;&#x2F;root&#x2F;node.sh dest&#x3D;&#x2F;root force&#x3D;yes backup&#x3D;yes”</p>
<p>4、复制的时候可以带参数：owner,group,mode</p>
<p>&#96;&#96;&#96;shell</p>
<p>-——–</p>
<p>&#96;&#96;&#96;shell<br>将本地的源拷贝到服务器上</p>
<p>root@Ansible:~# ansible k8s -m copy -a “src&#x3D;&#x2F;etc&#x2F;apt&#x2F;sources.list dest&#x3D;&#x2F;etc&#x2F;apt&#x2F;“</p>
<p>更新源</p>
<p>root@Ansible:~# ansible k8s  -m  command -a ‘apt update’</p>
<p>安装ntpdate</p>
<p>root@Ansible:~# ansible k8s  -m  command -a ‘apt install ntpdate’</p>
<p>同步时间</p>
<p>root@Ansible:~# ansible k8s  -m  command -a ‘ntpdate -u ntp.aliyun.com’</p>
<p>修改时区</p>
<p>root@Ansible:<del>#<br>root@Ansible:</del>#<br>root@Ansible:~# ansible k8s  -m  command -a ‘cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime’</p>
<p>查看是否修改</p>
<p>root@Ansible:<del>#<br>root@Ansible:</del># ansible k8s  -m  command -a ‘date -R ‘<br>192.168.1.13 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.10 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.14 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.12 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.11 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.15 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.51 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.52 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.16 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.53 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:57 +0800<br>192.168.1.55 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:58 +0800<br>192.168.1.54 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:58 +0800<br>192.168.1.57 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:58 +0800<br>192.168.1.56 | CHANGED | rc&#x3D;0 &gt;&gt;<br>Thu, 11 Nov 2021 14:52:58 +0800<br>root@Ansible:<del>#<br>root@Ansible:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/40ba7623bb9d4ae6bc4941bf4c672b7e~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>50篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5ba57b90f02b4710a4187c30b960fcc2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>CentOS8删除boot目录恢复</title>
    <url>/2021/12/30/2021-12-30-CentOS8%E5%88%A0%E9%99%A4boot%E7%9B%AE%E5%BD%95%E6%81%A2%E5%A4%8D/</url>
    <content><![CDATA[<p> 系统安装完之后，boot分区最好做一个备份，因为这个分区 我们基本不会动它，所以备份一次一劳永逸，以防万一。如果我们不小心 误删除了这个目录，也不用慌，正因为这个分区，我们除了开机 其他时候基本用不到，所以恢复起来还是很容易的。而且恢复之后，我们操作系统里的其他服务基本没有影响，我们看一下，如果误删除了&#x2F;boot，该如何恢复：</p>
<p>由于&#x2F;boot分区一般就是用于存放镜像和相关启动引导文件，所以误删之后，恢复并不影响系统其他服务的正常运行；但是误删之后 系统启动不了了，因为 grub.conf文件在 &#x2F;boot&#x2F;grub&#x2F;中 也被删除了。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/90f852e23d254098ac68d2d484e9fb6a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>删除boot目录</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1e9b0b0be060455a809ecf08349b3caf~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>已无法启动，进入grub模式</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2d1202adf6cd4dd7b19ffa6ae0852a9f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>   </p>
<p>这时需要进行挂盘修复</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d637fec4500946259a3589609d4b07e2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>急救模式启动后加载一个shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/83b6702ed96f47ee9707e1fdd45e8915~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>查看磁盘已自动挂载到&#x2F;mnt&#x2F;目录下</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6b2d18454a014ebea4237e43a56ec8be~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>使用chroot命令进入到磁盘系统。否则仅在内存系统中。</p>
<p>查看boot目录后是空的。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a9a954b4796c40d696e9641d41ec66b5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>挂载光盘镜像</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2229df13ac59400384bf53fe023f39ba~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>使用其他的Centos8 系统 查看boot目录下vmlinuz和initramfs生成的包</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3692fc698654492cbfa9b3af234b8e78~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>安装内核</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9572016158f7460399d3b027aeb7115d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>Boot目录恢复</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c7526425e1cd4603b327d1a829b26657~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/12d66b1f8e874173bee11118aa09e6f2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>   </p>
<p>已可以正常引导</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e4866700ba744a868c6ddb24d50ccdfc~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>CentOS 的 YUM安装时卡死解决方案</title>
    <url>/2021/12/30/2021-12-30-CentOS_%E7%9A%84_YUM%E5%AE%89%E8%A3%85%E6%97%B6%E5%8D%A1%E6%AD%BB%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<p>YUM是基于RPM的软件包管理器</p>
<p>YUM is an RPM-based package manager</p>
<p><strong>补充说明</strong></p>
<p><strong>Supplementary note</strong></p>
<p>yum命令 是在Fedora和RedHat以及SUSE中基于rpm的软件包管理器，它可以使系统管理人员交互和自动化地更新与管理RPM软件包，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。</p>
<p>    The yum command is a rpm-based package manager in Fedora, RedHat and SUSE. It enables system administrators to interactively and automatically update and manage RPM packages. It can automatically download and install RPM packages from a specified server, and can be processed automatically Dependency relationship, and install all dependent software packages at one time, no need to download and install tediously again and again. Yum provides commands to find, install, delete a certain, a group or even all packages, and the commands are concise and easy to remember.</p>
<p><strong>问题：</strong></p>
<p>    在使用yum安装时，卡死并且无法Ctrl+c终止，需要将其杀死才能停止。</p>
<p>如下图：</p>
<p>    When using yum to install, it is stuck and cannot be terminated by Ctrl+c. You need to kill it to stop.</p>
<p>As shown below:</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/118881abd6294aad84628b1a8577beed~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>解决方案一：</p>
<p>Solution 1:</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1d6b1ae48f6b4261b44e1bbf1929ac85~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    删除rpm数据文件后再重建rpm数据文件：</p>
<p> Rebuild the rpm data file after deleting the rpm data file:</p>
<p>    删除rpm数据文件</p>
<p> Delete rpm data file  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rm -f /var/lib/rpm/__db.00*</span><br></pre></td></tr></table></figure>

<p>重建rpm数据文件</p>
<p>Rebuild rpm data file</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rpm -vv --rebuilddb</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/43b8beadf721433c95cafb5dc3025d3f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>清空缓存后再重新缓存</p>
<p>Re-cache after clearing the cache</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum clean all </span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure>

<p>执行完一般情况就可以正常使用了，若依旧无法使用请参考以下方式二  </p>
<p>After executing the general situation, it can be used normally, if it still cannot be used, please refer to the following method two</p>
<p>解决方案二：</p>
<p>Solution two:</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c2c9ab9426a441c39761f6d3992d1e4b~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>将这俩个文件删除后在进行测试</p>
<p>Test after deleting these two files</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/67e2d09420d4403bb3713243f3fded27~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e53c0af8883a488aacbb62ba5286bd7d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Docker启动MySQL、MongoDB、Redis、Elasticsearch、Grafana，数据库</title>
    <url>/2021/12/30/2021-12-30-Docker%E5%90%AF%E5%8A%A8MySQL%E3%80%81MongoDB%E3%80%81Redis%E3%80%81Elasticsearch%E3%80%81Grafana%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d57a34049f8d46f78a989b92b19bbb1d~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>前言：  </p>
<p>临时使用数据库时可以使用docker运行，这样可以防止在系统上安装破坏环境，同时使用docker启动会比在系统中安装配置要快速，可以说是最快的方式安装部署并启动数据库。</p>
<hr>
<p><strong>docker配置启动运行MySQL</strong>  </p>
<p>首先创建目录并进入</p>
<p>&#96;&#96;&#96;shell<br>sudo docker run -p 3306:3306 \<br>–name mymysql \<br>–restart&#x3D;always \<br>-v $PWD&#x2F;conf:&#x2F;etc&#x2F;mysql&#x2F;conf.d \<br>-v $PWD&#x2F;logs:&#x2F;logs \<br>-v $PWD&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql \<br>-e MYSQL_ROOT_PASSWORD&#x3D;123456 \<br>-d mysql:8</p>
<p>&#96;&#96;&#96;shell</p>
<p>--restart&#x3D;always：在容器退出时总是重启容器</p>
<p>MYSQL_ROOT_PASSWORD&#x3D;123456：root密码123456</p>
<p>mysql:8  使用MySQL8</p>
<p>-v $PWD&#x2F;conf:&#x2F;etc&#x2F;mysql&#x2F;conf.d  配置文件</p>
<p>-v $PWD&#x2F;logs:&#x2F;logs   日志</p>
<p>-v $PWD&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql    数据</p>
<hr>
<p><strong>docker配置启动运行phpMyAdmin</strong></p>
<p>&#96;&#96;&#96;shell<br>docker run -d \<br>  -p 8001:80 \<br>  -e UPLOAD_LIMIT&#x3D;128M \<br>  -e MAX_EXECUTION_TIME&#x3D;10000 \<br>  –name phpmyadmin \<br>  phpmyadmin&#x2F;phpmyadmin</p>
<p>&#96;&#96;&#96;shell</p>
<p>UPLOAD_LIMIT 和 MAX_EXECUTION_TIME 需要设置一下</p>
<hr>
<p>*<em><strong>docker配置启动运行</strong>MongoDB</em>*</p>
<p>&#96;&#96;&#96;shell<br>docker run -d \<br>  -p 27017:27017 \<br>  -v mongo-data:&#x2F;data&#x2F;db \<br>  -v mongo-config:&#x2F;data&#x2F;configdb \<br>  –name mongo \<br>  -e MONGO_INITDB_ROOT_USERNAME&#x3D;mongoadmin \<br>  -e MONGO_INITDB_ROOT_PASSWORD&#x3D;123123 \<br>  -v &#x2F;data:&#x2F;mnt&#x2F;data \<br>  mongo</p>
<p>&#96;&#96;&#96;shell</p>
<p>MONGO_INITDB_ROOT_USERNAME 用户名</p>
<p>MONGO_INITDB_ROOT_PASSWORD 密码</p>
<p>mongo-data 数据目录</p>
<p>mongo-config 配置文件目录</p>
<hr>
<p>*<em><strong>docker配置启动运行</strong>Mongo Express</em>*</p>
<p>&#96;&#96;&#96;shell<br>  docker run -d \<br>  -p 8002:8081 \<br>  –name mongo-express \<br>  mongo-express</p>
<p>&#96;&#96;&#96;shell</p>
<hr>
<p>*<em><strong>docker配置启动运行</strong>Redis</em>*</p>
<p>&#96;&#96;&#96;shell<br>docker run -d \<br>  -p 6379:6379 \<br>  -v redis-data:&#x2F;data \<br>  –name redis \<br>  redis</p>
<p>&#96;&#96;&#96;shell</p>
<hr>
<p>*<em><strong>docker配置启动运行</strong>Elasticsearch</em>*</p>
<p>&#96;&#96;&#96;shell<br>docker run -d \<br>  -p 9100:9100 -p 9200:9200 \<br>  -e discovery.type&#x3D;single-node \<br>  -v es-data:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data \<br>  -v es-log:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;logs \<br>  –name elasticsearch \<br>  elasticsearch</p>
<p>&#96;&#96;&#96;shell</p>
<hr>
<p>*<em><strong>docker配置启动运行</strong>Grafana</em>*</p>
<p>&#96;&#96;&#96;shell<br>docker run -d \<br>  -p 8003:3000 \<br>  –link mysql:mysql \<br>  –link mongo:mongo \<br>  –name grafana \<br>  grafana&#x2F;grafana</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f8044e051f1458b8a62e9da38458826~tplv-k3u1fbpfcp-zoom-1.image"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>HaProxy 安装搭建配置</title>
    <url>/2021/12/30/2021-12-30-HaProxy_%E5%AE%89%E8%A3%85%E6%90%AD%E5%BB%BA%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p><strong>HaProxy简介</strong></p>
<p><strong><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b6fd39e9d7ad4cd290e7b34eb0022d6c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></strong></p>
<p>    HAProxy是一个免费的负载均衡软件，可以运行于大部分主流的Linux操作系统上。</p>
<p>    HAProxy提供了L4(TCP)和L7(HTTP)两种负载均衡能力，具备丰富的功能。HAProxy的社区非常活跃，版本更新快速。最关键的是，HAProxy具备媲美商用负载均衡器的性能和稳定性。</p>
<p><strong>HaProxy的核心功能</strong></p>
<p>    负载均衡：L4和L7两种模式，支持RR&#x2F;静态RR&#x2F;LC&#x2F;IP Hash&#x2F;URI Hash&#x2F;URL_PARAM Hash&#x2F;HTTP_HEADER Hash等丰富的负载均衡算法</p>
<p>    健康检查：支持TCP和HTTP两种健康检查模式</p>
<p>    会话保持：对于未实现会话共享的应用集群，可通过Insert Cookie&#x2F;Rewrite Cookie&#x2F;Prefix Cookie，以及上述的多种Hash方式实现会话保持</p>
<p>    SSL：HAProxy可以解析HTTPS协议，并能够将请求解密为HTTP后向后端传输</p>
<p>    HTTP请求重写与重定向</p>
<p>    监控与统计：HAProxy提供了基于Web的统计信息页面，展现健康状态和流量数据。基于此功能，使用者可以开发监控程序来监控HAProxy的状态</p>
<p><strong>HaProxy的关键特性</strong>  </p>
<p><strong>性能</strong></p>
<p>    1 . 采用单线程、事件驱动、非阻塞模型，减少上下文切换的消耗，能在1ms内处理数百个请求。并且每个会话只占用数KB的内存。</p>
<p>    2 . 大量精细的性能优化，如O(1)复杂度的事件检查器、延迟更新技术、Single-buffereing、Zero-copy forwarding等等，这些技术使得HAProxy在中等负载下只占用极低的CPU资源。</p>
<p>    3 . HAProxy大量利用操作系统本身的功能特性，使得其在处理请求时能发挥极高的性能，通常情况下，HAProxy自身只占用15%的处理时间，剩余的85%都是在系统内核层完成的。</p>
<p>    4 . HAProxy作者在8年前（2009）年使用1.4版本进行了一次测试，单个HAProxy进程的处理能力突破了10万请求&#x2F;秒，并轻松占满了10Gbps的网络带宽。</p>
<p><strong>稳定性</strong></p>
<p>    在上文中提到过，HAProxy的大部分工作都是在操作系统内核完成的，所以HAProxy的稳定性主要依赖于操作系统，作者建议使用2.6或3.x的Linux内核，对sysctls参数进行精细的优化，并且确保主机有足够的内存。这样HAProxy就能够持续满负载稳定运行数年之久。</p>
<p>设置主机名</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# hostnamectl  set-hostname haproxy</span><br><span class="line">root@hello:~#</span><br><span class="line">root@hello:~#</span><br><span class="line">root@hello:~# bash</span><br><span class="line">root@haproxy:~#</span><br></pre></td></tr></table></figure>

<p>安装 haproxy</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@haproxy:~# apt-get install haproxy</span><br><span class="line">root@haproxy:~# cp /etc/haproxy/haproxy.cfg&#123;,.ori&#125;</span><br><span class="line">root@haproxy:~#</span><br><span class="line">root@haproxy:~# vim /etc/haproxy/haproxy.cfg</span><br><span class="line">root@haproxy:~#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>配置文件如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@haproxy:~# cat /etc/haproxy/haproxy.cfg</span><br><span class="line">cat /etc/haproxy/haproxy.cfg</span><br><span class="line">global</span><br><span class="line">        log /dev/log    local0</span><br><span class="line">        log /dev/log    local1 notice</span><br><span class="line">        chroot /var/lib/haproxy</span><br><span class="line">        stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners</span><br><span class="line">        stats timeout 30s</span><br><span class="line">        user haproxy</span><br><span class="line">        group haproxy</span><br><span class="line">        daemon</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        ca-base /etc/ssl/certs</span><br><span class="line">        crt-base /etc/ssl/private</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384</span><br><span class="line">        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256</span><br><span class="line">        ssl-default-bind-options no-sslv3 no-tlsv10 no-tlsv11 no-tls-tickets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">        log     global</span><br><span class="line">        mode    http</span><br><span class="line">        option  httplog</span><br><span class="line">        option  dontlognull</span><br><span class="line">        timeout connect 5000</span><br><span class="line">        timeout client  50000</span><br><span class="line">        timeout server  50000</span><br><span class="line">        errorfile 400 /etc/haproxy/errors/400.http</span><br><span class="line">        errorfile 403 /etc/haproxy/errors/403.http</span><br><span class="line">        errorfile 408 /etc/haproxy/errors/408.http</span><br><span class="line">        errorfile 500 /etc/haproxy/errors/500.http</span><br><span class="line">        errorfile 502 /etc/haproxy/errors/502.http</span><br><span class="line">        errorfile 503 /etc/haproxy/errors/503.http</span><br><span class="line">        errorfile 504 /etc/haproxy/errors/504.http</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend LOADBALANCER-01</span><br><span class="line">    bind  0.0.0.0:80</span><br><span class="line">    mode http</span><br><span class="line">    default_backend WEBSERVERS-01</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">backend WEBSERVERS-01</span><br><span class="line">        balance roundrobin</span><br><span class="line">    server      node1 192.168.1.10:9200 check   inter 2000 rise 3 fall 3 weight 1 maxconn   2000</span><br><span class="line">        server      node2 192.168.1.11:9200 check   inter 2000 rise 3 fall 3 weight 1 maxconn   2000</span><br><span class="line">        server      node3 192.168.1.12:9200 check   inter 2000 rise 3 fall 3 weight 1 maxconn   2000</span><br><span class="line">        server      node4 192.168.1.13:9200 check   inter 2000 rise 3 fall 3 weight 1 maxconn   2000</span><br><span class="line">        server      node5 192.168.1.14:9200 check   inter 2000 rise 3 fall 3 weight 1 maxconn   2000</span><br><span class="line">        server      node6 192.168.1.15:9200 check   inter 2000 rise 3 fall 3 weight 1 maxconn   2000</span><br><span class="line">        server      node7 192.168.1.16:9200 check   inter 2000 rise 3 fall 3 weight 1 maxconn   2000 backup</span><br><span class="line">        option httpchk</span><br></pre></td></tr></table></figure>

<p>启动服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@haproxy:~#</span><br><span class="line">root@haproxy:~# systemctl start haproxy</span><br><span class="line">root@haproxy:~#</span><br></pre></td></tr></table></figure>

<p>设置开机自启</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@haproxy:~#</span><br><span class="line">root@haproxy:~# systemctl enable haproxy</span><br><span class="line">Synchronizing state of haproxy.service with SysV service script with /lib/systemd/systemd-sysv-install.</span><br><span class="line">Executing: /lib/systemd/systemd-sysv-install enable haproxy</span><br><span class="line">root@haproxy:~#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f3028b7aa22846438d361225664d9bcd~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>40篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/340301ad65794190baf494023bc827f0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Docker容器中使用GPU</title>
    <url>/2021/12/30/2021-12-30-Docker%E5%AE%B9%E5%99%A8%E4%B8%AD%E4%BD%BF%E7%94%A8GPU/</url>
    <content><![CDATA[<p><strong>背景</strong></p>
<p>容器封装了应用程序的依赖项，以提供可重复和可靠的应用程序和服务执行，而无需整个虚拟机的开销。如果您曾经花了一天的时间为一个科学或 深度学习 应用程序提供一个包含大量软件包的服务器，或者已经花费数周的时间来确保您的应用程序可以在多个 linux 环境中构建和部署，那么 Docker 容器非常值得您花费时间。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/392fd0434e4c4e4298215235ff8d5ef9~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>安装添加docker源</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# sudo yum-config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">adding repo from: https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">grabbing file https://download.docker.com/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">repo saved to /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">[root@localhost ~]#</span><br><span class="line">[root@localhost ~]# cat /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">[docker-ce-stable]</span><br><span class="line">name=Docker CE Stable - $basearch</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/stable</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[docker-ce-stable-debuginfo]</span><br><span class="line">name=Docker CE Stable - Debuginfo $basearch</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/stable</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[docker-ce-stable-source]</span><br><span class="line">name=Docker CE Stable - Sources</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/source/stable</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[docker-ce-test]</span><br><span class="line">name=Docker CE Test - $basearch</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/test</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[docker-ce-test-debuginfo]</span><br><span class="line">name=Docker CE Test - Debuginfo $basearch</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/test</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[docker-ce-test-source]</span><br><span class="line">name=Docker CE Test - Sources</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/source/test</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[docker-ce-nightly]</span><br><span class="line">name=Docker CE Nightly - $basearch</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/nightly</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[docker-ce-nightly-debuginfo]</span><br><span class="line">name=Docker CE Nightly - Debuginfo $basearch</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/nightly</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[docker-ce-nightly-source]</span><br><span class="line">name=Docker CE Nightly - Sources</span><br><span class="line">baseurl=https://download.docker.com/linux/centos/$releasever/source/nightly</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.docker.com/linux/centos/gpg</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>

<p><strong>下载安装包</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# cd docker</span><br><span class="line">[root@localhost docker]#</span><br><span class="line">[root@localhost docker]# repotrack docker-ce</span><br></pre></td></tr></table></figure>

<p><strong>安装docker 并设置开机自启</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost docker]# yum install ./*</span><br><span class="line">[root@localhost docker]# systemctl  start docker</span><br><span class="line">[root@localhost docker]#</span><br><span class="line">[root@localhost docker]# systemctl  enable docker</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.</span><br><span class="line">[root@localhost docker]#</span><br></pre></td></tr></table></figure>

<p><strong>配置nvidia-docker的源</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost docker]# distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">   &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.repo | sudo <span class="built_in">tee</span> /etc/yum.repos.d/nvidia-docker.repo</span></span><br><span class="line">[root@localhost docker]# cat /etc/yum.repos.d/nvidia-docker.repo</span><br><span class="line">[libnvidia-container]</span><br><span class="line">name=libnvidia-container</span><br><span class="line">baseurl=https://nvidia.github.io/libnvidia-container/stable/centos7/$basearch</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://nvidia.github.io/libnvidia-container/gpgkey</span><br><span class="line">sslverify=1</span><br><span class="line">sslcacert=/etc/pki/tls/certs/ca-bundle.crt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[libnvidia-container-experimental]</span><br><span class="line">name=libnvidia-container-experimental</span><br><span class="line">baseurl=https://nvidia.github.io/libnvidia-container/experimental/centos7/$basearch</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=https://nvidia.github.io/libnvidia-container/gpgkey</span><br><span class="line">sslverify=1</span><br><span class="line">sslcacert=/etc/pki/tls/certs/ca-bundle.crt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[nvidia-container-runtime]</span><br><span class="line">name=nvidia-container-runtime</span><br><span class="line">baseurl=https://nvidia.github.io/nvidia-container-runtime/stable/centos7/$basearch</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://nvidia.github.io/nvidia-container-runtime/gpgkey</span><br><span class="line">sslverify=1</span><br><span class="line">sslcacert=/etc/pki/tls/certs/ca-bundle.crt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[nvidia-container-runtime-experimental]</span><br><span class="line">name=nvidia-container-runtime-experimental</span><br><span class="line">baseurl=https://nvidia.github.io/nvidia-container-runtime/experimental/centos7/$basearch</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=https://nvidia.github.io/nvidia-container-runtime/gpgkey</span><br><span class="line">sslverify=1</span><br><span class="line">sslcacert=/etc/pki/tls/certs/ca-bundle.crt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[nvidia-docker]</span><br><span class="line">name=nvidia-docker</span><br><span class="line">baseurl=https://nvidia.github.io/nvidia-docker/centos7/$basearch</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://nvidia.github.io/nvidia-docker/gpgkey</span><br><span class="line">sslverify=1</span><br><span class="line">sslcacert=/etc/pki/tls/certs/ca-bundle.crt</span><br><span class="line">[root@localhost docker]#</span><br></pre></td></tr></table></figure>

<p><strong>安装下载nvidia-docker</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# mkdir nvidia-docker2</span><br><span class="line">[root@localhost ~]# cd nvidia-docker2</span><br><span class="line">[root@localhost nvidia-docker2]# yum update -y</span><br><span class="line">[root@localhost nvidia-docker2]# repotrack nvidia-docker2</span><br><span class="line">[root@localhost nvidia-docker2]# yum install ./*</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@localhost ~]# mkdir nvidia-container-toolkit</span><br><span class="line">[root@localhost ~]# cd nvidia-container-toolkit</span><br><span class="line">[root@localhost nvidia-container-toolkit]# repotrack nvidia-container-toolkit</span><br><span class="line">[root@ai-rd nvidia-container-toolkit]# yum install ./*</span><br></pre></td></tr></table></figure>

<p><strong>下载镜像，并保存</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# docker pull nvidia/cuda:11.0-base</span><br><span class="line">11.0-base: Pulling from nvidia/cuda</span><br><span class="line">54ee1f796a1e: Pull complete</span><br><span class="line">f7bfea53ad12: Pull complete</span><br><span class="line">46d371e02073: Pull complete</span><br><span class="line">b66c17bbf772: Pull complete</span><br><span class="line">3642f1a6dfb3: Pull complete</span><br><span class="line">e5ce55b8b4b9: Pull complete</span><br><span class="line">155bc0332b0a: Pull complete</span><br><span class="line">Digest: sha256:774ca3d612de15213102c2dbbba55df44dc5cf9870ca2be6c6e9c627fa63d67a</span><br><span class="line">Status: Downloaded newer image for nvidia/cuda:11.0-base</span><br><span class="line">docker.io/nvidia/cuda:11.0-base</span><br><span class="line">[root@localhost ~]#</span><br><span class="line">[root@localhost ~]# docker images</span><br><span class="line">REPOSITORY    TAG         IMAGE ID       CREATED         SIZE</span><br><span class="line">nvidia/cuda   11.0-base   2ec708416bb8   15 months ago   122MB</span><br><span class="line">[root@localhost ~]#</span><br><span class="line">[root@localhost ~]# docker save -o cuda-11.0.tar nvidia/cuda:11.0-base</span><br><span class="line">[root@localhost ~]#</span><br><span class="line">[root@localhost ~]# ls cuda-11.0.tar</span><br><span class="line">cuda-11.0.tar</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>

<p><strong>在要测试的服务器上导入镜像</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ai-rd cby]# docker load -i cuda-11.0.tar</span><br><span class="line">2ce3c188c38d: Loading layer [==================================================&gt;]  75.23MB/75.23MB</span><br><span class="line">ad44aa179b33: Loading layer [==================================================&gt;]  1.011MB/1.011MB</span><br><span class="line">35a91a75d24b: Loading layer [==================================================&gt;]  15.36kB/15.36kB</span><br><span class="line">a4399aeb9a0e: Loading layer [==================================================&gt;]  3.072kB/3.072kB</span><br><span class="line">fa39d0e9f3dc: Loading layer [==================================================&gt;]  18.84MB/18.84MB</span><br><span class="line">232fb43df6ad: Loading layer [==================================================&gt;]  30.08MB/30.08MB</span><br><span class="line">0da51e35db05: Loading layer [==================================================&gt;]  22.53kB/22.53kB</span><br><span class="line">Loaded image: nvidia/cuda:11.0-base</span><br><span class="line">[root@ai-rd cby]#</span><br><span class="line">[root@ai-rd cby]# docker images | grep cuda</span><br><span class="line">nvidia/cuda                          11.0-base   2ec708416bb8   15 months ago   122MB</span><br><span class="line">[root@ai-rd cby]#</span><br></pre></td></tr></table></figure>

<p><strong>安装升级内核</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ai-rd cby]# yum install kernel-headers</span><br><span class="line">[root@ai-rd cby]# yum install kernel-devel</span><br><span class="line">[root@ai-rd cby]# yum update kernel*</span><br></pre></td></tr></table></figure>

<p><strong>禁用模块，并升级boot</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ai-rd cby]# vim /etc/modprobe.d/blacklist-nouveau.conf</span><br><span class="line">[root@ai-rd cby]# cat /etc/modprobe.d/blacklist-nouveau.conf</span><br><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br><span class="line">[root@ai-rd cby]#</span><br><span class="line">[root@ai-rd cby]# mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak</span><br><span class="line">[root@ai-rd cby]# sudo dracut -v /boot/initramfs-$(uname -r).img $(uname -r)</span><br></pre></td></tr></table></figure>

<p><strong>下载驱动并安装</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# wget https://cn.download.nvidia.cn/tesla/450.156.00/NVIDIA-Linux-x86_64-450.156.00.run</span><br><span class="line">[root@ai-rd cby]# chmod +x NVIDIA-Linux-x86_64-450.156.00.run</span><br><span class="line">[root@ai-rd cby]# ./NVIDIA-Linux-x86_64-450.156.00.run</span><br></pre></td></tr></table></figure>

<p><strong>配置docker</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ai-rd ~]# vim /etc/docker/daemon.json</span><br><span class="line">[root@ai-rd ~]# cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;runtimes&quot;: &#123;</span><br><span class="line">        &quot;nvidia&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;nvidia-container-runtime&quot;,</span><br><span class="line">            &quot;runtimeArgs&quot;: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@ai-rd ~]#</span><br><span class="line">[root@ai-rd ~]# systemctl daemon-reload</span><br><span class="line">[root@ai-rd ~]#</span><br><span class="line">[root@ai-rd ~]#</span><br><span class="line">[root@ai-rd ~]#</span><br><span class="line">[root@ai-rd ~]# systemctl  restart docker</span><br><span class="line">[root@ai-rd ~]#</span><br></pre></td></tr></table></figure>

<p><strong>测试docker中的调用情况</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@ai-rd ~]#</span><br><span class="line">[root@ai-rd ~]# sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi</span><br><span class="line">Tue Nov 23 06:03:04 2021      </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 450.156.00   Driver Version: 450.156.00   CUDA Version: 11.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla T4            Off  | 00000000:86:00.0 Off |                    0 |</span><br><span class="line">| N/A   90C    P0    34W /  70W |      0MiB / 15109MiB |      6%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">[root@ai-rd ~]#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/966a8be815a448feae71b0cebcd47020~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>KubeSphere 升级 &amp;amp;&amp;amp; 安装后启用插件</title>
    <url>/2021/12/30/2021-12-30-KubeSphere_%E5%8D%87%E7%BA%A7_&amp;amp;&amp;amp;_%E5%AE%89%E8%A3%85%E5%90%8E%E5%90%AF%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p><strong>KubeSphere 升级</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@master1:~# export KKZONE=cn</span><br><span class="line">root@master1:~# kk upgrade --with-kubernetes v1.22.1 --with-kubesphere v3.2.0 -f sample.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/86d0648beb37491e99cece464f937e9c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>启用插件</strong></p>
<p>用户可以使用 KubeSphere Web 控制台查看和操作不同的资源。要在安装后启用可插拔组件，只需要在控制台中进行略微调整。对于那些习惯使用 Kubernetes 命令行工具 kubectl 的人来说，由于该工具已集成到控制台中，因此使用 KubeSphere 将毫无困难。</p>
<p>以 admin 身份登录控制台。点击左上角的平台管理 ，然后选择集群管理。</p>
<p><strong>集群管理</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4c9d92a98e4a41948018cce16f0d797c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>点击 CRD，然后在搜索栏中输入 clusterconfiguration，点击搜索结果进入其详情页面。</p>
<p><strong>CRD</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bb05d28c223f40059dbf1f976b18ae5f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7fc15c98332e452283636def960fbaf1~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0dd29db03665424fbb051f47d0b12e65~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>编辑配置文件</strong></p>
<p>在该配置文件中，将对应组件 enabled 的 false 更改为 true，以启用要安装的组件。完成后，点击更新以保存配置。</p>
<p><strong>我的内容：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: installer.kubesphere.io/v1alpha1</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    version: v3.2.0</span><br><span class="line">  name: ks-installer</span><br><span class="line">  namespace: kubesphere-system</span><br><span class="line">spec:</span><br><span class="line">  alerting:</span><br><span class="line">    enabled: true</span><br><span class="line">  auditing:</span><br><span class="line">    enabled: true</span><br><span class="line">  authentication:</span><br><span class="line">    jwtSecret: &#x27;&#x27;</span><br><span class="line">  common:</span><br><span class="line">    core:</span><br><span class="line">      console:</span><br><span class="line">        enableMultiLogin: true</span><br><span class="line">        port: 30880</span><br><span class="line">        type: NodePort</span><br><span class="line">    es:</span><br><span class="line">      basicAuth:</span><br><span class="line">        enabled: true</span><br><span class="line">        password: &#x27;&#x27;</span><br><span class="line">        username: &#x27;&#x27;</span><br><span class="line">      data:</span><br><span class="line">        volumeSize: 20Gi</span><br><span class="line">      elkPrefix: logstash</span><br><span class="line">      externalElasticsearchPort: &#x27;&#x27;</span><br><span class="line">      externalElasticsearchUrl: &#x27;&#x27;</span><br><span class="line">      logMaxAge: 7</span><br><span class="line">      master:</span><br><span class="line">        volumeSize: 4Gi</span><br><span class="line">    gpu:</span><br><span class="line">      kinds:</span><br><span class="line">        - default: true</span><br><span class="line">          resourceName: nvidia.com/gpu</span><br><span class="line">          resourceType: GPU</span><br><span class="line">    minio:</span><br><span class="line">      volumeSize: 20Gi</span><br><span class="line">    monitoring:</span><br><span class="line">      GPUMonitoring:</span><br><span class="line">        enabled: true</span><br><span class="line">      endpoint: &#x27;http://prometheus-operated.kubesphere-monitoring-system.svc:9090&#x27;</span><br><span class="line">    openldap:</span><br><span class="line">      enabled: true</span><br><span class="line">    redis:</span><br><span class="line">      enabled: true</span><br><span class="line">  devops:</span><br><span class="line">    enabled: true</span><br><span class="line">    jenkinsJavaOpts_MaxRAM: 2g</span><br><span class="line">    jenkinsJavaOpts_Xms: 512m</span><br><span class="line">    jenkinsJavaOpts_Xmx: 512m</span><br><span class="line">    jenkinsMemoryLim: 2Gi</span><br><span class="line">    jenkinsMemoryReq: 1500Mi</span><br><span class="line">    jenkinsVolumeSize: 8Gi</span><br><span class="line">  etcd:</span><br><span class="line">    endpointIps: 192.168.1.10</span><br><span class="line">    monitoring: false</span><br><span class="line">    port: 2379</span><br><span class="line">    tlsEnable: true</span><br><span class="line">  events:</span><br><span class="line">    enabled: true</span><br><span class="line">  kubeedge:</span><br><span class="line">    cloudCore:</span><br><span class="line">      cloudHub:</span><br><span class="line">        advertiseAddress:</span><br><span class="line">          - &#x27;&#x27;</span><br><span class="line">        nodeLimit: &#x27;100&#x27;</span><br><span class="line">      cloudhubHttpsPort: &#x27;10002&#x27;</span><br><span class="line">      cloudhubPort: &#x27;10000&#x27;</span><br><span class="line">      cloudhubQuicPort: &#x27;10001&#x27;</span><br><span class="line">      cloudstreamPort: &#x27;10003&#x27;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        node-role.kubernetes.io/worker: &#x27;&#x27;</span><br><span class="line">      service:</span><br><span class="line">        cloudhubHttpsNodePort: &#x27;30002&#x27;</span><br><span class="line">        cloudhubNodePort: &#x27;30000&#x27;</span><br><span class="line">        cloudhubQuicNodePort: &#x27;30001&#x27;</span><br><span class="line">        cloudstreamNodePort: &#x27;30003&#x27;</span><br><span class="line">        tunnelNodePort: &#x27;30004&#x27;</span><br><span class="line">      tolerations: []</span><br><span class="line">      tunnelPort: &#x27;10004&#x27;</span><br><span class="line">    edgeWatcher:</span><br><span class="line">      edgeWatcherAgent:</span><br><span class="line">        nodeSelector:</span><br><span class="line">          node-role.kubernetes.io/worker: &#x27;&#x27;</span><br><span class="line">        tolerations: []</span><br><span class="line">      nodeSelector:</span><br><span class="line">        node-role.kubernetes.io/worker: &#x27;&#x27;</span><br><span class="line">      tolerations: []</span><br><span class="line">    enabled: true</span><br><span class="line">  logging:</span><br><span class="line">    containerruntime: docker</span><br><span class="line">    enabled: true</span><br><span class="line">    logsidecar:</span><br><span class="line">      enabled: true</span><br><span class="line">      replicas: 2</span><br><span class="line">  metrics_server:</span><br><span class="line">    enabled: true</span><br><span class="line">  monitoring:</span><br><span class="line">    gpu:</span><br><span class="line">      nvidia_dcgm_exporter:</span><br><span class="line">        enabled: true</span><br><span class="line">    storageClass: &#x27;&#x27;</span><br><span class="line">  multicluster:</span><br><span class="line">    clusterRole: none</span><br><span class="line">  network:</span><br><span class="line">    ippool:</span><br><span class="line">      type: none</span><br><span class="line">    networkpolicy:</span><br><span class="line">      enabled: true</span><br><span class="line">    topology:</span><br><span class="line">      type: none</span><br><span class="line">  openpitrix:</span><br><span class="line">    store:</span><br><span class="line">      enabled: true</span><br><span class="line">  persistence:</span><br><span class="line">    storageClass: &#x27;&#x27;</span><br><span class="line">  servicemesh:</span><br><span class="line">    enabled: true</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>启用组件</p>
<p>执行以下命令，使用 Web kubectl 来检查安装过程：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@master1:~# kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如果组件安装成功，输出将显示以下消息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#####################################################</span><br><span class="line">###              Welcome to KubeSphere!           ###</span><br><span class="line">#####################################################</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Console: http://192.168.0.2:30880</span><br><span class="line">Account: admin</span><br><span class="line">Password: P@88w0rd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES：</span><br><span class="line">  1. After you log into the console, please check the</span><br><span class="line">     monitoring status of service components in</span><br><span class="line">     &quot;Cluster Management&quot;. If any service is not</span><br><span class="line">     ready, please wait patiently until all components</span><br><span class="line">     are up and running.</span><br><span class="line">  2. Please change the default password after login.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#####################################################</span><br><span class="line">https://kubesphere.io             20xx-xx-xx xx:xx:xx</span><br><span class="line">#####################################################</span><br></pre></td></tr></table></figure>

<p>登录 KubeSphere 控制台，在系统组件中可以查看不同组件的状态。</p>
<p>服务组件</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/95291f0fccea4148a035a4cfd005dbcb~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e98859ab58304e5f857cb6a1786099ff~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>47篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ca9a707ad0c24ae0a616067e655591a7~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>KVM WEB管理工具 WebVirtMgr</title>
    <url>/2021/12/30/2021-12-30-KVM_WEB%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7_WebVirtMgr/</url>
    <content><![CDATA[<p><strong>一、webvirtmgr介绍及环境说明</strong></p>
<p>温馨提示：安装KVM是需要2台都操作的，因为我们是打算将2台都设置为宿主机所有都需要安装KVM相关组件</p>
<p>github地址<a href="https://github.com/retspen/webvirtmgr">https://github.com/retspen/webvirtmgr</a></p>
<p>WebVirtMgr是一个基于libvirt的Web界面，用于管理虚拟机。它允许您创建和配置新域，并调整域的资源分配。VNC查看器为来宾域提供完整的图形控制台。KVM是目前唯一支持的虚拟机管理程序。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1c4c4b18d6b6495c8d291a1befc1d826~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>查看服务器版本号</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# cat /etc/redhat-release</span><br><span class="line">CentOS Linux release 7.9.2009 (Core)</span><br></pre></td></tr></table></figure>

<p><strong>内核版本</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# uname -r</span><br><span class="line">3.10.0-1160.42.2.el7.x86_64</span><br></pre></td></tr></table></figure>

<p><strong>关闭Selinux &amp; 防火墙</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# systemctl stop firewalld</span><br><span class="line">[root@webc ~]# systemctl disable firewalld</span><br><span class="line">[root@webc ~]# setenforce 0</span><br><span class="line">setenforce: SELinux is disabled</span><br><span class="line">[root@webc ~]# sed -i &#x27;/SELINUX/s/enforcing/disabled/&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure>

<p><strong>更新软件包并安装epel扩展源</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# yum update</span><br><span class="line">[root@webc ~]# yum install epel*</span><br></pre></td></tr></table></figure>

<p><strong>查看python版本</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# python -V</span><br><span class="line">Python 2.7.5</span><br><span class="line">[root@webc ~]#</span><br></pre></td></tr></table></figure>

<p><strong>查看KVM 驱动是否加载</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# lsmod | grep kvm</span><br><span class="line">kvm_intel             188740  0</span><br><span class="line">kvm                   637515  1 kvm_intel</span><br><span class="line">irqbypass              13503  1 kvm</span><br><span class="line">[root@webc ~]#</span><br><span class="line">[root@webc ~]#</span><br><span class="line">[root@webc ~]# modprobe -a kvm</span><br><span class="line">[root@webc ~]# modprobe -a kvm_intel</span><br><span class="line">[root@webc ~]#</span><br></pre></td></tr></table></figure>

<p><strong>免密配置</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# ssh-keygen</span><br><span class="line">[root@webc ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.104</span><br></pre></td></tr></table></figure>

<p><strong>二、安装KVM</strong></p>
<p><strong>安装KVM依赖包及管理工具</strong></p>
<p><strong>kvm属于内核态，不需要安装。但是需要一些管理工具包</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# yum install qemu-img qemu-kvm qemu-kvm-tools virt-manager virt-viewer virt-v2v virt-top libvirt libvirt-Python libvirt-client python-virtinst bridge-utils tunctl</span><br><span class="line">[root@webc ~]# yum install -y virt-install</span><br><span class="line">[root@webc ~]#</span><br><span class="line">[root@webc ~]# systemctl start libvirtd.service</span><br><span class="line">[root@webc ~]# systemctl enable libvirtd.service</span><br><span class="line">[root@webc ~]#</span><br><span class="line">[root@webc ~]# cd cby/kvm/</span><br><span class="line">[root@webc kvm]#</span><br><span class="line">[root@webc kvm]#</span><br><span class="line">[root@webc kvm]#  git clone https://github.com/palli/python-virtinst.git</span><br><span class="line">[root@webc kvm]# cd python-virtinst/</span><br><span class="line">[root@webc python-virtinst]#  python setup.py install</span><br><span class="line">[root@webc python-virtinst]# virt-install</span><br><span class="line">[root@webc python-virtinst]# yum install bridge-utils</span><br><span class="line">[root@webc python-virtinst]#</span><br><span class="line">[root@webc python-virtinst]# vim /etc/sysconfig/network-scripts/ifcfg-br0</span><br><span class="line">[root@webc python-virtinst]#</span><br><span class="line">[root@webc python-virtinst]#</span><br><span class="line">[root@webc python-virtinst]#</span><br><span class="line">[root@webc python-virtinst]#</span><br><span class="line">[root@webc python-virtinst]#</span><br><span class="line">[root@webc python-virtinst]# cat /etc/sysconfig/network-scripts/ifcfg-br0</span><br><span class="line">DEVICE=br0</span><br><span class="line">TYPE=Bridge</span><br><span class="line">ONBOOT=yes</span><br><span class="line">NM_CONTROLLED=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.1.49</span><br><span class="line">NETMASK=255.225.255.0</span><br><span class="line">GATEWAY=192.168.1.1</span><br><span class="line">DNS1=192.168.1.1</span><br><span class="line">[root@webc python-virtinst]# brctl show</span><br><span class="line">bridge name bridge id       STP enabled interfaces</span><br><span class="line">br-0d093958d245     8000.0242d5824d14   no      </span><br><span class="line">br-2e2d3c481379     8000.0242884030e2   no      </span><br><span class="line">br-36a6ad3375a8     8000.0242d7d7f1ef   no      </span><br><span class="line">br-66a9675a6dd5     8000.024248a61c72   no      </span><br><span class="line">br-b7daf4844ff7     8000.024263dd4715   no      </span><br><span class="line">br-deba197eb09e     8000.0242b290e104   no      </span><br><span class="line">br0     8000.000000000000   no      </span><br><span class="line">docker0     8000.0242858c017c   no      vethe14f7ac</span><br><span class="line">docker_gwbridge     8000.0242588c6db0   no      </span><br><span class="line">virbr0      8000.5254009ba65a   yes     virbr0-nic</span><br><span class="line">[root@webc python-virtinst]# ln -s /usr/libexec/qemu-kvm /usr/sbin/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>三、WebVirtMgr 安装</strong></p>
<p><strong>安装pip、git及supervisor &amp;&amp; Nginx</strong></p>
<p><strong>WebVirtMgr只在管理端安装</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# yum -y install git python-pip libvirt-python libxml2-python python-websockify supervisor gcc python-devel</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>使用pip安装Python扩展程序库</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# pip install numpy</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>git克隆配置并运行WebVirMgr</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# cd cby/</span><br><span class="line">[root@webc cby]# mkdir kvm</span><br><span class="line">[root@webc cby]# cd kvm</span><br><span class="line">[root@webc kvm]# pwd</span><br><span class="line">/root/cby/kvm</span><br><span class="line">[root@webc kvm]#</span><br><span class="line">[root@webc kvm]# git clone git://github.com/retspen/webvirtmgr.git</span><br><span class="line">正克隆到 &#x27;webvirtmgr&#x27;...</span><br><span class="line">remote: Enumerating objects: 5614, done.</span><br><span class="line">remote: Total 5614 (delta 0), reused 0 (delta 0), pack-reused 5614</span><br><span class="line">接收对象中: 100% (5614/5614), 2.97 MiB | 748.00 KiB/s, done.</span><br><span class="line">处理 delta 中: 100% (3606/3606), done.</span><br><span class="line">[root@webc kvm]#</span><br><span class="line">[root@webc kvm]#</span><br><span class="line">[root@webc kvm]# cd webvirtmgr</span><br><span class="line">[root@webc webvirtmgr]# pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#初始化环境</span><br><span class="line">[root@webc webvirtmgr]# ./manage.py syncdb</span><br><span class="line"></span><br><span class="line">#配置Django 静态页面</span><br><span class="line">[root@webc webvirtmgr]# ./manage.py collectstatic</span><br></pre></td></tr></table></figure>

<p><strong>启动WebVirMgr</strong></p>
<p><strong>前台启动WebVirMgr，默认是Debug模式同时日志打印在前台</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/789f53319bb245c69de4230c340b1585~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><strong>用户名和密码是我们刚刚创建的</strong></p>
<p><strong>下载Nginx</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc webvirtmgr]# cd ..</span><br><span class="line">[root@webc kvm]# ls</span><br><span class="line">webvirtmgr</span><br><span class="line">[root@webc kvm]#</span><br><span class="line">[root@webc kvm]# mkdir nginx</span><br><span class="line">[root@webc kvm]# cd nginx</span><br><span class="line">[root@webc nginx]# wget https://nginx.org/download/nginx-1.20.1.tar.gz</span><br><span class="line">[root@webc nginx]# tar xf nginx-1.20.1.tar.gz</span><br><span class="line">[root@webc nginx]# cd nginx-1.20.1/</span><br><span class="line">[root@webc nginx-1.20.1]#</span><br></pre></td></tr></table></figure>

<p><strong>修改nginx配置文件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc conf]# vim nginx.conf</span><br><span class="line">[root@webc conf]#</span><br><span class="line">[root@webc conf]# cat nginx.conf</span><br><span class="line">user  root;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    sendfile        on;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       90;</span><br><span class="line">        server_name  192.168.1.104;</span><br><span class="line">        #charset koi8-r;</span><br><span class="line">        #access_log  logs/host.access.log  main;</span><br><span class="line">        location / &#123;</span><br><span class="line">            #root   html;</span><br><span class="line">            #index  index.html index.htm;</span><br><span class="line">            proxy_pass http://127.0.0.1:8000;</span><br><span class="line">            proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-for $proxy_add_x_forwarded_for;</span><br><span class="line">            proxy_set_header Host $host:$server_port;</span><br><span class="line">            proxy_set_header X-Forwarded-Proto $remote_addr;</span><br><span class="line">            proxy_connect_timeout 600;</span><br><span class="line">            proxy_read_timeout 600;</span><br><span class="line">            proxy_send_timeout 600;</span><br><span class="line">            client_max_body_size 5120M;</span><br><span class="line">        &#125;</span><br><span class="line">        location /static/ &#123;</span><br><span class="line">            root /root/cby/kvm/webvirtmgr;</span><br><span class="line">            expires max;</span><br><span class="line">        &#125;</span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@webc conf]#</span><br></pre></td></tr></table></figure>

<p><strong>安装Nginx</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc nginx-1.20.1]# yum install -y gcc glibc gcc-c++ prce-devel openssl-devel pcre-devel</span><br><span class="line">[root@webc nginx-1.20.1]# useradd -s /sbin/nologin nginx -M</span><br><span class="line">[root@webc nginx-1.20.1]# ./configure --prefix=/root/cby/kvm/nginx/ --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module</span><br><span class="line">[root@webc nginx-1.20.1]# make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<p><strong>启动Nginx</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc nginx-1.20.1]# cd /root/cby/kvm/nginx/sbin/</span><br><span class="line">[root@webc sbin]# /root/cby/kvm/nginx/sbin/nginx -t</span><br><span class="line">nginx: the configuration file /root/cby/kvm/nginx//conf/nginx.conf syntax is ok</span><br><span class="line">nginx: configuration file /root/cby/kvm/nginx//conf/nginx.conf test is successful</span><br><span class="line">[root@webc sbin]# /root/cby/kvm/nginx/sbin/nginx</span><br></pre></td></tr></table></figure>

<p><strong>使用systemctl启停服务</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc sbin]# cat &gt; /etc/supervisord.d/webvirtmgr.ini &lt;&lt; EOF</span><br><span class="line">[program:webvirtmgr]</span><br><span class="line">command=/usr/bin/python /root/cby/kvm/webvirtmgr/manage.py run_gunicorn -c /root/cby/kvm/webvirtmgr/conf/gunicorn.conf.py</span><br><span class="line">directory=/root/cby/kvm/webvirtmgr</span><br><span class="line">autostart=true</span><br><span class="line">autorestart=true</span><br><span class="line">logfile=/var/log/supervisor/webvirtmgr.log</span><br><span class="line">log_stderr=true</span><br><span class="line">user=root</span><br><span class="line"> </span><br><span class="line">[program:webvirtmgr-console]</span><br><span class="line">command=/usr/bin/python /root/cby/kvm/webvirtmgr/console/webvirtmgr-console</span><br><span class="line">directory=/root/cby/kvm/webvirtmgr</span><br><span class="line">autostart=true</span><br><span class="line">autorestart=true</span><br><span class="line">stdout_logfile=/var/log/supervisor/webvirtmgr-console.log</span><br><span class="line">redirect_stderr=true</span><br><span class="line">user=root</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p><strong>启动supervisor</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc webvirtmgr]# systemctl daemon-reload</span><br><span class="line">[root@webc webvirtmgr]# systemctl stop supervisord</span><br><span class="line">[root@webc webvirtmgr]# systemctl start supervisord</span><br></pre></td></tr></table></figure>

<p><strong>查看是否启动成功</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc webvirtmgr]# supervisorctl status</span><br><span class="line">webvirtmgr                       RUNNING   pid 23783, uptime 0:00:11</span><br><span class="line">webvirtmgr-console               RUNNING   pid 23782, uptime 0:00:11</span><br><span class="line">[root@webc webvirtmgr]#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8eb2b3bafc90410ca3460ccfae88d5cd~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>四、Web界面配置webvirtmgr</strong></p>
<p>4.1 添加主机设置存储</p>
<p>1.Add Connection 添加宿主机(即KVM主机)</p>
<p>2.点击SSH连接</p>
<p>3.Label 为主机名，必须为主机名做免密</p>
<p>4.IP 为宿主机IP</p>
<p>5.用户名为服务器用户名</p>
<p>6.点击添加</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8da70c67a54f4f79a3b1bd14bb07873f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b760a3cebc714e00aefc8eda42550619~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>43篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cae69e92bf284a50b140e6307f5fd21d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Kubernetes基础概念</title>
    <url>/2021/12/30/2021-12-30-Kubernetes%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h2 id="Kubernetes基础概念"><a href="#Kubernetes基础概念" class="headerlink" title="Kubernetes基础概念"></a>Kubernetes基础概念</h2><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/03e85186ae7a494d8f57cba0a08cc3c0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h3 id="kubernetes特性："><a href="#kubernetes特性：" class="headerlink" title="kubernetes特性："></a>kubernetes特性：</h3><p><strong>- 服务发现和负载均衡</strong></p>
<p>Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p>
<p><strong>- 存储编排</strong></p>
<p>Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。</p>
<p><strong>- 自动部署和回滚</strong></p>
<p>你可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态 更改为期望状态。例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。</p>
<p><strong>- 自动完成装箱计算</strong></p>
<p>Kubernetes 允许你指定每个容器所需 CPU 和内存（RAM）。当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。</p>
<p><strong>- 自我修复</strong></p>
<p>Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的 运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。</p>
<p><strong>- 密钥与配置管理</strong></p>
<p>Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p>
<p>Kubernetes 为你提供了一个可弹性运行分布式系统的框架。Kubernetes 会满足你的扩展要求、故障转移、部署模式等。例如，Kubernetes 可以轻松管理系统的 Canary 部署。</p>
<h3 id="kubernetes组件结构与介绍"><a href="#kubernetes组件结构与介绍" class="headerlink" title="kubernetes组件结构与介绍"></a>kubernetes组件结构与介绍</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/921cf51e835043c59023c9df0cd1c583~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h4 id="1、控制平面组件（Control-Plane-Components）"><a href="#1、控制平面组件（Control-Plane-Components）" class="headerlink" title="1、控制平面组件（Control Plane Components）"></a>1、控制平面组件（Control Plane Components）</h4><p>控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。</p>
<p>控制平面组件可以在集群中的任何节点上运行。然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。请参阅使用 kubeadm 构建高可用性集群 中关于多 VM 控制平面设置的示例。</p>
<h5 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h5><p>API 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。API 服务器是 Kubernetes 控制面的前端。</p>
<p>Kubernetes API 服务器的主要实现是 kube-apiserver。kube-apiserver 设计上考虑了水平伸缩，也就是说，它可通过部署多个实例进行伸缩。你可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。</p>
<h5 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h5><p>etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。</p>
<p>您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。</p>
<p>要了解 etcd 更深层次的信息，请参考 etcd 文档。</p>
<h5 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h5><p>控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。</p>
<p>调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件&#x2F;软件&#x2F;策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。</p>
<h5 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h5><p>在主节点上运行 控制器 的组件。</p>
<p>从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。</p>
<p>这些控制器包括:</p>
<p>● 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应</p>
<p>● 任务控制器（Job controller）: 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成</p>
<p>● 端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)</p>
<p>● 服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌</p>
<h5 id="cloud-controller-manager"><a href="#cloud-controller-manager" class="headerlink" title="cloud-controller-manager"></a>cloud-controller-manager</h5><p>云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。云控制器管理器允许您链接集群到云提供商的应用编程接口中， 并把和该云平台交互的组件与只和您的集群交互的组件分离开。</p>
<p>cloud-controller-manager 仅运行特定于云平台的控制回路。如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器。</p>
<p>与 kube-controller-manager 类似，cloud-controller-manager 将若干逻辑上独立的 控制回路组合到同一个可执行文件中，供你以同一进程的方式运行。你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。</p>
<p>下面的控制器都包含对云平台驱动的依赖：</p>
<p>● 节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除</p>
<p>● 路由控制器（Route Controller）: 用于在底层云基础架构中设置路由</p>
<p>● 服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器</p>
<h4 id="2、Node-组件"><a href="#2、Node-组件" class="headerlink" title="2、Node 组件"></a>2、Node 组件</h4><p>节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。</p>
<h5 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h5><p>一个在集群中每个节点（node）上运行的代理。它保证容器（containers）都 运行在 Pod 中。</p>
<p>kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。kubelet 不会管理不是由 Kubernetes 创建的容器。</p>
<h5 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h5><p>kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。</p>
<p>kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。</p>
<p>如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。</p>
<h4 id="3、集群安装"><a href="#3、集群安装" class="headerlink" title="3、集群安装"></a>3、集群安装</h4><p>使用脚本一键部署：<a href="https://github.com/lework/kainstall">https://github.com/lework/kainstall</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# wget https://cdn.jsdelivr.net/gh/lework/kainstall@master/kainstall-ubuntu.sh</span><br><span class="line"></span><br><span class="line">--2021-11-17 02:56:26--  https://cdn.jsdelivr.net/gh/lework/kainstall@master/kainstall-ubuntu.sh</span><br><span class="line"></span><br><span class="line">Resolving cdn.jsdelivr.net (cdn.jsdelivr.net)... 117.12.41.16, 2408:8726:7000:5::10</span><br><span class="line"></span><br><span class="line">Connecting to cdn.jsdelivr.net (cdn.jsdelivr.net)|117.12.41.16|:443... connected.</span><br><span class="line"></span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line"></span><br><span class="line">Length: 128359 (125K) [application/x-sh]</span><br><span class="line"></span><br><span class="line">Saving to: ‘kainstall-ubuntu.sh’</span><br><span class="line"></span><br><span class="line">kainstall-ubuntu.sh          100%[========================================================================&gt;] 125.35K  --.-KB/s   in 0.006s  </span><br><span class="line"></span><br><span class="line">2021-11-17 02:56:26 (19.2 MB/s) - ‘kainstall-ubuntu.sh’ saved [128359/128359]</span><br><span class="line"></span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line">root@hello:~# chmod +x kainstall-ubuntu.sh</span><br><span class="line"></span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line">root@hello:~#  kainstall-ubuntu.sh init \</span><br><span class="line"></span><br><span class="line">&gt;  --master 192.168.1.100,192.168.1.101,192.168.1.102 \</span><br><span class="line"></span><br><span class="line">&gt;  --worker 192.168.1.103,192.168.1.104,192.168.1.105,192.168.1.106 \</span><br><span class="line"></span><br><span class="line">&gt;  --user root \</span><br><span class="line"></span><br><span class="line">&gt;  --password 123456 \</span><br><span class="line"></span><br><span class="line">&gt;  --version 1.20.6</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p>可参考：</p>
<p>kubeadm 手动安装高可用：<a href="https://blog.csdn.net/qq/_33921750/article/details/110298506">https://blog.csdn.net/qq\_33921750/article/details/110298506</a></p>
<p>kubeadm 手动安装单master集群：<a href="https://blog.csdn.net/qq/_33921750/article/details/103613599">https://blog.csdn.net/qq\_33921750/article/details/103613599</a></p>
<h4 id="4、部署dashboard"><a href="#4、部署dashboard" class="headerlink" title="4、部署dashboard"></a>4、部署dashboard</h4><p>参考：<a href="https://blog.csdn.net/qq/_33921750/article/details/121026799">https://blog.csdn.net/qq\_33921750/article/details/121026799</a></p>
<h4 id="5、命令自动补全（可选）"><a href="#5、命令自动补全（可选）" class="headerlink" title="5、命令自动补全（可选）"></a>5、命令自动补全（可选）</h4><p>参考：<a href="https://blog.csdn.net/qq/_33921750/article/details/121173706">https://blog.csdn.net/qq\_33921750/article/details/121173706</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3669d712337f4951bde355838cbe968d~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>55篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d5cd432fa11d48ffa9e8ac3478bd8a67~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Exchangis搭建安装</title>
    <url>/2021/12/30/2021-12-30-Exchangis%E6%90%AD%E5%BB%BA%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p><strong>项目简介</strong></p>
<p>Exchangis是一个轻量级的、高扩展性的数据交换平台，支持对结构化及无结构化的异构数据源之间的数据传输，在应用层上具有数据权限管控、节点服务高可用和多租户资源隔离等业务特性，而在数据层上又具有传输架构多样化、模块插件化和组件低耦合等架构特点。</p>
<p>Exchangis的传输交换能力依赖于其底层聚合的传输引擎，其顶层对各类数据源定义统一的参数模型，每种传输引擎对参数模型进行映射配置，转化为引擎的输入模型。每聚合一种引擎，都将增加Exchangis一类特性，对某类引擎的特性强化，都是对Exchangis特性的完善。默认聚合以及强化Alibaba的DataX传输引擎。</p>
<p><strong>核心特点</strong></p>
<p>数据源管理</p>
<p>以绑定项目的方式共享自己的数据源；</p>
<p>设置数据源对外权限，控制数据的流入和流出。</p>
<p><strong>多传输引擎支持</strong></p>
<p>传输引擎可横向扩展；</p>
<p>当前版本完整聚合了离线批量引擎DataX、部分聚合了大数据批量导数引擎SQOOP</p>
<p><strong>近实时任务管控</strong></p>
<p>快速抓取传输任务日志以及传输速率等信息，实时关闭任务；</p>
<p>可根据带宽状况对任务进行动态限流</p>
<p><strong>支持无结构化传输</strong></p>
<p>DataX框架改造，单独构建二进制流快速通道，适用于无数据转换的纯数据同步场景。</p>
<p><strong>任务状态自检</strong></p>
<p>监控长时间运行的任务和状态异常任务，及时释放占用的资源并发出告警。</p>
<p><strong>架构设计</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1d0966aca5e64bd880036b4efa5bc2b3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>环境准备</strong></p>
<p><strong>基础软件安装</strong></p>
<p>MySQL (5.5+) 必选，对应客户端可以选装, Linux服务上若安装mysql的客户端可以通过部署脚本快速初始化数据库</p>
<p>JDK (1.8.0_141) 必选</p>
<p>Maven (3.6.1+) 必选</p>
<p>SQOOP (1.4.6) 可选，如果想要SQOOP做传输引擎，可以安装SQOOP，SQOOP安装依赖Hive,Hadoop环境，这里就不展开来讲</p>
<p>Python (2.x) 可选，主要用于调度执行底层DataX的启动脚本，默认的方式是以Java子进程方式执行DataX，用户可以选择以Python方式来做自定义的改造</p>
<p><strong>mysql 数据库安装</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# mkdir mysql</span><br><span class="line">[root@localhost ~]# cd mysql</span><br><span class="line">[root@localhost mysql]# wget https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.35-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line">[root@localhost mysql]# tar xvf mysql-5.7.35-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line">[root@localhost mysql]# yum install ./*.rpm</span><br><span class="line">[root@localhost mysql]# systemctl start mysqld.service</span><br><span class="line">[root@localhost mysql]#</span><br><span class="line">[root@localhost mysql]# systemctl enable mysqld.service</span><br><span class="line">[root@localhost mysql]#</span><br><span class="line">[root@localhost mysql]#</span><br><span class="line">[root@localhost mysql]# sudo grep &#x27;temporary password&#x27; /var/log/mysqld.log</span><br><span class="line">2021-10-25T06:57:46.569037Z 1 [Note] A temporary password is generated for root@localhost: (l5aFfIxfNuu</span><br><span class="line">[root@localhost mysql]#</span><br><span class="line">[root@localhost mysql]#</span><br><span class="line">[root@localhost mysql]#</span><br><span class="line">[root@localhost mysql]# mysql -u root -p</span><br><span class="line">Enter password:</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 3</span><br><span class="line">Server version: 5.7.35 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2021, Oracle and/or its affiliates.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">ALTER USER <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED WITH mysql_native_password BY <span class="string">&#x27;Cby123..&#x27;</span>;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">mysql&gt;</span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">mysql&gt; use mysql;</span></span><br><span class="line">Reading table information for completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup with -A</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Database changed</span><br><span class="line"><span class="meta prompt_">mysql&gt;</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">mysql&gt;</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">update user <span class="built_in">set</span> host=<span class="string">&#x27;%&#x27;</span> <span class="built_in">where</span> user =<span class="string">&#x27;root&#x27;</span>;</span></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"><span class="built_in">set</span> global validate_password_policy=0;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"><span class="built_in">set</span> global validate_password_mixed_case_count=0;</span></span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"><span class="built_in">set</span> global validate_password_number_count=3;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"><span class="built_in">set</span> global validate_password_special_char_count=0;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"><span class="built_in">set</span> global validate_password_length=3;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>jdk安装</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# mkdir jdk</span><br><span class="line">[root@localhost ~]# cd jdk</span><br><span class="line">[root@localhost jdk]#</span><br><span class="line">[root@localhost jdk]# tar xf jdk-8u141-linux-x64.tar.gz</span><br><span class="line">[root@localhost jdk]#</span><br><span class="line">[root@localhost jdk]# ll</span><br><span class="line">total 181172</span><br><span class="line">drwxr-xr-x. 8   10  143       255 Jul 12  2017 jdk1.8.0_141</span><br><span class="line">-rw-r--r--. 1 root root 185516505 Jul 25  2017 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">[root@localhost jdk]#</span><br><span class="line">[root@localhost jdk]# vim /etc/profile</span><br><span class="line">[root@localhost jdk]#  tail -n 3 /etc/profile</span><br><span class="line">export JAVA_HOME=/root/jdk/jdk1.8.0_141/</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">[root@localhost jdk]#</span><br><span class="line">[root@localhost jdk]# source /etc/profile</span><br><span class="line">[root@localhost jdk]# java -version</span><br><span class="line">java version &quot;1.8.0_141&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_141-b15)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode)</span><br><span class="line">[root@localhost jdk]#</span><br></pre></td></tr></table></figure>

<p>maven 安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]#</span><br><span class="line">[root@localhost ~]# mkdir maven</span><br><span class="line">[root@localhost ~]# cd maven</span><br><span class="line">[root@localhost maven]# wget https://archive.apache.org/dist/maven/maven-3/3.6.1/binaries/apache-maven-3.6.1-bin.tar.gz</span><br><span class="line">[root@localhost maven]#</span><br><span class="line">[root@localhost maven]# tar xf apache-maven-3.6.1-bin.tar.gz</span><br><span class="line">[root@localhost maven]# ll</span><br><span class="line">total 8924</span><br><span class="line">drwxr-xr-x. 6 root root      99 Oct 25 15:08 apache-maven-3.6.1</span><br><span class="line">-rw-r--r--. 1 root root 9136463 Sep  4  2019 apache-maven-3.6.1-bin.tar.gz</span><br><span class="line">[root@localhost maven]# vim /etc/profile</span><br><span class="line">[root@localhost maven]#</span><br><span class="line">[root@localhost maven]# tail -n 3 /etc/profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export MAVEN_HOME=/root/maven/apache-maven-3.6.1</span><br><span class="line">export PATH=$MAVEN_HOME/bin:$PATH:$HOME/bin</span><br><span class="line">[root@localhost maven]#</span><br><span class="line">[root@localhost maven]# source /etc/profile</span><br><span class="line">[root@localhost maven]# mvn -version</span><br><span class="line">Apache Maven 3.6.1 (d66c9c0b3152b2e69ee9bac180bb8fcc8e6af555; 2019-04-05T03:00:29+08:00)</span><br><span class="line">Maven home: /root/maven/apache-maven-3.6.1</span><br><span class="line">Java version: 1.8.0_141, vendor: Oracle Corporation, runtime: /root/jdk/jdk1.8.0_141/jre</span><br><span class="line">Default locale: en_US, platform encoding: UTF-8</span><br><span class="line">OS name: &quot;linux&quot;, version: &quot;3.10.0-1160.31.1.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;</span><br><span class="line">[root@localhost maven]#</span><br></pre></td></tr></table></figure>

<p>Exchangis安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]#</span><br><span class="line">[root@localhost ~]# mkdir  Exchangis</span><br><span class="line">[root@localhost ~]# cd Exchangis</span><br><span class="line">[root@localhost Exchangis]# wget https://github.com/WeBankFinTech/Exchangis/releases/download/release-0.5.0/wedatasphere-exchangis-0.5.0.RELEASE.tar.gz</span><br><span class="line">[root@localhost Exchangis]# ll</span><br><span class="line">total 552904</span><br><span class="line">-rw-r--r--. 1 root root 566172217 Oct 25 15:14 wedatasphere-exchangis-0.5.0.RELEASE.tar.gz</span><br><span class="line">[root@localhost Exchangis]# tar xf wedatasphere-exchangis-0.5.0.RELEASE.tar.gz</span><br><span class="line">[root@localhost Exchangis]# ll</span><br><span class="line">total 552904</span><br><span class="line">drwxr-xr-x. 6 root root        91 Oct 25 15:14 wedatasphere-exchangis-0.5.0.RELEASE</span><br><span class="line">-rw-r--r--. 1 root root 566172217 Oct 25 15:14 wedatasphere-exchangis-0.5.0.RELEASE.tar.gz</span><br><span class="line">[root@localhost Exchangis]# cd wedatasphere-exchangis-0.5.0.RELEASE</span><br><span class="line">[root@localhost wedatasphere-exchangis-0.5.0.RELEASE]# ll</span><br><span class="line">total 20</span><br><span class="line">drwxrwxrwx. 2 root root   120 Oct 29  2020 bin</span><br><span class="line">drwxrwxrwx. 4 root root    32 May 12  2020 docs</span><br><span class="line">drwxrwxrwx. 4 root root    57 May 12  2020 images</span><br><span class="line">-rwxrwxrwx. 1 root root 11357 Oct 29  2020 LICENSE</span><br><span class="line">drwxr-xr-x. 2 root root   198 Oct 25 15:14 packages</span><br><span class="line">-rwxrwxrwx. 1 root root  4582 Oct 29  2020 README.md</span><br><span class="line">[root@localhost wedatasphere-exchangis-0.5.0.RELEASE]# cd bin/</span><br><span class="line">[root@localhost bin]# ./install.sh</span><br><span class="line">2021-10-25 15:16:19.723 [INFO] (12476) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/bin/../modules].</span><br><span class="line">2021-10-25 15:16:19.728 [INFO] (12476)  ####### Start To Uncompress Packages ######</span><br><span class="line">2021-10-25 15:16:19.730 [INFO] (12476) Uncompressing....</span><br><span class="line">Do you want to decompress this package: [exchangis-eureka_0.5.0.RELEASE_1.tar.gz]? (Y/N)y</span><br><span class="line">2021-10-25 15:16:22.691 [INFO] (12476)  Uncompress package: [exchangis-eureka_0.5.0.RELEASE_1.tar.gz] to modules directory</span><br><span class="line">Do you want to decompress this package: [exchangis-executor_0.5.0.RELEASE_1.tar.gz]? (Y/N)y</span><br><span class="line">2021-10-25 15:16:24.798 [INFO] (12476)  Uncompress package: [exchangis-executor_0.5.0.RELEASE_1.tar.gz] to modules directory</span><br><span class="line">Do you want to decompress this package: [exchangis-gateway_0.5.0.RELEASE_1.tar.gz]? (Y/N)y</span><br><span class="line">2021-10-25 15:16:31.947 [INFO] (12476)  Uncompress package: [exchangis-gateway_0.5.0.RELEASE_1.tar.gz] to modules directory</span><br><span class="line">Do you want to decompress this package: [exchangis-service_0.5.0.RELEASE_1.tar.gz]? (Y/N)y</span><br><span class="line">2021-10-25 15:16:35.029 [INFO] (12476)  Uncompress package: [exchangis-service_0.5.0.RELEASE_1.tar.gz] to modules directory</span><br><span class="line">2021-10-25 15:16:36.537 [INFO] (12476)  ####### Finish To Umcompress Packages ######</span><br><span class="line">Scan modules directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/bin/../modules] to find server under exchangis</span><br><span class="line">2021-10-25 15:16:36.542 [INFO] (12476)  ####### Start To Install Modules ######</span><br><span class="line">2021-10-25 15:16:36.545 [INFO] (12476) Module servers could be installed:</span><br><span class="line"> [exchangis-eureka]  [exchangis-executor]  [exchangis-gateway]  [exchangis-service]</span><br><span class="line">Do you want to confiugre and install [exchangis-eureka]? (Y/N)y</span><br><span class="line">2021-10-25 15:16:37.676 [INFO] (12476)  Install module server: [exchangis-eureka]</span><br><span class="line">2021-10-25 15:16:37.706 [INFO] (12527)  Start to build directory</span><br><span class="line">2021-10-25 15:16:37.709 [INFO] (12527) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-eureka/bin/../logs].</span><br><span class="line">2021-10-25 15:16:37.779 [INFO] (12527) Directory or file: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-eureka/bin/../conf] has been exist</span><br><span class="line">2021-10-25 15:16:37.782 [INFO] (12527) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-eureka/bin/../data].</span><br><span class="line">Do you want to confiugre and install [exchangis-executor]? (Y/N)y</span><br><span class="line">2021-10-25 15:16:38.529 [INFO] (12476)  Install module server: [exchangis-executor]</span><br><span class="line">2021-10-25 15:16:38.558 [INFO] (12565)  Start to build directory</span><br><span class="line">2021-10-25 15:16:38.561 [INFO] (12565) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-executor/bin/../logs].</span><br><span class="line">2021-10-25 15:16:38.596 [INFO] (12565) Directory or file: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-executor/bin/../conf] has been exist</span><br><span class="line">2021-10-25 15:16:38.599 [INFO] (12565) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-executor/bin/../data].</span><br><span class="line">Do you want to confiugre and install [exchangis-gateway]? (Y/N)y</span><br><span class="line">2021-10-25 15:16:39.291 [INFO] (12476)  Install module server: [exchangis-gateway]</span><br><span class="line">2021-10-25 15:16:39.317 [INFO] (12603)  Start to build directory</span><br><span class="line">2021-10-25 15:16:39.320 [INFO] (12603) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-gateway/bin/../logs].</span><br><span class="line">2021-10-25 15:16:39.354 [INFO] (12603) Directory or file: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-gateway/bin/../conf] has been exist</span><br><span class="line">2021-10-25 15:16:39.356 [INFO] (12603) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-gateway/bin/../data].</span><br><span class="line">Do you want to confiugre and install [exchangis-service]? (Y/N)y</span><br><span class="line">2021-10-25 15:16:39.991 [INFO] (12476)  Install module server: [exchangis-service]</span><br><span class="line">2021-10-25 15:16:40.017 [INFO] (12641)  Start to build directory</span><br><span class="line">2021-10-25 15:16:40.020 [INFO] (12641) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-service/bin/../logs].</span><br><span class="line">2021-10-25 15:16:40.056 [INFO] (12641) Directory or file: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-service/bin/../conf] has been exist</span><br><span class="line">2021-10-25 15:16:40.059 [INFO] (12641) Creating directory: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/modules/exchangis-service/bin/../data].</span><br><span class="line">2021-10-25 15:16:40.099 [INFO] (12641)  Scan out mysql command, so begin to initalize the database</span><br><span class="line">Do you want to initalize database with sql: [/root/Exchangis/wedatasphere-exchangis-0.5.0.RELEASE/bin/exchangis-init.sql]? (Y/N)y</span><br><span class="line">Please input the db host(default: 127.0.0.1):</span><br><span class="line">Please input the db port(default: 3306):</span><br><span class="line">Please input the db username(default: root):</span><br><span class="line">Please input the db password(default: ): Cby123..</span><br><span class="line">Please input the db name(default: exchangis)</span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">2021-10-25 15:16:55.665 [INFO] (12476)  ####### Finish To Install Modules ######</span><br><span class="line">[root@localhost bin]#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@localhost bin]# ./start-all.sh</span><br><span class="line">2021-10-25 15:18:22.181 [INFO] (12691)  Try To Start Modules In Order</span><br><span class="line">2021-10-25 15:18:22.189 [INFO] (12699)  ####### Begin To Start Module: [exchangis-eureka] ######</span><br><span class="line">2021-10-25 15:18:22.199 [INFO] (12707) load environment variables</span><br><span class="line">2021-10-25 15:18:22.717 [INFO] (12707) /root/jdk/jdk1.8.0_141//bin/java</span><br><span class="line">2021-10-25 15:18:22.721 [INFO] (12707) Waiting EXCHANGIS-EUREKA to start complete ...</span><br><span class="line">2021-10-25 15:18:22.994 [INFO] (12707) EXCHANGIS-EUREKA start success</span><br><span class="line">2021-10-25 15:18:23.003 [INFO] (13009)  ####### Begin To Start Module: [exchangis-gateway] ######</span><br><span class="line">2021-10-25 15:18:23.012 [INFO] (13017) load environment variables</span><br><span class="line">2021-10-25 15:18:23.493 [INFO] (13017) /root/jdk/jdk1.8.0_141//bin/java</span><br><span class="line">2021-10-25 15:18:23.497 [INFO] (13017) Waiting EXCHANGIS-GATEWAY to start complete ...</span><br><span class="line">2021-10-25 15:18:24.081 [INFO] (13017) EXCHANGIS-GATEWAY start success</span><br><span class="line">2021-10-25 15:18:24.091 [INFO] (13321)  ####### Begin To Start Module: [exchangis-service] ######</span><br><span class="line">2021-10-25 15:18:24.099 [INFO] (13329) load environment variables</span><br><span class="line">2021-10-25 15:18:24.933 [INFO] (13329) /root/jdk/jdk1.8.0_141//bin/java</span><br><span class="line">2021-10-25 15:18:24.936 [INFO] (13329) Waiting EXCHANGIS-SERVICE to start complete ...</span><br><span class="line">2021-10-25 15:18:26.398 [INFO] (13329) EXCHANGIS-SERVICE start success</span><br><span class="line">2021-10-25 15:18:26.410 [INFO] (13634)  ####### Begin To Start Module: [exchangis-executor] ######</span><br><span class="line">2021-10-25 15:18:26.423 [INFO] (13643) load environment variables</span><br><span class="line">2021-10-25 15:18:27.677 [INFO] (13643) /root/jdk/jdk1.8.0_141//bin/java</span><br><span class="line">2021-10-25 15:18:27.681 [INFO] (13643) Waiting EXCHANGIS-EXECUTOR to start complete ...</span><br><span class="line">2021-10-25 15:18:28.441 [INFO] (13643) EXCHANGIS-EXECUTOR start success</span><br><span class="line">[root@localhost bin]#</span><br></pre></td></tr></table></figure>

<p>**登陆访问<br>**  </p>
<p>注册中心：<a href="http://192.168.1.161:8500/">http://192.168.1.161:8500/</a></p>
<p>访问地址：<a href="http://192.168.1.161:9503/">http://192.168.1.161:9503/</a></p>
<p>账号：admin</p>
<p>密码：admin</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b542ed0cbce34d6e805da63b5ad59b8a~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>43篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6ead02601b9342759564716f374b20a1~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Kubernetes（k8s）集群安装JupyterHub以及Lab</title>
    <url>/2021/12/30/2021-12-30-Kubernetes%EF%BC%88k8s%EF%BC%89%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85JupyterHub%E4%BB%A5%E5%8F%8ALab/</url>
    <content><![CDATA[<p><strong>背景</strong></p>
<p>JupyterHub 为用户组带来了笔记本的强大功能。它使用户能够访问计算环境和资源，而不会给用户带来安装和维护任务的负担。用户——包括学生、研究人员和数据科学家——可以在他们自己的工作空间中完成他们的工作，共享资源可以由系统管理员有效管理。</p>
<p>JupyterHub 在云端或您自己的硬件上运行，可以为世界上的任何用户提供预先配置的数据科学环境。它是可定制和可扩展的，适用于小型和大型团队、学术课程和大型基础设施。</p>
<p><strong>第一步</strong>、参考：<a href="https://cloud.tencent.com/developer/article/1902519">https://cloud.tencent.com/developer/article/1902519</a> 创建动态挂载存储</p>
<p><strong>第二步</strong>、安装helm</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -</span><br><span class="line">root@hello:~# sudo apt-get install apt-transport-https --yes</span><br><span class="line">root@hello:~# echo &quot;deb https://baltocdn.com/helm/stable/debian/ all main&quot; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list</span><br><span class="line">root@hello:~# sudo apt-get update</span><br><span class="line">root@hello:~# sudo apt-get install helm</span><br></pre></td></tr></table></figure>

<p><strong>第三步</strong>、导入镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker load -i pause-3.5.tar</span><br><span class="line">root@hello:~# docker load -i kube-scheduler.tar</span><br></pre></td></tr></table></figure>

<p><strong>第四步</strong>、安装jupyterhub</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">helm repo update</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">helm upgrade --cleanup-on-fail \</span><br><span class="line">  --install ju jupyterhub/jupyterhub \</span><br><span class="line">  --namespace ju \</span><br><span class="line">  --create-namespace \</span><br><span class="line">  --version=1.2.0 \</span><br><span class="line">  --values config.yaml</span><br></pre></td></tr></table></figure>

<p>注：此文件可以自定义内容，具体看注释，如下开启lab功能</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# vim config.yaml</span><br><span class="line">root@hello:~# cat config.yaml </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">This file can update the JupyterHub Helm chart<span class="string">&#x27;s default configuration values.</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">#</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"># For reference see the configuration reference and default values, but make</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"># sure to refer to the Helm chart version of interest to you!</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">#</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"># Introduction to YAML:     https://www.youtube.com/watch?v=cdLNKUoMc6c</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"># Chart config reference:   https://zero-to-jupyterhub.readthedocs.io/en/stable/resources/reference.html</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"># Chart default values:     https://github.com/jupyterhub/zero-to-jupyterhub-k8s/blob/HEAD/jupyterhub/values.yaml</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"># Available chart versions: https://jupyterhub.github.io/helm-chart/</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">#</span></span></span><br><span class="line">singleuser:</span><br><span class="line">  defaultUrl: &quot;/lab&quot;</span><br><span class="line">  extraEnv:</span><br><span class="line">    JUPYTERHUB_SINGLEUSER_APP: &quot;jupyter_server.serverapp.ServerApp&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">singleuser:</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"> defaultUrl: &quot;/lab&quot;</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"> extraEnv:</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">   JUPYTERHUB_SINGLEUSER_APP: &quot;notebook.notebookapp.NotebookApp&quot;</span></span></span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>第五步、修改svc为nodeport</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl get svc  -A</span><br><span class="line">NAMESPACE     NAME                        TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">default       kubernetes                  ClusterIP      10.68.0.1       &lt;none&gt;        443/TCP                  16h</span><br><span class="line">ju            hub                         ClusterIP      10.68.60.16     &lt;none&gt;        8081/TCP                 114s</span><br><span class="line">ju            proxy-api                   ClusterIP      10.68.239.54    &lt;none&gt;        8001/TCP                 114s</span><br><span class="line">ju            proxy-public                LoadBalancer   10.68.62.47     &lt;pending&gt;     80:32070/TCP             114s</span><br><span class="line">kube-system   dashboard-metrics-scraper   ClusterIP      10.68.244.241   &lt;none&gt;        8000/TCP                 16h</span><br><span class="line">kube-system   kube-dns                    ClusterIP      10.68.0.2       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   16h</span><br><span class="line">kube-system   kube-dns-upstream           ClusterIP      10.68.221.104   &lt;none&gt;        53/UDP,53/TCP            16h</span><br><span class="line">kube-system   kubernetes-dashboard        NodePort       10.68.206.196   &lt;none&gt;        443:32143/TCP            16h</span><br><span class="line">kube-system   metrics-server              ClusterIP      10.68.1.149     &lt;none&gt;        443/TCP                  16h</span><br><span class="line">kube-system   node-local-dns              ClusterIP      None            &lt;none&gt;        9253/TCP                 16h</span><br><span class="line">root@hello:~# kubectl edit svc proxy-public -n ju</span><br><span class="line">service/proxy-public edited</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# kubectl get svc  -A</span><br><span class="line">NAMESPACE     NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">default       kubernetes                  ClusterIP   10.68.0.1       &lt;none&gt;        443/TCP                  16h</span><br><span class="line">ju            hub                         ClusterIP   10.68.60.16     &lt;none&gt;        8081/TCP                 2m19s</span><br><span class="line">ju            proxy-api                   ClusterIP   10.68.239.54    &lt;none&gt;        8001/TCP                 2m19s</span><br><span class="line">ju            proxy-public                NodePort    10.68.62.47     &lt;none&gt;        80:32070/TCP             2m19s</span><br><span class="line">kube-system   dashboard-metrics-scraper   ClusterIP   10.68.244.241   &lt;none&gt;        8000/TCP                 16h</span><br><span class="line">kube-system   kube-dns                    ClusterIP   10.68.0.2       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   16h</span><br><span class="line">kube-system   kube-dns-upstream           ClusterIP   10.68.221.104   &lt;none&gt;        53/UDP,53/TCP            16h</span><br><span class="line">kube-system   kubernetes-dashboard        NodePort    10.68.206.196   &lt;none&gt;        443:32143/TCP            16h</span><br><span class="line">kube-system   metrics-server              ClusterIP   10.68.1.149     &lt;none&gt;        443/TCP                  16h</span><br><span class="line">kube-system   node-local-dns              ClusterIP   None            &lt;none&gt;        9253/TCP                 16h</span><br><span class="line">root@hello:~#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://mmbiz.qpic.cn/mmbiz_png/KYOkQ49zfMf4BicLuGydibIKb2tftJtCBW5lzdULRlqlmrzDgOkbMIByevhzh2dRtLabALJicjqtmtm2GYzQkpwXw/640?wx_fmt=png"></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/KYOkQ49zfMf4BicLuGydibIKb2tftJtCBWcphA0lCzZVZJL2X5piaXcMJpMNoh0yPba7Ric8qE1btuQK7Jlam7TNkA/640?wx_fmt=png"></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/KYOkQ49zfMdA6AqIqjlTKC2oKfCKRNFLaTibVZXQ5hq0VLsrfDAn1pLLCNneOVrpCIF2JXy5U9HlU6H5tRgbB4g/640?wx_fmt=jpeg">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>KubeSphere 高可用集群搭建并启用所有插件</title>
    <url>/2021/12/30/2021-12-30-KubeSphere_%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E5%B9%B6%E5%90%AF%E7%94%A8%E6%89%80%E6%9C%89%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p><strong>介绍</strong></p>
<p>大多数情况下，单主节点集群大致足以供开发和测试环境使用。但是，对于生产环境，您需要考虑集群的高可用性。如果关键组件（例如 kube-apiserver、kube-scheduler 和 kube-controller-manager）都在同一个主节点上运行，一旦主节点宕机，Kubernetes 和 KubeSphere 都将不可用。因此，您需要为多个主节点配置负载均衡器，以创建高可用集群。您可以使用任意云负载均衡器或者任意硬件负载均衡器（例如 F5）。此外，也可以使用 Keepalived 和 HAproxy，或者 Nginx 来创建高可用集群。</p>
<p><strong>架构</strong></p>
<p>在您开始操作前，请确保准备了 6 台 Linux 机器，其中 3 台充当主节点，另外 3 台充当工作节点。下图展示了这些机器的详情，包括它们的私有 IP 地址和角色。</p>
<p><strong>配置负载均衡器</strong></p>
<p>您必须在您的环境中创建一个负载均衡器来监听（在某些云平台也称作监听器）关键端口。建议监听下表中的端口。</p>
<p>服务  协议  端口</p>
<p>apiserver TCP 6443</p>
<p>ks-console  TCP 30880</p>
<p>http  TCP 80</p>
<p>https TCP 443</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f6d53d4c347947de82600070f4a2474c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>配置免密</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# ssh-keygen</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.10</span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.11  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.12  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.13  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.14  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.15  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.16  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.51  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.52  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.53  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.54  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.55  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.56  </span><br><span class="line">root@hello:~# ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.57</span><br></pre></td></tr></table></figure>

<p><strong>下载 KubeKey</strong></p>
<p>Kubekey 是新一代安装程序，可以简单、快速和灵活地安装 Kubernetes 和 KubeSphere。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@cby:~# export KKZONE=cn</span><br><span class="line">root@cby:~# curl -sfL https://get-kk.kubesphere.io | VERSION=v1.2.0 sh -</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading kubekey v1.2.0 from https://kubernetes.pek3b.qingstor.com/kubekey/releases/download/v1.2.0/kubekey-v1.2.0-linux-amd64.tar.gz ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Kubekey v1.2.0 Download Complete!</span><br></pre></td></tr></table></figure>

<p><strong>为 kk 添加可执行权限</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@cby:~# chmod +x kk</span><br><span class="line">root@cby:~# ./kk create config --with-kubesphere v3.2.0 --with-kubernetes v1.22.1</span><br></pre></td></tr></table></figure>

<p><strong>部署 KubeSphere 和 Kubernetes</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@cby:~# vim config-sample.yaml</span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# cat config-sample.yaml</span><br><span class="line">apiVersion: kubekey.kubesphere.io/v1alpha1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: sample</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - &#123;name: master1, address: 192.168.1.10, internalAddress: 192.168.1.10, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: master2, address: 192.168.1.11, internalAddress: 192.168.1.11, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: master3, address: 192.168.1.12, internalAddress: 192.168.1.12, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node1, address: 192.168.1.13, internalAddress: 192.168.1.13, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node2, address: 192.168.1.14, internalAddress: 192.168.1.14, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node3, address: 192.168.1.15, internalAddress: 192.168.1.15, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node4, address: 192.168.1.16, internalAddress: 192.168.1.16, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node5, address: 192.168.1.51, internalAddress: 192.168.1.51, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node6, address: 192.168.1.52, internalAddress: 192.168.1.52, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node7, address: 192.168.1.53, internalAddress: 192.168.1.53, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node8, address: 192.168.1.54, internalAddress: 192.168.1.54, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node9, address: 192.168.1.55, internalAddress: 192.168.1.55, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node10, address: 192.168.1.56, internalAddress: 192.168.1.56, user: root, password: Cby123..&#125;</span><br><span class="line">  - &#123;name: node11, address: 192.168.1.57, internalAddress: 192.168.1.57, user: root, password: Cby123..&#125;</span><br><span class="line">  roleGroups:</span><br><span class="line">    etcd:</span><br><span class="line">    - master1</span><br><span class="line">    - master2</span><br><span class="line">    - master3</span><br><span class="line">    master:</span><br><span class="line">    - master1</span><br><span class="line">    - master2</span><br><span class="line">    - master3</span><br><span class="line">    worker:</span><br><span class="line">    - node1</span><br><span class="line">    - node2</span><br><span class="line">    - node3</span><br><span class="line">    - node4</span><br><span class="line">    - node5</span><br><span class="line">    - node6</span><br><span class="line">    - node7</span><br><span class="line">    - node8</span><br><span class="line">    - node9</span><br><span class="line">    - node10</span><br><span class="line">    - node11</span><br><span class="line">  controlPlaneEndpoint:</span><br><span class="line">    ##Internal loadbalancer for apiservers</span><br><span class="line">    #internalLoadbalancer: haproxy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    domain: lb.kubesphere.local</span><br><span class="line">    address: &quot;192.168.1.20&quot;</span><br><span class="line">    port: 6443</span><br><span class="line">  kubernetes:</span><br><span class="line">    version: v1.22.1</span><br><span class="line">    clusterName: cluster.local</span><br><span class="line">  network:</span><br><span class="line">    plugin: calico</span><br><span class="line">    kubePodsCIDR: 10.233.64.0/18</span><br><span class="line">    kubeServiceCIDR: 10.233.0.0/18</span><br><span class="line">  registry:</span><br><span class="line">    registryMirrors: []</span><br><span class="line">    insecureRegistries: []</span><br><span class="line">  addons: []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: installer.kubesphere.io/v1alpha1</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  name: ks-installer</span><br><span class="line">  namespace: kubesphere-system</span><br><span class="line">  labels:</span><br><span class="line">    version: v3.2.0</span><br><span class="line">spec:</span><br><span class="line">  persistence:</span><br><span class="line">    storageClass: &quot;&quot;</span><br><span class="line">  authentication:</span><br><span class="line">    jwtSecret: &quot;&quot;</span><br><span class="line">  local_registry: &quot;&quot;</span><br><span class="line">  # dev_tag: &quot;&quot;</span><br><span class="line">  etcd:</span><br><span class="line">    monitoring: false</span><br><span class="line">    endpointIps: localhost</span><br><span class="line">    port: 2379</span><br><span class="line">    tlsEnable: true</span><br><span class="line">  common:</span><br><span class="line">    core:</span><br><span class="line">      console:</span><br><span class="line">        enableMultiLogin: true</span><br><span class="line">        port: 30880</span><br><span class="line">        type: NodePort</span><br><span class="line">    # apiserver:</span><br><span class="line">    #  resources: &#123;&#125;</span><br><span class="line">    # controllerManager:</span><br><span class="line">    #  resources: &#123;&#125;</span><br><span class="line">    redis:</span><br><span class="line">      enabled: false</span><br><span class="line">      volumeSize: 2Gi</span><br><span class="line">    openldap:</span><br><span class="line">      enabled: false</span><br><span class="line">      volumeSize: 2Gi</span><br><span class="line">    minio:</span><br><span class="line">      volumeSize: 20Gi</span><br><span class="line">    monitoring:</span><br><span class="line">      # type: external</span><br><span class="line">      endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090</span><br><span class="line">      GPUMonitoring:</span><br><span class="line">        enabled: false</span><br><span class="line">    gpu:</span><br><span class="line">      kinds:        </span><br><span class="line">      - resourceName: &quot;nvidia.com/gpu&quot;</span><br><span class="line">        resourceType: &quot;GPU&quot;</span><br><span class="line">        default: true</span><br><span class="line">    es:</span><br><span class="line">      # master:</span><br><span class="line">      #   volumeSize: 4Gi</span><br><span class="line">      #   replicas: 1</span><br><span class="line">      #   resources: &#123;&#125;</span><br><span class="line">      # data:</span><br><span class="line">      #   volumeSize: 20Gi</span><br><span class="line">      #   replicas: 1</span><br><span class="line">      #   resources: &#123;&#125;</span><br><span class="line">      logMaxAge: 7</span><br><span class="line">      elkPrefix: logstash</span><br><span class="line">      basicAuth:</span><br><span class="line">        enabled: false</span><br><span class="line">        username: &quot;&quot;</span><br><span class="line">        password: &quot;&quot;</span><br><span class="line">      externalElasticsearchUrl: &quot;&quot;</span><br><span class="line">      externalElasticsearchPort: &quot;&quot;</span><br><span class="line">  alerting:</span><br><span class="line">    enabled: false</span><br><span class="line">    # thanosruler:</span><br><span class="line">    #   replicas: 1</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">  auditing:</span><br><span class="line">    enabled: false</span><br><span class="line">    # operator:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # webhook:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">  devops:</span><br><span class="line">    enabled: false</span><br><span class="line">    jenkinsMemoryLim: 2Gi</span><br><span class="line">    jenkinsMemoryReq: 1500Mi</span><br><span class="line">    jenkinsVolumeSize: 8Gi</span><br><span class="line">    jenkinsJavaOpts_Xms: 512m</span><br><span class="line">    jenkinsJavaOpts_Xmx: 512m</span><br><span class="line">    jenkinsJavaOpts_MaxRAM: 2g</span><br><span class="line">  events:</span><br><span class="line">    enabled: false</span><br><span class="line">    # operator:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # exporter:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # ruler:</span><br><span class="line">    #   enabled: false</span><br><span class="line">    #   replicas: 2</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">  logging:</span><br><span class="line">    enabled: false</span><br><span class="line">    containerruntime: docker</span><br><span class="line">    logsidecar:</span><br><span class="line">      enabled: false</span><br><span class="line">      replicas: 2</span><br><span class="line">      # resources: &#123;&#125;</span><br><span class="line">  metrics_server:</span><br><span class="line">    enabled: false</span><br><span class="line">  monitoring:</span><br><span class="line">    storageClass: &quot;&quot;</span><br><span class="line">    # kube_rbac_proxy:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # kube_state_metrics:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # prometheus:</span><br><span class="line">    #   replicas: 1</span><br><span class="line">    #   volumeSize: 20Gi</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    #   operator:</span><br><span class="line">    #     resources: &#123;&#125;</span><br><span class="line">    #   adapter:</span><br><span class="line">    #     resources: &#123;&#125;</span><br><span class="line">    # node_exporter:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # alertmanager:</span><br><span class="line">    #   replicas: 1</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # notification_manager:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    #   operator:</span><br><span class="line">    #     resources: &#123;&#125;</span><br><span class="line">    #   proxy:</span><br><span class="line">    #     resources: &#123;&#125;</span><br><span class="line">    gpu:</span><br><span class="line">      nvidia_dcgm_exporter:</span><br><span class="line">        enabled: false</span><br><span class="line">        # resources: &#123;&#125;</span><br><span class="line">  multicluster:</span><br><span class="line">    clusterRole: none </span><br><span class="line">  network:</span><br><span class="line">    networkpolicy:</span><br><span class="line">      enabled: false</span><br><span class="line">    ippool:</span><br><span class="line">      type: none</span><br><span class="line">    topology:</span><br><span class="line">      type: none</span><br><span class="line">  openpitrix:</span><br><span class="line">    store:</span><br><span class="line">      enabled: false</span><br><span class="line">  servicemesh:</span><br><span class="line">    enabled: false</span><br><span class="line">  kubeedge:</span><br><span class="line">    enabled: false  </span><br><span class="line">    cloudCore:</span><br><span class="line">      nodeSelector: &#123;&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;&#125;</span><br><span class="line">      tolerations: []</span><br><span class="line">      cloudhubPort: &quot;10000&quot;</span><br><span class="line">      cloudhubQuicPort: &quot;10001&quot;</span><br><span class="line">      cloudhubHttpsPort: &quot;10002&quot;</span><br><span class="line">      cloudstreamPort: &quot;10003&quot;</span><br><span class="line">      tunnelPort: &quot;10004&quot;</span><br><span class="line">      cloudHub:</span><br><span class="line">        advertiseAddress:</span><br><span class="line">          - &quot;&quot;</span><br><span class="line">        nodeLimit: &quot;100&quot;</span><br><span class="line">      service:</span><br><span class="line">        cloudhubNodePort: &quot;30000&quot;</span><br><span class="line">        cloudhubQuicNodePort: &quot;30001&quot;</span><br><span class="line">        cloudhubHttpsNodePort: &quot;30002&quot;</span><br><span class="line">        cloudstreamNodePort: &quot;30003&quot;</span><br><span class="line">        tunnelNodePort: &quot;30004&quot;</span><br><span class="line">    edgeWatcher:</span><br><span class="line">      nodeSelector: &#123;&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;&#125;</span><br><span class="line">      tolerations: []</span><br><span class="line">      edgeWatcherAgent:</span><br><span class="line">        nodeSelector: &#123;&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;&#125;</span><br><span class="line">        tolerations: []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~#</span><br></pre></td></tr></table></figure>

<p><strong>若是haproxy配置如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">frontend kube-apiserver</span><br><span class="line">  bind *:6443</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  default_backend kube-apiserver</span><br><span class="line"></span><br><span class="line">backend kube-apiserver</span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    option tcp-check</span><br><span class="line">    balance roundrobin</span><br><span class="line">    default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line">    server kube-apiserver-1 192.168.1.10:6443 check</span><br><span class="line">    server kube-apiserver-2 192.168.1.11:6443 check</span><br><span class="line">    server kube-apiserver-3 192.168.1.12:6443 check </span><br></pre></td></tr></table></figure>

<p><strong>安装所需环境</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# bash -x 1.sh </span><br><span class="line">root@hello:~# cat 1.sh</span><br><span class="line">ssh root@192.168.1.10 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.11 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.12 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.13 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.14 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.15 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.16 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.51 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.52 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.53 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.54 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.55 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.56 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br><span class="line">ssh root@192.168.1.57 &quot;apt update &amp;&amp; apt install sudo curl openssl ebtables socat ipset conntrack nfs-common -y&quot;</span><br></pre></td></tr></table></figure>

<p><strong>开始安装</strong></p>
<p><strong>配置完成后，您可以执行以下命令来开始安装：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# ./kk create cluster -f config-sample.yaml</span><br><span class="line">+---------+------+------+---------+----------+-------+-------+-----------+--------+------------+-------------+------------------+--------------+</span><br><span class="line">| name    | sudo | curl | openssl | ebtables | socat | ipset | conntrack | docker | nfs client | ceph client | glusterfs client | time         |</span><br><span class="line">+---------+------+------+---------+----------+-------+-------+-----------+--------+------------+-------------+------------------+--------------+</span><br><span class="line">| node3   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| node1   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| node4   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| node8   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| node11  | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| master1 | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:00 |</span><br><span class="line">| node5   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:00 |</span><br><span class="line">| master2 | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:00 |</span><br><span class="line">| node2   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| node7   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:00 |</span><br><span class="line">| master3 | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| node6   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| node9   | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">| node10  | y    | y    | y       | y        | y     | y     | y         |        | y          |             |                  | UTC 13:26:01 |</span><br><span class="line">+---------+------+------+---------+----------+-------+-------+-----------+--------+------------+-------------+------------------+--------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">This is a simple check of your environment.</span><br><span class="line">Before installation, you should ensure that your machines meet all requirements specified at</span><br><span class="line">https://github.com/kubesphere/kubekey#requirements-and-recommendations</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Continue this installation? [yes/no]: yes</span><br><span class="line">INFO[13:26:06 UTC] Downloading Installation Files              </span><br><span class="line">INFO[13:26:06 UTC] Downloading kubeadm ...                      </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---略---</span><br></pre></td></tr></table></figure>

<p><strong>验证安装</strong></p>
<p><strong>运行以下命令查看安装日志。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@cby:~# kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**************************************************</span><br><span class="line">Collecting installation results ...</span><br><span class="line">#####################################################</span><br><span class="line">###              Welcome to KubeSphere!           ###</span><br><span class="line">#####################################################</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Console: http://192.168.1.10:30880</span><br><span class="line">Account: admin</span><br><span class="line">Password: P@88w0rd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES：</span><br><span class="line">  1. After you log into the console, please check the</span><br><span class="line">     monitoring status of service components in</span><br><span class="line">     &quot;Cluster Management&quot;. If any service is not</span><br><span class="line">     ready, please wait patiently until all components </span><br><span class="line">     are up and running.</span><br><span class="line">  2. Please change the default password after login.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#####################################################</span><br><span class="line">https://kubesphere.io             2021-11-10 10:24:00</span><br><span class="line">#####################################################</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl get node </span><br><span class="line">NAME      STATUS   ROLES                  AGE   VERSION</span><br><span class="line">master1   Ready    control-plane,master   30m   v1.22.1</span><br><span class="line">master2   Ready    control-plane,master   29m   v1.22.1</span><br><span class="line">master3   Ready    control-plane,master   29m   v1.22.1</span><br><span class="line">node1     Ready    worker                 29m   v1.22.1</span><br><span class="line">node10    Ready    worker                 29m   v1.22.1</span><br><span class="line">node11    Ready    worker                 29m   v1.22.1</span><br><span class="line">node2     Ready    worker                 29m   v1.22.1</span><br><span class="line">node3     Ready    worker                 29m   v1.22.1</span><br><span class="line">node4     Ready    worker                 29m   v1.22.1</span><br><span class="line">node5     Ready    worker                 29m   v1.22.1</span><br><span class="line">node6     Ready    worker                 29m   v1.22.1</span><br><span class="line">node7     Ready    worker                 30m   v1.22.1</span><br><span class="line">node8     Ready    worker                 30m   v1.22.1</span><br><span class="line">node9     Ready    worker                 29m   v1.22.1</span><br></pre></td></tr></table></figure>

<p><strong>在安装后启用插件</strong></p>
<p>使用 admin 用户登录控制台。点击左上角的平台管理，然后选择集群管理。</p>
<p>点击 CRD，然后在搜索栏中输入 clusterconfiguration。点击搜索结果查看其详情页。</p>
<p>在自定义资源中，点击 ks-installer 右侧的 ，然后选择编辑 YAML。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/267930fc6cf6476e8770003867ec01d5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: installer.kubesphere.io/v1alpha1</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    kubectl.kubernetes.io/last-applied-configuration: &gt;</span><br><span class="line">      &#123;&quot;apiVersion&quot;:&quot;installer.kubesphere.io/v1alpha1&quot;,&quot;kind&quot;:&quot;ClusterConfiguration&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;version&quot;:&quot;v3.2.0&quot;&#125;,&quot;name&quot;:&quot;ks-installer&quot;,&quot;namespace&quot;:&quot;kubesphere-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;alerting&quot;:&#123;&quot;enabled&quot;:false&#125;,&quot;auditing&quot;:&#123;&quot;enabled&quot;:false&#125;,&quot;authentication&quot;:&#123;&quot;jwtSecret&quot;:&quot;&quot;&#125;,&quot;common&quot;:&#123;&quot;core&quot;:&#123;&quot;console&quot;:&#123;&quot;enableMultiLogin&quot;:true,&quot;port&quot;:30880,&quot;type&quot;:&quot;NodePort&quot;&#125;&#125;,&quot;es&quot;:&#123;&quot;basicAuth&quot;:&#123;&quot;enabled&quot;:false,&quot;password&quot;:&quot;&quot;,&quot;username&quot;:&quot;&quot;&#125;,&quot;elkPrefix&quot;:&quot;logstash&quot;,&quot;externalElasticsearchPort&quot;:&quot;&quot;,&quot;externalElasticsearchUrl&quot;:&quot;&quot;,&quot;logMaxAge&quot;:7&#125;,&quot;gpu&quot;:&#123;&quot;kinds&quot;:[&#123;&quot;default&quot;:true,&quot;resourceName&quot;:&quot;nvidia.com/gpu&quot;,&quot;resourceType&quot;:&quot;GPU&quot;&#125;]&#125;,&quot;minio&quot;:&#123;&quot;volumeSize&quot;:&quot;20Gi&quot;&#125;,&quot;monitoring&quot;:&#123;&quot;GPUMonitoring&quot;:&#123;&quot;enabled&quot;:false&#125;,&quot;endpoint&quot;:&quot;http://prometheus-operated.kubesphere-monitoring-system.svc:9090&quot;&#125;,&quot;openldap&quot;:&#123;&quot;enabled&quot;:false,&quot;volumeSize&quot;:&quot;2Gi&quot;&#125;,&quot;redis&quot;:&#123;&quot;enabled&quot;:false,&quot;volumeSize&quot;:&quot;2Gi&quot;&#125;&#125;,&quot;devops&quot;:&#123;&quot;enabled&quot;:false,&quot;jenkinsJavaOpts_MaxRAM&quot;:&quot;2g&quot;,&quot;jenkinsJavaOpts_Xms&quot;:&quot;512m&quot;,&quot;jenkinsJavaOpts_Xmx&quot;:&quot;512m&quot;,&quot;jenkinsMemoryLim&quot;:&quot;2Gi&quot;,&quot;jenkinsMemoryReq&quot;:&quot;1500Mi&quot;,&quot;jenkinsVolumeSize&quot;:&quot;8Gi&quot;&#125;,&quot;etcd&quot;:&#123;&quot;endpointIps&quot;:&quot;192.168.1.10,192.168.1.11,192.168.1.12&quot;,&quot;monitoring&quot;:false,&quot;port&quot;:2379,&quot;tlsEnable&quot;:true&#125;,&quot;events&quot;:&#123;&quot;enabled&quot;:false&#125;,&quot;kubeedge&quot;:&#123;&quot;cloudCore&quot;:&#123;&quot;cloudHub&quot;:&#123;&quot;advertiseAddress&quot;:[&quot;&quot;],&quot;nodeLimit&quot;:&quot;100&quot;&#125;,&quot;cloudhubHttpsPort&quot;:&quot;10002&quot;,&quot;cloudhubPort&quot;:&quot;10000&quot;,&quot;cloudhubQuicPort&quot;:&quot;10001&quot;,&quot;cloudstreamPort&quot;:&quot;10003&quot;,&quot;nodeSelector&quot;:&#123;&quot;node-role.kubernetes.io/worker&quot;:&quot;&quot;&#125;,&quot;service&quot;:&#123;&quot;cloudhubHttpsNodePort&quot;:&quot;30002&quot;,&quot;cloudhubNodePort&quot;:&quot;30000&quot;,&quot;cloudhubQuicNodePort&quot;:&quot;30001&quot;,&quot;cloudstreamNodePort&quot;:&quot;30003&quot;,&quot;tunnelNodePort&quot;:&quot;30004&quot;&#125;,&quot;tolerations&quot;:[],&quot;tunnelPort&quot;:&quot;10004&quot;&#125;,&quot;edgeWatcher&quot;:&#123;&quot;edgeWatcherAgent&quot;:&#123;&quot;nodeSelector&quot;:&#123;&quot;node-role.kubernetes.io/worker&quot;:&quot;&quot;&#125;,&quot;tolerations&quot;:[]&#125;,&quot;nodeSelector&quot;:&#123;&quot;node-role.kubernetes.io/worker&quot;:&quot;&quot;&#125;,&quot;tolerations&quot;:[]&#125;,&quot;enabled&quot;:false&#125;,&quot;logging&quot;:&#123;&quot;containerruntime&quot;:&quot;docker&quot;,&quot;enabled&quot;:false,&quot;logsidecar&quot;:&#123;&quot;enabled&quot;:false,&quot;replicas&quot;:2&#125;&#125;,&quot;metrics_server&quot;:&#123;&quot;enabled&quot;:false&#125;,&quot;monitoring&quot;:&#123;&quot;gpu&quot;:&#123;&quot;nvidia_dcgm_exporter&quot;:&#123;&quot;enabled&quot;:false&#125;&#125;,&quot;storageClass&quot;:&quot;&quot;&#125;,&quot;multicluster&quot;:&#123;&quot;clusterRole&quot;:&quot;none&quot;&#125;,&quot;network&quot;:&#123;&quot;ippool&quot;:&#123;&quot;type&quot;:&quot;none&quot;&#125;,&quot;networkpolicy&quot;:&#123;&quot;enabled&quot;:false&#125;,&quot;topology&quot;:&#123;&quot;type&quot;:&quot;none&quot;&#125;&#125;,&quot;openpitrix&quot;:&#123;&quot;store&quot;:&#123;&quot;enabled&quot;:false&#125;&#125;,&quot;persistence&quot;:&#123;&quot;storageClass&quot;:&quot;&quot;&#125;,&quot;servicemesh&quot;:&#123;&quot;enabled&quot;:false&#125;&#125;&#125;</span><br><span class="line">  labels:</span><br><span class="line">    version: v3.2.0</span><br><span class="line">  name: ks-installer</span><br><span class="line">  namespace: kubesphere-system</span><br><span class="line">spec:</span><br><span class="line">  alerting:</span><br><span class="line">    enabled: true</span><br><span class="line">  auditing:</span><br><span class="line">    enabled: true</span><br><span class="line">  authentication:</span><br><span class="line">    jwtSecret: &#x27;&#x27;</span><br><span class="line">  common:</span><br><span class="line">    core:</span><br><span class="line">      console:</span><br><span class="line">        enableMultiLogin: true</span><br><span class="line">        port: 30880</span><br><span class="line">        type: NodePort</span><br><span class="line">    es:</span><br><span class="line">      basicAuth:</span><br><span class="line">        enabled: true</span><br><span class="line">        password: &#x27;&#x27;</span><br><span class="line">        username: &#x27;&#x27;</span><br><span class="line">      elkPrefix: logstash</span><br><span class="line">      externalElasticsearchPort: &#x27;&#x27;</span><br><span class="line">      externalElasticsearchUrl: &#x27;&#x27;</span><br><span class="line">      logMaxAge: 7</span><br><span class="line">    gpu:</span><br><span class="line">      kinds:</span><br><span class="line">        - default: true</span><br><span class="line">          resourceName: nvidia.com/gpu</span><br><span class="line">          resourceType: GPU</span><br><span class="line">    minio:</span><br><span class="line">      volumeSize: 20Gi</span><br><span class="line">    monitoring:</span><br><span class="line">      GPUMonitoring:</span><br><span class="line">        enabled: true</span><br><span class="line">      endpoint: &#x27;http://prometheus-operated.kubesphere-monitoring-system.svc:9090&#x27;</span><br><span class="line">    openldap:</span><br><span class="line">      enabled: true</span><br><span class="line">      volumeSize: 2Gi</span><br><span class="line">    redis:</span><br><span class="line">      enabled: true</span><br><span class="line">      volumeSize: 2Gi</span><br><span class="line">  devops:</span><br><span class="line">    enabled: true</span><br><span class="line">    jenkinsJavaOpts_MaxRAM: 2g</span><br><span class="line">    jenkinsJavaOpts_Xms: 512m</span><br><span class="line">    jenkinsJavaOpts_Xmx: 512m</span><br><span class="line">    jenkinsMemoryLim: 2Gi</span><br><span class="line">    jenkinsMemoryReq: 1500Mi</span><br><span class="line">    jenkinsVolumeSize: 8Gi</span><br><span class="line">  etcd:</span><br><span class="line">    endpointIps: &#x27;192.168.1.10,192.168.1.11,192.168.1.12&#x27;</span><br><span class="line">    monitoring: false</span><br><span class="line">    port: 2379</span><br><span class="line">    tlsEnable: true</span><br><span class="line">  events:</span><br><span class="line">    enabled: true</span><br><span class="line">  kubeedge:</span><br><span class="line">    cloudCore:</span><br><span class="line">      cloudHub:</span><br><span class="line">        advertiseAddress:</span><br><span class="line">          - &#x27;&#x27;</span><br><span class="line">        nodeLimit: &#x27;100&#x27;</span><br><span class="line">      cloudhubHttpsPort: &#x27;10002&#x27;</span><br><span class="line">      cloudhubPort: &#x27;10000&#x27;</span><br><span class="line">      cloudhubQuicPort: &#x27;10001&#x27;</span><br><span class="line">      cloudstreamPort: &#x27;10003&#x27;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        node-role.kubernetes.io/worker: &#x27;&#x27;</span><br><span class="line">      service:</span><br><span class="line">        cloudhubHttpsNodePort: &#x27;30002&#x27;</span><br><span class="line">        cloudhubNodePort: &#x27;30000&#x27;</span><br><span class="line">        cloudhubQuicNodePort: &#x27;30001&#x27;</span><br><span class="line">        cloudstreamNodePort: &#x27;30003&#x27;</span><br><span class="line">        tunnelNodePort: &#x27;30004&#x27;</span><br><span class="line">      tolerations: []</span><br><span class="line">      tunnelPort: &#x27;10004&#x27;</span><br><span class="line">    edgeWatcher:</span><br><span class="line">      edgeWatcherAgent:</span><br><span class="line">        nodeSelector:</span><br><span class="line">          node-role.kubernetes.io/worker: &#x27;&#x27;</span><br><span class="line">        tolerations: []</span><br><span class="line">      nodeSelector:</span><br><span class="line">        node-role.kubernetes.io/worker: &#x27;&#x27;</span><br><span class="line">      tolerations: []</span><br><span class="line">    enabled: true</span><br><span class="line">  logging:</span><br><span class="line">    containerruntime: docker</span><br><span class="line">    enabled: true</span><br><span class="line">    logsidecar:</span><br><span class="line">      enabled: true</span><br><span class="line">      replicas: 2</span><br><span class="line">  metrics_server:</span><br><span class="line">    enabled: true</span><br><span class="line">  monitoring:</span><br><span class="line">    gpu:</span><br><span class="line">      nvidia_dcgm_exporter:</span><br><span class="line">        enabled: true</span><br><span class="line">    storageClass: &#x27;&#x27;</span><br><span class="line">  multicluster:</span><br><span class="line">    clusterRole: none</span><br><span class="line">  network:</span><br><span class="line">    ippool:</span><br><span class="line">      type: weave-scope</span><br><span class="line">    networkpolicy:</span><br><span class="line">      enabled: true</span><br><span class="line">    topology:</span><br><span class="line">      type: none</span><br><span class="line">  openpitrix:</span><br><span class="line">    store:</span><br><span class="line">      enabled: true</span><br><span class="line">  persistence:</span><br><span class="line">    storageClass: &#x27;&#x27;</span><br><span class="line">  servicemesh:</span><br><span class="line">    enabled: true</span><br></pre></td></tr></table></figure>

<p><strong>批量将所有服务器设置阿里云加速</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# vim 8 </span><br><span class="line">root@hello:~# cat 8 </span><br><span class="line">sudo mkdir -p /etc/docker</span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://ted9wxpi.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# vim 7 </span><br><span class="line">root@hello:~# cat 7</span><br><span class="line">scp 8 root@192.168.1.11:</span><br><span class="line">scp 8 root@192.168.1.12:</span><br><span class="line">scp 8 root@192.168.1.13:</span><br><span class="line">scp 8 root@192.168.1.14:</span><br><span class="line">scp 8 root@192.168.1.15:</span><br><span class="line">scp 8 root@192.168.1.16:</span><br><span class="line">scp 8 root@192.168.1.51:</span><br><span class="line">scp 8 root@192.168.1.52:</span><br><span class="line">scp 8 root@192.168.1.53:</span><br><span class="line">scp 8 root@192.168.1.54:</span><br><span class="line">scp 8 root@192.168.1.55:</span><br><span class="line">scp 8 root@192.168.1.56:</span><br><span class="line">scp 8 root@192.168.1.57:</span><br><span class="line">root@hello:~# bash -x 7</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# vim 6 </span><br><span class="line">root@hello:~# cat 6</span><br><span class="line">ssh root@192.168.1.10 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.11 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.12 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.13 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.14 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.15 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.16 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.51 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.52 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.53 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.54 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.55 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.56 &quot;bash -x 8&quot;</span><br><span class="line">ssh root@192.168.1.57 &quot;bash -x 8&quot;</span><br><span class="line">root@hello:~# bash -x 6</span><br></pre></td></tr></table></figure>

<p><strong>查看node节点</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  get node</span><br><span class="line">NAME      STATUS   ROLES                  AGE   VERSION</span><br><span class="line">master1   Ready    control-plane,master   11h   v1.22.1</span><br><span class="line">master2   Ready    control-plane,master   11h   v1.22.1</span><br><span class="line">master3   Ready    control-plane,master   11h   v1.22.1</span><br><span class="line">node1     Ready    worker                 11h   v1.22.1</span><br><span class="line">node10    Ready    worker                 11h   v1.22.1</span><br><span class="line">node11    Ready    worker                 11h   v1.22.1</span><br><span class="line">node2     Ready    worker                 11h   v1.22.1</span><br><span class="line">node3     Ready    worker                 11h   v1.22.1</span><br><span class="line">node4     Ready    worker                 11h   v1.22.1</span><br><span class="line">node5     Ready    worker                 11h   v1.22.1</span><br><span class="line">node6     Ready    worker                 11h   v1.22.1</span><br><span class="line">node7     Ready    worker                 11h   v1.22.1</span><br><span class="line">node8     Ready    worker                 11h   v1.22.1</span><br><span class="line">node9     Ready    worker                 11h   v1.22.1</span><br><span class="line">root@hello:~#  </span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/17c387d141a443db9630d3ff27430cc5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f0f83b94eb37491588affe5dbcbb9138~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>51篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b94ea426dc134a6f9aa413398eaa9ec5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Centos9网卡配置</title>
    <url>/2021/12/30/2021-12-30-Centos9%E7%BD%91%E5%8D%A1%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9132a1d6ffec43a08279b9af36f744c2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>Centos9 网卡配置文件已修改，如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@bogon ~]# cat /etc/NetworkManager/system-connections/ens18.nmconnection </span><br><span class="line">[connection]</span><br><span class="line">id=ens18</span><br><span class="line">uuid=8d1ece55-d999-3c97-866b-d2e23832a324</span><br><span class="line">type=ethernet</span><br><span class="line">autoconnect-priority=-999</span><br><span class="line">interface-name=ens18</span><br><span class="line">permissions=</span><br><span class="line">timestamp=1639473429</span><br><span class="line"></span><br><span class="line">[ethernet]</span><br><span class="line">mac-address-blacklist=</span><br><span class="line"></span><br><span class="line">[ipv4]</span><br><span class="line">address1=192.168.1.92/24,192.168.1.1</span><br><span class="line">dns=8.8.8.8;</span><br><span class="line">dns-search=</span><br><span class="line">method=manual</span><br><span class="line"></span><br><span class="line">[ipv6]</span><br><span class="line">addr-gen-mode=eui64</span><br><span class="line">dns-search=</span><br><span class="line">method=auto</span><br><span class="line"></span><br><span class="line">[proxy]</span><br><span class="line">[root@bogon ~]#</span><br></pre></td></tr></table></figure>

<p>命令语法：</p>
<p># nmcli connection modify &lt;interface_name&gt; ipv4.address  &lt;ip&#x2F;prefix&gt;</p>
<p>复制代码注意: 为了简化语句，在 nmcli 命令中，我们通常用 con 关键字替换 connection，并用 mod 关键字替换 modify。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">将 IPv4 地址 (192.168.1.91) 分配给 ens18网卡上，</span><br><span class="line">[root@chenby ~]# nmcli con mod ens18 ipv4.addresses 192.168.1.91/24;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">复制代码使用下面的 nmcli 命令设置网关，</span><br><span class="line">[root@chenby ~]# nmcli con mod ens18 ipv4.gateway 192.168.1.1;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">复制代码设置手动配置（从 dhcp 到 static），</span><br><span class="line">[root@chenby ~]# nmcli con mod ens18 ipv4.method manual;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">复制代码设置 DNS 值为 “8.8.8.8”，</span><br><span class="line">[root@chen&#x27;b&#x27;y ~]# nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">复制代码要保存上述更改并重新加载，请执行如下 nmcli 命令，</span><br><span class="line">[root@chenby ~]# nmcli con up ens18</span><br></pre></td></tr></table></figure>

<p>合成一句话为：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nmcli con mod ens18 ipv4.addresses 192.168.1.91/24; nmcli con mod ens18 ipv4.gateway 192.168.1.1; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18</span><br></pre></td></tr></table></figure>

<p>远程修改IP为：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@192.168.1.197 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.91/24; nmcli con mod ens18 ipv4.gateway 192.168.1.1; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4c9a8e6e7175484a9c3a06c59c1c06b6~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>69篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4323d9f0616440c2bea509e553653f8d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步v</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Linux内核高性能优化</title>
    <url>/2021/12/30/2021-12-30-Linux%E5%86%85%E6%A0%B8%E9%AB%98%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="Linux内核高性能优化"><a href="#Linux内核高性能优化" class="headerlink" title="Linux内核高性能优化"></a>Linux内核高性能优化</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/38aa0cb9e1da43ecb7b3c39980f8e24f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/db5c004355e542a689cc95288ea43f82~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
<p>#—内核优化开始——–</p>
<p># 内核panic时，1秒后自动重启</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kernel.panic = 1</span><br></pre></td></tr></table></figure>

<p># 允许更多的PIDs (减少滚动翻转问题); may break some programs 32768</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kernel.pid_max = 32768</span><br></pre></td></tr></table></figure>

<p># 内核所允许的最大共享内存段的大小（bytes）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kernel.shmmax = 4294967296</span><br></pre></td></tr></table></figure>

<p># 在任何给定时刻，系统上可以使用的共享内存的总量（pages）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kernel.shmall = 1073741824</span><br></pre></td></tr></table></figure>

<p># 设定程序core时生成的文件名格式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kernel.core_pattern = core_%e</span><br></pre></td></tr></table></figure>

<p># 当发生oom时，自动转换为panic</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vm.panic_on_oom = 1</span><br></pre></td></tr></table></figure>

<p># 表示强制Linux VM最低保留多少空闲内存（Kbytes）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vm.min_free_kbytes = 1048576</span><br></pre></td></tr></table></figure>

<p># 该值高于100，则将导致内核倾向于回收directory和inode cache</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vm.vfs_cache_pressure = 250</span><br></pre></td></tr></table></figure>

<p># 表示系统进行交换行为的程度，数值（0-100）越高，越可能发生磁盘交换</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vm.swappiness = 20</span><br></pre></td></tr></table></figure>

<p># 仅用10%做为系统cache</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vm.dirty_ratio = 10</span><br></pre></td></tr></table></figure>

<p># 增加系统文件描述符限制 2^20-1</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fs.file-max = 1048575</span><br></pre></td></tr></table></figure>

<p># 网络层优化</p>
<p># listen()的默认参数,挂起请求的最大数量，默认128</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.core.somaxconn = 1024</span><br></pre></td></tr></table></figure>

<p># 增加Linux自动调整TCP缓冲区限制</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.core.wmem\_default = 8388608</span><br><span class="line">net.core.rmem\_default = 8388608</span><br><span class="line">net.core.rmem\_max = 16777216</span><br><span class="line">net.core.wmem\_max = 16777216</span><br></pre></td></tr></table></figure>

<p># 进入包的最大设备队列.默认是300</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.core.netdev_max_backlog = 2000</span><br></pre></td></tr></table></figure>

<p># 开启SYN洪水攻击保护</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_syncookies = 1</span><br></pre></td></tr></table></figure>

<p># 开启并记录欺骗，源路由和重定向包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.conf.all.log\_martians = 1</span><br><span class="line">net.ipv4.conf.default.log\_martians = 1</span><br></pre></td></tr></table></figure>

<p># 处理无源路由的包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.conf.all.accept\_source\_route = 0</span><br><span class="line">net.ipv4.conf.default.accept\_source\_route = 0</span><br></pre></td></tr></table></figure>

<p># 开启反向路径过滤</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.conf.all.rp\_filter = 1</span><br><span class="line">net.ipv4.conf.default.rp\_filter = 1</span><br></pre></td></tr></table></figure>

<p># 确保无人能修改路由表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.conf.all.accept\_redirects = 0</span><br><span class="line">net.ipv4.conf.default.accept\_redirects = 0</span><br><span class="line">net.ipv4.conf.all.secure\_redirects = 0</span><br><span class="line">net.ipv4.conf.default.secure\_redirects = 0</span><br></pre></td></tr></table></figure>

<p># 增加系统IP端口限制</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.ip_local_port_range = 9000 65533</span><br></pre></td></tr></table></figure>

<p># TTL</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.ip_default_ttl = 64</span><br></pre></td></tr></table></figure>

<p># 增加TCP最大缓冲区大小</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp\_rmem = 4096 87380 8388608</span><br><span class="line">net.ipv4.tcp\_wmem = 4096 32768 8388608</span><br></pre></td></tr></table></figure>

<p># Tcp自动窗口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_window_scaling = 1</span><br></pre></td></tr></table></figure>

<p># 进入SYN包的最大请求队列.默认1024</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_max_syn_backlog = 8192</span><br></pre></td></tr></table></figure>

<p># 打开TIME-WAIT套接字重用功能，对于存在大量连接的Web服务器非常有效。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp\_tw\_recycle = 1 </span><br><span class="line">net.ipv4.tcp\_tw\_reuse = 0  </span><br></pre></td></tr></table></figure>

<p># 表示是否启用以一种比超时重发更精确的方法（请参阅 RFC 1323）来启用对 RTT 的计算；为了实现更好的性能应该启用这个选项</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_timestamps = 0</span><br></pre></td></tr></table></figure>

<p># 表示本机向外发起TCP SYN连接超时重传的次数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp\_syn\_retries = 2</span><br><span class="line">net.ipv4.tcp\_synack\_retries = 2</span><br></pre></td></tr></table></figure>

<p># 减少处于FIN-WAIT-2连接状态的时间，使系统可以处理更多的连接。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_fin_timeout = 10 </span><br></pre></td></tr></table></figure>

<p># 减少TCP KeepAlive连接侦测的时间，使系统可以处理更多的连接。 </p>
<p># 如果某个TCP连接在idle 300秒后,内核才发起probe.如果probe 2次(每次2秒)不成功,内核才彻底放弃,认为该连接已失效.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp\_keepalive\_time = 300 </span><br><span class="line">net.ipv4.tcp\_keepalive\_probes = 2</span><br><span class="line">net.ipv4.tcp\_keepalive\_intvl = 2</span><br></pre></td></tr></table></figure>

<p># 系统所能处理不属于任何进程的TCP sockets最大数量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_max_orphans = 262144</span><br></pre></td></tr></table></figure>

<p># 系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_max_tw_buckets = 20000 </span><br></pre></td></tr></table></figure>

<p># arp_table的缓存限制优化</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.neigh.default.gc\_thresh1 = 128</span><br><span class="line">net.ipv4.neigh.default.gc\_thresh2 = 512</span><br><span class="line">net.ipv4.neigh.default.gc\_thresh3 = 4096</span><br></pre></td></tr></table></figure>

<p>#——内核优化结束——–</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3fabe4023f8646169d3188d3dc53601e~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Linux文件系统故障，Input/output error</title>
    <url>/2021/12/30/2021-12-30-Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%95%85%E9%9A%9C%EF%BC%8CInput_output_error/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/698bb5a1576a4882bb866a23a962fa6c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    事情是这样的，在启动某一个应用程序的时候，出现 Input&#x2F;output error 的报错，磁盘以及目录无法使用的情况下，进行了重启，重启完成后是可以正常使用的，过一段时间后就会再次出现这个问题，一番Google之后怀疑是磁盘出现问题，根据网友的解决方案尝试之后发现，这个方法可行，下文是命令及回显：</p>
<p>      </p>
<p>    使用ls命令查看的时候出现这个报错  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# ls /data/</span><br><span class="line">ls: 无法访问/data/: 输入/输出错误</span><br><span class="line">[root@webc ~]#</span><br></pre></td></tr></table></figure>

<p>    这个是xfs的文件系统，所以使用如下命令进行修复  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# xfs_repair /dev/sdc1</span><br><span class="line">xfs_repair: cannot open /dev/sdc1: 设备或资源忙</span><br></pre></td></tr></table></figure>

<p>   </p>
<p>      </p>
<p>    这时这个问题，不要慌，先把磁盘卸载了在进行修复  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# umount /dev/sdc1</span><br><span class="line">[root@webc ~]# xfs_repair /dev/sdc1</span><br><span class="line">Phase 1 - find and verify superblock...</span><br><span class="line">Phase 2 - using internal log</span><br><span class="line">        - zero log...</span><br><span class="line">ERROR: The filesystem has valuable metadata changes in a log which needs to</span><br><span class="line">be replayed.  Mount the filesystem to replay the log, and unmount it before</span><br><span class="line">re-running xfs_repair.  If you are unable to mount the filesystem, then use</span><br><span class="line">the -L option to destroy the log and attempt a repair.</span><br><span class="line">Note that destroying the log may cause corruption -- please attempt a mount</span><br><span class="line">of the filesystem before doing this.</span><br><span class="line">[root@webc ~]# </span><br><span class="line">[root@webc ~]# </span><br><span class="line">[root@webc ~]# xfs_repair /dev/sdc1</span><br><span class="line">Phase 1 - find and verify superblock...</span><br><span class="line">Phase 2 - using internal log</span><br><span class="line">        - zero log...</span><br><span class="line">ERROR: The filesystem has valuable metadata changes in a log which needs to</span><br><span class="line">be replayed.  Mount the filesystem to replay the log, and unmount it before</span><br><span class="line">re-running xfs_repair.  If you are unable to mount the filesystem, then use</span><br><span class="line">the -L option to destroy the log and attempt a repair.</span><br><span class="line">Note that destroying the log may cause corruption -- please attempt a mount</span><br><span class="line">of the filesystem before doing this.</span><br><span class="line">[root@webc ~]# xfs_repair /dev/sdc1 -L</span><br><span class="line">Phase 1 - find and verify superblock...</span><br><span class="line">Phase 2 - using internal log</span><br><span class="line">        - zero log...</span><br><span class="line">ALERT: The filesystem has valuable metadata changes in a log which is being</span><br><span class="line">destroyed because the -L option was used.</span><br><span class="line">        - scan filesystem freespace and inode maps...</span><br><span class="line">agi unlinked bucket 31 is 7620063 in ag 5 (inode=10745038303)</span><br><span class="line">sb_icount 533632, counted 533568</span><br><span class="line">sb_ifree 617, counted 614</span><br><span class="line">sb_fdblocks 2852137932, counted 2860186916</span><br><span class="line">        - found root inode chunk</span><br><span class="line">Phase 3 - for each AG...</span><br><span class="line">        - scan and clear agi unlinked lists...</span><br><span class="line">        - process known inodes and perform inode discovery...</span><br><span class="line">        - agno = 0</span><br><span class="line">        - agno = 1</span><br><span class="line">        - agno = 2</span><br><span class="line">        - agno = 3</span><br><span class="line">        - agno = 4</span><br><span class="line">        - agno = 5</span><br><span class="line">correcting bt key (was 91997, now 92001) in inode 10745038303</span><br><span class="line">    data fork, btree block 1343129285</span><br><span class="line">correcting bt key (was 226254, now 226257) in inode 10745038303</span><br><span class="line">    data fork, btree block 1345535075</span><br><span class="line">correcting bt key (was 241554, now 241557) in inode 10745038303</span><br><span class="line">    data fork, btree block 1345535075</span><br><span class="line">correcting bt key (was 795517, now 795515) in inode 10745038303</span><br><span class="line">    data fork, btree block 1343659983</span><br><span class="line">data fork in regular inode 10745038303 claims used block 1353137709</span><br><span class="line">correcting nextents for inode 10745038303</span><br><span class="line">bad data fork in inode 10745038303</span><br><span class="line">cleared inode 10745038303</span><br><span class="line">        - agno = 6</span><br><span class="line">        - agno = 7</span><br><span class="line">        - agno = 8</span><br><span class="line">correcting nextents for inode 17197661037, was 870903 - counted 870911</span><br><span class="line">        - agno = 9</span><br><span class="line">        - agno = 10</span><br><span class="line">correcting bt key (was 1923723, now 1923730) in inode 21481716216</span><br><span class="line">    data fork, btree block 2687659655</span><br><span class="line">correcting bt key (was 1997785, now 1997794) in inode 21481716216</span><br><span class="line">    data fork, btree block 2687659655</span><br><span class="line">correcting nextents for inode 21481716216, was 918874 - counted 918898</span><br><span class="line">        - process newly discovered inodes...</span><br><span class="line">Phase 4 - check for duplicate blocks...</span><br><span class="line">        - setting up duplicate extent list...</span><br><span class="line">        - check for inodes claiming duplicate blocks...</span><br><span class="line">        - agno = 0</span><br><span class="line">        - agno = 3</span><br><span class="line">        - agno = 4</span><br><span class="line">        - agno = 2</span><br><span class="line">        - agno = 5</span><br><span class="line">        - agno = 6</span><br><span class="line">        - agno = 1</span><br><span class="line">        - agno = 7</span><br><span class="line">        - agno = 9</span><br><span class="line">        - agno = 8</span><br><span class="line">        - agno = 10</span><br><span class="line">Phase 5 - rebuild AG headers and trees...</span><br><span class="line">        - reset superblock...</span><br><span class="line">Phase 6 - check inode connectivity...</span><br><span class="line">        - resetting contents of realtime bitmap and summary inodes</span><br><span class="line">        - traversing filesystem ...</span><br><span class="line">        - traversal finished ...</span><br><span class="line">        - moving disconnected inodes to lost+found ...</span><br><span class="line">Phase 7 - verify and correct link counts...</span><br><span class="line">Maximum metadata LSN (15:166217) is ahead of log (1:2).</span><br><span class="line">Format log to cycle 18.</span><br><span class="line">done</span><br><span class="line">[root@webc ~]#</span><br></pre></td></tr></table></figure>

<p>    修复完成后在把磁盘挂上，即可生效  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# mount /dev/sdc1 /data/</span><br></pre></td></tr></table></figure>

<p>    查看一下这个磁盘是否可以正常使用  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@webc ~]# cd /data/vm/</span><br><span class="line">[root@webc vm]# ls</span><br><span class="line">CentOS7-Clone-1  CentOS7-Clone-3  CentOS7-Clone-4  CentOS7-Clone-5  CentOS8  Ubuntu</span><br></pre></td></tr></table></figure>

<p>此刻文件系统已修复完毕  </p>
<p>注意：  </p>
<p>    修复其他文件系统使用fsck命令进行修复  </p>
<p>    例如ext4文件系统  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fsck -t ext4 -y /dev/sda1</span><br></pre></td></tr></table></figure>

<p>不同的文件系统，命令会有些许不同，灵活变通一下</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/474a9cd132244fd9be4c3bee283ebb5c~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>28篇原创内容</p>
<p>公众号</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>MINIO搭建单机以及集群</title>
    <url>/2021/12/30/2021-12-30-MINIO%E6%90%AD%E5%BB%BA%E5%8D%95%E6%9C%BA%E4%BB%A5%E5%8F%8A%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/639caaa0fe8b47a18330ca0090e4a052~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>MINIO简介</strong></p>
<p>    Minio是Apache License v2.0下发布的对象存储服务器。它与Amazon S3云存储服务兼容。它最适合存储非结构化数据，如照片，视频，日志文件，备份和容器&#x2F;VM映像。对象的大小可以从几KB到最大5TB。Minio服务器足够轻，可以与应用程序堆栈捆绑在一起，类似于NodeJS，Redis和MySQL。</p>
<p>      <a href="https://docs.minio.io/">https://docs.minio.io/</a></p>
<p><strong>一、单机版搭建</strong>  </p>
<table><tbody><tr><td width="268" valign="top" style="word-break: break-all;"><section style="text-indent: 0em;">操作系统<br></section></td><td width="268" valign="top" style="word-break: break-all;"><section style="text-indent: 0em;">搭建方式<br></section></td></tr><tr><td width="268" valign="top" style="word-break: break-all;"><section style="text-indent: 0em;">Linux<br></section></td><td width="268" valign="top" style="word-break: break-all;"><section style="text-indent: 0em;">docker<br></section></td></tr><tr><td width="268" valign="top" style="word-break: break-all;"><section style="text-indent: 0em;">Linux<br></section></td><td width="268" valign="top" style="word-break: break-all;"><section style="text-indent: 0em;">宿主机<br></section></td></tr></tbody></table>

  

<p><strong>1. docker模式搭建</strong></p>
<p><strong>1.1安装docker</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br><span class="line">[root@localhost ~]# systemctl start docker #启动docker</span><br><span class="line">[root@localhost ~]# docker ps -a #查看一下命令是否可以执行</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>

<p><strong>1.2使用docker安装MINIO</strong>  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# docker search minio</span><br><span class="line">NAME                           DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED</span><br><span class="line">minio/minio                    Kubernetes Native, High Performance Object S…   445                  [OK]</span><br><span class="line">minio/mc                       Minio Client (mc) provides a modern alternat…   22                   [OK]</span><br><span class="line">bitnami/minio                  Bitnami MinIO Docker Image                      6                    </span><br><span class="line">pixelchrome/minio-arm          This Dockerfile installs Minio on your ARM-P…   5                    </span><br><span class="line">jessestuart/minio              Minio server — supports arm (arm32v6, arm32v…   5                    </span><br><span class="line">minio/console                  A graphical user interface for MinIO server     4                    </span><br><span class="line">webhippie/minio                Docker images for Minio                         3                    [OK]</span><br><span class="line">opennms/minion                 Application container runs Minion by OpenNMS…   3                    [OK]</span><br><span class="line">bitnami/minio-client           Bitnami MinIO Client Docker Image               3                    </span><br><span class="line">rook/minio                     Minio is a high performance distributed obje…   2                    </span><br><span class="line">rancher/minio-minio                                                            1                    </span><br><span class="line">zenithar/minio-server          Minio.io Server in Alpine Linux docker          1                    [OK]</span><br><span class="line">teamwork/minio                 Minio for Teamwork                              1                    </span><br><span class="line">azinchen/minio                 Minio server Docker image. Always up-to-date…   1                    </span><br><span class="line">minio/mint                     Collection of tests to detect overall correc…   0                    [OK]</span><br><span class="line">tobilg/minio-dcos              minio on DC/OS                                  0                    [OK]</span><br><span class="line">topdockercat/minio-unraid      Minio is an Amazon S3 compatible object stor…   0                    [OK]</span><br><span class="line">keikoproj/minion-manager       https://github.com/orkaproj/minion-manager      0                    </span><br><span class="line">joepll/minio-exporter          Prometheus exporter for Minio server            0                    </span><br><span class="line">opsmx11/minio                  Minio for Openshift                             0                    [OK]</span><br><span class="line">leviy/minio                    Minio image for development and testing of (…   0                    [OK]</span><br><span class="line">minio/k8s-operator             Minio Operator for k8s https://kubernetes.io/   0                    </span><br><span class="line">rwsdockercf/minio-resource                                                     0                    </span><br><span class="line">nerc/minio                     Minio container for use in the datalab proje…   0                    [OK]</span><br><span class="line">kazesberger/miniomc-postgres   this image is used to create postgres dumps …   0                    </span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# docker pull minio/minio</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from minio/minio</span><br><span class="line">8f403cb21126: Pull complete </span><br><span class="line">65c0f2178ac8: Pull complete </span><br><span class="line">6e32ce08526e: Pull complete </span><br><span class="line">932fb72de569: Pull complete </span><br><span class="line">71bfd33c61af: Pull complete </span><br><span class="line">588b2addab38: Pull complete </span><br><span class="line">093f7de724c9: Pull complete </span><br><span class="line">Digest: sha256:fe69dcaed404faa1a36953513bf2fe2d5427071fa612487295eddb2b18cfe918</span><br><span class="line">Status: Downloaded newer image for minio/minio:latest</span><br><span class="line">docker.io/minio/minio:latest</span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# docker run -p 9000:9000 --name minio1 \</span><br><span class="line">&gt; -e &quot;MINIO_ACCESS_KEY=admin&quot; \</span><br><span class="line">&gt; -e &quot;MINIO_SECRET_KEY=12345678&quot; \</span><br><span class="line">&gt; -v /Users/xiyou/my_minio/data:/data \</span><br><span class="line">&gt; -v /Users/xiyou/my_minio/config:/root/.minio \</span><br><span class="line">&gt; minio/minio server /data</span><br><span class="line">Endpoint: http://172.17.0.2:9000  http://127.0.0.1:9000 </span><br><span class="line"></span><br><span class="line">Browser Access:</span><br><span class="line">   http://172.17.0.2:9000  http://127.0.0.1:9000</span><br><span class="line"></span><br><span class="line">Object API (Amazon S3 compatible):</span><br><span class="line">   Go:         https://docs.min.io/docs/golang-client-quickstart-guide</span><br><span class="line">   Java:       https://docs.min.io/docs/java-client-quickstart-guide</span><br><span class="line">   Python:     https://docs.min.io/docs/python-client-quickstart-guide</span><br><span class="line">   JavaScript: https://docs.min.io/docs/javascript-client-quickstart-guide</span><br><span class="line">   .NET:       https://docs.min.io/docs/dotnet-client-quickstart-guide</span><br><span class="line">IAM initialization complete</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>1.3使用该命令将其放置在后台启动</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# docker run -d -p 9000:9000 --name minio1 \</span><br><span class="line">&gt; -e &quot;MINIO_ACCESS_KEY=admin&quot; \</span><br><span class="line">&gt; -e &quot;MINIO_SECRET_KEY=12345678&quot; \</span><br><span class="line">&gt; -v /my_minio/data:/data \</span><br><span class="line">&gt; -v /my_minio/config:/root/.minio \</span><br><span class="line">&gt; minio/minio server /data</span><br><span class="line">b6fca0d91b4bc5ef5f5b4b2a77a6f4761fc18e1d4b08f88519304813b52586d7</span><br><span class="line">[root@localhost ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/95417991985346ed98981199dbd13400~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ce7ec3609a034f689bb1f295dbad545b~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>1.4宿主机安装</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# wget https://dl.min.io/server/minio/release/linux-amd64/minio</span><br><span class="line">--2021-05-12 23:14:06--  https://dl.min.io/server/minio/release/linux-amd64/minio</span><br><span class="line">Resolving dl.min.io (dl.min.io)... 178.128.69.202</span><br><span class="line">Connecting to dl.min.io (dl.min.io)|178.128.69.202|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 58748928 (56M) [application/octet-stream]</span><br><span class="line">Saving to: ‘minio’</span><br><span class="line"></span><br><span class="line">minio                                   100%[============================================================================&gt;]  56.03M  7.24MB/s    in 9.5s    </span><br><span class="line"></span><br><span class="line">2021-05-12 23:14:17 (5.89 MB/s) - ‘minio’ saved [58748928/58748928]</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# chmod +x minio</span><br><span class="line">[root@localhost ~]#  MINIO_ACCESS_KEY=minio MINIO_SECRET_KEY=minio123 ./minio server /cby</span><br><span class="line">Endpoint: http://192.168.100.139:9000  http://127.0.0.1:9000         </span><br><span class="line">RootUser: minio </span><br><span class="line">RootPass: minio123 </span><br><span class="line"></span><br><span class="line">Browser Access:</span><br><span class="line">   http://192.168.100.139:9000  http://127.0.0.1:9000        </span><br><span class="line"></span><br><span class="line">Command-line Access: https://docs.min.io/docs/minio-client-quickstart-guide</span><br><span class="line">   $ mc alias set myminio http://192.168.100.139:9000 minio minio123</span><br><span class="line"></span><br><span class="line">Object API (Amazon S3 compatible):</span><br><span class="line">   Go:         https://docs.min.io/docs/golang-client-quickstart-guide</span><br><span class="line">   Java:       https://docs.min.io/docs/java-client-quickstart-guide</span><br><span class="line">   Python:     https://docs.min.io/docs/python-client-quickstart-guide</span><br><span class="line">   JavaScript: https://docs.min.io/docs/javascript-client-quickstart-guide</span><br><span class="line">   .NET:       https://docs.min.io/docs/dotnet-client-quickstart-guide</span><br><span class="line">IAM initialization complete</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eefb6210052e4f3ebba536185bbffe7d~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>二、集群版搭建</strong></p>
<p><strong>2. 集群搭建</strong></p>
<p><strong>2.1 集群服务器配置及启动</strong></p>
<p>启动一个分布式Minio实例，你只需要把硬盘位置做为参数传给minio server命令即可，然后，你需要在所有其它节点运行同样的命令。</p>
<p><strong>*注意</strong></p>
<p>    分布式Minio里所有的节点需要有同样的access秘钥和secret秘钥，这样这些节点才能建立联接。为了实现这个，你需要在执行minio server命令之前，先将access秘钥和secret秘钥export成环境变量。同时分布式Minio使用的磁盘里必须是干净的，里面没有数据。</p>
<p>    分布式Minio里的节点时间差不能超过3秒，你可以使用NTP 来保证时间一致。在Windows下运行分布式Minio处于实验阶段，请悠着点使用。</p>
<p>参考：<a href="https://docs.min.io/cn/distributed-minio-quickstart-guide.html">https://docs.min.io/cn/distributed-minio-quickstart-guide.html</a></p>
<table><tbody><tr><td width="268" valign="top" style="word-break: break-all;">名称<br></td><td width="268" valign="top" style="word-break: break-all;">IP<br></td></tr><tr><td width="268" valign="top" style="word-break: break-all;">node</td><td width="268" valign="top" style="word-break: break-all;">192.168.100.138<br></td></tr><tr><td width="268" valign="top" style="word-break: break-all;">node<br></td><td width="268" valign="top" style="word-break: break-all;">192.168.100.139<br></td></tr><tr><td valign="top" colspan="1" rowspan="1" style="word-break: break-all;">node<br></td><td valign="top" colspan="1" rowspan="1" style="word-break: break-all;">192.168.100.140</td></tr><tr><td valign="top" colspan="1" rowspan="1" style="word-break: break-all;">node<br></td><td valign="top" colspan="1" rowspan="1" style="word-break: break-all;">192.168.100.141</td></tr></tbody></table>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d5de3f81de174774bbdb7fa403292d3b~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>2.2每台上面搭建</strong>  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost software]# mkdir -p /chenby/software</span><br><span class="line">[root@localhost software]# cd /chenby/software</span><br><span class="line">[root@localhost software]# wget https://dl.min.io/server/minio/release/linux-amd64/minio</span><br><span class="line">--2021-05-13 00:06:25--  https://dl.min.io/server/minio/release/linux-amd64/minio</span><br><span class="line">Resolving dl.min.io (dl.min.io)... 178.128.69.202</span><br><span class="line">Connecting to dl.min.io (dl.min.io)|178.128.69.202|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 58748928 (56M) [application/octet-stream]</span><br><span class="line">Saving to: ‘minio’</span><br><span class="line"></span><br><span class="line">minio                                   100%[============================================================================&gt;]  56.03M  1.95MB/s    in 21s     </span><br><span class="line"></span><br><span class="line">2021-05-13 00:06:48 (2.63 MB/s) - ‘minio’ saved [58748928/58748928]</span><br><span class="line"></span><br><span class="line">[root@localhost software]# chmod +x minio</span><br><span class="line">[root@localhost software]# MINIO_ACCESS_KEY=minio MINIO_SECRET_KEY=minio123 ./minio server http://192.168.100.138/chenby/software/cby http://192.168.100.139/chenby/software/cby http://192.168.100.140/chenby/software/cby http://192.168.100.141/chenby/software/cby</span><br><span class="line">Waiting for all MinIO sub-systems to be initialized.. lock acquired</span><br><span class="line">All MinIO sub-systems initialized successfully</span><br><span class="line">Status:         4 Online, 0 Offline. </span><br><span class="line">Endpoint: http://192.168.100.138:9000  http://127.0.0.1:9000       </span><br><span class="line">RootUser: minio </span><br><span class="line">RootPass: minio123 </span><br><span class="line"></span><br><span class="line">Browser Access:</span><br><span class="line">   http://192.168.100.138:9000  http://127.0.0.1:9000      </span><br><span class="line"></span><br><span class="line">Command-line Access: https://docs.min.io/docs/minio-client-quickstart-guide</span><br><span class="line">   $ mc alias set myminio http://192.168.100.138:9000 minio minio123</span><br><span class="line"></span><br><span class="line">Object API (Amazon S3 compatible):</span><br><span class="line">   Go:         https://docs.min.io/docs/golang-client-quickstart-guide</span><br><span class="line">   Java:       https://docs.min.io/docs/java-client-quickstart-guide</span><br><span class="line">   Python:     https://docs.min.io/docs/python-client-quickstart-guide</span><br><span class="line">   JavaScript: https://docs.min.io/docs/javascript-client-quickstart-guide</span><br><span class="line">   .NET:       https://docs.min.io/docs/dotnet-client-quickstart-guide</span><br><span class="line">Waiting for all MinIO IAM sub-system to be initialized.. lock acquired</span><br><span class="line">IAM initialization complete</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>2.3 访问测试</strong>  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# curl -I http://192.168.100.138:9000/minio/login</span><br><span class="line">HTTP/1.1 403 Forbidden</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Content-Length: 256</span><br><span class="line">Content-Type: application/xml</span><br><span class="line">Server: MinIO</span><br><span class="line">Vary: Origin</span><br><span class="line">Date: Wed, 12 May 2021 16:09:19 GMT</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# curl -I http://192.168.100.139:9000/minio/login</span><br><span class="line">HTTP/1.1 403 Forbidden</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Content-Length: 256</span><br><span class="line">Content-Type: application/xml</span><br><span class="line">Server: MinIO</span><br><span class="line">Vary: Origin</span><br><span class="line">Date: Wed, 12 May 2021 16:09:25 GMT</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# curl -I http://192.168.100.140:9000/minio/login</span><br><span class="line">HTTP/1.1 403 Forbidden</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Content-Length: 256</span><br><span class="line">Content-Type: application/xml</span><br><span class="line">Server: MinIO</span><br><span class="line">Vary: Origin</span><br><span class="line">Date: Wed, 12 May 2021 16:09:32 GMT</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# curl -I http://192.168.100.141:9000/minio/login</span><br><span class="line">HTTP/1.1 403 Forbidden</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Content-Length: 256</span><br><span class="line">Content-Type: application/xml</span><br><span class="line">Server: MinIO</span><br><span class="line">Vary: Origin</span><br><span class="line">Date: Wed, 12 May 2021 16:09:36 GMT</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0338969963c241f4af29984109badbee~tplv-k3u1fbpfcp-zoom-1.image"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Nginx主要功能</title>
    <url>/2021/12/30/2021-12-30-Nginx%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8c00608547b148539d75e232591f18c3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>Nginx主要功能：  </p>
<hr>
<p>1、反向代理<br>2、负载均衡<br>3、HTTP服务器（包含动静分离）<br>4、正向代理</p>
<hr>
<h2 id="一、反向代理"><a href="#一、反向代理" class="headerlink" title="一、反向代理"></a><strong>一、反向代理</strong></h2><p>反向代理应该是 Nginx 做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet上 的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。下面贴上一段简单的实现反向代理的代码</p>
<p>&#96;&#96;&#96;shell<br>server {<br>      listen      80;<br>      server_name  localhost;      <br>      client_max_body_size 1024M;      <br>      location &#x2F; {<br>                proxy_pass <a href="http://localhost:8080/">http://localhost:8080</a>;          <br>                proxy_set_header Host $host:$server_port;      <br>                }  <br>      }</p>
<p>&#96;&#96;&#96;shell</p>
<p>保存配置文件后启动 Nginx，这样当我们访问 localhost 的时候，就相当于访问 localhost:8080 了。</p>
<hr>
<h2 id="二、负载均衡"><a href="#二、负载均衡" class="headerlink" title="二、负载均衡"></a><strong>二、负载均衡</strong></h2><p>负载均衡也是 Nginx 常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如：Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。<br><strong>1、RR（默认）</strong></p>
<p>&#96;&#96;&#96;shell<br>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。简单配置<br>upstream test {<br>      server localhost:8080;<br>      server localhost:8081;<br>      }  <br>      server {<br>            listen      81;      <br>            server_name  localhost;      <br>            client_max_body_size 1024M;      <br>            location &#x2F; {<br>                      proxy_pass <a href="http://test/">http://test</a>;          <br>                      proxy_set_header Host $host:$server_port;      <br>                      }  <br>       }</p>
<p>&#96;&#96;&#96;shell</p>
<p>配置了2台服务器，当然实际上是一台，只是端口不一样而已，而8081的服务器是不存在的,也就是说访问不到，但是我们访问 <a href="http://localhost/">http://localhost</a> 的时候,也不会有问题，会默认跳转到<a href="http://localhost:8080/">http://localhost:8080</a> 具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于 Nginx 默认是RR策略，所以我们不需要其他更多的设置。</p>
<p><strong>2、权重</strong><br>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如</p>
<p>&#96;&#96;&#96;shell<br>upstream test {<br>     server localhost:8080 weight&#x3D;9;<br>     server localhost:8081 weight&#x3D;1;<br>     }</p>
<p>&#96;&#96;&#96;shell</p>
<p>那么10次一般只会有1次会访问到8081，而有9次会访问到8080。</p>
<p><strong>3、ip_hash</strong><br>上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p>
<p>&#96;&#96;&#96;shell<br>upstream test {<br>     ip_hash;<br>     server localhost:8080;<br>     server localhost:8081;<br>     }</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>4、fair（第三方）</strong><br>按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p>
<p>&#96;&#96;&#96;shell<br>upstream backend {<br>    fair;    <br>    server localhost:8080;    <br>    server localhost:8081;<br>    }</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>5、url_hash（第三方）</strong><br>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。</p>
<p>&#96;&#96;&#96;shell<br>upstream backend {<br>    hash $request_uri;<br>    hash_method crc32;<br>    server localhost:8080;<br>    server localhost:8081;<br>    }</p>
<p>&#96;&#96;&#96;shell</p>
<p>以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用，由于本文主要介绍Nginx能做的事情，所以Nginx安装第三方模块不会再本文介绍。</p>
<hr>
<h2 id="三、HTTP服务器"><a href="#三、HTTP服务器" class="headerlink" title="三、HTTP服务器"></a><strong>三、HTTP服务器</strong></h2><p>Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器。</p>
<p>&#96;&#96;&#96;shell<br>  server {<br>        listen      80;<br>        server_name  localhost;<br>        client_max_body_size 1024M;<br>        location &#x2F; {<br>                      root  e:\wwwroot;<br>                      index  index.html;<br>                      }<br>         }</p>
<p>&#96;&#96;&#96;shell</p>
<p>这样如果访问<a href="http://localhost/">http://localhost</a> 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。</p>
<p>动静分离<br>动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。</p>
<p>&#96;&#96;&#96;shell<br>upstream test{<br>      server localhost:8080;<br>      server localhost:8081;<br>      }<br>      server {<br>            listen      80;<br>            server_name  localhost;<br>            location &#x2F; {<br>                      root  e:\wwwroot;<br>                      index  index.html;<br>                      }      # 所有静态请求都由nginx处理，存放目录为html<br>            location ~ \.(gif|jpg|jpeg|png|bmp|swf|css|js)$ {<br>                      root    e:\wwwroot;      <br>                      }      # 所有动态请求都转发给tomcat处理      <br>            location ~ \.(jsp|do)$ {<br>                      proxy_pass  <a href="http://test/">http://test</a>;      <br>                      }      <br>            error_page  500 502 503 504  &#x2F;50x.html;      <br>            location &#x3D; &#x2F;50x.html {<br>                      root  e:\wwwroot;      <br>                      }  <br>            }</p>
<p>&#96;&#96;&#96;shell</p>
<p>这样我们就可以把HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，<br>例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了，只要搞清楚了最基本的流程，很多配置就很简单了，另外localtion后面其实是一个正则表达式，所以非常灵活。</p>
<hr>
<h2 id="四、正向代理"><a href="#四、正向代理" class="headerlink" title="四、正向代理"></a><strong>四、正向代理</strong></h2><p>正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS，虽然我百度到过配置HTTPS的正向代理，但是到最后发现还是代理不了，当然可能是我配置的不对。</p>
<p>&#96;&#96;&#96;shell<br>  resolver 114.114.114.114 8.8.8.8;  server {<br>        resolver_timeout 5s;<br>        listen 81;<br>        access_log  e:\wwwroot\proxy.access.log;<br>        error_log  e:\wwwroot\proxy.error.log;<br>        location &#x2F; {<br>                  proxy_pass http:&#x2F;&#x2F;$host$request_uri;<br>                  }<br>        }</p>
<p>&#96;&#96;&#96;shell</p>
<p>resolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。</p>
<p>注意：<code>Nginx</code>是支持热启动的，也就是说当我们修改配置文件后，不用关闭<code>Nginx</code>，就可以实现让配置生效。<code>Nginx</code>从新读取配置的命令是：<code>nginx -s reload</code> 。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/983f284591274a119228c91f63b4c621~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL8.0允许外部访问</title>
    <url>/2021/12/30/2021-12-30-MySQL8.0%E5%85%81%E8%AE%B8%E5%A4%96%E9%83%A8%E8%AE%BF%E9%97%AE/</url>
    <content><![CDATA[<h1 id="MySQL8-0允许外部访问"><a href="#MySQL8-0允许外部访问" class="headerlink" title="MySQL8.0允许外部访问"></a>MySQL8.0允许外部访问</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6ea2bc3ed27549908286720b6a9f1215~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h3 id="一、前置条件："><a href="#一、前置条件：" class="headerlink" title="一、前置条件："></a>一、前置条件：</h3><p>按照<a href="https://blog.csdn.net/h996666/article/details/80917268%E5%AE%89%E8%A3%85%E5%AE%8CMySQL%E4%B9%8B%E5%90%8E%E3%80%82">https://blog.csdn.net/h996666/article/details/80917268安装完MySQL之后。</a></p>
<h3 id="二、开始修改配置："><a href="#二、开始修改配置：" class="headerlink" title="二、开始修改配置："></a>二、开始修改配置：</h3><p>1，登进MySQL之后，</p>
<p>2，输入以下语句，进入mysql库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">use mysql</span><br></pre></td></tr></table></figure>

<p>3，更新域属性，’%’表示允许外部访问：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">update user set host=&#x27;%&#x27; where user =&#x27;root&#x27;;</span><br></pre></td></tr></table></figure>

<p>4，执行以上语句之后再执行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<p>5，再执行授权语句：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27;WITH GRANT OPTION;</span><br></pre></td></tr></table></figure>

<p>然后外部就可以通过账户密码访问了。</p>
<p>6，其它说明：</p>
<p>FLUSH PRIVILEGES; 命令本质上的作用是：</p>
<p>将当前user和privilige表中的用户信息&#x2F;权限设置从mysql库(MySQL数据库的内置库)中提取到内存里。</p>
<p>MySQL用户数据和权限有修改后，希望在”不重启MySQL服务”的情况下直接生效，那么就需要执行这个命令。</p>
<p>通常是在修改ROOT帐号的设置后，怕重启后无法再登录进来，那么直接flush之后就可以看权限设置是否生效。</p>
<p>而不必冒太大风险。</p>
<h3 id="三、可能存在的其它问题："><a href="#三、可能存在的其它问题：" class="headerlink" title="三、可能存在的其它问题："></a>三、可能存在的其它问题：</h3><p>执行完之后，再用Navicat连接mysql，报错如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Client does not support authentication protocol requested by server；</span><br></pre></td></tr></table></figure>

<p>报错原因：</p>
<p>mysql8.0 引入了新特性 caching_sha2_password；这种密码加密方式Navicat 12以下客户端不支持；</p>
<p>Navicat 12以下客户端支持的是mysql_native_password 这种加密方式；</p>
<p>解决方案：</p>
<p>1，用如下语句查看MySQL当前加密方式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select host,user,plugin from user;</span><br></pre></td></tr></table></figure>

<p>查询结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+-----------+------------------+-----------------------+</span><br><span class="line">| host      | user             | plugin                |</span><br><span class="line">+-----------+------------------+-----------------------+</span><br><span class="line">| %         | root             | caching\_sha2\_password |</span><br><span class="line">| localhost | mysql.infoschema | mysql\_native\_password |</span><br><span class="line">| localhost | mysql.session    | mysql\_native\_password |</span><br><span class="line">| localhost | mysql.sys        | mysql\_native\_password |</span><br><span class="line">+-----------+------------------+-----------------------+</span><br></pre></td></tr></table></figure>

<p>看第一行，root加密方式为caching_sha2_password。  </p>
<p>2，使用命令将他修改成mysql_native_password加密模式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">update user set plugin=&#x27;mysql_native_password&#x27; where user=&#x27;root&#x27;;</span><br></pre></td></tr></table></figure>

<p>再次连接的时候，就成功了。</p>
<h3 id="四、如果还连接不上"><a href="#四、如果还连接不上" class="headerlink" title="四、如果还连接不上"></a>四、如果还连接不上</h3><p>通过以上操作后，依然无法连接上，问题可能出在了防火墙上。</p>
<p><strong>1，MySQL部署在实体服务器上解决方案如下：</strong><br>a.开放MySQL的端口号，默认端口号是3306。<br>b.直接关闭防火墙（慎重操作，不建议。当然测试玩的话就随意了。。。。）</p>
<p><strong>2，MySQL部署在云计算机上的方案如下：</strong><br>a.以阿里云为例，找到实例，设置安全组，开放端口号即可。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a99b8c6d78e64b13b6f8626c8c2b1fad~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Python 人工智能 5秒钟偷走你的声音</title>
    <url>/2021/12/30/2021-12-30-Python_%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD_5%E7%A7%92%E9%92%9F%E5%81%B7%E8%B5%B0%E4%BD%A0%E7%9A%84%E5%A3%B0%E9%9F%B3/</url>
    <content><![CDATA[<p>介绍</p>
<p>Python 深度学习AI - 声音克隆、声音模仿，是一个三阶段的深度学习框架，允许从几秒钟的音频中创建语音的数字表示，并用它来调节文本到语音模型，该模型经过培训，可以概括到新的声音。</p>
<p>环境准备与安装</p>
<p>原始英文版地址：</p>
<p><a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning">https://github.com/CorentinJ/Real-Time-Voice-Cloning</a></p>
<p>中文二次开发版（本文使用该版本）：</p>
<p><a href="https://github.com/babysor/MockingBird">https://github.com/babysor/MockingBird</a></p>
<p>pycharm环境下载：</p>
<p><a href="https://www.jetbrains.com/pycharm/download/#section=windows">https://www.jetbrains.com/pycharm/download/#section=windows</a></p>
<p>conda虚拟环境：</p>
<p><a href="https://www.anaconda.com/products/individual">https://www.anaconda.com/products/individual</a></p>
<p>FFmpeg ：</p>
<p><a href="https://github.com/BtbN/FFmpeg-Builds/releases">https://github.com/BtbN/FFmpeg-Builds/releases</a></p>
<p>模型文件：</p>
<p><a href="https://pan.baidu.com/s/1PI-hM3sn5wbeChRryX-RCQ">https://pan.baidu.com/s/1PI-hM3sn5wbeChRryX-RCQ</a> 提取码 2021</p>
<p>在电脑系统上安装 FFmpeg 工具</p>
<p>下载zip压缩包连接为：<a href="https://github.com/BtbN/FFmpeg-Builds/releases/download/autobuild-2021-11-09-12-23/ffmpeg-N-104488-ga13646639f-win64-gpl.zip">https://github.com/BtbN/FFmpeg-Builds/releases/download/autobuild-2021-11-09-12-23/ffmpeg-N-104488-ga13646639f-win64-gpl.zip</a></p>
<p>下载完成后将其解压到一个目录后在系统的环境变量中添加该目录</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dc5860656f3b46b987cefc067b5e60e0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>打开新的cmd中查看是否安装成功</p>
<p>ffmpeg -version</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1068725e289043d2b8fd0230ade44f17~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>使用打开项目目录后，创建时使用conda的Python 3.9虚拟环境</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8eee53b28c5948568b10998b8d55cc34~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>创建完成后，在cmd中查看现有的虚拟环境，并进入刚刚创建的虚拟环境</p>
<p>conda env list</p>
<p>activate pythonProject1</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c1e01a94936403fa8ef3e90c97b8d59~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>进入环境后在进行安装pip所需依赖，并使用国内源进行安装实现下载加速</p>
<p>pip install -r requirements.txt -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b83937d957b743de9af41e331846e0fb~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>在虚拟环境下安装pytorch</p>
<p>pip install torch  -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/33c3bde9f5d8410aac64af1f9bcc2abf~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>回到pycharm中，将模型导入到项目目录下，把目录复制黏贴到项目中</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/31a4ff2f688b4205835a6ebd3a26b7e4~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>修改一行代码，在 synthesizer&#x2F;utils&#x2F;symbols.py 文件中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">修改为：</span><br><span class="line">_characters = &#x27;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz12340!&#x27;(),-.:;? &#x27;</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/410cfa4dedb84fe59b0a676b2292716d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>之后在terminal中启动工具箱</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4808629d6b5d4bf9ba24d23a397e85b3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>使用音频合成工具箱</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/36858a67eb56462599197da8a65f91a2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/57ed8584b0fe4318bd446be059e106e9~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>48篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f6d12ef77d354dc6b7e5ada2175dde38~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Proxmox VE镜像分析与定制</title>
    <url>/2021/12/30/2021-12-30-Proxmox_VE%E9%95%9C%E5%83%8F%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9A%E5%88%B6/</url>
    <content><![CDATA[<p>    Proxmox VE（Proxmox Virtual Environment，简称PVE）是一个开源的服务器虚拟化环境Linux发行版，基于Debian，使用给予Ubuntu的定制内核。相比于其他虚拟化平台，PVE具有的一个显著的特点就是无需master节点，安装完成后，无需特殊配置即可将多个节点组成集群。</p>
<p>由于工程要求，PVE需要大规模部署在物理服务器上，所以定制镜像就显得很有必要。</p>
<p>定制目标包括</p>
<p>（1）修改initrd中init脚本的提示信息</p>
<p>（2）删除GRUB界面多余选项，直接进入安装界面</p>
<p>（3）添加预装软件</p>
<p>（4）在安装过程中对软件进行个性化配置</p>
<p>（5）修改PVE安装界面，在PVE安装界面中的所有输入框设置默认文本</p>
<p><strong>Proxmox VE镜像分析</strong></p>
<p>下载Proxmox VE 6.4版镜像后挂载，观察文件结构</p>
<p>&#96;&#96;&#96;shell<br>$ tree -L 2<br>.<br>├── boot<br>│   ├── boot.cat<br>│   ├── grub<br>│   ├── initrd.img<br>│   ├── linux26<br>│   └── memtest86+.bin<br>├── COPYING<br>├── COPYRIGHT<br>├── debian -&gt; .<br>├── dists<br>│   └── stretch<br>├── efi.img<br>├── EULA<br>├── mach_kernel<br>├── proxmox<br>│   ├── country.dat<br>│   ├── packages<br>│   └── pve-base.cnt<br>├── pve-base.squashfs<br>├── pve-installer.squashfs<br>├── Release.txt<br>└── System<br>    └── Library</p>
<p>9 directories, 14 files</p>
<p>&#96;&#96;&#96;shell</p>
<p>其中：</p>
<p>&#96;&#96;&#96;shell<br>grub文件夹：包含引导程序GRUB所用到的文件。<br>initrd.img：系统初始化所使用的镜像，里面包含一个最小化的系统，包含了&#x2F;dev、&#x2F;etc、&#x2F;bin等很多基本的目录，还有关键的init程序，负责驱动的加载和文件系统的初始化。<br>linux26：Linux 2.6内核<br>efi.img：系统引导镜像，内含boot.efi、bootia32.efi、bootx64.efi。<br>proxmox文件夹：系统预安装包的存放目录<br>PVE的根系统默认安装包是在proxmox文件夹下的，只要不破坏其依赖关系，可以将需要预安装的包及其依赖放到这个文件夹下。<br>PVE预安装包时候使用的是循环读取proxmox&#x2F;packages中的deb，然后使用的安装方法是先解压然后再配置，这样不会产生依赖关系而导致装不上deb的问题。<br>pve-base.squashfs：安装的根系统，也就是最终的系统<br>pve-installer.squashfs：安装时需要的系统</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>Proxmox VE安装流程</strong></p>
<p>PVE安装流程主要分为以下4个步骤：</p>
<p>（1）Boot Loader：由 BIOS 加载，用于将后续的 kernel 和 initrd 的装载到内存中。（PVE安装时使用的是UEFI模式的安装，但是又不是传统意义上的UEFI，它先是使用了BIOS加载kernel和initrd到内存，然后又跳到UEFI分区执行efi.img文件，调用proxinstall进入到系统安装界面，然后是挂载pve-base.squashfs进行系统安装）</p>
<p>（2）kernel：为 initrd 运行提供基础的运行环境，对应boot目录下的linux26文件</p>
<p>（3）initrd：检测并加载各种驱动程序，并执行init，对应boot目录下的initrd.img文件</p>
<p>（4）rootfs：根文件系统，用户的各种操作都是基于这个被最后加载的文件系统，这里对应了pve-base.squashfs</p>
<p><strong>Proxmox VE镜像定制</strong></p>
<p>ISO解压与压缩</p>
<p>在原先使用ISO Master作为解压缩ISO的工具中，产生的ISO文件可以直接作为cdrom启动，但刻录进USB设备后缺失MBR等重要部分所以无法启动，因此改用命令行进行解压缩。</p>
<p>（1）ISO提取</p>
<p>首先挂载镜像文件。</p>
<p>&#96;&#96;&#96;shell<br>$ mount -o loop Desktop&#x2F;proxmox-ve_6.4-1.iso cby&#x2F;</p>
<p>&#96;&#96;&#96;shell</p>
<p>挂载点目录中的文件是只读的，所以需要同步到工作目录下。</p>
<p>&#96;&#96;&#96;shell<br>$ cd cby<br>$ sudo rsync -av &#x2F;home&#x2F;cby&#x2F;cby&#x2F; &#x2F;home&#x2F;cby&#x2F;</p>
<p>&#96;&#96;&#96;shell</p>
<p>同步之后就即可修改ISO内的文件。</p>
<p>&#96;&#96;&#96;shell<br>$ sudo umount &#x2F;home&#x2F;cby&#x2F;cby<br>$ ll<br>total 386672<br>dr-xr-xr-x 10 root root      4096 Apr 27 04:26 .&#x2F;<br>dr-xr-xr-x 23 root root      4096 May 19 18:56 ..&#x2F;<br>dr-xr-xr-x  3 root root      4096 Apr 27 04:26 boot&#x2F;<br>-r–r–r–  1 root root        89 Apr 27 04:26 .cd-info<br>-r–r–r–  1 root root     32386 Apr 27 04:26 COPYING<br>-r–r–r–  1 root root       955 Apr 27 04:26 COPYRIGHT<br>lrwxrwxrwx  1 root root         1 Apr 27 04:26 debian -&gt; .&#x2F;<br>dr-xr-xr-x  3 root root      4096 Apr 27 04:26 dists&#x2F;<br>-r–r–r–  1 root root   2949120 Apr 27 04:26 efi.img<br>-r–r–r–  1 root root      4470 Apr 27 04:26 EULA<br>-r–r–r–  1 root root         0 Apr 27 04:26 mach_kernel<br>dr-xr-xr-x  3 root root      4096 Apr 27 04:26 proxmox&#x2F;<br>dr-xr-xr-x  2 root root      4096 Apr 27 04:26 .pve-base&#x2F;<br>-r–r–r–  1 root root 101306368 Apr 27 04:26 pve-base.squashfs<br>-r–r–r–  1 root root        37 Apr 27 04:26 .pve-cd-id.txt<br>dr-xr-xr-x  2 root root      4096 Apr 27 04:26 .pve-installer&#x2F;<br>dr-xr-xr-x  2 root root      4096 Apr 27 04:26 .pve-installer-mp&#x2F;<br>-r–r–r–  1 root root 291586048 Apr 27 04:26 pve-installer.squashfs<br>-r–r–r–  1 root root     15792 Apr 27 04:26 Release.txt<br>dr-xr-xr-x  3 root root      4096 Apr 27 04:26 System&#x2F;<br>dr-xr-xr-x  2 root root      4096 Apr 27 04:26 .workdir&#x2F;</p>
<p>&#96;&#96;&#96;shell</p>
<p>（2）ISO压缩</p>
<p>使用原镜像的MBR（前512字节）作为定制镜像的MBR</p>
<p>&#96;&#96;&#96;shell<br>$ sudo dd if&#x3D;&#x2F;home&#x2F;cby&#x2F;proxmox-ve_6.4-1.iso bs&#x3D;512 count&#x3D;1 of&#x3D;proxmox.mbr<br>1+0 records in<br>1+0 records out<br>512 bytes copied, 0.000134541 s, 3.8 MB&#x2F;s</p>
<p>&#96;&#96;&#96;shell</p>
<p>打包ISO镜像  </p>
<p>&#96;&#96;&#96;shell<br>$ sudo xorriso -as mkisofs -o proxmox-ve_6.4-1.iso -r -V ‘inspur’ –grub2-mbr proxmox.mbr –protective-msdos-label -efi-boot-part –efi-boot-image  -c ‘&#x2F;boot&#x2F;boot.cat’ -b ‘&#x2F;boot&#x2F;grub&#x2F;i386-pc&#x2F;eltorito.img’ -no-emul-boot -boot-load-size 4 -boot-info-table –grub2-boot-info -eltorito-alt-boot -e ‘&#x2F;efi.img’ -no-emul-boot .<br>xorriso 1.5.2 : RockRidge filesystem manipulator, libburnia project.</p>
<p>Drive current: -outdev ‘stdio:proxmox-ve_6.4-1.iso’<br>Media current: stdio file, overwriteable<br>Media status : is blank<br>Media summary: 0 sessions, 0 data blocks, 0 data, 80.6g free<br>xorriso : WARNING : -volid text does not comply to ISO 9660 &#x2F; ECMA 119 rules<br>Added to ISO image: directory ‘&#x2F;‘&#x3D;’&#x2F;home&#x2F;cby&#x2F;chenby’<br>xorriso : UPDATE :    1421 files added in 1 seconds<br>xorriso : UPDATE :    1421 files added in 1 seconds<br>xorriso : NOTE : Copying to System Area: 512 bytes from file ‘&#x2F;home&#x2F;cby&#x2F;chenby&#x2F;proxmox.mbr’<br>xorriso : UPDATE :  1.00% done<br>xorriso : UPDATE :  42.39% done<br>xorriso : UPDATE :  86.68% done<br>ISO image produced: 453265 sectors<br>Written to medium : 453265 sectors at LBA 0<br>Writing to ‘stdio:proxmox-ve_6.4-1.iso’ completed successfully.</p>
<p>&#96;&#96;&#96;shell</p>
<p>修改initrd</p>
<p>    initrd.img位于原始镜像的boot目录下，修改initrd的目的是修改安装过程中的输出文本，是一个比较特殊的部分，要从initrd引入的目的讲起。</p>
<p>    initrd 的英文含义是 boot loader initialized RAM disk，就是由 boot loader 初始化的内存盘。initrd的最初的目的是为了把kernel的启动分成两个阶段：在kernel中保留最少最基本的启动代码，然后把对各种各样硬件设备的支持以模块的方式放在initrd中，这样就在启动过程中可以从initrd所mount的根文件系统中装载需要的模块。这样的一个好处就是在保持kernel不变的情况下，通过修改initrd中的内容就可以灵活的支持不同的硬件。在启动完成的最后阶段，根文件系统可以重新mount到其他设备上。也就是说由于initrd会在内存虚拟一个文件系统，然后可以根据不同的硬件加载不同的驱动，而不需要重新编译整个核心。所以，大部分的发行版都会通过这种方式对驱动进行加载。</p>
<p>initrd引入之后Linux的引导会变成如下流程。</p>
<p>（1）boot loader 把内核以及 initrd 文件加载到内存的特定位置。</p>
<p>（2）内核判断initrd的文件格式，如果是cpio格式。</p>
<p>（3）将initrd的内容释放到rootfs中。</p>
<p>（4）执行initrd中的&#x2F;init文件，执行到这一点，内核的工作全部结束，完全交给&#x2F;init文件处理。</p>
<p>    根据核心版本的不同，initrd文件有两种格式：image和cpio。**kernel 2.4只使用image格式，而kernel 2.6可同时支持两种格式。**它们不单格式不一样，而且运作的机制和流程也完全不同，甚至制作方法也不一样。pve的kernel版本是2.6，所以在此只讲cpio格式的initrd制作。</p>
<p>initrd解压、修改与压缩流程：</p>
<p>（1）解压proxmox-ve_6.4-1.iso，boot目录下的initrd.img就是gz格式的压缩文件</p>
<p>（2）将initrd.img备份后重命名为initrd.org.img，并解压缩</p>
<p>&#96;&#96;&#96;shell<br>$ sudo gzip -d -S “.img” .&#x2F;initrd.org.img</p>
<p>&#96;&#96;&#96;shell</p>
<p>执行file后查看格式</p>
<p>&#96;&#96;&#96;shell<br>$ sudo file initrd.org<br>initrd.org: ASCII cpio archive (SVR4 with no CRC)</p>
<p>&#96;&#96;&#96;shell</p>
<p>（3）创建initrd.tmp目录以存放后续还原出来的文件，然后执行cpio命令将文件还原</p>
<p>&#96;&#96;&#96;shell<br>$ sudo mkdir initrd.tmp<br>$ cd initrd.tmp<br>$ sudo cpio -id &lt; ..&#x2F;initrd.org<br>241820 blocks<br>$ ls<br>bin  dev  devfs  etc  init  lib  lib64  mnt  proc  sbin  sys  tmp  usr</p>
<p>&#96;&#96;&#96;shell</p>
<p>去除GRUB界面</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/76f87ea449a14ac5960020d6a0fa4a6f~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    pve在安装时使用了GRUB2，所以想要去除掉GRUB界面需要找到原始镜像中boot&#x2F;grub&#x2F;grub.cfg文件，添加set timeout&#x3D;0，就可以直接进入默认选项Install Proxmox VE模式。如果有需要我们也可以修改默认选项来实现直接进入其他模式的功能。</p>
<p>&#96;&#96;&#96;shell<br>$ vim grub.cfg<br>$ cat grub.cfg<br>insmod gzio<br>insmod iso9660<br>insmod png</p>
<p>loadfont &#x2F;boot&#x2F;grub&#x2F;unicode.pf2</p>
<p>set gfxmode&#x3D;640x400</p>
<h1 id="set-kernel-parameter-vga-x3D-791"><a href="#set-kernel-parameter-vga-x3D-791" class="headerlink" title="set kernel parameter vga&#x3D;791"></a>set kernel parameter vga&#x3D;791</h1><h1 id="do-not-specify-color-depth-here-else-efifb-can-fall-back-to-800x600"><a href="#do-not-specify-color-depth-here-else-efifb-can-fall-back-to-800x600" class="headerlink" title="do not specify color depth here (else efifb can fall back to 800x600)"></a>do not specify color depth here (else efifb can fall back to 800x600)</h1><p>set gfxpayload&#x3D;1024x768<br>#set gfxmode&#x3D;auto<br>#set gfxpayload&#x3D;keep</p>
<p>set timeout&#x3D;0</p>
<p>insmod all_video<br>insmod gfxterm</p>
<p>set theme&#x3D;&#x2F;boot&#x2F;grub&#x2F;pvetheme&#x2F;theme.txt</p>
<p>…</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>定制预装软件</strong></p>
<p>    Proxmox VE所有的预装软件都以deb包的形式存放在镜像的proxmox&#x2F;packages下，并将在安装pve的过程中统一安装这些软件包，全部安装完成之后再进行配置，这样可以避免依赖关系出现问题。</p>
<p>    所以定制预装软件只需要在proxmox&#x2F;packages目录下放入需要的deb包，pve将会自动安装并进行默认配置。</p>
<p><strong>配置预装程序</strong></p>
<p>    pve在配置软件是只会按照默认的配置，如果希望将软件配置成我们想要的形式，则只需要修改pve-installer.squashfs里的usr&#x2F;bin&#x2F;proxinstall文件。pve-installer.squashfs是pve安装时由initrd加载的系统，安装过程中proxinstall负责所有业务逻辑，其中配置软件部分的代码如下：</p>
<p>&#96;&#96;&#96;shell</p>
<h1 id="needed-for-postfix-postinst-in-case-no-other-NIC-is-active"><a href="#needed-for-postfix-postinst-in-case-no-other-NIC-is-active" class="headerlink" title="needed for postfix postinst in case no other NIC is active"></a>needed for postfix postinst in case no other NIC is active</h1><p>syscmd(“chroot $targetdir ifup lo”);</p>
<p>my $cmd &#x3D; “chroot $targetdir dpkg $dpkg_opts –force-confold –configure -a”;<br>$count &#x3D; 0;<br>run_command ($cmd, sub {<br>    my $line &#x3D; shift;<br>    if ($line &#x3D;~ m&#x2F;Setting up\s+(\S+)&#x2F;) {<br>    update_progress ((++$count)&#x2F;$pkg_count, 0.75, 0.95,<br>             “configuring $1”);<br>    }<br>});</p>
<p>&#96;&#96;&#96;shell</p>
<p>…  </p>
<p>&#96;&#96;&#96;shell</p>
<h1 id="set-apt-mirror"><a href="#set-apt-mirror" class="headerlink" title="set apt mirror"></a>set apt mirror</h1><p>if (my $mirror &#x3D; $cmap-&gt;{country}-&gt;{$country}-&gt;{mirror}) {<br>    my $fn &#x3D; “$targetdir&#x2F;etc&#x2F;apt&#x2F;sources.list”;<br>    syscmd (“sed -i ‘s&#x2F;ftp\.debian\.org&#x2F;$mirror&#x2F;‘ ‘$fn’”);<br>}</p>
<h1 id="create-extended-states-for-apt-avoid-cron-job-warning-if-that"><a href="#create-extended-states-for-apt-avoid-cron-job-warning-if-that" class="headerlink" title="create extended_states for apt (avoid cron job warning if that"></a>create extended_states for apt (avoid cron job warning if that</h1><h1 id="file-does-not-exist"><a href="#file-does-not-exist" class="headerlink" title="file does not exist)"></a>file does not exist)</h1><p>write_config (‘’, “$targetdir&#x2F;var&#x2F;lib&#x2F;apt&#x2F;extended_states”);</p>
<h1 id="allow-ssh-root-login"><a href="#allow-ssh-root-login" class="headerlink" title="allow ssh root login"></a>allow ssh root login</h1><p>syscmd([‘sed’, ‘-i’, ‘s&#x2F;^#?PermitRootLogin.*&#x2F;PermitRootLogin yes&#x2F;‘, “$targetdir&#x2F;etc&#x2F;ssh&#x2F;sshd_config”]);</p>
<p>&#96;&#96;&#96;shell</p>
<p>    可以看出pve也是对部分程序进行了个性化的配置，所以对配置文件的编辑的代码只需要仿照后者，使用syscmd函数，将修改的命令作为参数，写在前者之后即可。</p>
<p><strong>定制安装界面</strong></p>
<p>    在pve-installer.squashfs里的usr&#x2F;bin&#x2F;proxinstall文件中，有create_main_window函数，这个函数的功能是创建图形界面窗口里的各种组件，通过分析这个函数我们可以得到安装UI的结构。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/90857943437e4edf91a77c7e9f77705e~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    顶部的image、中心的htmlview窗口以及下方的cmdbox构成了我们所看到的外观。在此只修改image和htmlview。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/49987692502f454999d981cd118a1417~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>定制安装界面</strong></p>
<p>    在pve-installer.squashfs里的usr&#x2F;bin&#x2F;proxinstall文件中，有create_main_window函数，这个函数的功能是创建图形界面窗口里的各种组件，通过分析这个函数我们可以得到安装UI的结构。</p>
<p>    顶部的image、中心的htmlview窗口以及下方的cmdbox构成了我们所看到的外观。在此只修改image和htmlview。</p>
<p>    顶部的image是在1785行加载pve-installer下var&#x2F;lib&#x2F;pve-installer&#x2F;pve-banner.png来完成的，所以只需要用一个尺寸同样为1024X164的图像替代。</p>
<p>    中心的htmlview是通过在每个create_*函数中调用display_html函数来加载，加载的html文件都位于var&#x2F;lib&#x2F;pve-installer&#x2F;html文件夹下，对应的只需要修改每个html文件就可以实现外观上的替换。</p>
<p>    另外由于窗口运行环境openbox的语言设置默认不是中文，所以使用中文字符展示会出现乱码，因此可以由html加载含中文的图片，以此来展示中文。</p>
<p>    默认输入信息的修改就只需要在proxinstall中找到对应的输入框，修改预设文本。</p>
<p>使用命令unsquashfs将unsquashfs格式的镜像将其解压  </p>
<p>&#96;&#96;&#96;shell<br>$ sudo unsquashfs pve-installer.squashfs<br>Parallel unsquashfs: Using 16 processors<br>20078 inodes (25826 blocks) to write</p>
<p>[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] 25826&#x2F;25826 100%</p>
<p>created 19247 files<br>created 2620 directories<br>created 819 symlinks<br>created 0 devices<br>created 0 fifos</p>
<p>$ ll<br>total 3256748<br>dr-xr-xr-x 12 root root       4096 May 19 19:55 .&#x2F;<br>dr-xr-xr-x 24 root root       4096 May 19 19:29 ..&#x2F;<br>-rw-r–r–  1 root root  348389376 May 19 19:42 pve-installer.squashfs<br>drwxr-xr-x 17 root root       4096 Apr 27 04:23 squashfs-root&#x2F;</p>
<p>…</p>
<p>&#96;&#96;&#96;shell</p>
<p>    解压完成后会出现pve-installer.squashfs镜像盘的squashfs-root&#x2F; 文件夹，进入该文件夹即可看到安装时的引导系统  </p>
<p>&#96;&#96;&#96;shell<br>$ ll<br>total 68<br>drwxr-xr-x 11 root root 4096 Mar 19 03:08 .&#x2F;<br>dr-xr-xr-x 12 root root 4096 May 19 19:55 ..&#x2F;<br>drwxr-xr-x  2 root root 4096 Mar 19 03:08 boot&#x2F;<br>drwxr-xr-x  2 root root 4096 Apr 27 04:25 cdrom&#x2F;<br>drwxr-xr-x  2 root root 4096 Apr 27 04:25 devfs&#x2F;<br>drwxr-xr-x 40 root root 4096 Apr 27 04:25 etc&#x2F;<br>drwxr-xr-x  2 root root 4096 Apr 27 04:25 rpool&#x2F;<br>-rwxr-xr-x  1 root root  376 Apr 26 09:53 .spice-vdagent.sh*<br>drwxr-xr-x  2 root root 4096 Apr 27 04:25 target&#x2F;<br>drwxr-xr-x  2 root root 4096 Apr 27 04:25 tmp&#x2F;<br>drwxr-xr-x  8 root root 4096 Mar 19 03:08 usr&#x2F;<br>drwxr-xr-x  5 root root 4096 Apr 26 09:53 var&#x2F;<br>-rw-r–r–  1 root root   87 Apr 26 09:53 .Xdefaults<br>-rw-r–r–  1 root root  140 Apr 26 09:53 .xinitrc</p>
<p>&#96;&#96;&#96;shell</p>
<p>把准备好的图片替换</p>
<p>&#96;&#96;&#96;shell<br>$ sudo cp &#x2F;home&#x2F;cby&#x2F;Desktop&#x2F;pve-banner.png .</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d5b6be93678b4f5d9461aa6d82d60d97~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>     使用命令解压完成后会出现pve-base.squashfs镜像盘的squashfs-root&#x2F; 文件夹</p>
<p>&#96;&#96;&#96;shell<br>$ sudo unsquashfs pve-base.squashfs<br>Parallel unsquashfs: Using 16 processors<br>12892 inodes (14248 blocks) to write</p>
<p>[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;-] 14248&#x2F;14248 100%</p>
<p>created 10856 files<br>created 1385 directories<br>created 2024 symlinks<br>created 9 devices<br>created 0 fifos</p>
<p>&#96;&#96;&#96;shell</p>
<p> 进入该文件夹即可看到安装后的系统根目录</p>
<p>&#96;&#96;&#96;shell<br>$ ll<br>total 68<br>drwxr-xr-x 17 root root 4096 Apr 27 04:23 .&#x2F;<br>dr-xr-xr-x 12 root root 4096 May 19 19:55 ..&#x2F;<br>lrwxrwxrwx  1 root root    7 Apr 27 04:22 bin -&gt; usr&#x2F;bin&#x2F;<br>drwxr-xr-x  3 root root 4096 Apr 27 04:23 boot&#x2F;<br>drwxr-xr-x  5 root root 4096 Apr 27 04:23 dev&#x2F;<br>drwxr-xr-x 57 root root 4096 Apr 27 04:23 etc&#x2F;<br>drwxr-xr-x  2 root root 4096 Mar 19 16:44 home&#x2F;<br>lrwxrwxrwx  1 root root    7 Apr 27 04:22 lib -&gt; usr&#x2F;lib&#x2F;<br>lrwxrwxrwx  1 root root    9 Apr 27 04:22 lib32 -&gt; usr&#x2F;lib32&#x2F;<br>lrwxrwxrwx  1 root root    9 Apr 27 04:22 lib64 -&gt; usr&#x2F;lib64&#x2F;<br>lrwxrwxrwx  1 root root   10 Apr 27 04:22 libx32 -&gt; usr&#x2F;libx32&#x2F;<br>drwxr-xr-x  2 root root 4096 Apr 27 04:22 media&#x2F;<br>drwxr-xr-x  2 root root 4096 Apr 27 04:22 mnt&#x2F;<br>drwxr-xr-x  2 root root 4096 Apr 27 04:22 opt&#x2F;<br>drwxr-xr-x  2 root root 4096 Mar 19 16:44 proc&#x2F;<br>drwx——  2 root root 4096 Apr 27 04:23 root&#x2F;<br>drwxr-xr-x  5 root root 4096 Apr 27 04:23 run&#x2F;<br>lrwxrwxrwx  1 root root    8 Apr 27 04:22 sbin -&gt; usr&#x2F;sbin&#x2F;<br>drwxr-xr-x  2 root root 4096 Apr 27 04:22 srv&#x2F;<br>drwxr-xr-x  2 root root 4096 Mar 19 16:44 sys&#x2F;<br>drwxrwxrwt  2 root root 4096 Apr 27 04:23 tmp&#x2F;<br>drwxr-xr-x 13 root root 4096 Apr 27 04:22 usr&#x2F;<br>drwxr-xr-x 11 root root 4096 Apr 27 04:22 var&#x2F;</p>
<p>&#96;&#96;&#96;shell</p>
<p>修改完需要定制的文件系统后，使用如下命进行打包</p>
<p>&#96;&#96;&#96;shell<br>$ sudo mksquashfs  squashfs-root&#x2F; pve-installer.squashfs<br>Parallel mksquashfs: Using 16 processors<br>Creating 4.0 filesystem on pve-installer.squashfs-, block size 131072.<br>[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] 25008&#x2F;25008 100%</p>
<p>Exportable Squashfs 4.0 filesystem, gzip compressed, data block size 131072<br>  compressed data, compressed metadata, compressed fragments,<br>  compressed xattrs, compressed ids<br>  duplicates are removed<br>Filesystem size 340223.99 Kbytes (332.25 Mbytes)<br>  33.70% of uncompressed filesystem size (1009698.26 Kbytes)<br>Inode table size 225637 bytes (220.35 Kbytes)<br>  29.06% of uncompressed inode table size (776542 bytes)<br>Directory table size 235667 bytes (230.14 Kbytes)<br>  38.69% of uncompressed directory table size (609117 bytes)<br>Xattr table size 673 bytes (0.66 Kbytes)<br>  7.40% of uncompressed xattr table size (9096 bytes)<br>Number of duplicate files found 853<br>Number of inodes 22686<br>Number of files 19247<br>Number of fragments 1982<br>Number of symbolic links  819<br>Number of device nodes 0<br>Number of fifo nodes 0<br>Number of socket nodes 0<br>Number of directories 2620<br>Number of ids (unique uids + gids) 9<br>Number of uids 3<br>  root (0)<br>  man (6)<br>  syslog (104)<br>Number of gids 7<br>  root (0)<br>  shadow (42)<br>  bluetooth (112)<br>  utmp (43)<br>  staff (50)<br>  man (12)<br>  tss (111)</p>
<p>&#96;&#96;&#96;shell</p>
<p>使用该名进行制作ISO镜像盘</p>
<p>&#96;&#96;&#96;shell<br>$ sudo xorriso -as mkisofs -o proxmox-ve_6.4-1.iso -r -V ‘inspur’ –grub2-mbr proxmox.mbr –protective-msdos-label -efi-boot-part –efi-boot-image  -c ‘&#x2F;boot&#x2F;boot.cat’ -b ‘&#x2F;boot&#x2F;grub&#x2F;i386-pc&#x2F;eltorito.img’ -no-emul-boot -boot-load-size 4 -boot-info-table –grub2-boot-info -eltorito-alt-boot -e ‘&#x2F;efi.img’ -no-emul-boot .<br>xorriso 1.5.2 : RockRidge filesystem manipulator, libburnia project.</p>
<p>Drive current: -outdev ‘stdio:proxmox-ve_6.4-1.iso’<br>Media current: stdio file, overwriteable<br>Media status : is blank<br>Media summary: 0 sessions, 0 data blocks, 0 data, 78.0g free<br>xorriso : WARNING : -volid text does not comply to ISO 9660 &#x2F; ECMA 119 rules<br>Added to ISO image: directory ‘&#x2F;‘&#x3D;’&#x2F;home&#x2F;cby&#x2F;chenby’<br>xorriso : UPDATE :   32892 files added in 1 seconds<br>xorriso : UPDATE :   32892 files added in 1 seconds<br>xorriso : NOTE : Copying to System Area: 512 bytes from file ‘&#x2F;home&#x2F;cby&#x2F;chenby&#x2F;proxmox.mbr’<br>libisofs: NOTE : Automatically adjusted MBR geometry to 1021&#x2F;155&#x2F;32<br>xorriso : UPDATE :  0.66% done<br>xorriso : UPDATE :  8.03% done<br>xorriso : UPDATE :  19.34% done<br>xorriso : UPDATE :  34.06% done, estimate finish Wed May 19 19:46:25 2021<br>xorriso : UPDATE :  48.84% done, estimate finish Wed May 19 19:46:24 2021<br>xorriso : UPDATE :  61.72% done, estimate finish Wed May 19 19:46:24 2021<br>xorriso : UPDATE :  73.41% done, estimate finish Wed May 19 19:46:25 2021<br>xorriso : UPDATE :  82.19% done, estimate finish Wed May 19 19:46:25 2021<br>xorriso : UPDATE :  92.15% done<br>xorriso : UPDATE :  97.28% done<br>ISO image produced: 1264917 sectors<br>Written to medium : 1264917 sectors at LBA 0<br>Writing to ‘stdio:proxmox-ve_6.4-1.iso’ completed successfully.</p>
<p>&#96;&#96;&#96;shell</p>
<p>    使用新创建的ISO镜像盘启动后，已出现修改过后的背景图，以此类推，通过修改根目录文件，可以实现完全定制化的pve系统。  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f2598c6d809e4791b7cac905c02fe787~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    若修改安装后的管理后台的页面，在proxmox&#x2F;packages目录下找到pve-manager的deb安装包。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2830eb0747a04abab976cb403960c347~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>&#96;&#96;&#96;shell<br>$ ls | grep manager<br>pve-ha-manager_3.1-1_amd64.deb<br>pve-manager_6.4-4_amd64.deb</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>$ mkdir extract，在当前目录下新建文件夹，用于存放解压后的内容<br>$ mkdir extract&#x2F;DEBIAN，新建DEBIAN目录用于存放包的控制信息<br>$ sudo dpkg -X .&#x2F;pve-manager_6.4-4_amd64.deb extract&#x2F;，将要修改的deb包解压到extract目录下，可以看到：</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3d513af1f6a44bfb9788cd5bcc18ca7c~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    在其解压出来的包内修改所需的代码后，导入debian包的控制信息，可以使用命令再次打包成deb包。  </p>
<p>&#96;&#96;&#96;shell<br>$ sudo dpkg-deb -e .&#x2F;pve-manager_6.4-4_amd64.deb extract&#x2F;DEBIAN&#x2F;<br>$ ls extract&#x2F;DEBIAN&#x2F;<br>conffiles  control  md5sums  postinst  postrm  preinst  prerm  triggers</p>
<p>$ sudo dpkg-deb -b .&#x2F;extract 123.deb<br>dpkg-deb: building package ‘pve-manager’ in ‘123.deb’.</p>
<p>$ ll 123.deb<br>-rw-r–r– 1 root root 2042764 May 19 21:54 123.deb</p>
<p>&#96;&#96;&#96;shell</p>
<p>查看deb包的详细信息。  </p>
<p>&#96;&#96;&#96;shell<br>$ dpkg-deb -I 123.deb<br> new Debian package, version 2.0.<br> size 2042764 bytes: control archive&#x3D;16976 bytes.<br>     320 bytes,    10 lines      conffiles<br>    1532 bytes,    15 lines      control<br>   56553 bytes,   574 lines      md5sums<br>    3246 bytes,   101 lines   *  postinst             #!&#x2F;bin&#x2F;sh<br>    1645 bytes,    44 lines   *  postrm               #!&#x2F;bin&#x2F;sh<br>     192 bytes,     5 lines   *  preinst              #!&#x2F;bin&#x2F;sh<br>     626 bytes,    24 lines   *  prerm                #!&#x2F;bin&#x2F;sh<br>      33 bytes,     1 lines      triggers<br> Package: pve-manager<br> Version: 6.4-4<br> Architecture: amd64<br> Maintainer: Proxmox Support Team <a href="mailto:&#x73;&#117;&#x70;&#x70;&#x6f;&#x72;&#116;&#64;&#x70;&#114;&#x6f;&#x78;&#x6d;&#111;&#120;&#46;&#99;&#111;&#109;">&#x73;&#117;&#x70;&#x70;&#x6f;&#x72;&#116;&#64;&#x70;&#114;&#x6f;&#x78;&#x6d;&#111;&#120;&#46;&#99;&#111;&#109;</a><br> Installed-Size: 9876<br> Depends: apt-transport-https | apt (&gt;&#x3D; 1.5~), ca-certificates, cstream, dtach, fonts-font-awesome, gdisk, hdparm, ifenslave (&gt;&#x3D; 2.6) | ifupdown2 (&gt;&#x3D; 2.0.1-1+pve8), libapt-pkg-perl, libc6 (&gt;&#x3D; 2.14), libcrypt-ssleay-perl, libfile-readbackwards-perl, libfilesys-df-perl, libjs-extjs (&gt;&#x3D; 6.0.1), libjson-perl, liblwp-protocol-https-perl, libnet-dns-perl, libproxmox-acme-perl, libpve-access-control (&gt;&#x3D; 6.0-6), libpve-cluster-api-perl, libpve-cluster-perl (&gt;&#x3D; 6.1-6), libpve-common-perl (&gt;&#x3D; 6.2-2), libpve-guest-common-perl (&gt;&#x3D; 3.1-5), libpve-http-server-perl (&gt;&#x3D; 3.2-1), libpve-storage-perl (&gt;&#x3D; 6.3-6), librados2-perl, libtemplate-perl, libterm-readline-gnu-perl, liburi-perl, libuuid-perl, libwww-perl (&gt;&#x3D; 6.04-1), logrotate, lsb-base, lzop, zstd, novnc-pve, pciutils, perl (&gt;&#x3D; 5.10.0-19), postfix | mail-transport-agent, proxmox-mini-journalreader, proxmox-widget-toolkit (&gt;&#x3D; 2.5-2), pve-cluster (&gt;&#x3D; 6.0-4), pve-container (&gt;&#x3D; 2.0-21), pve-docs, pve-firewall, pve-ha-manager, pve-i18n (&gt;&#x3D; 1.0-3), pve-xtermjs (&gt;&#x3D; 0.1-1), qemu-server (&gt;&#x3D; 6.2-17), rsync, spiceterm, systemd, vncterm, wget<br> Suggests: libpve-network-perl (&gt;&#x3D; 0.5-1)<br> Conflicts: vlan, vzdump<br> Breaks: libpve-network-perl (&lt;&lt; 0.5-1)<br> Replaces: vlan, vzdump<br> Provides: vlan, vzdump<br> Section: admin<br> Priority: optional<br> Description: Proxmox Virtual Environment Management Tools<br>  This package contains the Proxmox Virtual Environment management tools.</p>
<p>&#96;&#96;&#96;shell</p>
<p>    将打好的deb包放回到原目录后，在进行ISO的打包，这样在安装系统后的镜像即可是定制化的页面。  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3b5b253b5505485a9bfb75681a811ef9~tplv-k3u1fbpfcp-zoom-1.image"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Prometheus+Grafana监控系统</title>
    <url>/2021/12/30/2021-12-30-Prometheus+Grafana%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h3 id="Prometheus-vs-Zabbix"><a href="#Prometheus-vs-Zabbix" class="headerlink" title="Prometheus vs Zabbix"></a>Prometheus vs Zabbix</h3><p>    Zabbix的客户端更多是只做上报的事情，push模式。而Prometheus则是客户端本地也会存储监控数据，服务端定时来拉取想要的数据。</p>
<p> Zabbix的客户端agent可以比较方便的通过脚本来读取机器内数据库、日志等文件来做上报。zabbix的客户端agent可以比较方便的通过脚本来读取机器内数据库、日志等文件来做上报。Prometheus的上报客户端则分为不同语言的SDK和不同用途的exporter两种，比如如果你要监控机器状态、mysql性能等，有大量已经成熟的exporter来直接开箱使用，通过http通信来对服务端提供信息上报（server去pull信息）；</p>
<p>Zabbix’s client is more of only reporting things, push mode. In Prometheus, the client also stores monitoring data locally, and the server regularly pulls the desired data.</p>
<p>     Zabbix’s client agent can easily read the database, log and other files in the machine through scripts for reporting. The zabbix client agent can easily read the database, log and other files in the machine through scripts for reporting. Prometheus reporting clients are divided into SDKs in different languages and exporters for different purposes. For example, if you want to monitor machine status, mysql performance, etc., there are a large number of mature exporters to use directly out of the box, and serve through HTTP communication. The terminal provides information reporting (server to pull information);</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d1528e9872de49549f77699874d9de9a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h3 id="安装Prometheus："><a href="#安装Prometheus：" class="headerlink" title="安装Prometheus："></a>安装Prometheus：</h3><p><strong>install Prometheus</strong></p>
<p>    官网下载地址：</p>
<p>Official website download address</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://prometheus.io/download/</span><br></pre></td></tr></table></figure>

<p>    下载您想要的版本后，进行安装使用即可。</p>
<p>After downloading the version you want, install it and use it</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~$ wget https://github.com/prometheus/prometheus/releases/download/v2.21.0/prometheus-2.21.0.linux-amd64.tar.gz</span><br><span class="line">cby@cby-Inspiron-7577:~$ tar xvf prometheus-2.21.0.linux-amd64.tar.gz </span><br><span class="line">prometheus-2.21.0.linux-amd64/</span><br><span class="line">prometheus-2.21.0.linux-amd64/LICENSE</span><br><span class="line">prometheus-2.21.0.linux-amd64/prometheus</span><br><span class="line">prometheus-2.21.0.linux-amd64/promtool</span><br><span class="line">prometheus-2.21.0.linux-amd64/prometheus.yml</span><br><span class="line">prometheus-2.21.0.linux-amd64/NOTICE</span><br><span class="line">prometheus-2.21.0.linux-amd64/console\_libraries/</span><br><span class="line">prometheus-2.21.0.linux-amd64/console\_libraries/menu.lib</span><br><span class="line">prometheus-2.21.0.linux-amd64/console\_libraries/prom.lib</span><br><span class="line">prometheus-2.21.0.linux-amd64/consoles/</span><br><span class="line">prometheus-2.21.0.linux-amd64/consoles/node-overview.html</span><br><span class="line">prometheus-2.21.0.linux-amd64/consoles/node.html</span><br><span class="line">prometheus-2.21.0.linux-amd64/consoles/prometheus.html</span><br><span class="line">prometheus-2.21.0.linux-amd64/consoles/node-cpu.html</span><br><span class="line">prometheus-2.21.0.linux-amd64/consoles/index.html.example</span><br><span class="line">prometheus-2.21.0.linux-amd64/consoles/prometheus-overview.html</span><br><span class="line">prometheus-2.21.0.linux-amd64/consoles/node-disk.html</span><br></pre></td></tr></table></figure>

<p>    解压后进入文件夹内即可看到该程序。同时即可使用。</p>
<p>After decompression, enter the folder to see the program. Can be used at the same time</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~/prometheus-2.21.0.linux-amd64$ ll</span><br><span class="line">总用量 161140</span><br><span class="line">drwxr-xr-x  4 cby cby     4096 9月  11 21:30 ./</span><br><span class="line">drwxr-xr-x 22 cby cby     4096 10月  5 00:18 ../</span><br><span class="line">drwxr-xr-x  2 cby cby     4096 9月  11 21:29 console\_libraries/</span><br><span class="line">drwxr-xr-x  2 cby cby     4096 9月  11 21:29 consoles/</span><br><span class="line">-rw-r--r--  1 cby cby    11357 9月  11 21:29 LICENSE</span><br><span class="line">-rw-r--r--  1 cby cby     3420 9月  11 21:29 NOTICE</span><br><span class="line">-rwxr-xr-x  1 cby cby 88471209 9月  11 19:37 prometheus\*</span><br><span class="line">-rw-r--r--  1 cby cby      926 9月  11 21:29 prometheus.yml</span><br><span class="line">-rwxr-xr-x  1 cby cby 76493104 9月  11 19:39 promtool\*</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>    查看一下版本：  </p>
<p>Check the version</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~/prometheus-2.21.0.linux-amd64$ ./prometheus --version</span><br><span class="line">prometheus, version 2.21.0 (branch: HEAD, revision: e83ef207b6c2398919b69cd87d2693cfc2fb4127)</span><br><span class="line">  build user:       root@a4d9bea8479e</span><br><span class="line">  build date:       20200911-11:35:02</span><br><span class="line">  go version:       go1.15.2</span><br></pre></td></tr></table></figure>

<p>    查看启动sever文件：  </p>
<p>View startup sever file</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~/prometheus-2.21.0.linux-amd64$ cat prometheus.yml</span><br><span class="line"># my global config</span><br><span class="line">global:</span><br><span class="line">  scrape\_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.</span><br><span class="line">  evaluation\_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.</span><br><span class="line">  # scrape\_timeout is set to the global default (10s).</span><br><span class="line"></span><br><span class="line"># Alertmanager configuration</span><br><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static\_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      # - alertmanager:9093</span><br><span class="line"></span><br><span class="line"># Load rules once and periodically evaluate them according to the global &#x27;evaluation\_interval&#x27;.</span><br><span class="line">rule\_files:</span><br><span class="line">  # - &quot;first\_rules.yml&quot;</span><br><span class="line">  # - &quot;second\_rules.yml&quot;</span><br><span class="line"></span><br><span class="line"># A scrape configuration containing exactly one endpoint to scrape:</span><br><span class="line"># Here it&#x27;s Prometheus itself.</span><br><span class="line">scrape\_configs:</span><br><span class="line">  # The job name is added as a label \`job=&lt;job\_name&gt;\` to any timeseries scraped from this config.</span><br><span class="line">  - job\_name: &#x27;prometheus&#x27;</span><br><span class="line"></span><br><span class="line">    # metrics\_path defaults to &#x27;/metrics&#x27;</span><br><span class="line">    # scheme defaults to &#x27;http&#x27;.</span><br><span class="line"></span><br><span class="line">    static\_configs:</span><br><span class="line">    - targets: \[&#x27;localhost:9090&#x27;\]</span><br></pre></td></tr></table></figure>

<p>    其大致分为四部分：</p>
<p>It is roughly divided into four parts:</p>
<ul>
<li><p>global：全局配置，其中scrape_interval表示抓取一次数据的间隔时间，evaluation_interval表示进行告警规则检测的间隔时间；</p>
</li>
<li><p>global: global configuration, in which scrape_interval represents the interval of data capture, evaluation_interval represents the interval of alarm rule detection;</p>
</li>
<li></li>
<li><p>alerting：告警管理器（Alertmanager）的配置，目前还没有安装Alertmanager；</p>
</li>
<li><p>alerting: The configuration of the alert manager (Alertmanager), Alertmanager is not installed yet;</p>
</li>
<li></li>
<li><p>rule_files：告警规则有哪些；</p>
</li>
<li><p>rule_files: what are the alarm rules;</p>
</li>
<li></li>
<li><p>scrape_configs：抓取监控信息的目标。一个job_name就是一个目标，其targets就是采集信息的IP和端口。这里默认监控了Prometheus自己，可以通过修改这里来修改Prometheus的监控端口。Prometheus的每个exporter都会是一个目标，它们可以上报不同的监控信息，比如机器状态，或者mysql性能等等，不同语言sdk也会是一个目标，它们会上报你自定义的业务监控信息。</p>
</li>
<li><p>scrape_configs: The goal of grabbing monitoring information. A job_name is a target, and its targets are the IP and port for collecting information. Prometheus itself is monitored by default here, and the monitoring port of Prometheus can be modified by modifying this. Each exporter of Prometheus will be a target, they can report different monitoring information, such as machine status, or mysql performance, etc., different language SDK will also be a target, they will report your customized business monitoring information.</p>
</li>
</ul>
<p>    启动运行sever：</p>
<p>Start running sever</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~/prometheus-2.21.0.linux-amd64$ ./prometheus --config.file=prometheus.yml</span><br></pre></td></tr></table></figure>

<p>    运行后，使用默认9090端口即可进行访问，若无法访问您可以查看一下是否有防火墙的限制，若没有限制，那就看一下是否正常启动，有端口的监听。  </p>
<p>    After running, you can use the default port 9090 to access it. If you can’t access it, you can check if there is a firewall restriction. If there is no restriction, check if it is started normally and there is port monitoring.</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1c2fcbebeecc41da9186e09c2721645b~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/836e9218798543c78b610fe580c510f0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>添加机器的监控器：</strong></p>
<p><strong>Add machine monitor</strong></p>
<p>    在官网的下载页面中，可以找到 node_exporter 这个tar包，这个监空插件可以监控基础的硬件信息，例如CPU内存硬盘等信息，node_exporter本身也是一个http服务可以进行直接调用使用哦。</p>
<p>    On the download page of the official website, you can find the tar package of node_exporter. This plug-in can monitor basic hardware information, such as CPU memory and hard disk information. The node_exporter itself is also an http service that can be used directly.</p>
<p>    下载最新的此插件，同时进行解压，并运行：</p>
<p>Download the latest plug-in, unzip at the same time, and run</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~$ wget https://github.com/prometheus/node\_exporter/releases/download/v1.0.1/node\_exporter-1.0.1.linux-amd64.tar.gz</span><br><span class="line">cby@cby-Inspiron-7577:~$ cd node\_exporter-1.0.1.linux-amd64/</span><br><span class="line">cby@cby-Inspiron-7577:~/node\_exporter-1.0.1.linux-amd64$ ls</span><br><span class="line">LICENSE  node\_exporter  NOTICE</span><br><span class="line">cby@cby-Inspiron-7577:~/node\_exporter-1.0.1.linux-amd64$ ./node\_exporter </span><br><span class="line">level=info ts=2020-10-04T16:31:41.858Z caller=node\_exporter.go:177 msg=&quot;Starting node\_exporter&quot; version=&quot;(version=1.0.1, branch=HEAD, revision=3715be6ae899f2a9b9dbfd9c39f3e09a7bd4559f)&quot;</span><br><span class="line">level=info ts=2020-10-04T16:31:41.858Z caller=node\_exporter.go:178 msg=&quot;Build context&quot; build\_context=&quot;(go=go1.14.4, user=root@1f76dbbcfa55, date=20200616-12:44:12)&quot;</span><br><span class="line">level=info ts=2020-10-04T16:31:41.859Z caller=node\_exporter.go:105 msg=&quot;Enabled collectors&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>    可以使用curl进行测试一下是否正常启动</p>
<p> You can use curl to test whether it starts normally</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~$ curl http://localhost:9100/metrics</span><br></pre></td></tr></table></figure>

<p>    若可以正常访问，那就可以在prometheus.yml文件中添加一个target</p>
<p>If you can access normally, you can add a target in the prometheus.yml file</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\# my global config</span><br><span class="line">global:</span><br><span class="line">  scrape\_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.</span><br><span class="line">  evaluation\_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.</span><br><span class="line">  # scrape\_timeout is set to the global default (10s).</span><br><span class="line"></span><br><span class="line"># Alertmanager configuration</span><br><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static\_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      # - alertmanager:9093</span><br><span class="line"></span><br><span class="line"># Load rules once and periodically evaluate them according to the global &#x27;evaluation\_interval&#x27;.</span><br><span class="line">rule\_files:</span><br><span class="line">  # - &quot;first\_rules.yml&quot;</span><br><span class="line">  # - &quot;second\_rules.yml&quot;</span><br><span class="line"></span><br><span class="line"># A scrape configuration containing exactly one endpoint to scrape:</span><br><span class="line"># Here it&#x27;s Prometheus itself.</span><br><span class="line">scrape\_configs:</span><br><span class="line">  # The job name is added as a label \`job=&lt;job\_name&gt;\` to any timeseries scraped from this config.</span><br><span class="line">  - job\_name: &#x27;prometheus&#x27;</span><br><span class="line"></span><br><span class="line">    # metrics\_path defaults to &#x27;/metrics&#x27;</span><br><span class="line">    # scheme defaults to &#x27;http&#x27;.</span><br><span class="line"></span><br><span class="line">    static\_configs:</span><br><span class="line">    - targets: \[&#x27;localhost:9090&#x27;\]</span><br><span class="line"></span><br><span class="line">  - job\_name: &#x27;server&#x27;</span><br><span class="line">    static\_configs:</span><br><span class="line">    - targets: \[&#x27;localhost:9100&#x27;\]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>    在标签栏的 Status –&gt; Targets 中可以：</p>
<p>In Status –&gt; Targets in the tab bar, you can</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/548ef0ace1b941d6ac554e5064c5bbce~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h3 id="安装Grafana："><a href="#安装Grafana：" class="headerlink" title="安装Grafana："></a>安装Grafana：</h3><p><strong>Install Grafana</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~$ sudo apt-get install -y adduser libfontconfig1</span><br><span class="line">cby@cby-Inspiron-7577:~$ wget https://dl.grafana.com/oss/release/grafana\_7.2.0\_amd64.deb</span><br><span class="line"></span><br><span class="line">cby@cby-Inspiron-7577:~$ sudo dpkg -i grafana\_7.2.0\_amd64.deb</span><br><span class="line">正在选中未选择的软件包 grafana。</span><br><span class="line">(正在读取数据库 ... 系统当前共安装有 211277 个文件和目录。)</span><br><span class="line">准备解压 grafana\_7.2.0\_amd64.deb  ...</span><br><span class="line">正在解压 grafana (7.2.0) ...</span><br><span class="line">正在设置 grafana (7.2.0) ...</span><br><span class="line">正在添加系统用户&quot;grafana&quot; (UID 130)...</span><br><span class="line">正在将新用户&quot;grafana&quot; (UID 130)添加到组&quot;grafana&quot;...</span><br><span class="line">无法创建主目录&quot;/usr/share/grafana&quot;。</span><br><span class="line">### NOT starting on installation, please execute the following statements to configure grafana to start automatically using systemd</span><br><span class="line"> sudo /bin/systemctl daemon-reload</span><br><span class="line"> sudo /bin/systemctl enable grafana-server</span><br><span class="line">### You can start grafana-server by executing</span><br><span class="line"> sudo /bin/systemctl start grafana-server</span><br><span class="line">正在处理用于 systemd (245.4-4ubuntu3.2) 的触发器 ...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>    安装完成后，进行启动：  </p>
<p>After the installation is complete, start</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cby@cby-Inspiron-7577:~$ sudo systemctl start grafana-server.service</span><br><span class="line">cby@cby-Inspiron-7577:~$ sudo systemctl status grafana-server.service</span><br><span class="line">\[sudo\] cby 的密码：</span><br><span class="line">对不起，请重试。</span><br><span class="line">\[sudo\] cby 的密码：</span><br><span class="line">对不起，请重试。</span><br><span class="line">\[sudo\] cby 的密码：</span><br><span class="line">● grafana-server.service - Grafana instance</span><br><span class="line">     Loaded: loaded (/lib/systemd/system/grafana-server.service; disabled; vendor preset: enabled)</span><br><span class="line">     Active: active (running) since Mon 2020-10-05 00:02:59 CST; 40min ago</span><br><span class="line">       Docs: http://docs.grafana.org</span><br><span class="line">   Main PID: 1521572 (grafana-server)</span><br><span class="line">      Tasks: 14 (limit: 18689)</span><br><span class="line">     Memory: 25.3M</span><br><span class="line">     CGroup: /system.slice/grafana-server.service</span><br><span class="line">             └─1521572 /usr/sbin/grafana-server --config=/etc/grafana/grafana.ini --pidfile=/var/run/grafa</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ca97d6954de84f6bb1b5df3b80b7912f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    默认端口为3000 ，使用IP加端口即可进行访问，默认用户名密码是admin，登录后即可看到首页。在设置中进行添加Prometheus监控数据。  </p>
<p>    The default port is 3000, you can access by using IP plus port, the default user name and password is admin, you can see the home page after logging in. Add Prometheus monitoring data in the settings.</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4c3edba91a864cd998e1e0e53150c403~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/05bbc9bcf4bc46f7b15d7a630a1c8a4d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    添加监控数据后，导入一个监控面板，或者勤劳的人们可以自行进行配置面板，哇哈哈哈，同时可以在官方的面板界面中寻找到一个心仪的面板</p>
<p>地址为：<a href="https://grafana.com/dashboards">https://grafana.com/dashboards</a></p>
<p>下载面板的json后，可以进行导入面板。</p>
<p>    After adding monitoring data, import a monitoring panel, or industrious people can configure the panel by themselves, wow ha ha ha, and you can find a favorite panel in the official panel interface</p>
<p>The address is: <a href="https://grafana.com/dashboards">https://grafana.com/dashboards</a></p>
<p>After downloading the json of the panel, you can import the panel.</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eadf9f2650ae4a34a923e622219ff3f6~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>导入后即可显示看到花里胡哨的面版了</p>
<p>After importing, you can see the bells and whistles</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8188207dea0a440481d12f89601f93d7~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    面板添加后，必然需要报警。可以使用onealert，进行告警。  </p>
<p><a href="https://caweb.aiops.com/#/Application/newBuild/grafana/0">https://caweb.aiops.com/#/Application/newBuild/grafana/0</a></p>
<p>    After the panel is added, an alarm is necessary. You can use onealert to alert.</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4eece143b6e245859c112c2cf08a5d4f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b202d06e2f964dbebc2528faa54c4779~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/61f421538f5b48a9bf5398a25c510e8c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>到这里环境已经配置完成</p>
<p>The environment has been configured here</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bc597a7d80f54efe8b755c0b6e530c51~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Ubuntu 通过 Netplan 配置网络教程</title>
    <url>/2021/12/30/2021-12-30-Ubuntu_%E9%80%9A%E8%BF%87_Netplan_%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>Ubuntu 通过 Netplan 配置网络教程</strong></p>
<p>Ubuntu through Netplan configuration network tutorial</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f57883d164c4b79a4210075234a7ee8~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>一、Netplan 配置流程</strong></p>
<p>1. Netplan configuration process</p>
<p><strong>1、Netplan默认配置文件在&#x2F;etc&#x2F;netplan目录下。您可以使用以下命令找到：</strong></p>
<p>1. The default configuration file of Netplan is in the &#x2F;etc&#x2F;netplan directory. You can find it with the following command:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /etc/netplan/</span><br></pre></td></tr></table></figure>

<p><strong>就可以看到配置文件名称。</strong></p>
<p>You can see the configuration file name.</p>
<p><strong>2、查看Netplan网络配置文件的内容，执行以下命令：</strong></p>
<p>2. View the contents of the Netplan network configuration file and execute the following command:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /etc/netplan/*.yaml</span><br></pre></td></tr></table></figure>

<p><strong>3、现在你需要在任何编辑器中打开配置文件： 由于我使用 vim 编辑器来编辑配置文件，所以我将运行：</strong></p>
<p>3. Now you need to open the configuration file in any editor: Since I use the vim editor to edit the configuration file, I will run:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/netplan/*.yaml</span><br></pre></td></tr></table></figure>

<p><strong>根据您的网络需要更新配置文件。对于静态 IP 寻址，添加 IP 地址、网关、DNS 信息，而对于动态 IP 寻址，无需添加此信息，因为它将从 DHCP 服务器获取此信息。使用以下语法编辑配置文件。</strong></p>
<p>Update the configuration file according to your network needs. For static IP addressing, add IP address, gateway, DNS information, and for dynamic IP addressing, there is no need to add this information because it will get this information from the DHCP server. Use the following syntax to edit the configuration file.</p>
<p><strong>4、在应用任何更改之前，我们将测试配置文件。</strong></p>
<p>4. We will test the configuration file before applying any changes.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo netplan try</span><br></pre></td></tr></table></figure>

<p><strong>如果没有问题，它将返回配置接受消息。如果配置文件未通过测试，它将恢复为以前的工作配置。</strong></p>
<p>If there is no problem, it will return a configuration acceptance message. If the configuration file fails the test, it will revert to the previous working configuration.</p>
<p><strong>5、运行以下命令来应用新配置：</strong></p>
<p>5. Run the following command to apply the new configuration:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo netplan apply</span><br></pre></td></tr></table></figure>

<p><strong>6、成功应用所有配置后，通过运行以下命令重新启动 Network-Manager 服务：</strong></p>
<p>6. After successfully applying all the configurations, restart the Network-Manager service by running the following command:</p>
<p><strong>如果是桌面版：</strong></p>
<p>If it is the desktop version:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart system-networkd</span><br></pre></td></tr></table></figure>

<p><strong>如果您使用的是 Ubuntu 服务器，请改用以下命令：</strong></p>
<p>If you are using an Ubuntu server, use the following command instead:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart network-manager</span><br></pre></td></tr></table></figure>

<p><strong>7、验证 IP 地址</strong></p>
<p>7. Verify the IP address</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ip a</span><br></pre></td></tr></table></figure>

<p><strong>二、Netplan 配置文件详解</strong></p>
<p>2. Detailed explanation of Netplan configuration file </p>
<p><strong>1、使用 DHCP：</strong></p>
<p>1. Use DHCP:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    enp3s0:</span><br><span class="line">      dhcp4: true</span><br></pre></td></tr></table></figure>

<p><strong>2、使用静态 IP：</strong></p>
<p>2. Use static IP:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    enp3s0:</span><br><span class="line">      addresses:</span><br><span class="line">        - 10.0.0.10/8</span><br><span class="line">      gateway4: 10.0.0.1</span><br><span class="line">      nameservers:</span><br><span class="line">          search: [mydomain, otherdomain]</span><br><span class="line">          addresses: [10.0.0.5, 1.1.1.1]</span><br></pre></td></tr></table></figure>

<p><strong>3、多个网口 DHCP：</strong></p>
<p>3. Multiple network ports DHCP:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  ethernets:</span><br><span class="line">    enred:</span><br><span class="line">      dhcp4: yes</span><br><span class="line">      dhcp4-overrides:</span><br><span class="line">        route-metric: 100</span><br><span class="line">    engreen:</span><br><span class="line">      dhcp4: yes</span><br><span class="line">      dhcp4-overrides:</span><br><span class="line">        route-metric: 200</span><br></pre></td></tr></table></figure>

<p><strong>4、连接开放的 WiFi（无密码）：</strong></p>
<p>4. Connect to open WiFi (without password):</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  wifis:</span><br><span class="line">    wl0:</span><br><span class="line">      access-points:</span><br><span class="line">        opennetwork: &#123;&#125;</span><br><span class="line">      dhcp4: yes</span><br></pre></td></tr></table></figure>

<p><strong>5、连接 WPA 加密的 WiFi：</strong></p>
<p>5. Connect to WPA encrypted WiFi:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  wifis:</span><br><span class="line">    wlp2s0b1:</span><br><span class="line">      dhcp4: no</span><br><span class="line">      dhcp6: no</span><br><span class="line">      addresses: [10.0.0.10/8]</span><br><span class="line">      gateway4: 10.0.0.1</span><br><span class="line">      nameservers:</span><br><span class="line">        addresses: [10.0.0.5, 8.8.8.8]</span><br><span class="line">      access-points:</span><br><span class="line">        &quot;network_ssid_name&quot;:</span><br><span class="line">          password: &quot;**********&quot;</span><br></pre></td></tr></table></figure>

<p><strong>6、在单网卡上使用多个 IP 地址（同一网段）：</strong></p>
<p>6. Use multiple IP addresses on a single network card (same network segment):</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    enp3s0:</span><br><span class="line">     addresses:</span><br><span class="line">       - 10.0.0.10/8</span><br><span class="line">       - 10.0.0.10/8</span><br><span class="line">     gateway4: 10.0.0.1</span><br></pre></td></tr></table></figure>

<p><strong>7、在单网卡使用多个不同网段的 IP 地址：</strong></p>
<p>7. Use multiple IP addresses of different network segments on a single network card:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    enp3s0:</span><br><span class="line">     addresses:</span><br><span class="line">       - 9.0.0.9/24</span><br><span class="line">       - 10.0.0.10/24</span><br><span class="line">       - 11.0.0.11/24</span><br><span class="line">     #gateway4:    # unset, since we configure routes below</span><br><span class="line">     routes:</span><br><span class="line">       - to: 0.0.0.0/0</span><br><span class="line">         via: 9.0.0.1</span><br><span class="line">         metric: 100</span><br><span class="line">       - to: 0.0.0.0/0</span><br><span class="line">         via: 10.0.0.1</span><br><span class="line">         metric: 100</span><br><span class="line">       - to: 0.0.0.0/0</span><br><span class="line">         via: 11.0.0.1</span><br><span class="line">         metric: 100</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/65712ff42e42446097889a0b6bd631b1~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>35篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/86040f64eabc4141a87a111afab1d53c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>elk7.15.1安装部署搭建</title>
    <url>/2021/12/30/2021-12-30-elk7.15.1%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p><strong>ELK简介</strong></p>
<p>ELK是Elasticsearch、Logstash、Kibana三大开源框架首字母大写简称（但是后期出现的Filebeat（beats中的一种）可以用来替代Logstash的数据收集功能，比较轻量级）。市面上也被成为Elastic Stack。</p>
<p><strong>Filebeat</strong>是用于转发和集中日志数据的轻量级传送工具。Filebeat监视您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或 Logstash进行索引。Filebeat的工作方式如下：启动Filebeat时，它将启动一个或多个输入，这些输入将在为日志数据指定的位置中查找。对于Filebeat所找到的每个日志，Filebeat都会启动收集器。每个收集器都读取单个日志以获取新内容，并将新日志数据发送到libbeat，libbeat将聚集事件，并将聚集的数据发送到为Filebeat配置的输出。</p>
<p><strong>Logstash</strong>是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。Logstash能够动态地采集、转换和传输数据，不受格式或复杂度的影响。利用Grok从非结构化数据中派生出结构，从IP地址解码出地理坐标，匿名化或排除敏感字段，并简化整体处理过程。</p>
<p><strong>Elasticsearch</strong>是Elastic Stack核心的分布式搜索和分析引擎，是一个基于Lucene、分布式、通过Restful方式进行交互的近实时搜索平台框架。Elasticsearch为所有类型的数据提供近乎实时的搜索和分析。无论您是结构化文本还是非结构化文本，数字数据或地理空间数据，Elasticsearch都能以支持快速搜索的方式有效地对其进行存储和索引。</p>
<p><strong>Kibana</strong>是一个针对Elasticsearch的开源分析及可视化平台，用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana，可以通过各种图表进行高级数据分析及展示。并且可以为Logstash和ElasticSearch提供的日志分析友好的 Web 界面，可以汇总、分析和搜索重要数据日志。还可以让海量数据更容易理解。它操作简单，基于浏览器的用户界面可以快速创建仪表板（Dashboard）实时显示Elasticsearch查询动态</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/04339a2911744c46b7fac726e2c764fa~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>完整日志系统基本特征</p>
<p>收集：能够采集多种来源的日志数据</p>
<p>传输：能够稳定的把日志数据解析过滤并传输到存储系统</p>
<p>存储：存储日志数据</p>
<p>分析：支持UI分析</p>
<p>警告：能够提供错误报告，监控机制</p>
<p><strong>安装jdk17环境</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:<del># mkdir jdk<br>root@elk:</del># cd jdk<br>root@elk:<del>&#x2F;jdk# wget <a href="https://download.oracle.com/java/17/latest/jdk-17_linux-x64_bin.tar.gz">https://download.oracle.com/java/17/latest/jdk-17_linux-x64_bin.tar.gz</a><br>root@elk:</del>&#x2F;jdk# tar xf jdk-17_linux-x64_bin.tar.gz<br>root@elk:<del>&#x2F;jdk# cd ..<br>root@elk:</del>#<br>root@elk:<del># mv jdk&#x2F; &#x2F;<br>root@elk:</del># vim &#x2F;etc&#x2F;profile<br>root@elk:<del>#<br>root@elk:</del>#<br>root@elk:~# tail -n 4 &#x2F;etc&#x2F;profile</p>
<p>export JAVA_HOME&#x3D;&#x2F;jdk&#x2F;jdk-17.0.1&#x2F;<br>export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH<br>export CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar<br>root@elk:<del>#<br>root@elk:</del># source &#x2F;etc&#x2F;profile<br>root@elk:~# chmod -R 777  &#x2F;jdk&#x2F;</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>创建elk文件夹，并下载所需包</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:<del># mkdir elk<br>root@elk:</del># cd elk<br>root@elk:<del>&#x2F;elk# wget <a href="https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.15.1-linux-x86_64.tar.gz">https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.15.1-linux-x86_64.tar.gz</a><br>root@elk:</del>&#x2F;elk# wget <a href="https://artifacts.elastic.co/downloads/kibana/kibana-7.15.1-linux-x86_64.tar.gz">https://artifacts.elastic.co/downloads/kibana/kibana-7.15.1-linux-x86_64.tar.gz</a><br>root@elk:~&#x2F;elk# wget <a href="https://artifacts.elastic.co/downloads/logstash/logstash-7.15.1-linux-x86_64.tar.gz">https://artifacts.elastic.co/downloads/logstash/logstash-7.15.1-linux-x86_64.tar.gz</a></p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>解压安装包</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:<del>&#x2F;elk# tar xf elasticsearch-7.15.1-linux-x86_64.tar.gz<br>root@elk:</del>&#x2F;elk# tar xf kibana-7.15.1-linux-x86_64.tar.gz<br>root@elk:<del>&#x2F;elk# tar xf logstash-7.15.1-linux-x86_64.tar.gz<br>root@elk:</del>&#x2F;elk# ll<br>total 970288<br>drwxr-xr-x  5 root root      4096 Oct 20 06:09 .&#x2F;<br>drwx——  7 root root      4096 Oct 20 06:04 ..&#x2F;<br>drwxr-xr-x  9 root root      4096 Oct  7 22:00 elasticsearch-7.15.1&#x2F;<br>-rw-r–r–  1 root root 340849929 Oct 14 13:28 elasticsearch-7.15.1-linux-x86_64.tar.gz<br>drwxr-xr-x 10 root root      4096 Oct 20 06:09 kibana-7.15.1-linux-x86_64&#x2F;<br>-rw-r–r–  1 root root 283752241 Oct 14 13:34 kibana-7.15.1-linux-x86_64.tar.gz<br>drwxr-xr-x 13 root root      4096 Oct 20 06:09 logstash-7.15.1&#x2F;<br>-rw-r–r–  1 root root 368944379 Oct 14 13:38 logstash-7.15.1-linux-x86_64.tar.gz</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>创建用户并设置权限</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:<del>&#x2F;elk# cd<br>root@elk:</del># useradd elk<br>root@elk:<del># mkdir &#x2F;home&#x2F;elk<br>root@elk:</del># cp -r elk&#x2F; &#x2F;home&#x2F;elk&#x2F;<br>root@elk:~# chown -R elk:elk &#x2F;home&#x2F;elk&#x2F;</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>修改系统配置文件</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:<del># vim &#x2F;etc&#x2F;security&#x2F;limits.conf<br>root@elk:</del>#<br>root@elk:<del>#<br>root@elk:</del># tail -n 3 &#x2F;etc&#x2F;security&#x2F;limits.conf</p>
<ul>
<li><pre><code>  soft    nofile          65536
</code></pre>
</li>
<li><pre><code>  hard    nofile          65536
</code></pre>
root@elk:~#</li>
</ul>
<p>root@elk:<del># vim &#x2F;etc&#x2F;sysctl.conf<br>root@elk:</del>#<br>root@elk:~# tail -n 2 &#x2F;etc&#x2F;sysctl.conf</p>
<p>vm.max_map_count&#x3D;262144<br>root@elk:<del>#<br>root@elk:</del># sysctl -p<br>vm.max_map_count &#x3D; 262144<br>root@elk:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>修改elk配置文件</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:<del># su - elk<br>$ bash<br>elk@elk:</del>$ cd &#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;config<br>elk@elk:<del>&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;config$ vim elasticsearch.yml<br>elk@elk:</del>&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;config$<br>elk@elk:~&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;config$ tail -n 20 elasticsearch.yml</p>
<p>#设置data存放的路径为&#x2F;data&#x2F;es-data<br>path.data: &#x2F;home&#x2F;elk&#x2F;data&#x2F;<br>#设置logs日志的路径为&#x2F;log&#x2F;es-log<br>path.logs: &#x2F;home&#x2F;elk&#x2F;data&#x2F;<br>#设置内存不使用交换分区<br>bootstrap.memory_lock: false<br>#配置了bootstrap.memory_lock为true时反而会引发9200不会被监听，原因不明<br>#设置允许所有ip可以连接该elasticsearch<br>network.host: 0.0.0.0<br>#开启监听的端口为9200<br>http.port: 9500<br>#增加新的参数，为了让elasticsearch-head插件可以访问es (5.x版本，如果没有可以自己手动加)<br>http.cors.enabled: true<br>http.cors.allow-origin: “*”<br>cluster.initial_master_nodes: [“elk”]<br>node.name: elk</p>
<p>root@elk:~&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;config#</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>使用elk用户去启动elasticsearch</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:<del># su - elk<br>$ bash<br>elk@elk:</del>$<br>elk@elk:<del>$ mkdir data<br>elk@elk:</del>&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;bin$ cd<br>elk@elk:<del>$ cd &#x2F;home&#x2F;elk&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;bin<br>elk@elk:</del>&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;bin$ .&#x2F;elasticsearch</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>启动之后访问测试：</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:~# curl -I <a href="http://192.168.1.19:9500/">http://192.168.1.19:9500/</a><br>HTTP&#x2F;1.1 200 OK<br>X-elastic-product: Elasticsearch<br>Warning: 299 Elasticsearch-7.15.1-83c34f456ae29d60e94d886e455e6a3409bba9ed “Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html</a> to enable security.”<br>content-type: application&#x2F;json; charset&#x3D;UTF-8<br>content-length: 532</p>
<p>root@elk:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/92edd7720aa34cbda6c7acd791f88856~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>放到后台运行</strong></p>
<p>&#96;&#96;&#96;shell<br>elk@elk:<del>&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;bin$ nohup &#x2F;home&#x2F;elk&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;bin&#x2F;elasticsearch &gt;&gt; &#x2F;home&#x2F;elk&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;output.log 2&gt;&amp;1 &amp;<br>[1] 8811<br>elk@elk:</del>&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;bin$</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>elk@elk:<del>$ cd elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;config&#x2F;<br>elk@elk:</del>&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;config$ vim kibana.yml<br>elk@elk:<del>&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;config$ tail -n 18 kibana.yml<br>#设置监听端口为5601<br>server.port: 5601<br>#设置可访问的主机地址<br>server.host: “0.0.0.0”<br>#设置elasticsearch主机地址<br>elasticsearch.hosts: [“<a href="http://localhost:9500&quot;]">http://localhost:9500&quot;]</a><br>#如果elasticsearch设置了用户名密码,那么需要配置该两项,如果没配置,那就不用管<br>#elasticsearch.username: “user”<br>#elasticsearch.password: “pass”<br>elk@elk:</del>&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;config$</p>
<p>elk@elk:~$ cd &#x2F;home&#x2F;elk&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;bin</p>
<p>elk@elk:~&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;bin$ .&#x2F;kibana</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>测试访问</strong></p>
<p>&#96;&#96;&#96;shell<br>root@elk:<del># curl -I <a href="http://192.168.1.19:5601/app/home#/tutorial_directory">http://192.168.1.19:5601/app/home#/tutorial_directory</a><br>HTTP&#x2F;1.1 200 OK<br>content-security-policy: script-src ‘unsafe-eval’ ‘self’; worker-src blob: ‘self’; style-src ‘unsafe-inline’ ‘self’<br>x-content-type-options: nosniff<br>referrer-policy: no-referrer-when-downgrade<br>kbn-name: elk<br>kbn-license-sig: aaa69ea6a0792153cde61e88d0cd9bbad7ddcdaec87b613f281dd275e9dbad47<br>content-type: text&#x2F;html; charset&#x3D;utf-8<br>cache-control: private, no-cache, no-store, must-revalidate<br>content-length: 144351<br>vary: accept-encoding<br>Date: Wed, 20 Oct 2021 07:11:10 GMT<br>Connection: keep-alive<br>Keep-Alive: timeout&#x3D;120<br>root@elk:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1d77de83c3a84101857b57d6ebbe1199~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>放到后台运行</strong></p>
<p>&#96;&#96;&#96;shell<br>elk@elk:<del>&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;bin$ nohup &#x2F;home&#x2F;elk&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;bin&#x2F;kibana &gt;&gt; &#x2F;home&#x2F;elk&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;output.log 2&gt;&amp;1 &amp;<br>[2] 9378<br>elk@elk:</del>&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;bin$</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>将日志信息输出到屏幕上</strong></p>
<p>&#96;&#96;&#96;shell<br>elk@elk:<del>$ cd elk&#x2F;logstash-7.15.1&#x2F;bin&#x2F;<br>elk@elk:</del>&#x2F;elk&#x2F;logstash-7.15.1&#x2F;bin$ .&#x2F;logstash -e ‘input {stdin{}} output{stdout{}}’</p>
<p>输入个123然后回车,会把结果输出到屏幕上</p>
<p>{<br>          “host” &#x3D;&gt; “elk”,<br>    “@timestamp” &#x3D;&gt; 2021-10-20T07:15:54.230Z,<br>      “@version” &#x3D;&gt; “1”,<br>       “message” &#x3D;&gt; “”<br>}<br>123<br>{<br>          “host” &#x3D;&gt; “elk”,<br>    “@timestamp” &#x3D;&gt; 2021-10-20T07:15:56.453Z,<br>      “@version” &#x3D;&gt; “1”,<br>       “message” &#x3D;&gt; “123”<br>}</p>
<p>elk@elk:<del>&#x2F;elk&#x2F;logstash-7.15.1&#x2F;bin$ cd ..&#x2F;config&#x2F;<br>elk@elk:</del>&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config$ vim logstash<br>elk@elk:~&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config$ cat logstash<br>input {<br>    # 从文件读取日志信息<br>      file {<br>          path &#x3D;&gt; “&#x2F;var&#x2F;log&#x2F;messages”<br>          type &#x3D;&gt; “system”<br>          start_position &#x3D;&gt; “beginning”<br>           }<br>}</p>
<p>filter {<br>}</p>
<p>output {<br>      # 标准输出<br>      stdout {}<br>}<br>elk@elk:<del>&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config$ mv logstash logstash.conf<br>elk@elk:</del>&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config$</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>启动测试</strong></p>
<p>&#96;&#96;&#96;shell<br>elk@elk:<del>&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config$ cd ..&#x2F;bin&#x2F;<br>elk@elk:</del>&#x2F;elk&#x2F;logstash-7.15.1&#x2F;bin$ .&#x2F;logstash -f ..&#x2F;config&#x2F;logstash.conf</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>后台启动</strong></p>
<p>&#96;&#96;&#96;shell<br>elk@elk:<del>$ nohup &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;bin&#x2F;logstash -f &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config&#x2F;logstash.conf &gt;&gt; &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;output.log 2&gt;&amp;1 &amp;<br>[3] 10177<br>elk@elk:</del>$</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>设置开机自启</strong></p>
<p>&#96;&#96;&#96;shell<br>elk@elk:<del>$ vim startup.sh<br>elk@elk:</del>$<br>elk@elk:~$ cat startup.sh<br>#!&#x2F;bin&#x2F;bash<br>nohup &#x2F;home&#x2F;elk&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;bin&#x2F;elasticsearch &gt;&gt; &#x2F;home&#x2F;elk&#x2F;elk&#x2F;elasticsearch-7.15.1&#x2F;output.log 2&gt;&amp;1 &amp;<br>nohup &#x2F;home&#x2F;elk&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;bin&#x2F;kibana &gt;&gt; &#x2F;home&#x2F;elk&#x2F;elk&#x2F;kibana-7.15.1-linux-x86_64&#x2F;output.log 2&gt;&amp;1 &amp;<br>nohup &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;bin&#x2F;logstash -f &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config&#x2F;logstash.conf &gt;&gt; &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;output.log 2&gt;&amp;1 &amp;</p>
<p>elk@elk:<del>$<br>elk@elk:</del>$ crontab -e<br>no crontab for elk - using an empty one</p>
<p>Select an editor.  To change later, run ‘select-editor’.</p>
<ol>
<li>&#x2F;bin&#x2F;nano        &lt;—- easiest</li>
<li>&#x2F;usr&#x2F;bin&#x2F;vim.basic</li>
<li>&#x2F;usr&#x2F;bin&#x2F;vim.tiny</li>
<li>&#x2F;bin&#x2F;ed</li>
</ol>
<p>Choose 1-4 [1]: 2<br>crontab: installing new crontab<br>elk@elk:<del>$<br>elk@elk:</del>$<br>elk@elk:~$ crontab -l</p>
<p>@reboot &#x2F;home&#x2F;elk&#x2F;startup.sh</p>
<p>elk@elk:~$</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>logstash插件</strong></p>
<p>logstash是通过插件对其功能进行加强</p>
<p>插件分类:</p>
<p>inputs 输入</p>
<p>codecs 解码</p>
<p>filters 过滤</p>
<p>outputs 输出</p>
<p>在Gemfile文件里记录了logstash的插件</p>
<p>&#96;&#96;&#96;shell<br>elk@elk:<del>$ cd elk&#x2F;logstash-7.15.1<br>elk@elk:</del>&#x2F;elk&#x2F;logstash-7.15.1$ ls Gemfile<br>Gemfile<br>elk@elk:~&#x2F;elk&#x2F;logstash-7.15.1$</p>
<p>&#96;&#96;&#96;shell</p>
<p>去其github上下载插件,地址为:<strong><a href="https://github.com/logstash-plugins">https://github.com/logstash-plugins</a></strong></p>
<p>使用filter插件logstash-filter-mutate</p>
<p>&#96;&#96;&#96;shell<br>elk@elk:~&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config$  vim logstash2.conf<br>#创建一个新的配置文件用来过滤<br>input {<br>    stdin {<br>    }<br>}<br>filter {<br>   mutate {<br>        split &#x3D;&gt; [“message”, “|”]<br>    }<br>}<br>output {<br>    stdout {<br>    }<br>}</p>
<p>&#96;&#96;&#96;shell</p>
<p>当输入sss|sssni|akok223|23即会按照|分隔符进行分隔</p>
<p>其数据处理流程:input–&gt;解码–&gt;filter–&gt;解码–&gt;output</p>
<p><strong>启动服务</strong></p>
<p>然后去启动logstash服务</p>
<p>&#96;&#96;&#96;shellshell<br>elk@elk:~$ nohup &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;bin&#x2F;logstash -f &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;config&#x2F;logstash2.conf &gt;&gt; &#x2F;home&#x2F;elk&#x2F;elk&#x2F;logstash-7.15.1&#x2F;output.log 2&gt;&amp;1 &amp;</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/35ff564359d54a618b8ec6ec1fb02086~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>41篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9b1ff1cfdbf4db4b66dadd717fbdfa0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>SELinux入门学习总结</title>
    <url>/2021/12/30/2021-12-30-SELinux%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p><strong>前言</strong></p>
<p>安全增强型 Linux（Security-Enhanced Linux）简称 SELinux，它是一个 Linux 内核模块，也是 Linux 的一个安全子系统。</p>
<p>SELinux 主要由美国国家安全局开发。2.6 及以上版本的 Linux 内核都已经集成了 SELinux 模块。</p>
<p>SELinux 的结构及配置非常复杂，而且有大量概念性的东西，要学精难度较大。很多 Linux 系统管理员嫌麻烦都把 SELinux 关闭了。</p>
<p>如果可以熟练掌握 SELinux 并正确运用，我觉得整个系统基本上可以到达“坚不可摧”的地步了（请永远记住没有绝对的安全）。</p>
<p>掌握 SELinux 的基本概念以及简单的配置方法是每个 Linux 系统管理员的必修课。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/33a7ae230f5d409fb7f165b0010ff55e~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>一、基本概念</strong></p>
<p><strong>1、TE模型的安全上下文</strong></p>
<p>所有的操作系统访问控制都基于主体、客体，以及与他们相关的访问控制属性。</p>
<p>在selinux中，<strong>访问控制属性叫做安全上下文。</strong>所有对象(文件、进程间通信通道、套接字、网络主机等)和主体(进程)都有一个与之关联的安全上下文。</p>
<p><strong>一个安全上下文包含三个元素：</strong>用户（user）、角色（role）和类型标识符（type identifiers）</p>
<p><strong>安全上下文的形式如下：</strong>user：role：type</p>
<p><strong>对进程来说：</strong>分别表示用户、角色、类型标识符也被称为域</p>
<p><strong>对客体来说：</strong>前两项基本没有实际用途，role通常为object_r，user通常位创建这个对象的进程的user，对访问控制没有影响</p>
<p><strong>总结：</strong></p>
<p>SELinux是通过MAC(Mandatory Access Control)方式来控管进程，它控制的主体是进程，而目标则是该进程能否读取的”文件资源”。</p>
<p><strong>主体</strong></p>
<p>SELinux 主要是想管理控制进程。</p>
<p>注*：为了方便理解，如无特别说明，以下均把进程视为主体。</p>
<p><strong>目标</strong></p>
<p>主体进程能否访问的”目标资源”一般是文件系统。</p>
<p><strong>对象</strong></p>
<p>被主体访问的资源。可以是文件、目录、端口、设备等。</p>
<p>注*：为了方便理解，如无特别说明，以下均把文件或者目录视为对象。</p>
<p><strong>策略</strong></p>
<p>因为进程和文件的数量庞大，因此 SELiunx会根据某些服务来制定基本的访问安全性策略。</p>
<p>这些策略内部还有详细的规则来指定不同的服务开放某些资源的访问与否。</p>
<p>系统中通常有大量的文件和进程，为了节省时间和开销，通常我们只是选择性地对某些进程进行管制。</p>
<p>而哪些进程需要管制、要怎么管制是由政策决定的。</p>
<p>一套政策里面有多个规则。部分规则可以按照需求启用或禁用（以下把该类型的规则称为布尔型规则）。</p>
<p>规则是模块化、可扩展的。在安装新的应用程序时，应用程序可通过添加新的模块来添加规则。用户也可以手动地增减规则。</p>
<p><strong>SELINUX参数值：</strong></p>
<p>enforcing:强制执行SELinux功能；</p>
<p>permissive:只显示警告信息；</p>
<p>disabled:停用SELinux功能。</p>
<p>SELINUXTYPE参数值：</p>
<p>targeted:针对网络服务限制较多，针对本机限制较少，是默认的策略；</p>
<p>strict:完整的保护功能，包括网络服务、一般指令、应用程序，限制方面较为严格。</p>
<p><strong>安全上下文</strong></p>
<p>安全上下文是 SELinux 的核心。</p>
<p>安全上下文我自己把它分为「进程安全上下文」和「文件安全上下文」。</p>
<p>一个「进程安全上下文」一般对应多个「文件安全上下文」。</p>
<p>只有两者的安全上下文对应上了，进程才能访问文件。它们的对应关系由政策中的规则决定。</p>
<p>文件安全上下文由文件创建的位置和创建文件的进程所决定。而且系统有一套默认值，用户也可以对默认值进行设定。</p>
<p>需要注意的是，单纯的移动文件操作并不会改变文件的安全上下文。</p>
<p>安全上下文的结构及含义</p>
<p>安全上下文有四个字段，分别用冒号隔开。形如：system_u:object_r:admin_home_t:s0。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6fd13628198b4df29e5b5b497955a78d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>SELinux 的工作模式</strong></p>
<p>SELinux 有三种工作模式，分别是：</p>
<p>enforcing：强制模式。违反 SELinux 规则的行为将被阻止并记录到日志中。</p>
<p>permissive：宽容模式。违反 SELinux 规则的行为只会记录到日志中。一般为调试用。</p>
<p>disabled：关闭 SELinux。</p>
<p>SELinux 工作模式可以在 &#x2F;etc&#x2F;selinux&#x2F;config 中设定。</p>
<p>如果想从 disabled 切换到 enforcing 或者 permissive 的话，需要重启系统。反过来也一样。</p>
<p>enforcing 和 permissive 模式可以通过 setenforce 1|0 命令快速切换。</p>
<p>需要注意的是，如果系统已经在关闭 SELinux 的状态下运行了一段时间，在打开 SELinux 之后的第一次重启速度可能会比较慢。因为系统必须为磁盘中的文件创建安全上下文。</p>
<p>SELinux 日志的记录需要借助 auditd.service 这个服务，请不要禁用它。</p>
<p><strong>SELinux 工作流程</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5281d13148334d958546b13cbbd26914~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>显示安全上下文</strong></p>
<p>加上-Z能显示主体、客体的上下文</p>
<p>ls -Z能显示文件系统的安全上下文</p>
<p>ps -Z能显示进程的安全上下文</p>
<p>id -Z能显示shell的安全上下文：joe：usr_r：usr_t</p>
<p><strong>2、TE访问控制</strong></p>
<p>在SELinux中，默认时没有允许规则的，也没有超级用户。被允许的访问必须由规则给出。</p>
<p>一条规则如下：</p>
<p>allow Source type(s) Target type(s): Object class(es) Permission(s)</p>
<p>比如这样的访问规则：</p>
<p>allow user_t bin_t : file {read execute getattr};</p>
<p>表示允许域为user_t的进程对type为bin_t的文件具有读、执行、得到属性的操作</p>
<p><strong>3、角色的作用</strong></p>
<p>SELinux也提供基于角色的访问控制</p>
<p>通过以下语句指定role的type：</p>
<p>role user_r type passwd_t;</p>
<p>如果没有以上这条语句，则：</p>
<p>安全上下文joe：user_r：passwd_t则不能被创建</p>
<p>exec调用则失败，即便策略允许</p>
<p><strong>二、架构</strong></p>
<p><strong>1、内核架构</strong></p>
<p>基于LSM（linux security module），为所有的内核的资源提供强制访问控制</p>
<p><strong>注*：LSM（linux security module）一种轻量级的安全访问控制框架，主要利用Hook函数对权限进行访问控制，并在部分对象中内置了透明的安全属性。</strong></p>
<p>LSM提供了一系列的钩子函数</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f19f42d70854b0d852dae925d4a2fbc~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>如果访问被DAC拒绝，则会影响审计结果</p>
<p><strong>SELinux的架构如下所示：</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f42877ac2734297b0a6910d6b3f07cb~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>策略决定包含在安全服务器中，与具体架构无关，便于移植</p>
<p>对象管理者时各对象的管理者，在LSM架构中，是一系列的LSM钩子，遍布在内核的子系统中。</p>
<p><strong>注*：Linux安全模块（LSM）提供的接口就是钩子，其初始化时所指向的虚拟函数实现了缺省的传统UNIX超级用户机制，模块编写者必须重新实现这些钩子函数来满足自己的安全策略。</strong></p>
<p><strong>2、用户空间的对象管理器</strong></p>
<p>SELinux支持将对象管理器放到用户态，使用内核的对象管理策略服务器来管理用户态的对象</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7b3a83bda020406ca8995d7478e2528a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>然而，支持用户空间的对象管理器有一些弱点：</p>
<p>对于TE模型，还需要定义class</p>
<p>对于对象管理器的管理策略不再内核之中</p>
<p><strong>策略服务架构如下：</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/78acf33ec8ff4ff7ab7324697bfce65d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>AVC表示各种缓存</p>
<p><strong>三、SELinux 的作用及权限管理机制</strong></p>
<p><strong>1 SELinux 的作用</strong></p>
<p>SELinux 主要作用就是最大限度地减小系统中服务进程可访问的资源（最小权限原则）。</p>
<p>设想一下，如果一个以 root 身份运行的网络服务存在 0day 漏洞，黑客就可以利用这个漏洞，以 root 的身份在您的服务器上为所欲为了。是不是很可怕？</p>
<p>SELinux 就是来解决这个问题的。</p>
<p><strong>2 DAC</strong></p>
<p>在没有使用 SELinux 的操作系统中，决定一个资源是否能被访问的因素是：某个资源是否拥有对应用户的权限（读、写、执行）。</p>
<p>只要访问这个资源的进程符合以上的条件就可以被访问。</p>
<p>而最致命问题是，root 用户不受任何管制，系统上任何资源都可以无限制地访问。</p>
<p>这种权限管理机制的主体是用户，也称为自主访问控制（DAC）。</p>
<p><strong>3 MAC</strong></p>
<p>在使用了 SELinux 的操作系统中，决定一个资源是否能被访问的因素除了上述因素之外，还需要判断每一类进程是否拥有对某一类资源的访问权限。</p>
<p>这样一来，即使进程是以 root 身份运行的，也需要判断这个进程的类型以及允许访问的资源类型才能决定是否允许访问某个资源。进程的活动空间也可以被压缩到最小。</p>
<p>即使是以 root 身份运行的服务进程，一般也只能访问到它所需要的资源。即使程序出了漏洞，影响范围也只有在其允许访问的资源范围内。安全性大大增加。</p>
<p>这种权限管理机制的主体是进程，也称为强制访问控制（MAC）。</p>
<p>而 MAC 又细分为了两种方式，一种叫类别安全（MCS）模式，另一种叫多级安全（MLS）模式。</p>
<p>下文中的操作均为 MCS 模式。</p>
<p><strong>4 DAC 和 MAC 的对比</strong></p>
<p>这里引用一张图片来说明。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/36cc4e3257814439ba62c13bb69d0379~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>可以看到，在 DAC 模式下，只要相应目录有相应用户的权限，就可以被访问。而在 MAC 模式下，还要受进程允许访问目录范围的限制。</p>
<p><strong>四、SELinux 基本操作</strong></p>
<p><strong>1 查询文件或目录的安全上下文</strong></p>
<p>命令基本用法</p>
<p>ls -Z能显示文件系统的安全上下文</p>
<p>ps -Z能显示进程的安全上下文</p>
<p>id -Z能显示shell的安全上下文：joe：usr_r：usr_t</p>
<p>用法举例</p>
<p>查询 &#x2F;etc&#x2F;hosts 的安全上下文。</p>
<p>ls -Z &#x2F;etc&#x2F;hosts</p>
<p>执行结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# ls -Z /etc/hosts</span><br><span class="line">-rw-r--r--. root root system_u:object_r:net_conf_t:s0  /etc/hosts</span><br><span class="line">[root@localhost ~]# </span><br></pre></td></tr></table></figure>

<p><strong>2 查询进程的安全上下文</strong></p>
<p>命令基本用法</p>
<p>ps auxZ | grep -v grep | grep &lt;进程名&gt;</p>
<p>用法举例</p>
<p>查询 Nginx 相关进程的安全上下文。</p>
<p>ps auxZ | grep -v grep | grep sshd</p>
<p>执行结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# ps auxZ | grep -v grep | grep sshd</span><br><span class="line">system_u:system_r:sshd_t:s0-s0:c0.c1023 root 1454 0.0  0.0 112940 4324 ?        Ss   Sep03   0:00 /usr/sbin/sshd -D</span><br><span class="line">unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 root 11664 0.0  0.0 158944 5596 ? Ss 10:34   0:00 sshd: root@pts/0</span><br><span class="line">unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 root 11668 0.0  0.0 156812 5444 ? Ss 10:34   0:00 sshd: root@notty</span><br><span class="line">[root@localhost ~]#</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>3 手动修改文件或目录的安全上下文</strong></p>
<p>命令基本用法</p>
<p>chcon &lt;选项&gt; &lt;文件或目录 1&gt; [&lt;文件或目录 2&gt;…]</p>
<p>用法举例</p>
<p>修改 test 的安全上下文为 system_u:object_r:httpd_sys_content_t:s0。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chcon -u system_u -r object_r -t httpd_sys_content_t html2/*</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@localhost nginx]# ls -Z</span><br><span class="line">drwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 html</span><br><span class="line">drwxr-xr-x. root root unconfined_u:object_r:usr_t:s0   html2</span><br><span class="line">[root@localhost nginx]# ls -Z html2</span><br><span class="line">-rw-r--r--. root root unconfined_u:object_r:usr_t:s0   404.html</span><br><span class="line">-rw-r--r--. root root unconfined_u:object_r:usr_t:s0   50x.html</span><br><span class="line">-rwxr-xr-x. root root unconfined_u:object_r:usr_t:s0   index.html</span><br><span class="line">-rw-r--r--. root root unconfined_u:object_r:usr_t:s0   nginx-logo.png</span><br><span class="line">-rw-r--r--. root root unconfined_u:object_r:usr_t:s0   poweredby.png</span><br><span class="line"></span><br><span class="line">[root@localhost nginx]# chcon -u system_u -r object_r -t httpd_sys_content_t html2/*</span><br><span class="line">[root@localhost nginx]# ls -Z html2</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 404.html</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 50x.html</span><br><span class="line">-rwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 index.html</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 nginx-logo.png</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 poweredby.png</span><br><span class="line">[root@localhost nginx]# </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>4 把文件或目录的安全上下文恢复到默认值</strong></p>
<p>命令基本用法</p>
<p>restorecon [选项] &lt;文件或目录 1&gt; [&lt;文件或目录 2&gt;…]</p>
<p>用法举例</p>
<p>添加一些网页文件到 Nginx 服务器的目录之后，为这些新文件设置正确的安全上下文。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# restorecon -R /root/test/</span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# ls -Z </span><br><span class="line">-rw-------. root root system_u:object_r:admin_home_t:s0 anaconda-ks.cfg</span><br><span class="line">drwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 test</span><br><span class="line">[root@localhost ~]# </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>5 查询系统中的布尔型规则及其状态</strong></p>
<p>命令基本用法</p>
<p>getsebool -a</p>
<p>由于该命令要么查询所有规则，要么只查询一个规则，所以一般都是先查询所有规则然后用 grep 筛选。</p>
<p>用法举例</p>
<p>查询与 httpd 有关的布尔型规则。</p>
<p>getsebool -a | grep ssh</p>
<p>执行结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# getsebool -a | grep ssh</span><br><span class="line">fenced_can_ssh --&gt; off</span><br><span class="line">selinuxuser_use_ssh_chroot --&gt; off</span><br><span class="line">ssh_chroot_rw_homedirs --&gt; off</span><br><span class="line">ssh_keysign --&gt; off</span><br><span class="line">ssh_sysadm_login --&gt; off</span><br><span class="line">[root@localhost ~]#</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>6 开关一个布尔型规则</strong>  </p>
<p>命令基本用法</p>
<p>setsebool [选项] &lt;规则名称&gt; &lt;on|off&gt;</p>
<p>用法举例</p>
<p>开启 httpd_anon_write 规则。</p>
<p>setsebool -P httpd_anon_write on</p>
<p>执行结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]#  getsebool -a | grep ssh</span><br><span class="line">fenced_can_ssh --&gt; off</span><br><span class="line">selinuxuser_use_ssh_chroot --&gt; off</span><br><span class="line">ssh_chroot_rw_homedirs --&gt; off</span><br><span class="line">ssh_keysign --&gt; off</span><br><span class="line">ssh_sysadm_login --&gt; off</span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# </span><br></pre></td></tr></table></figure>

<p>修改布尔型规则</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# setsebool -P ssh_sysadm_login on</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]#  getsebool -a | grep ssh</span><br><span class="line">fenced_can_ssh --&gt; off</span><br><span class="line">selinuxuser_use_ssh_chroot --&gt; off</span><br><span class="line">ssh_chroot_rw_homedirs --&gt; off</span><br><span class="line">ssh_keysign --&gt; off</span><br><span class="line">ssh_sysadm_login --&gt; on</span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# setsebool -P ssh_sysadm_login off</span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]#  getsebool -a | grep ssh</span><br><span class="line">fenced_can_ssh --&gt; off</span><br><span class="line">selinuxuser_use_ssh_chroot --&gt; off</span><br><span class="line">ssh_chroot_rw_homedirs --&gt; off</span><br><span class="line">ssh_keysign --&gt; off</span><br><span class="line">ssh_sysadm_login --&gt; off</span><br><span class="line">[root@localhost ~]# </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>配置文件目录即文件内容</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost booleans]# pwd</span><br><span class="line">/sys/fs/selinux/booleans</span><br><span class="line">[root@localhost booleans]# cat mpd_use_cifs</span><br><span class="line">0 0</span><br></pre></td></tr></table></figure>

<p><strong>7 添加目录的默认安全上下文</strong></p>
<p>命令基本用法</p>
<p>（如果提示找不到命令的话请安装 <code>policycoreutils-python</code> 软件包，下同。）</p>
<p>semanage fcontext -a -t &lt;文件安全上下文中的类型字段&gt; “&lt;目录（后面不加斜杠）&gt;(&#x2F;.*)?”</p>
<p>注：目录或文件的默认安全上下文可以通过 semanage fcontext -l 命令配合 grep 过滤查看。</p>
<p>用法举例</p>
<p>为 Nginx 新增一个网站目录 &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html2 之后，需要为其设置与原目录相同的默认安全上下文。</p>
<p>semanage fcontext -a -t httpd_sys_content_t “ &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html2(&#x2F;.*)?”</p>
<p><strong>8 添加某类进程允许访问的端口</strong></p>
<p>命令基本用法</p>
<p>semanage port -a -t &lt;服务类型&gt; -p &lt;协议&gt; &lt;端口号&gt;</p>
<p>注：各种服务类型所允许的端口号可以通过 semanage port -l 命令配合 grep 过滤查看。</p>
<p>用法举例</p>
<p>为 Nginx 需要使用 10080 的端口用于 HTTP 服务。</p>
<p>semanage port -a -t http_port_t -p tcp 10080</p>
<p><strong>9 参考其它进行修改</strong></p>
<p>命令基本用法</p>
<p>chcon –reference&#x3D;&lt;源文件&gt;  &lt;要修改的文件&gt;</p>
<p>修改 1.txt文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost html]# ll -Z</span><br><span class="line">-rw-r--r--. root root unconfined_u:object_r:usr_t:s0   1.txt</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 404.html</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 50x.html</span><br><span class="line">lrwxrwxrwx. root root system_u:object_r:httpd_sys_content_t:s0 en-US -&gt; ../../doc/HTML/en-US</span><br><span class="line">drwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 icons</span><br><span class="line">lrwxrwxrwx. root root system_u:object_r:httpd_sys_content_t:s0 img -&gt; ../../doc/HTML/img</span><br><span class="line">lrwxrwxrwx. root root system_u:object_r:httpd_sys_content_t:s0 index.html -&gt; ../../doc/HTML/index.h</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 nginx-logo.png</span><br><span class="line">lrwxrwxrwx. root root system_u:object_r:httpd_sys_content_t:s0 poweredby.png -&gt; nginx-logo.png</span><br></pre></td></tr></table></figure>

<p>执行结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost html]# chcon --reference=404.html 1.txt </span><br><span class="line">[root@localhost html]# </span><br><span class="line">[root@localhost html]# </span><br><span class="line">[root@localhost html]# ll -Z</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 1.txt</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 404.html</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 50x.html</span><br><span class="line">lrwxrwxrwx. root root system_u:object_r:httpd_sys_content_t:s0 en-US -&gt; ../../doc/HTML/en-US</span><br><span class="line">drwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 icons</span><br><span class="line">lrwxrwxrwx. root root system_u:object_r:httpd_sys_content_t:s0 img -&gt; ../../doc/HTML/img</span><br><span class="line">lrwxrwxrwx. root root system_u:object_r:httpd_sys_content_t:s0 index.html -&gt; ../../doc/HTML/index.html</span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_sys_content_t:s0 nginx-logo.png</span><br><span class="line">lrwxrwxrwx. root root system_u:object_r:httpd_sys_content_t:s0 poweredby.png -&gt; nginx-logo.png</span><br></pre></td></tr></table></figure>

<p><strong>10 修改后的权限，恢复到原始的</strong></p>
<p>命令基本用法</p>
<p>restorecon -v &lt;文件&gt;</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost files]# ls -Z /etc/yum.conf </span><br><span class="line">-rw-r--r--. root root system_u:object_r:etc_t:s0       /etc/yum.conf</span><br><span class="line">[root@localhost files]# </span><br><span class="line">[root@localhost files]# </span><br><span class="line">[root@localhost files]# chcon -t httpd_config_t /etc/yum.conf</span><br><span class="line">[root@localhost files]# </span><br><span class="line">[root@localhost files]# ls -Z /etc/yum.conf </span><br><span class="line">-rw-r--r--. root root system_u:object_r:httpd_config_t:s0 /etc/yum.conf</span><br><span class="line">[root@localhost files]# </span><br></pre></td></tr></table></figure>

<p>执行结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost files]# restorecon -v /etc/yum.conf </span><br><span class="line">restorecon reset /etc/yum.conf context system_u:object_r:httpd_config_t:s0-&gt;system_u:object_r:etc_t:s0</span><br><span class="line">[root@localhost files]# ls -Z /etc/yum.conf </span><br><span class="line">-rw-r--r--. root root system_u:object_r:etc_t:s0       /etc/yum.conf</span><br><span class="line">[root@localhost files]# </span><br></pre></td></tr></table></figure>

<p><strong>11 查看身份角色类似</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# yum install setools-console</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@localhost ~]# seinfo [选项]</span><br><span class="line">选项：</span><br><span class="line">-u： 列出SELinux中所有的身份（user）；</span><br><span class="line">-r： 列出SELinux中所有的角色（role）；</span><br><span class="line">-t： 列出SELinux中所有的类型（type）；</span><br><span class="line">-b： 列出所有的布尔值（也就是策略中的具体规则名称）；</span><br><span class="line">-x： 显示更多的信息；</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>五、SELinux 错误分析和解决</strong></p>
<p><strong>1 认识 SELinux 日志</strong></p>
<p>当开启了 SELinux 之后，很多服务的一些正常行为都会被视为违规行为（标题及下文中的错误均指违规行为）。</p>
<p>这时候我们就需要借助 SELinux 违规日志来分析解决。</p>
<p>SELinux 违规日志保存在 &#x2F;var&#x2F;log&#x2F;audit&#x2F;audit.log 中。</p>
<p>&#x2F;var&#x2F;log&#x2F;audit&#x2F;audit.log 的内容大概是这样的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# tailf /var/log/audit/audit.log</span><br><span class="line">type=GRP_MGMT msg=audit(1630901844.207:878): pid=11979 uid=0 auid=0 ses=76 subj=unconfined_u:unconfined_r:groupadd_t:s0-s0:c0.c1023 msg=&#x27;op=add-shadow-group id=994 exe=&quot;/usr/sbin/groupadd&quot; hostname=? addr=? terminal=? res=success&#x27;</span><br><span class="line">type=ADD_USER msg=audit(1630901844.247:879): pid=11984 uid=0 auid=0 ses=76 subj=unconfined_u:unconfined_r:useradd_t:s0-s0:c0.c1023 msg=&#x27;op=add-user id=997 exe=&quot;/usr/sbin/useradd&quot; hostname=? addr=? terminal=? res=success&#x27;</span><br><span class="line">type=USER_MGMT msg=audit(1630901844.288:880): pid=11989 uid=0 auid=0 ses=76 subj=unconfined_u:unconfined_r:useradd_t:s0-s0:c0.c1023 msg=&#x27;op=pam_tally2 reset=0 id=997 exe=&quot;/usr/sbin/pam_tally2&quot; hostname=? addr=? terminal=? res=success&#x27;</span><br><span class="line">type=SOFTWARE_UPDATE msg=audit(1630901844.314:881): pid=11968 uid=0 auid=0 ses=76 subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 msg=&#x27;sw=&quot;nginx-filesystem-1:1.20.1-2.el7.noarch&quot; sw_type=rpm key_enforce=0 gpg_res=1 root_dir=&quot;/&quot; comm=&quot;yum&quot; exe=&quot;/usr/bin/python2.7&quot; hostname=localhost.localdomain addr=? terminal=pts/0 res=success&#x27;</span><br><span class="line">type=SOFTWARE_UPDATE msg=audit(1630901844.581:882): pid=11968 uid=0 auid=0 ses=76 subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 msg=&#x27;sw=&quot;nginx-1:1.20.1-2.el7.x86_64&quot; sw_type=rpm key_enforce=0 gpg_res=1 root_dir=&quot;/&quot; comm=&quot;yum&quot; exe=&quot;/usr/bin/python2.7&quot; hostname=localhost.localdomain addr=? terminal=pts/0 res=success&#x27;</span><br><span class="line">type=USER_AVC msg=audit(1630904068.840:883): pid=1053 uid=81 auid=4294967295 ses=4294967295 subj=system_u:system_r:system_dbusd_t:s0-s0:c0.c1023 msg=&#x27;avc:  received policyload notice (seqno=7)  exe=&quot;/usr/bin/dbus-daemon&quot; sauid=81 hostname=? addr=? terminal=?&#x27;</span><br><span class="line">type=MAC_POLICY_LOAD msg=audit(1630904065.495:884): policy loaded auid=0 ses=76</span><br><span class="line">type=SYSCALL msg=audit(1630904065.495:884): arch=c000003e syscall=1 success=yes exit=3881672 a0=4 a1=7f3cf9ca2000 a2=3b3ac8 a3=7ffd6fe646a0 items=0 ppid=12014 pid=12019 auid=0 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=pts0 ses=76 comm=&quot;load_policy&quot; exe=&quot;/usr/sbin/load_policy&quot; subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 key=(null)</span><br><span class="line">type=PROCTITLE msg=audit(1630904065.495:884): proctitle=&quot;/sbin/load_policy&quot;</span><br><span class="line">type=USER_MAC_CONFIG_CHANGE msg=audit(1630904068.901:885): pid=12014 uid=0 auid=0 ses=76 subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 msg=&#x27;resrc=port op=add lport=10080 proto=6 tcontext=system_u:object_r:http_port_t:s0 comm=&quot;semanage&quot; exe=&quot;/usr/bin/python2.7&quot; hostname=? addr=? terminal=? res=success&#x27;</span><br></pre></td></tr></table></figure>

<p>该文件的内容很多，而且混有很多与 SELinux 错误无关的系统审计日志。我们要借助 sealert 这个实用工具来帮忙分析（如果提示找不到命令的话请安装 setroubleshoot 软件包）。</p>
<p><strong>2 使用 sealert 分析错误</strong></p>
<p>命令基本用法</p>
<p>sealert -a &#x2F;var&#x2F;log&#x2F;audit&#x2F;audit.log</p>
<p>执行完命令之后，系统需要花一段时间去分析日志中的违规行为并给出分析报告。分析报告的结构讲解请看下图：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# yum install setroubleshoot-server python3-pydbus</span><br></pre></td></tr></table></figure>

<p><strong>3  SELinux 错误的思路</strong></p>
<p>当发现一个服务出现错误的时候，请先检查一下 sealert 的分析报告里面是否有该服务进程名称的关键字。如果没有，说明不是 SELinux 造成的错误，请往其他方面排查。</p>
<p>文件目录默认的权限在这个文件下，具体文件是file_contexts</p>
<p>&#x2F;etc&#x2F;selinux&#x2F;targeted&#x2F;contexts&#x2F;files&#x2F;</p>
<p>接下来就是阅读 sealert 的分析报告了。</p>
<p>首先需要了解的就是违规原因。如果违规原因里面出现了该服务不该访问的文件或资源，那就要小心了。有可能是服务的配置有问题或者服务本身存在漏洞，请优先排查服务的配置文件。</p>
<p>在分析报告中，对于一个违规行为，通常会有 2~3 个解决方案。请优先选择修改布尔值、设置默认安全上下文之类操作简单、容易理解的解决方案。</p>
<p>如果没有这种操作简单、容易理解的解决方案，请先去搜索引擎搜索一下有没有其他更好的解决方案。</p>
<p>需要注意的是，可信度只是一个参考值，并不代表使用可信度最高的解决方案就一定可以解决问题。我个人感觉使用可信度越高的解决方案对系统的改动就越小。</p>
<p>不过请记住，在执行解决方案之前，一定要先搞清楚解决方案中的命令是干什么的！</p>
<p>最后，请谨慎使用 audit2allow 这个命令。这个命令的作用非常简单粗暴，就是强制允许所遇到的错误然后封装成一个 SELinux 模块，接着让 SELinux 加载这个模块来达到消除错误的目的。不是万不得已建议不要随便使用 audit2allow。</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>PVE开启硬件显卡直通功能</title>
    <url>/2021/12/30/2021-12-30-PVE%E5%BC%80%E5%90%AF%E7%A1%AC%E4%BB%B6%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<p>首先编辑GRUB配置文件：</p>
<p>&#96;&#96;&#96;shell<br>root@pve:<del># vim &#x2F;etc&#x2F;default&#x2F;grub<br>root@pve:</del>#<br>root@pve:~# cat &#x2F;etc&#x2F;default&#x2F;grub</p>
<h1 id="If-you-change-this-file-run-‘update-grub’-afterwards-to-update"><a href="#If-you-change-this-file-run-‘update-grub’-afterwards-to-update" class="headerlink" title="If you change this file, run ‘update-grub’ afterwards to update"></a>If you change this file, run ‘update-grub’ afterwards to update</h1><h1 id="x2F-boot-x2F-grub-x2F-grub-cfg"><a href="#x2F-boot-x2F-grub-x2F-grub-cfg" class="headerlink" title="&#x2F;boot&#x2F;grub&#x2F;grub.cfg."></a>&#x2F;boot&#x2F;grub&#x2F;grub.cfg.</h1><h1 id="For-full-documentation-of-the-options-in-this-file-see"><a href="#For-full-documentation-of-the-options-in-this-file-see" class="headerlink" title="For full documentation of the options in this file, see:"></a>For full documentation of the options in this file, see:</h1><h1 id="info-f-grub-n-‘Simple-configuration’"><a href="#info-f-grub-n-‘Simple-configuration’" class="headerlink" title="info -f grub -n ‘Simple configuration’"></a>info -f grub -n ‘Simple configuration’</h1><p>GRUB_DEFAULT&#x3D;0<br>GRUB_TIMEOUT&#x3D;5<br>GRUB_DISTRIBUTOR&#x3D;<code>lsb_release -i -s 2&gt; /dev/null || echo Debian</code><br>GRUB_CMDLINE_LINUX_DEFAULT&#x3D;”quiet intel_iommu&#x3D;on video&#x3D;efifb:off”<br>GRUB_CMDLINE_LINUX&#x3D;””</p>
<h1 id="Uncomment-to-enable-BadRAM-filtering-modify-to-suit-your-needs"><a href="#Uncomment-to-enable-BadRAM-filtering-modify-to-suit-your-needs" class="headerlink" title="Uncomment to enable BadRAM filtering, modify to suit your needs"></a>Uncomment to enable BadRAM filtering, modify to suit your needs</h1><h1 id="This-works-with-Linux-no-patch-required-and-with-any-kernel-that-obtains"><a href="#This-works-with-Linux-no-patch-required-and-with-any-kernel-that-obtains" class="headerlink" title="This works with Linux (no patch required) and with any kernel that obtains"></a>This works with Linux (no patch required) and with any kernel that obtains</h1><h1 id="the-memory-map-information-from-GRUB-GNU-Mach-kernel-of-FreeBSD-…"><a href="#the-memory-map-information-from-GRUB-GNU-Mach-kernel-of-FreeBSD-…" class="headerlink" title="the memory map information from GRUB (GNU Mach, kernel of FreeBSD …)"></a>the memory map information from GRUB (GNU Mach, kernel of FreeBSD …)</h1><p>#GRUB_BADRAM&#x3D;”0x01234567,0xfefefefe,0x89abcdef,0xefefefef”</p>
<h1 id="Uncomment-to-disable-graphical-terminal-grub-pc-only"><a href="#Uncomment-to-disable-graphical-terminal-grub-pc-only" class="headerlink" title="Uncomment to disable graphical terminal (grub-pc only)"></a>Uncomment to disable graphical terminal (grub-pc only)</h1><p>#GRUB_TERMINAL&#x3D;console</p>
<h1 id="The-resolution-used-on-graphical-terminal"><a href="#The-resolution-used-on-graphical-terminal" class="headerlink" title="The resolution used on graphical terminal"></a>The resolution used on graphical terminal</h1><h1 id="note-that-you-can-use-only-modes-which-your-graphic-card-supports-via-VBE"><a href="#note-that-you-can-use-only-modes-which-your-graphic-card-supports-via-VBE" class="headerlink" title="note that you can use only modes which your graphic card supports via VBE"></a>note that you can use only modes which your graphic card supports via VBE</h1><h1 id="you-can-see-them-in-real-GRUB-with-the-command-96-vbeinfo’"><a href="#you-can-see-them-in-real-GRUB-with-the-command-96-vbeinfo’" class="headerlink" title="you can see them in real GRUB with the command &#96;vbeinfo’"></a>you can see them in real GRUB with the command &#96;vbeinfo’</h1><p>#GRUB_GFXMODE&#x3D;640x480</p>
<h1 id="Uncomment-if-you-don’t-want-GRUB-to-pass-“root-x3D-UUID-x3D-xxx”-parameter-to-Linux"><a href="#Uncomment-if-you-don’t-want-GRUB-to-pass-“root-x3D-UUID-x3D-xxx”-parameter-to-Linux" class="headerlink" title="Uncomment if you don’t want GRUB to pass “root&#x3D;UUID&#x3D;xxx” parameter to Linux"></a>Uncomment if you don’t want GRUB to pass “root&#x3D;UUID&#x3D;xxx” parameter to Linux</h1><p>#GRUB_DISABLE_LINUX_UUID&#x3D;true</p>
<h1 id="Uncomment-to-disable-generation-of-recovery-mode-menu-entries"><a href="#Uncomment-to-disable-generation-of-recovery-mode-menu-entries" class="headerlink" title="Uncomment to disable generation of recovery mode menu entries"></a>Uncomment to disable generation of recovery mode menu entries</h1><p>#GRUB_DISABLE_RECOVERY&#x3D;”true”</p>
<h1 id="Uncomment-to-get-a-beep-at-grub-start"><a href="#Uncomment-to-get-a-beep-at-grub-start" class="headerlink" title="Uncomment to get a beep at grub start"></a>Uncomment to get a beep at grub start</h1><p>#GRUB_INIT_TUNE&#x3D;”480 440 1”<br>root@pve:~#</p>
<p>开启IOMMU支持：</p>
<p>GRUB_CMDLINE_LINUX_DEFAULT&#x3D;”quiet intel_iommu&#x3D;on video&#x3D;efifb:off”<br>如果是AMD的CPU：</p>
<p>GRUB_CMDLINE_LINUX_DEFAULT&#x3D;”quiet amd_iommu&#x3D;on video&#x3D;efifb:off”</p>
<p>&#96;&#96;&#96;shell</p>
<p>更新GRUB：</p>
<p>&#96;&#96;&#96;shell<br>root@pve:<del># update-grub<br>Generating grub configuration file …<br>Found linux image: &#x2F;boot&#x2F;vmlinuz-5.11.22-5-pve<br>Found initrd image: &#x2F;boot&#x2F;initrd.img-5.11.22-5-pve<br>Found linux image: &#x2F;boot&#x2F;vmlinuz-5.11.22-4-pve<br>Found initrd image: &#x2F;boot&#x2F;initrd.img-5.11.22-4-pve<br>Found memtest86+ image: &#x2F;boot&#x2F;memtest86+.bin<br>Found memtest86+ multiboot image: &#x2F;boot&#x2F;memtest86+_multiboot.bin<br>done<br>root@pve:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>添加所需的系统模块（驱动）：</p>
<p>&#96;&#96;&#96;shell<br>root@pve:<del>#<br>root@pve:</del># echo “vfio” &gt;&gt; &#x2F;etc&#x2F;modules<br>root@pve:<del># echo “vfio_iommu_type1” &gt;&gt; &#x2F;etc&#x2F;modules<br>root@pve:</del># echo “vfio_pci” &gt;&gt; &#x2F;etc&#x2F;modules<br>root@pve:<del># echo “vfio_virqfd” &gt;&gt; &#x2F;etc&#x2F;modules<br>root@pve:</del>#<br>root@pve:~# cat &#x2F;etc&#x2F;modules</p>
<h1 id="x2F-etc-x2F-modules-kernel-modules-to-load-at-boot-time"><a href="#x2F-etc-x2F-modules-kernel-modules-to-load-at-boot-time" class="headerlink" title="&#x2F;etc&#x2F;modules: kernel modules to load at boot time."></a>&#x2F;etc&#x2F;modules: kernel modules to load at boot time.</h1><h1 id=""><a href="#" class="headerlink" title=""></a></h1><h1 id="This-file-contains-the-names-of-kernel-modules-that-should-be-loaded"><a href="#This-file-contains-the-names-of-kernel-modules-that-should-be-loaded" class="headerlink" title="This file contains the names of kernel modules that should be loaded"></a>This file contains the names of kernel modules that should be loaded</h1><h1 id="at-boot-time-one-per-line-Lines-beginning-with-“-”-are-ignored"><a href="#at-boot-time-one-per-line-Lines-beginning-with-“-”-are-ignored" class="headerlink" title="at boot time, one per line. Lines beginning with “#” are ignored."></a>at boot time, one per line. Lines beginning with “#” are ignored.</h1><h1 id="Generated-by-sensors-detect-on-Fri-Sep-24-17-22-44-2021"><a href="#Generated-by-sensors-detect-on-Fri-Sep-24-17-22-44-2021" class="headerlink" title="Generated by sensors-detect on Fri Sep 24 17:22:44 2021"></a>Generated by sensors-detect on Fri Sep 24 17:22:44 2021</h1><h1 id="Chip-drivers"><a href="#Chip-drivers" class="headerlink" title="Chip drivers"></a>Chip drivers</h1><p>coretemp<br>vfio<br>vfio_iommu_type1<br>vfio_pci<br>vfio_virqfd</p>
<p>&#96;&#96;&#96;shell</p>
<p>接着添加模块（驱动）黑名单，即让GPU设备在下次系统启动之后不使用这些驱动，把设备腾出来给vfio驱动用：  </p>
<p>Intel核显：</p>
<p>&#96;&#96;&#96;shell<br>echo “blacklist snd_hda_intel” &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;pve-blacklist.conf<br>echo “blacklist snd_hda_codec_hdmi” &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;pve-blacklist.conf<br>echo “blacklist i915” &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;pve-blacklist.conf</p>
<p>&#96;&#96;&#96;shell</p>
<p>N卡&#x2F;A卡：</p>
<p>&#96;&#96;&#96;shell<br>echo “blacklist nouveau” &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;pve-blacklist.conf<br>echo “blacklist radeon” &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;pve-blacklist.conf</p>
<p>&#96;&#96;&#96;shell</p>
<p>如果是N卡还需要加入下面的配置到kvm.conf（据老外说是避免一些莫名其妙的错误）：</p>
<p>&#96;&#96;&#96;shell<br>echo “options kvm ignore_msrs&#x3D;1” &gt; &#x2F;etc&#x2F;modprobe.d&#x2F;kvm.conf</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@pve:<del># echo “blacklist nouveau” &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;pve-blacklist.conf<br>root@pve:</del># echo “blacklist radeon” &gt;&gt; &#x2F;etc&#x2F;modprobe.d&#x2F;pve-blacklist.conf<br>root@pve:<del>#<br>root@pve:</del># cat &#x2F;etc&#x2F;modprobe.d&#x2F;pve-blacklist.conf</p>
<h1 id="This-file-contains-a-list-of-modules-which-are-not-supported-by-Proxmox-VE"><a href="#This-file-contains-a-list-of-modules-which-are-not-supported-by-Proxmox-VE" class="headerlink" title="This file contains a list of modules which are not supported by Proxmox VE"></a>This file contains a list of modules which are not supported by Proxmox VE</h1><h1 id="nidiafb-see-bugreport-https-bugzilla-proxmox-com-show-bug-cgi-id-701"><a href="#nidiafb-see-bugreport-https-bugzilla-proxmox-com-show-bug-cgi-id-701" class="headerlink" title="nidiafb see bugreport https://bugzilla.proxmox.com/show_bug.cgi?id=701"></a>nidiafb see bugreport <a href="https://bugzilla.proxmox.com/show_bug.cgi?id=701">https://bugzilla.proxmox.com/show_bug.cgi?id=701</a></h1><p>blacklist nvidiafb<br>blacklist nouveau<br>blacklist radeon<br>root@pve:<del>#<br>root@pve:</del># echo “options kvm ignore_msrs&#x3D;1” &gt; &#x2F;etc&#x2F;modprobe.d&#x2F;kvm.conf<br>root@pve:<del>#<br>root@pve:</del># cat &#x2F;etc&#x2F;modprobe.d&#x2F;kvm.conf<br>options kvm ignore_msrs&#x3D;1</p>
<p>&#96;&#96;&#96;shell</p>
<p>更新内核：</p>
<p>&#96;&#96;&#96;shell<br>root@pve:<del># update-initramfs -u<br>update-initramfs: Generating &#x2F;boot&#x2F;initrd.img-5.11.22-5-pve<br>Running hook script ‘zz-proxmox-boot’..<br>Re-executing ‘&#x2F;etc&#x2F;kernel&#x2F;postinst.d&#x2F;zz-proxmox-boot’ in new private mount namespace..<br>No &#x2F;etc&#x2F;kernel&#x2F;proxmox-boot-uuids found, skipping ESP sync.<br>root@pve:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>重启机器：</p>
<p>root@pve:~# reboot</p>
<p>重启上来之后检查模块是否正常加载：</p>
<p>&#96;&#96;&#96;shell<br>root@pve:<del># lsmod | grep vfio<br>vfio_pci               57344  1<br>vfio_virqfd            16384  1 vfio_pci<br>irqbypass              16384  11 vfio_pci,kvm<br>vfio_iommu_type1       36864  1<br>vfio                   36864  5 vfio_iommu_type1,vfio_pci<br>root@pve:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>查看显卡</p>
<p>&#96;&#96;&#96;shell<br>root@pve:<del># lspci -nn | grep NV<br>86:00.0 3D controller [0302]: NVIDIA Corporation TU104GL [Tesla T4] [10de:1eb8] (rev a1)<br>root@pve:</del>#<br>root@pve:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p>查看显卡ID，写入到配置中  </p>
<p>&#96;&#96;&#96;shell<br>root@pve:<del># lspci -n -s 86:00<br>86:00.0 0302: 10de:1eb8 (rev a1)<br>root@pve:</del>#<br>root@pve:<del>#<br>root@pve:</del># echo “options vfio-pci ids&#x3D;10de:1eb8” &gt; &#x2F;etc&#x2F;modprobe.d&#x2F;vfio.conf<br>root@pve:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f1878eff91e44661a900a2f4c0dbe0bd~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/df6655444ba44dd4974e5558dba2f149~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d2203f2d5f38423f9729c0c2a8f7ce4f~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>k8s加入新的master节点出现etcd检查失败</title>
    <url>/2021/12/30/2021-12-30-k8s%E5%8A%A0%E5%85%A5%E6%96%B0%E7%9A%84master%E8%8A%82%E7%82%B9%E5%87%BA%E7%8E%B0etcd%E6%A3%80%E6%9F%A5%E5%A4%B1%E8%B4%A5/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/822b3cb8ad29468fbab442636897ca91~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p> <strong>背景：</strong>  </p>
<p> <strong>昨天在建立好新的集群后，出现了新的问题，其中的一台master节点无法正常工作。虽然可以正常使用，但是就出现了单点故障，今天在修复时出现了etcd健康检查自检没通过。</strong></p>
<p> <strong>Yesterday, after a new cluster was established, a new problem a problem occurred, and one of the master nodes did not work properly. Although can be used normally, but there is a single point of failure, today in the repair of the etcd health check self-test failed.</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d331969e33c44e378170cce9b8c803dd~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>对加入集群中时，出现如下报错：</strong></p>
<p><strong>When you join a cluster, the following error occurs</strong>  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0d6b5acc83f54005847ad3a4eb70338e~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    <strong>提示 etcd 监控检查失败，查看一下Kubernetes 集群中的 kubeadm 配置信息。</strong></p>
<p> <strong>Prompt the etcd monitoring check to fail and review the kubeadm configuration information in the Kubernetes cluster.</strong></p>
<hr>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 ~\]# kubectl describe configmaps kubeadm-config -n kube-system</span><br><span class="line">----</span><br><span class="line">apiEndpoints:</span><br><span class="line">  master-01:</span><br><span class="line">    advertiseAddress: 10.0.0.11</span><br><span class="line">    bindPort: 6443</span><br><span class="line">  master-02:</span><br><span class="line">    advertiseAddress: 10.0.0.12</span><br><span class="line">    bindPort: 6443</span><br><span class="line">  master-03:</span><br><span class="line">    advertiseAddress: 10.0.0.13</span><br><span class="line">    bindPort: 6443</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: ClusterStatus</span><br><span class="line"></span><br><span class="line">Events:  &lt;none&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>  <strong>因为集群搭建的时候，etcd是镜像的方式，在master02上面出现问题后，进行剔除完成后，etcd还是在存储在每个master上面，所以重新添加的时候会得知健康检查失败。</strong></p>
<p> <strong>Because when the cluster is built, etcd is mirrored, after the problem on master02, after the cull is completed, etcd is still stored on top of each master, so when you add again, you will learn that the health check failed.</strong></p>
<hr>
<p> <strong>这时就需要进入容器内部进行手动删除这个etcd了，首先获取集群中的etcd pod列表看一下，并进入内部给一个sh窗口。</strong>  </p>
<p> <strong>At this point you need to go inside the container to manually delete this etcd, first get the list of etcd pods in the cluster to see, and go inside to give a sh window</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 ~\]# kubectl get pods -n kube-system | grep etcd</span><br><span class="line">\[root@master-01 ~\]# kubectl exec -it etcd-master-03 sh -n kube-system</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/693f737c0d5343d6a3f622380144f2ce~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    <strong>进入容器后，执行如下操作</strong>：</p>
<p>    <strong>After entering the container, do the following</strong>  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\## 配置环境</span><br><span class="line">$ export ETCDCTL\_API=3</span><br><span class="line">$ alias etcdctl=&#x27;etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key&#x27;</span><br><span class="line"></span><br><span class="line">## 查看 etcd 集群成员列表</span><br><span class="line">$ etcdctl member list</span><br><span class="line"></span><br><span class="line">## 删除 etcd 集群成员 master-02</span><br><span class="line">$ etcdctl member remove </span><br><span class="line"></span><br><span class="line">## 再次查看 etcd 集群成员列表</span><br><span class="line">$ etcdctl member list</span><br><span class="line"></span><br><span class="line">## 退出容器</span><br><span class="line">$ exit</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de5f4d3222304d2998cf66d5e13d878f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/69580aae7635438787b6e2f7ed18d513~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>查看列表并删除已不存在的master</strong></p>
<p><strong>View the list and remove the master that no longer exists</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a800ec4b901346e6b1bcda214dea07d7~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<hr>
<p><strong>再次进行加入master，即可成功。</strong></p>
<p><strong>Join master again and you’ll be successful</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c5560a9a6ea24fa09d7ac83e72d50220~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<hr>
<hr>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/23cb342ecf694be6a7b3317b62995d9d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>高新科技园</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>YUM下载全量依赖</title>
    <url>/2021/12/30/2021-12-30-YUM%E4%B8%8B%E8%BD%BD%E5%85%A8%E9%87%8F%E4%BE%9D%E8%B5%96/</url>
    <content><![CDATA[<p>    在离线的内网环境下进行安装一些软件的时候会出现依赖不完整的情况，一般情况下会使用如下方式进行下载依赖包  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/942f25d7509a404f9b6e5f7cbc194fd4~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>查看依赖包可以使用 yum deplist 进行查找</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# yum deplist nginx</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * epel: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * extras: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * updates: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line">package: nginx.x86_64 1:1.20.1-2.el7</span><br><span class="line">  dependency: /bin/sh</span><br><span class="line">   provider: bash.x86_64 4.2.46-34.el7</span><br><span class="line">  dependency: libc.so.6(GLIBC_2.17)(64bit)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">  dependency: libcrypt.so.1()(64bit)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">  dependency: libcrypt.so.1(GLIBC_2.2.5)(64bit)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">  dependency: libcrypto.so.1.1()(64bit)</span><br><span class="line">   provider: openssl11-libs.x86_64 1:1.1.1g-3.el7</span><br><span class="line">  dependency: libcrypto.so.1.1(OPENSSL_1_1_0)(64bit)</span><br><span class="line">   provider: openssl11-libs.x86_64 1:1.1.1g-3.el7</span><br><span class="line">  dependency: libdl.so.2()(64bit)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">  dependency: libdl.so.2(GLIBC_2.2.5)(64bit)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">  dependency: libpcre.so.1()(64bit)</span><br><span class="line">   provider: pcre.x86_64 8.32-17.el7</span><br><span class="line">  dependency: libprofiler.so.0()(64bit)</span><br><span class="line">   provider: gperftools-libs.x86_64 2.6.1-1.el7</span><br><span class="line">  dependency: libpthread.so.0()(64bit)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">  dependency: libpthread.so.0(GLIBC_2.2.5)(64bit)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">  dependency: libpthread.so.0(GLIBC_2.3.2)(64bit)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">  dependency: libssl.so.1.1()(64bit)</span><br><span class="line">   provider: openssl11-libs.x86_64 1:1.1.1g-3.el7</span><br><span class="line">  dependency: libssl.so.1.1(OPENSSL_1_1_0)(64bit)</span><br><span class="line">   provider: openssl11-libs.x86_64 1:1.1.1g-3.el7</span><br><span class="line">  dependency: libssl.so.1.1(OPENSSL_1_1_1)(64bit)</span><br><span class="line">   provider: openssl11-libs.x86_64 1:1.1.1g-3.el7</span><br><span class="line">  dependency: libz.so.1()(64bit)</span><br><span class="line">   provider: zlib.x86_64 1.2.7-19.el7_9</span><br><span class="line">  dependency: nginx-filesystem</span><br><span class="line">   provider: nginx-filesystem.noarch 1:1.20.1-2.el7</span><br><span class="line">  dependency: nginx-filesystem = 1:1.20.1-2.el7</span><br><span class="line">   provider: nginx-filesystem.noarch 1:1.20.1-2.el7</span><br><span class="line">  dependency: openssl</span><br><span class="line">   provider: openssl.x86_64 1:1.0.2k-21.el7_9</span><br><span class="line">  dependency: pcre</span><br><span class="line">   provider: pcre.x86_64 8.32-17.el7</span><br><span class="line">   provider: pcre.i686 8.32-17.el7</span><br><span class="line">  dependency: redhat-indexhtml</span><br><span class="line">   provider: centos-indexhtml.noarch 7-9.el7.centos</span><br><span class="line">  dependency: rtld(GNU_HASH)</span><br><span class="line">   provider: glibc.x86_64 2.17-324.el7_9</span><br><span class="line">   provider: glibc.i686 2.17-324.el7_9</span><br><span class="line">  dependency: system-logos</span><br><span class="line">   provider: centos-logos.noarch 70.0.6-3.el7.centos</span><br><span class="line">  dependency: systemd</span><br><span class="line">   provider: systemd.x86_64 219-78.el7_9.3</span><br><span class="line">[root@localhost ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>使用 repotrack 命令进行下载所需依赖</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# yum -y install yum-utils</span><br><span class="line">[root@localhost ~]# repotrack  nginx</span><br><span class="line">Downloading acl-2.2.51-15.el7.x86_64.rpm</span><br><span class="line">Downloading audit-libs-2.8.5-4.el7.x86_64.rpm</span><br><span class="line">Downloading audit-libs-2.8.5-4.el7.i686.rpm</span><br><span class="line">Downloading basesystem-10.0-7.el7.centos.noarch.rpm</span><br><span class="line">Downloading bash-4.2.46-34.el7.x86_64.rpm</span><br><span class="line">Downloading binutils-2.27-44.base.el7.x86_64.rpm</span><br><span class="line">Downloading bzip2-libs-1.0.6-13.el7.x86_64.rpm</span><br><span class="line">Downloading bzip2-libs-1.0.6-13.el7.i686.rpm</span><br><span class="line">Downloading ca-certificates-2020.2.41-70.0.el7_8.noarch.rpm</span><br><span class="line">Downloading centos-indexhtml-7-9.el7.centos.noarch.rpm</span><br><span class="line">Downloading centos-logos-70.0.6-3.el7.centos.noarch.rpm</span><br><span class="line">Downloading centos-release-7-9.2009.1.el7.centos.x86_64.rpm</span><br><span class="line">Downloading chkconfig-1.7.6-1.el7.x86_64.rpm</span><br><span class="line">Downloading coreutils-8.22-24.el7_9.2.x86_64.rpm</span><br><span class="line">Downloading cpio-2.11-28.el7.x86_64.rpm</span><br><span class="line">Downloading cracklib-2.9.0-11.el7.x86_64.rpm</span><br><span class="line">Downloading cracklib-2.9.0-11.el7.i686.rpm</span><br><span class="line">Downloading cracklib-dicts-2.9.0-11.el7.x86_64.rpm</span><br><span class="line">Downloading cryptsetup-libs-2.0.3-6.el7.x86_64.rpm</span><br><span class="line">Downloading curl-7.29.0-59.el7_9.1.x86_64.rpm</span><br><span class="line">Downloading cyrus-sasl-lib-2.1.26-23.el7.x86_64.rpm</span><br><span class="line">Downloading cyrus-sasl-lib-2.1.26-23.el7.i686.rpm</span><br><span class="line">Downloading dbus-1.10.24-15.el7.x86_64.rpm</span><br><span class="line">Downloading dbus-libs-1.10.24-15.el7.x86_64.rpm</span><br><span class="line">Downloading device-mapper-1.02.170-6.el7_9.5.x86_64.rpm</span><br><span class="line">Downloading device-mapper-libs-1.02.170-6.el7_9.5.i686.rpm</span><br><span class="line">Downloading device-mapper-libs-1.02.170-6.el7_9.5.x86_64.rpm</span><br><span class="line">Downloading diffutils-3.3-5.el7.i686.rpm</span><br><span class="line">Downloading diffutils-3.3-5.el7.x86_64.rpm</span><br><span class="line">Downloading dracut-033-572.el7.x86_64.rpm</span><br><span class="line">Downloading elfutils-default-yama-scope-0.176-5.el7.noarch.rpm</span><br><span class="line">Downloading elfutils-libelf-0.176-5.el7.x86_64.rpm</span><br><span class="line">Downloading elfutils-libelf-0.176-5.el7.i686.rpm</span><br><span class="line">Downloading elfutils-libs-0.176-5.el7.x86_64.rpm</span><br><span class="line">Downloading elfutils-libs-0.176-5.el7.i686.rpm</span><br><span class="line">Downloading expat-2.1.0-12.el7.x86_64.rpm</span><br><span class="line">Downloading filesystem-3.2-25.el7.x86_64.rpm</span><br><span class="line">Downloading findutils-4.5.11-6.el7.x86_64.rpm</span><br><span class="line">Downloading gawk-4.0.2-4.el7_3.1.x86_64.rpm</span><br><span class="line">Downloading glib2-2.56.1-9.el7_9.i686.rpm</span><br><span class="line">Downloading glib2-2.56.1-9.el7_9.x86_64.rpm</span><br><span class="line">Downloading glibc-2.17-324.el7_9.i686.rpm</span><br><span class="line">Downloading glibc-2.17-324.el7_9.x86_64.rpm</span><br><span class="line">Downloading glibc-common-2.17-324.el7_9.x86_64.rpm</span><br><span class="line">Downloading gmp-6.0.0-15.el7.i686.rpm</span><br><span class="line">Downloading gmp-6.0.0-15.el7.x86_64.rpm</span><br><span class="line">Downloading gperftools-libs-2.6.1-1.el7.x86_64.rpm</span><br><span class="line">Downloading grep-2.20-3.el7.x86_64.rpm</span><br><span class="line">Downloading gzip-1.5-10.el7.x86_64.rpm</span><br><span class="line">Downloading hardlink-1.0-19.el7.x86_64.rpm</span><br><span class="line">Downloading info-5.1-5.el7.x86_64.rpm</span><br><span class="line">Downloading json-c-0.11-4.el7_0.x86_64.rpm</span><br><span class="line">Downloading keyutils-libs-1.5.8-3.el7.i686.rpm</span><br><span class="line">Downloading keyutils-libs-1.5.8-3.el7.x86_64.rpm</span><br><span class="line">Downloading kmod-20-28.el7.x86_64.rpm</span><br><span class="line">Downloading kmod-libs-20-28.el7.x86_64.rpm</span><br><span class="line">Downloading kpartx-0.4.9-134.el7_9.x86_64.rpm</span><br><span class="line">Downloading krb5-libs-1.15.1-50.el7.i686.rpm</span><br><span class="line">Downloading krb5-libs-1.15.1-50.el7.x86_64.rpm</span><br><span class="line">Downloading libacl-2.2.51-15.el7.x86_64.rpm</span><br><span class="line">Downloading libacl-2.2.51-15.el7.i686.rpm</span><br><span class="line">Downloading libattr-2.4.46-13.el7.i686.rpm</span><br><span class="line">Downloading libattr-2.4.46-13.el7.x86_64.rpm</span><br><span class="line">Downloading libblkid-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">Downloading libblkid-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">Downloading libcap-2.22-11.el7.x86_64.rpm</span><br><span class="line">Downloading libcap-2.22-11.el7.i686.rpm</span><br><span class="line">Downloading libcap-ng-0.7.5-4.el7.i686.rpm</span><br><span class="line">Downloading libcap-ng-0.7.5-4.el7.x86_64.rpm</span><br><span class="line">Downloading libcom_err-1.42.9-19.el7.x86_64.rpm</span><br><span class="line">Downloading libcom_err-1.42.9-19.el7.i686.rpm</span><br><span class="line">Downloading libcurl-7.29.0-59.el7_9.1.i686.rpm</span><br><span class="line">Downloading libcurl-7.29.0-59.el7_9.1.x86_64.rpm</span><br><span class="line">Downloading libdb-5.3.21-25.el7.i686.rpm</span><br><span class="line">Downloading libdb-5.3.21-25.el7.x86_64.rpm</span><br><span class="line">Downloading libdb-utils-5.3.21-25.el7.x86_64.rpm</span><br><span class="line">Downloading libffi-3.0.13-19.el7.i686.rpm</span><br><span class="line">Downloading libffi-3.0.13-19.el7.x86_64.rpm</span><br><span class="line">Downloading libgcc-4.8.5-44.el7.x86_64.rpm</span><br><span class="line">Downloading libgcc-4.8.5-44.el7.i686.rpm</span><br><span class="line">Downloading libgcrypt-1.5.3-14.el7.x86_64.rpm</span><br><span class="line">Downloading libgcrypt-1.5.3-14.el7.i686.rpm</span><br><span class="line">Downloading libgpg-error-1.12-3.el7.i686.rpm</span><br><span class="line">Downloading libgpg-error-1.12-3.el7.x86_64.rpm</span><br><span class="line">Downloading libidn-1.28-4.el7.i686.rpm</span><br><span class="line">Downloading libidn-1.28-4.el7.x86_64.rpm</span><br><span class="line">Downloading libmount-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">Downloading libmount-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">Downloading libpwquality-1.2.3-5.el7.i686.rpm</span><br><span class="line">Downloading libpwquality-1.2.3-5.el7.x86_64.rpm</span><br><span class="line">Downloading libselinux-2.5-15.el7.x86_64.rpm</span><br><span class="line">Downloading libselinux-2.5-15.el7.i686.rpm</span><br><span class="line">Downloading libsemanage-2.5-14.el7.x86_64.rpm</span><br><span class="line">Downloading libsepol-2.5-10.el7.i686.rpm</span><br><span class="line">Downloading libsepol-2.5-10.el7.x86_64.rpm</span><br><span class="line">Downloading libsmartcols-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">Downloading libsmartcols-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">Downloading libssh2-1.8.0-4.el7.x86_64.rpm</span><br><span class="line">Downloading libssh2-1.8.0-4.el7.i686.rpm</span><br><span class="line">Downloading libstdc++-4.8.5-44.el7.x86_64.rpm</span><br><span class="line">Downloading libstdc++-4.8.5-44.el7.i686.rpm</span><br><span class="line">Downloading libtasn1-4.10-1.el7.i686.rpm</span><br><span class="line">Downloading libtasn1-4.10-1.el7.x86_64.rpm</span><br><span class="line">Downloading libuser-0.60-9.el7.x86_64.rpm</span><br><span class="line">Downloading libuser-0.60-9.el7.i686.rpm</span><br><span class="line">Downloading libutempter-1.1.6-4.el7.x86_64.rpm</span><br><span class="line">Downloading libutempter-1.1.6-4.el7.i686.rpm</span><br><span class="line">Downloading libuuid-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">Downloading libuuid-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">Downloading libverto-0.2.5-4.el7.i686.rpm</span><br><span class="line">Downloading libverto-0.2.5-4.el7.x86_64.rpm</span><br><span class="line">Downloading libxml2-2.9.1-6.el7.5.x86_64.rpm</span><br><span class="line">Downloading lua-5.1.4-15.el7.x86_64.rpm</span><br><span class="line">Downloading lz4-1.8.3-1.el7.x86_64.rpm</span><br><span class="line">Downloading lz4-1.8.3-1.el7.i686.rpm</span><br><span class="line">Downloading make-3.82-24.el7.x86_64.rpm</span><br><span class="line">Downloading ncurses-5.9-14.20130511.el7_4.x86_64.rpm</span><br><span class="line">Downloading ncurses-base-5.9-14.20130511.el7_4.noarch.rpm</span><br><span class="line">Downloading ncurses-libs-5.9-14.20130511.el7_4.x86_64.rpm</span><br><span class="line">Downloading ncurses-libs-5.9-14.20130511.el7_4.i686.rpm</span><br><span class="line">Downloading nginx-1.20.1-2.el7.x86_64.rpm</span><br><span class="line">Downloading nginx-filesystem-1.20.1-2.el7.noarch.rpm</span><br><span class="line">Downloading nspr-4.25.0-2.el7_9.x86_64.rpm</span><br><span class="line">Downloading nspr-4.25.0-2.el7_9.i686.rpm</span><br><span class="line">Downloading nss-3.53.1-7.el7_9.x86_64.rpm</span><br><span class="line">Downloading nss-3.53.1-7.el7_9.i686.rpm</span><br><span class="line">Downloading nss-pem-1.0.3-7.el7.x86_64.rpm</span><br><span class="line">Downloading nss-pem-1.0.3-7.el7.i686.rpm</span><br><span class="line">Downloading nss-softokn-3.53.1-6.el7_9.x86_64.rpm</span><br><span class="line">Downloading nss-softokn-3.53.1-6.el7_9.i686.rpm</span><br><span class="line">Downloading nss-softokn-freebl-3.53.1-6.el7_9.i686.rpm</span><br><span class="line">Downloading nss-softokn-freebl-3.53.1-6.el7_9.x86_64.rpm</span><br><span class="line">Downloading nss-sysinit-3.53.1-7.el7_9.x86_64.rpm</span><br><span class="line">Downloading nss-tools-3.53.1-7.el7_9.x86_64.rpm</span><br><span class="line">Downloading nss-util-3.53.1-1.el7_9.i686.rpm</span><br><span class="line">Downloading nss-util-3.53.1-1.el7_9.x86_64.rpm</span><br><span class="line">Downloading openldap-2.4.44-23.el7_9.i686.rpm</span><br><span class="line">Downloading openldap-2.4.44-23.el7_9.x86_64.rpm</span><br><span class="line">Downloading openssl-1.0.2k-21.el7_9.x86_64.rpm</span><br><span class="line">Downloading openssl-libs-1.0.2k-21.el7_9.x86_64.rpm</span><br><span class="line">Downloading openssl-libs-1.0.2k-21.el7_9.i686.rpm</span><br><span class="line">Downloading openssl11-libs-1.1.1g-3.el7.x86_64.rpm</span><br><span class="line">Downloading p11-kit-0.23.5-3.el7.i686.rpm</span><br><span class="line">Downloading p11-kit-0.23.5-3.el7.x86_64.rpm</span><br><span class="line">Downloading p11-kit-trust-0.23.5-3.el7.i686.rpm</span><br><span class="line">Downloading p11-kit-trust-0.23.5-3.el7.x86_64.rpm</span><br><span class="line">Downloading pam-1.1.8-23.el7.x86_64.rpm</span><br><span class="line">Downloading pam-1.1.8-23.el7.i686.rpm</span><br><span class="line">Downloading pcre-8.32-17.el7.i686.rpm</span><br><span class="line">Downloading pcre-8.32-17.el7.x86_64.rpm</span><br><span class="line">Downloading pkgconfig-0.27.1-4.el7.x86_64.rpm</span><br><span class="line">Downloading pkgconfig-0.27.1-4.el7.i686.rpm</span><br><span class="line">Downloading popt-1.13-16.el7.i686.rpm</span><br><span class="line">Downloading popt-1.13-16.el7.x86_64.rpm</span><br><span class="line">Downloading procps-ng-3.3.10-28.el7.x86_64.rpm</span><br><span class="line">Downloading procps-ng-3.3.10-28.el7.i686.rpm</span><br><span class="line">Downloading qrencode-libs-3.4.1-3.el7.x86_64.rpm</span><br><span class="line">Downloading readline-6.2-11.el7.i686.rpm</span><br><span class="line">Downloading readline-6.2-11.el7.x86_64.rpm</span><br><span class="line">Downloading rpm-4.11.3-45.el7.x86_64.rpm</span><br><span class="line">Downloading rpm-libs-4.11.3-45.el7.x86_64.rpm</span><br><span class="line">Downloading sed-4.2.2-7.el7.x86_64.rpm</span><br><span class="line">Downloading setup-2.8.71-11.el7.noarch.rpm</span><br><span class="line">Downloading shadow-utils-4.6-5.el7.x86_64.rpm</span><br><span class="line">Downloading shared-mime-info-1.8-5.el7.x86_64.rpm</span><br><span class="line">Downloading sqlite-3.7.17-8.el7_7.1.i686.rpm</span><br><span class="line">Downloading sqlite-3.7.17-8.el7_7.1.x86_64.rpm</span><br><span class="line">Downloading systemd-219-78.el7_9.3.x86_64.rpm</span><br><span class="line">Downloading systemd-libs-219-78.el7_9.3.x86_64.rpm</span><br><span class="line">Downloading systemd-libs-219-78.el7_9.3.i686.rpm</span><br><span class="line">Downloading tar-1.26-35.el7.x86_64.rpm</span><br><span class="line">Downloading tzdata-2021a-1.el7.noarch.rpm</span><br><span class="line">Downloading ustr-1.0.4-16.el7.x86_64.rpm</span><br><span class="line">Downloading util-linux-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">Downloading util-linux-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">Downloading xz-5.2.2-1.el7.x86_64.rpm</span><br><span class="line">Downloading xz-libs-5.2.2-1.el7.x86_64.rpm</span><br><span class="line">Downloading xz-libs-5.2.2-1.el7.i686.rpm</span><br><span class="line">Downloading zlib-1.2.7-19.el7_9.x86_64.rpm</span><br><span class="line">Downloading zlib-1.2.7-19.el7_9.i686.rpm</span><br><span class="line">[root@localhost ~]# ll</span><br><span class="line">total 114432</span><br><span class="line">-rw-r--r--. 1 root root    83408 Apr  4  2020 acl-2.2.51-15.el7.x86_64.rpm</span><br><span class="line">-rw-------. 1 root root     1201 Jun 25 09:37 anaconda-ks.cfg</span><br><span class="line">-rw-r--r--. 1 root root   104824 Aug 23  2019 audit-libs-2.8.5-4.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   104408 Aug 23  2019 audit-libs-2.8.5-4.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root     5124 Jul  4  2014 basesystem-10.0-7.el7.centos.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root  1037976 Apr  4  2020 bash-4.2.46-34.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  6196400 Oct 15  2020 binutils-2.27-44.base.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    40620 Nov 25  2015 bzip2-libs-1.0.6-13.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    40740 Nov 25  2015 bzip2-libs-1.0.6-13.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   391340 Jun 24  2020 ca-certificates-2020.2.41-70.0.el7_8.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    93872 Jul  4  2014 centos-indexhtml-7-9.el7.centos.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root 22354804 Oct  1  2015 centos-logos-70.0.6-3.el7.centos.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    27288 Dec  3  2020 centos-release-7-9.2009.1.el7.centos.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   186016 Oct 15  2020 chkconfig-1.7.6-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  3417472 Nov 18  2020 coreutils-8.22-24.el7_9.2.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   216500 Oct 15  2020 cpio-2.11-28.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    80952 Jul  4  2014 cracklib-2.9.0-11.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    81964 Jul  4  2014 cracklib-2.9.0-11.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  3751124 Jul  4  2014 cracklib-dicts-2.9.0-11.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   346748 Apr  4  2020 cryptsetup-libs-2.0.3-6.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   277288 Nov 18  2020 curl-7.29.0-59.el7_9.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   158124 Apr 25  2018 cyrus-sasl-lib-2.1.26-23.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   159156 Apr 25  2018 cyrus-sasl-lib-2.1.26-23.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   251300 Oct 15  2020 dbus-1.10.24-15.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   173428 Oct 15  2020 dbus-libs-1.10.24-15.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   304544 Apr 29 23:03 device-mapper-1.02.170-6.el7_9.5.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   335628 Apr 29 23:04 device-mapper-libs-1.02.170-6.el7_9.5.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   333248 Apr 29 23:03 device-mapper-libs-1.02.170-6.el7_9.5.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   327892 Aug 23  2019 diffutils-3.3-5.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   329696 Aug 23  2019 diffutils-3.3-5.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   337240 Oct 15  2020 dracut-033-572.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    33680 Oct 15  2020 elfutils-default-yama-scope-0.176-5.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   204904 Oct 15  2020 elfutils-libelf-0.176-5.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   199352 Oct 15  2020 elfutils-libelf-0.176-5.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   325648 Oct 15  2020 elfutils-libs-0.176-5.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   297844 Oct 15  2020 elfutils-libs-0.176-5.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    82628 Oct 15  2020 expat-2.1.0-12.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  1067124 Apr 25  2018 filesystem-3.2-25.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   572216 Nov 12  2018 findutils-4.5.11-6.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   894476 Jun 29  2017 gawk-4.0.2-4.el7_3.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  2554540 Jun 11 23:07 glib2-2.56.1-9.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root  2571788 Jun 11 23:04 glib2-2.56.1-9.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  4465908 Apr 29 23:05 glibc-2.17-324.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root  3817176 Apr 29 23:03 glibc-2.17-324.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root 12059644 Apr 29 23:03 glibc-common-2.17-324.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   425588 Aug 11  2017 gmp-6.0.0-15.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   287768 Aug 11  2017 gmp-6.0.0-15.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   278636 Apr 25  2018 gperftools-libs-2.6.1-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   352624 Aug 11  2017 grep-2.20-3.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   132636 Apr 25  2018 gzip-1.5-10.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    14640 Jul  4  2014 hardlink-1.0-19.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   238564 Apr 25  2018 info-5.1-5.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    31312 Jul  5  2014 json-c-0.11-4.el7_0.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    25852 Jul  4  2014 keyutils-libs-1.5.8-3.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    25920 Jul  4  2014 keyutils-libs-1.5.8-3.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   125760 Apr  4  2020 kmod-20-28.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    52412 Apr  4  2020 kmod-libs-20-28.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    82532 Nov 18  2020 kpartx-0.4.9-134.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   830508 Oct 15  2020 krb5-libs-1.15.1-50.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   828540 Oct 15  2020 krb5-libs-1.15.1-50.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    28280 Apr  4  2020 libacl-2.2.51-15.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    27976 Apr  4  2020 libacl-2.2.51-15.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    18632 Apr 25  2018 libattr-2.4.46-13.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    18656 Apr 25  2018 libattr-2.4.46-13.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   191636 Feb  4  2021 libblkid-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   187272 Feb  4  2021 libblkid-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    48904 Apr  4  2020 libcap-2.22-11.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    48548 Apr  4  2020 libcap-2.22-11.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    24976 Nov 25  2015 libcap-ng-0.7.5-4.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    25244 Nov 25  2015 libcap-ng-0.7.5-4.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    43132 Oct 15  2020 libcom_err-1.42.9-19.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    43092 Oct 15  2020 libcom_err-1.42.9-19.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   231516 Nov 18  2020 libcurl-7.29.0-59.el7_9.1.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   228648 Nov 18  2020 libcurl-7.29.0-59.el7_9.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   748832 Aug 23  2019 libdb-5.3.21-25.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   737156 Aug 23  2019 libdb-5.3.21-25.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   135576 Aug 23  2019 libdb-utils-5.3.21-25.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    28144 Apr  4  2020 libffi-3.0.13-19.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    30960 Apr  4  2020 libffi-3.0.13-19.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   113236 Oct 15  2020 libgcc-4.8.5-44.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   105308 Oct 15  2020 libgcc-4.8.5-44.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   272044 Aug 11  2017 libgcrypt-1.5.3-14.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   269660 Aug 11  2017 libgcrypt-1.5.3-14.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    89068 Jul  4  2014 libgpg-error-1.12-3.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    89332 Jul  4  2014 libgpg-error-1.12-3.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   213888 Nov 25  2015 libidn-1.28-4.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   213816 Nov 25  2015 libidn-1.28-4.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   188712 Feb  4  2021 libmount-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   189228 Feb  4  2021 libmount-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    87100 Apr 25  2018 libpwquality-1.2.3-5.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    86540 Apr 25  2018 libpwquality-1.2.3-5.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   169856 Apr  4  2020 libselinux-2.5-15.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   166012 Apr  4  2020 libselinux-2.5-15.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   154244 Nov 12  2018 libsemanage-2.5-14.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   301460 Nov 12  2018 libsepol-2.5-10.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   304196 Nov 12  2018 libsepol-2.5-10.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   147288 Feb  4  2021 libsmartcols-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   146164 Feb  4  2021 libsmartcols-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    90480 Oct 15  2020 libssh2-1.8.0-4.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    89984 Oct 15  2020 libssh2-1.8.0-4.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   326568 Oct 15  2020 libstdc++-4.8.5-44.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   313196 Oct 15  2020 libstdc++-4.8.5-44.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   328116 Aug 11  2017 libtasn1-4.10-1.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   328028 Aug 11  2017 libtasn1-4.10-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   405604 Apr 25  2018 libuser-0.60-9.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   409732 Apr 25  2018 libuser-0.60-9.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    25576 Jul  4  2014 libutempter-1.1.6-4.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    25428 Jul  4  2014 libutempter-1.1.6-4.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    87036 Feb  4  2021 libuuid-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    86332 Feb  4  2021 libuuid-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    16728 Jul  4  2014 libverto-0.2.5-4.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    16820 Jul  4  2014 libverto-0.2.5-4.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   684200 Oct 15  2020 libxml2-2.9.1-6.el7.5.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   205412 Nov 21  2016 lua-5.1.4-15.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    98452 Oct 15  2020 lz4-1.8.3-1.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    86572 Oct 15  2020 lz4-1.8.3-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   430712 Aug 23  2019 make-3.82-24.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   310928 Sep  7  2017 ncurses-5.9-14.20130511.el7_4.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    69900 Sep  7  2017 ncurses-base-5.9-14.20130511.el7_4.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   323976 Sep  7  2017 ncurses-libs-5.9-14.20130511.el7_4.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   323192 Sep  7  2017 ncurses-libs-5.9-14.20130511.el7_4.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   600265 Jun  2 08:27 nginx-1.20.1-2.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    23333 Jun  2 08:27 nginx-filesystem-1.20.1-2.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   131612 Oct 15  2020 nspr-4.25.0-2.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   129900 Oct 15  2020 nspr-4.25.0-2.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   890208 Apr 29 23:05 nss-3.53.1-7.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   889384 Apr 29 23:04 nss-3.53.1-7.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    74872 Aug 23  2019 nss-pem-1.0.3-7.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    75584 Aug 23  2019 nss-pem-1.0.3-7.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   370104 Nov  7  2020 nss-softokn-3.53.1-6.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   362588 Nov  7  2020 nss-softokn-3.53.1-6.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   329232 Nov  7  2020 nss-softokn-freebl-3.53.1-6.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   329744 Nov  7  2020 nss-softokn-freebl-3.53.1-6.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    67104 Apr 29 23:04 nss-sysinit-3.53.1-7.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   547892 Apr 29 23:04 nss-tools-3.53.1-7.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    79396 Oct 15  2020 nss-util-3.53.1-1.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    80948 Oct 15  2020 nss-util-3.53.1-1.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   363460 Apr 29 23:05 openldap-2.4.44-23.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   364488 Apr 29 23:04 openldap-2.4.44-23.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   505208 Dec 18  2020 openssl-1.0.2k-21.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  1521105 Mar 30 07:56 openssl11-libs-1.1.1g-3.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  1020608 Dec 18  2020 openssl-libs-1.0.2k-21.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root  1254644 Dec 18  2020 openssl-libs-1.0.2k-21.el7_9.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   247076 Aug 11  2017 p11-kit-0.23.5-3.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   257620 Aug 11  2017 p11-kit-0.23.5-3.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   131504 Aug 11  2017 p11-kit-trust-0.23.5-3.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   131984 Aug 11  2017 p11-kit-trust-0.23.5-3.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   736976 Apr  4  2020 pam-1.1.8-23.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   737960 Apr  4  2020 pam-1.1.8-23.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   430428 Aug 11  2017 pcre-8.32-17.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   432020 Aug 11  2017 pcre-8.32-17.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    54276 Jul  4  2014 pkgconfig-0.27.1-4.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    54928 Jul  4  2014 pkgconfig-0.27.1-4.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    42436 Jul  4  2014 popt-1.13-16.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    42740 Jul  4  2014 popt-1.13-16.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   292948 Oct 15  2020 procps-ng-3.3.10-28.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   298092 Oct 15  2020 procps-ng-3.3.10-28.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    51112 Jul  4  2014 qrencode-libs-3.4.1-3.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   194000 Aug 23  2019 readline-6.2-11.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   197696 Aug 23  2019 readline-6.2-11.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  1219860 Oct 15  2020 rpm-4.11.3-45.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   285088 Oct 15  2020 rpm-libs-4.11.3-45.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   236688 Oct 15  2020 sed-4.2.2-7.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   170000 Apr  4  2020 setup-2.8.71-11.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root  1250180 Aug 23  2019 shadow-utils-4.6-5.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   319576 Apr  4  2020 shared-mime-info-1.8-5.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   406104 Jan 29  2020 sqlite-3.7.17-8.el7_7.1.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   403100 Jan 29  2020 sqlite-3.7.17-8.el7_7.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  5324844 Feb  4  2021 systemd-219-78.el7_9.3.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   435292 Feb  4  2021 systemd-libs-219-78.el7_9.3.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   428468 Feb  4  2021 systemd-libs-219-78.el7_9.3.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   865848 Nov 12  2018 tar-1.26-35.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   513088 Jan 27  2021 tzdata-2021a-1.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    94456 Jul  4  2014 ustr-1.0.4-16.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  2104080 Feb  4  2021 util-linux-2.23.2-65.el7_9.1.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root  2076012 Feb  4  2021 util-linux-2.23.2-65.el7_9.1.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   234160 Nov 21  2016 xz-5.2.2-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   111716 Nov 21  2016 xz-libs-5.2.2-1.el7.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root   105728 Nov 21  2016 xz-libs-5.2.2-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    92968 Feb  4  2021 zlib-1.2.7-19.el7_9.i686.rpm</span><br><span class="line">-rw-r--r--. 1 root root    92068 Feb  4  2021 zlib-1.2.7-19.el7_9.x86_64.rpm</span><br><span class="line">[root@localhost ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>使用 yumdownloader 命令下软件依赖</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# yumdownloader --resolve --destdir=/tmp ansible</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * epel: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * extras: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * updates: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package ansible.noarch 0:2.9.24-2.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: PyYAML for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: python-httplib2 for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: python-jinja2 for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: python-paramiko for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: python-setuptools for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: python-six for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: python2-cryptography for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: python2-jmespath for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: sshpass for package: ansible-2.9.24-2.el7.noarch</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package PyYAML.x86_64 0:3.10-11.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64</span><br><span class="line">---&gt; Package python-jinja2.noarch 0:2.7.2-4.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: python-babel &gt;= 0.8 for package: python-jinja2-2.7.2-4.el7.noarch</span><br><span class="line">--&gt; Processing Dependency: python-markupsafe for package: python-jinja2-2.7.2-4.el7.noarch</span><br><span class="line">---&gt; Package python-paramiko.noarch 0:2.1.1-9.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: python2-pyasn1 for package: python-paramiko-2.1.1-9.el7.noarch</span><br><span class="line">---&gt; Package python-setuptools.noarch 0:0.9.8-7.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: python-backports-ssl_match_hostname for package: python-setuptools-0.9.8-7.el7.noarch</span><br><span class="line">---&gt; Package python-six.noarch 0:1.9.0-2.el7 will be installed</span><br><span class="line">---&gt; Package python2-cryptography.x86_64 0:1.7.2-2.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: python-idna &gt;= 2.0 for package: python2-cryptography-1.7.2-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: python-cffi &gt;= 1.4.1 for package: python2-cryptography-1.7.2-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: python-ipaddress for package: python2-cryptography-1.7.2-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: python-enum34 for package: python2-cryptography-1.7.2-2.el7.x86_64</span><br><span class="line">---&gt; Package python2-httplib2.noarch 0:0.18.1-3.el7 will be installed</span><br><span class="line">---&gt; Package python2-jmespath.noarch 0:0.9.4-2.el7 will be installed</span><br><span class="line">---&gt; Package sshpass.x86_64 0:1.06-2.el7 will be installed</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed</span><br><span class="line">---&gt; Package python-babel.noarch 0:0.9.6-8.el7 will be installed</span><br><span class="line">---&gt; Package python-backports-ssl_match_hostname.noarch 0:3.5.0.1-1.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: python-backports for package: python-backports-ssl_match_hostname-3.5.0.1-1.el7.noarch</span><br><span class="line">---&gt; Package python-cffi.x86_64 0:1.6.0-5.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: python-pycparser for package: python-cffi-1.6.0-5.el7.x86_64</span><br><span class="line">---&gt; Package python-enum34.noarch 0:1.0.4-1.el7 will be installed</span><br><span class="line">---&gt; Package python-idna.noarch 0:2.4-1.el7 will be installed</span><br><span class="line">---&gt; Package python-ipaddress.noarch 0:1.0.16-2.el7 will be installed</span><br><span class="line">---&gt; Package python-markupsafe.x86_64 0:0.11-10.el7 will be installed</span><br><span class="line">---&gt; Package python2-pyasn1.noarch 0:0.1.9-7.el7 will be installed</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package python-backports.x86_64 0:1.0-8.el7 will be installed</span><br><span class="line">---&gt; Package python-pycparser.noarch 0:2.14-1.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: python-ply for package: python-pycparser-2.14-1.el7.noarch</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package python-ply.noarch 0:3.4-11.el7 will be installed</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line">(1/22): PyYAML-3.10-11.el7.x86_64.rpm                                               | 153 kB  00:00:00     </span><br><span class="line">(2/22): python-backports-ssl_match_hostname-3.5.0.1-1.el7.noarch.rpm                |  13 kB  00:00:00     </span><br><span class="line">(3/22): libyaml-0.1.4-11.el7_0.x86_64.rpm                                           |  55 kB  00:00:00     </span><br><span class="line">(4/22): python-cffi-1.6.0-5.el7.x86_64.rpm                                          | 218 kB  00:00:00     </span><br><span class="line">(5/22): python-backports-1.0-8.el7.x86_64.rpm                                       | 5.8 kB  00:00:00     </span><br><span class="line">(6/22): python-idna-2.4-1.el7.noarch.rpm                                            |  94 kB  00:00:00     </span><br><span class="line">(7/22): python-enum34-1.0.4-1.el7.noarch.rpm                                        |  52 kB  00:00:00     </span><br><span class="line">(8/22): python-jinja2-2.7.2-4.el7.noarch.rpm                                        | 519 kB  00:00:00     </span><br><span class="line">(9/22): python-babel-0.9.6-8.el7.noarch.rpm                                         | 1.4 MB  00:00:00     </span><br><span class="line">(10/22): python-paramiko-2.1.1-9.el7.noarch.rpm                                     | 269 kB  00:00:00     </span><br><span class="line">(11/22): python-ply-3.4-11.el7.noarch.rpm                                           | 123 kB  00:00:00     </span><br><span class="line">(12/22): python-pycparser-2.14-1.el7.noarch.rpm                                     | 104 kB  00:00:00     </span><br><span class="line">(13/22): python-six-1.9.0-2.el7.noarch.rpm                                          |  29 kB  00:00:00     </span><br><span class="line">(14/22): python-setuptools-0.9.8-7.el7.noarch.rpm                                   | 397 kB  00:00:00     </span><br><span class="line">(15/22): python2-cryptography-1.7.2-2.el7.x86_64.rpm                                | 502 kB  00:00:00     </span><br><span class="line">(16/22): python-markupsafe-0.11-10.el7.x86_64.rpm                                   |  25 kB  00:00:00     </span><br><span class="line">(17/22): python-ipaddress-1.0.16-2.el7.noarch.rpm                                   |  34 kB  00:00:00     </span><br><span class="line">(18/22): ansible-2.9.24-2.el7.noarch.rpm                                            |  17 MB  00:00:01     </span><br><span class="line">(19/22): python2-httplib2-0.18.1-3.el7.noarch.rpm                                   | 125 kB  00:00:00     </span><br><span class="line">(20/22): python2-jmespath-0.9.4-2.el7.noarch.rpm                                    |  41 kB  00:00:00     </span><br><span class="line">(21/22): sshpass-1.06-2.el7.x86_64.rpm                                              |  21 kB  00:00:00     </span><br><span class="line">(22/22): python2-pyasn1-0.1.9-7.el7.noarch.rpm                                      | 100 kB  00:00:00     </span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# </span><br><span class="line">[root@localhost ~]# ll /tmp/*</span><br><span class="line">-rw-r--r--. 1 root root 17829351 Jul 29 02:38 /tmp/ansible-2.9.24-2.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    56068 Jan 30  2015 /tmp/libyaml-0.1.4-11.el7_0.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   514504 Apr 25  2018 /tmp/python2-cryptography-1.7.2-2.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   128003 Jun 20  2020 /tmp/python2-httplib2-0.18.1-3.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    42303 Apr 23  2020 /tmp/python2-jmespath-0.9.4-2.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   102132 Nov 21  2016 /tmp/python2-pyasn1-0.1.9-7.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root  1426348 Jul  4  2014 /tmp/python-babel-0.9.6-8.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root     5932 Mar 14  2015 /tmp/python-backports-1.0-8.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    12896 Apr 25  2018 /tmp/python-backports-ssl_match_hostname-3.5.0.1-1.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   223012 Nov 21  2016 /tmp/python-cffi-1.6.0-5.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    53496 Nov 25  2015 /tmp/python-enum34-1.0.4-1.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    95952 Aug 11  2017 /tmp/python-idna-2.4-1.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    35176 Nov 21  2016 /tmp/python-ipaddress-1.0.16-2.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   531040 Aug 23  2019 /tmp/python-jinja2-2.7.2-4.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    25792 Jul  4  2014 /tmp/python-markupsafe-0.11-10.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   275112 Nov 21  2018 /tmp/python-paramiko-2.1.1-9.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   125732 Aug 11  2017 /tmp/python-ply-3.4-11.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   106984 Nov 25  2015 /tmp/python-pycparser-2.14-1.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   406404 Aug 11  2017 /tmp/python-setuptools-0.9.8-7.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root    29404 Nov 25  2015 /tmp/python-six-1.9.0-2.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root   156952 Jul  4  2014 /tmp/PyYAML-3.10-11.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    21896 Sep  8  2017 /tmp/sshpass-1.06-2.el7.x86_64.rpm</span><br><span class="line">[root@localhost ~]# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">destdir：指定 rpm 包下载目录（不指定时，默认为当前目录）</span><br><span class="line">resolve：下载依赖的 rpm 包。</span><br></pre></td></tr></table></figure>

<p>只会下载当前系统环境下所需的依赖包</p>
<p><strong>yum 自带的 downloadonly 插件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# yum -y install nginx --downloadonly --downloaddir=/tmp/</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * epel: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * extras: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * updates: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line">Resolving Dependencies</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package nginx.x86_64 1:1.20.1-2.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: nginx-filesystem = 1:1.20.1-2.el7 for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: libcrypto.so.1.1(OPENSSL_1_1_0)(64bit) for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: libssl.so.1.1(OPENSSL_1_1_0)(64bit) for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: libssl.so.1.1(OPENSSL_1_1_1)(64bit) for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: nginx-filesystem for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: redhat-indexhtml for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: libcrypto.so.1.1()(64bit) for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: libprofiler.so.0()(64bit) for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: libssl.so.1.1()(64bit) for package: 1:nginx-1.20.1-2.el7.x86_64</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package centos-indexhtml.noarch 0:7-9.el7.centos will be installed</span><br><span class="line">---&gt; Package gperftools-libs.x86_64 0:2.6.1-1.el7 will be installed</span><br><span class="line">---&gt; Package nginx-filesystem.noarch 1:1.20.1-2.el7 will be installed</span><br><span class="line">---&gt; Package openssl11-libs.x86_64 1:1.1.1g-3.el7 will be installed</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">====================================================================================================================================</span><br><span class="line"> Package                              Arch                       Version                             Repository                Size</span><br><span class="line">====================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> nginx                                x86_64                     1:1.20.1-2.el7                      epel                     586 k</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> centos-indexhtml                     noarch                     7-9.el7.centos                      base                      92 k</span><br><span class="line"> gperftools-libs                      x86_64                     2.6.1-1.el7                         base                     272 k</span><br><span class="line"> nginx-filesystem                     noarch                     1:1.20.1-2.el7                      epel                      23 k</span><br><span class="line"> openssl11-libs                       x86_64                     1:1.1.1g-3.el7                      epel                     1.5 M</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">====================================================================================================================================</span><br><span class="line">Install  1 Package (+4 Dependent packages)</span><br><span class="line"></span><br><span class="line">Total download size: 2.4 M</span><br><span class="line">Installed size: 6.7 M</span><br><span class="line">Background downloading packages, then exiting:</span><br><span class="line">(1/5): centos-indexhtml-7-9.el7.centos.noarch.rpm                                                            |  92 kB  00:00:00     </span><br><span class="line">(2/5): gperftools-libs-2.6.1-1.el7.x86_64.rpm                                                                | 272 kB  00:00:00     </span><br><span class="line">(3/5): nginx-1.20.1-2.el7.x86_64.rpm                                                                         | 586 kB  00:00:00     </span><br><span class="line">(4/5): nginx-filesystem-1.20.1-2.el7.noarch.rpm                                                              |  23 kB  00:00:00     </span><br><span class="line">(5/5): openssl11-libs-1.1.1g-3.el7.x86_64.rpm                                                                | 1.5 MB  00:00:00     </span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                                               8.0 MB/s | 2.4 MB  00:00:00     </span><br><span class="line">exiting because &quot;Download Only&quot; specified</span><br><span class="line">[root@localhost ~]# ll /tmp/*</span><br><span class="line">-rw-r--r--. 1 root root   93872 Jul  4  2014 /tmp/centos-indexhtml-7-9.el7.centos.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root  278636 Apr 25  2018 /tmp/gperftools-libs-2.6.1-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  600265 Jun  2 08:27 /tmp/nginx-1.20.1-2.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   23333 Jun  2 08:27 /tmp/nginx-filesystem-1.20.1-2.el7.noarch.rpm</span><br><span class="line">-rw-r--r--. 1 root root 1521105 Mar 30 07:56 /tmp/openssl11-libs-1.1.1g-3.el7.x86_64.rpm</span><br><span class="line">-rw-------. 1 root root    1183 Aug 16 11:24 /tmp/yum_save_tx.2021-08-16.11-24.riZifR.yumtx</span><br><span class="line">[root@localhost ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3b6d26bce8904f0b931e11b19bc0cd89~tplv-k3u1fbpfcp-zoom-1.image"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（一）--- namespace</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89---_namespace/</url>
    <content><![CDATA[<h3 id="kubernetes核心实战"><a href="#kubernetes核心实战" class="headerlink" title="kubernetes核心实战"></a>kubernetes核心实战</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/914bb248938e4a8997f638331b293d69~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h4 id="1、资源创建方式"><a href="#1、资源创建方式" class="headerlink" title="1、资源创建方式"></a>1、资源创建方式</h4><p>命令行创建</p>
<p>yaml文件创建</p>
<h4 id="2、namespace"><a href="#2、namespace" class="headerlink" title="2、namespace"></a>2、namespace</h4><p>命名空间（namespace）是Kubernetes提供的组织机制，用于给集群中的任何对象组进行分类、筛选和管理。每一个添加到Kubernetes集群的工作负载必须放在一个命名空间中。</p>
<p>命名空间为集群中的对象名称赋予作用域。虽然在命名空间中名称必须是唯一的，但是相同的名称可以在不同的命名空间中使用。这对于某些场景来说可能帮助很大。例如，如果使用命名空间来划分应用程序生命周期环境（如开发、staging、生产），则可以在每个环境中维护利用同样的名称维护相同对象的副本。</p>
<p>命名空间还可以让用户轻松地将策略应用到集群的具体部分。你可以通过定义ResourceQuota对象来控制资源的使用，该对象在每个命名空间的基础上设置了使用资源的限制。类似地，当在集群上使用支持网络策略的CNI（容器网络接口）时，比如Calico或Canal（calico用于策略，flannel用于网络）。你可以将NetworkPolicy应用到命名空间，其中的规则定义了pod之间如何彼此通信。不同的命名空间可以有不同的策略。</p>
<p>使用命名空间最大的好处之一是能够利用Kubernetes RBAC（基于角色的访问控制）。RBAC允许您在单个名称下开发角色，这样将权限或功能列表分组。ClusterRole对象用于定义集群规模的使用模式，而角色对象类型（Role object type）应用于具体的命名空间，从而提供更好的控制和粒度。在角色创建后，RoleBinding可以将定义的功能授予单个命名空间上下文中的具体具体用户或用户组。通过这种方式，命名空间可以使得集群操作者能够将相同的策略映射到组织好的资源集合。</p>
<p><strong>将命名空间映射到团队或项目上</strong></p>
<p><strong>使用命名空间对生命周期环境进行分区</strong></p>
<p><strong>使用命名空间隔离不同的使用者</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# kubectl  create  namespace cby</span><br><span class="line">namespace/cby created</span><br><span class="line">[root@k8s-master-node1 ~]# </span><br><span class="line">[root@k8s-master-node1 ~]# kubectl  get namespaces </span><br><span class="line">NAME                   STATUS   AGE</span><br><span class="line">cby                    Active   2s</span><br><span class="line">default                Active   21h</span><br><span class="line">ingress-nginx          Active   21h</span><br><span class="line">kube-node-lease        Active   21h</span><br><span class="line">kube-public            Active   21h</span><br><span class="line">kube-system            Active   21h</span><br><span class="line">kubernetes-dashboard   Active   21h</span><br><span class="line">[root@k8s-master-node1 ~]# </span><br><span class="line">[root@k8s-master-node1 ~]# kubectl  delete  namespace cby</span><br><span class="line">namespace &quot;cby&quot; deleted</span><br><span class="line">[root@k8s-master-node1 ~]# </span><br><span class="line">[root@k8s-master-node1 ~]# </span><br><span class="line">[root@k8s-master-node1 ~]# kubectl  get namespaces </span><br><span class="line">NAME                   STATUS   AGE</span><br><span class="line">default                Active   21h</span><br><span class="line">ingress-nginx          Active   21h</span><br><span class="line">kube-node-lease        Active   21h</span><br><span class="line">kube-public            Active   21h</span><br><span class="line">kube-system            Active   21h</span><br><span class="line">kubernetes-dashboard   Active   21h</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="查看yaml格式"><a href="#查看yaml格式" class="headerlink" title="查看yaml格式"></a>查看yaml格式</h5><ul>
<li><pre><code>[root@k8s-master-node1 ~]# kubectl  create  namespace cby
namespace/cby created
[root@k8s-master-node1 ~]# 
[root@k8s-master-node1 ~]# kubectl  get namespaces cby -o yaml
apiVersion: v1
kind: Namespace
metadata:
creationTimestamp: &quot;2021-11-17T03:08:10Z&quot;
labels:
  kubernetes.io/metadata.name: cby
name: cby
resourceVersion: &quot;311903&quot;
uid: 63f2e47d-a2a5-4a67-8fd2-7ca29bfb02be
spec:
finalizers:

- kubernetes
  status:
    phase: Active
[root@k8s-master-node1 ~]#
</code></pre>
</li>
</ul>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e358ba9f0bfa41e39fa47c8f7420ffab~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>57篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5d357157ea1e4fceb1a22c8e6dc229c3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes(k8s) 存储动态挂载</title>
    <url>/2021/12/30/2021-12-30-kubernetes(k8s)_%E5%AD%98%E5%82%A8%E5%8A%A8%E6%80%81%E6%8C%82%E8%BD%BD/</url>
    <content><![CDATA[<p>使用 nfs 文件系统 实现kubernetes存储动态挂载</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dba1e41aadeb45279e8a921040b9cdd1~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>1. 安装服务端和客户端</p>
<p>&#96;&#96;&#96;shell<br>root@hello:~# apt install nfs-kernel-server nfs-common</p>
<p>&#96;&#96;&#96;shell</p>
<p>其中 nfs-kernel-server 为服务端，　nfs-common 为客户端。</p>
<p>2. 配置 nfs 共享目录</p>
<p>&#96;&#96;&#96;shell<br>root@hello:<del># mkdir &#x2F;nfs<br>root@hello:</del># sudo vim &#x2F;etc&#x2F;exports<br>&#x2F;nfs *(rw,sync,no_root_squash,no_subtree_check)</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>各字段解析如下：<br>&#x2F;nfs: 要共享的目录<br>：指定可以访问共享目录的用户 ip, * 代表所有用户。192.168.3.　指定网段。192.168.3.29 指定 ip。<br>rw：可读可写。如果想要只读的话，可以指定 ro。<br>sync：文件同步写入到内存与硬盘中。<br>async：文件会先暂存于内存中，而非直接写入硬盘。<br>no_root_squash：登入 nfs 主机使用分享目录的使用者，如果是 root 的话，那么对于这个分享的目录来说，他就具有 root 的权限！这个项目『极不安全』，不建议使用！但如果你需要在客户端对 nfs 目录进行写入操作。你就得配置 no_root_squash。方便与安全不可兼得。<br>root_squash：在登入 nfs 主机使用分享之目录的使用者如果是 root 时，那么这个使用者的权限将被压缩成为匿名使用者，通常他的 UID 与 GID 都会变成 nobody 那个系统账号的身份。<br>subtree_check：强制 nfs 检查父目录的权限（默认）<br>no_subtree_check：不检查父目录权限</p>
<p>&#96;&#96;&#96;shell</p>
<p>配置完成后，执行以下命令导出共享目录，并重启 nfs 服务:</p>
<p>&#96;&#96;&#96;shell<br>root@hello:<del># exportfs -a<br>root@hello:</del># systemctl restart nfs-kernel-server<br>root@hello:<del>#<br>root@hello:</del># systemctl enable nfs-kernel-server</p>
<p>&#96;&#96;&#96;shell</p>
<p>客户端挂载</p>
<p>&#96;&#96;&#96;shell<br>root@hello:<del># apt install nfs-common<br>root@hello:</del># mkdir -p &#x2F;nfs&#x2F;<br>root@hello:~# mount -t nfs 192.168.1.66:&#x2F;nfs&#x2F; &#x2F;nfs&#x2F;</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@hello:~# df -hT<br>Filesystem                        Type      Size  Used Avail Use% Mounted on<br>udev                              devtmpfs  7.8G     0  7.8G   0% &#x2F;dev<br>tmpfs                             tmpfs     1.6G  2.9M  1.6G   1% &#x2F;run<br>&#x2F;dev&#x2F;mapper&#x2F;ubuntu–vg-ubuntu–lv ext4       97G  9.9G   83G  11% &#x2F;<br>tmpfs                             tmpfs     7.9G     0  7.9G   0% &#x2F;dev&#x2F;shm<br>tmpfs                             tmpfs     5.0M     0  5.0M   0% &#x2F;run&#x2F;lock<br>tmpfs                             tmpfs     7.9G     0  7.9G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup<br>&#x2F;dev&#x2F;loop0                        squashfs   56M   56M     0 100% &#x2F;snap&#x2F;core18&#x2F;2128<br>&#x2F;dev&#x2F;loop1                        squashfs   56M   56M     0 100% &#x2F;snap&#x2F;core18&#x2F;2246<br>&#x2F;dev&#x2F;loop3                        squashfs   33M   33M     0 100% &#x2F;snap&#x2F;snapd&#x2F;12704<br>&#x2F;dev&#x2F;loop2                        squashfs   62M   62M     0 100% &#x2F;snap&#x2F;core20&#x2F;1169<br>&#x2F;dev&#x2F;loop4                        squashfs   33M   33M     0 100% &#x2F;snap&#x2F;snapd&#x2F;13640<br>&#x2F;dev&#x2F;loop6                        squashfs   68M   68M     0 100% &#x2F;snap&#x2F;lxd&#x2F;21835<br>&#x2F;dev&#x2F;loop5                        squashfs   71M   71M     0 100% &#x2F;snap&#x2F;lxd&#x2F;21029<br>&#x2F;dev&#x2F;sda2                         ext4      976M  107M  803M  12% &#x2F;boot<br>tmpfs                             tmpfs     1.6G     0  1.6G   0% &#x2F;run&#x2F;user&#x2F;0<br>192.168.1.66:&#x2F;nfs                 nfs4       97G  6.4G   86G   7% &#x2F;nfs</p>
<p>&#96;&#96;&#96;shell</p>
<p>创建配置默认存储</p>
<p>&#96;&#96;&#96;shell<br>[root@k8s-master-node1 ~&#x2F;yaml]# vim nfs-storage.yaml<br>[root@k8s-master-node1 ~&#x2F;yaml]#<br>[root@k8s-master-node1 ~&#x2F;yaml]# cat nfs-storage.yaml<br>apiVersion: storage.k8s.io&#x2F;v1<br>kind: StorageClass<br>metadata:<br>  name: nfs-storage<br>  annotations:<br>    storageclass.kubernetes.io&#x2F;is-default-class: “true”<br>provisioner: k8s-sigs.io&#x2F;nfs-subdir-external-provisioner<br>parameters:<br>  archiveOnDelete: “true”  ## 删除pv的时候，pv的内容是否要备份</p>
<hr>
<p>apiVersion: apps&#x2F;v1<br>kind: Deployment<br>metadata:<br>  name: nfs-client-provisioner<br>  labels:<br>    app: nfs-client-provisioner</p>
<h1 id="replace-with-namespace-where-provisioner-is-deployed"><a href="#replace-with-namespace-where-provisioner-is-deployed" class="headerlink" title="replace with namespace where provisioner is deployed"></a>replace with namespace where provisioner is deployed</h1><p>  namespace: default<br>spec:<br>  replicas: 1<br>  strategy:<br>    type: Recreate<br>  selector:<br>    matchLabels:<br>      app: nfs-client-provisioner<br>  template:<br>    metadata:<br>      labels:<br>        app: nfs-client-provisioner<br>    spec:<br>      serviceAccountName: nfs-client-provisioner<br>      containers:<br>        - name: nfs-client-provisioner<br>          image: registry.cn-hangzhou.aliyuncs.com&#x2F;lfy_k8s_images&#x2F;nfs-subdir-external-provisioner:v4.0.2<br>          # resources:<br>          #    limits:<br>          #      cpu: 10m<br>          #    requests:<br>          #      cpu: 10m<br>          volumeMounts:<br>            - name: nfs-client-root<br>              mountPath: &#x2F;persistentvolumes<br>          env:<br>            - name: PROVISIONER_NAME<br>              value: k8s-sigs.io&#x2F;nfs-subdir-external-provisioner<br>            - name: NFS_SERVER<br>              value: 192.168.1.66 ## 指定自己nfs服务器地址<br>            - name: NFS_PATH<br>              value: &#x2F;nfs&#x2F;  ## nfs服务器共享的目录<br>      volumes:<br>        - name: nfs-client-root<br>          nfs:<br>            server: 192.168.1.66<br>            path: &#x2F;nfs&#x2F;</p>
<hr>
<p>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>  name: nfs-client-provisioner</p>
<h1 id="replace-with-namespace-where-provisioner-is-deployed-1"><a href="#replace-with-namespace-where-provisioner-is-deployed-1" class="headerlink" title="replace with namespace where provisioner is deployed"></a>replace with namespace where provisioner is deployed</h1><h2 id="namespace-default"><a href="#namespace-default" class="headerlink" title="  namespace: default"></a>  namespace: default</h2><p>kind: ClusterRole<br>apiVersion: rbac.authorization.k8s.io&#x2F;v1<br>metadata:<br>  name: nfs-client-provisioner-runner<br>rules:</p>
<ul>
<li>apiGroups: [“”]<br>resources: [“nodes”]<br>verbs: [“get”, “list”, “watch”]</li>
<li>apiGroups: [“”]<br>resources: [“persistentvolumes”]<br>verbs: [“get”, “list”, “watch”, “create”, “delete”]</li>
<li>apiGroups: [“”]<br>resources: [“persistentvolumeclaims”]<br>verbs: [“get”, “list”, “watch”, “update”]</li>
<li>apiGroups: [“storage.k8s.io”]<br>resources: [“storageclasses”]<br>verbs: [“get”, “list”, “watch”]</li>
<li>apiGroups: [“”]<br>resources: [“events”]<br>verbs: [“create”, “update”, “patch”]</li>
</ul>
<hr>
<p>kind: ClusterRoleBinding<br>apiVersion: rbac.authorization.k8s.io&#x2F;v1<br>metadata:<br>  name: run-nfs-client-provisioner<br>subjects:</p>
<ul>
<li>kind: ServiceAccount<br>name: nfs-client-provisioner<h1 id="replace-with-namespace-where-provisioner-is-deployed-2"><a href="#replace-with-namespace-where-provisioner-is-deployed-2" class="headerlink" title="replace with namespace where provisioner is deployed"></a>replace with namespace where provisioner is deployed</h1>namespace: default<br>roleRef:<br>  kind: ClusterRole<br>  name: nfs-client-provisioner-runner<br>  apiGroup: rbac.authorization.k8s.io</li>
</ul>
<hr>
<p>kind: Role<br>apiVersion: rbac.authorization.k8s.io&#x2F;v1<br>metadata:<br>  name: leader-locking-nfs-client-provisioner</p>
<h1 id="replace-with-namespace-where-provisioner-is-deployed-3"><a href="#replace-with-namespace-where-provisioner-is-deployed-3" class="headerlink" title="replace with namespace where provisioner is deployed"></a>replace with namespace where provisioner is deployed</h1><p>  namespace: default<br>rules:</p>
<ul>
<li>apiGroups: [“”]<br>resources: [“endpoints”]<br>verbs: [“get”, “list”, “watch”, “create”, “update”, “patch”]</li>
</ul>
<hr>
<p>kind: RoleBinding<br>apiVersion: rbac.authorization.k8s.io&#x2F;v1<br>metadata:<br>  name: leader-locking-nfs-client-provisioner</p>
<h1 id="replace-with-namespace-where-provisioner-is-deployed-4"><a href="#replace-with-namespace-where-provisioner-is-deployed-4" class="headerlink" title="replace with namespace where provisioner is deployed"></a>replace with namespace where provisioner is deployed</h1><p>  namespace: default<br>subjects:</p>
<ul>
<li>kind: ServiceAccount<br>name: nfs-client-provisioner<h1 id="replace-with-namespace-where-provisioner-is-deployed-5"><a href="#replace-with-namespace-where-provisioner-is-deployed-5" class="headerlink" title="replace with namespace where provisioner is deployed"></a>replace with namespace where provisioner is deployed</h1>namespace: default<br>roleRef:<br>  kind: Role<br>  name: leader-locking-nfs-client-provisioner<br>  apiGroup: rbac.authorization.k8s.io<br>&#96;&#96;&#96;shell</li>
</ul>
<p>创建</p>
<p>&#96;&#96;&#96;shell<br>[root@k8s-master-node1 ~&#x2F;yaml]# kubectl apply -f nfs-storage.yaml<br>storageclass.storage.k8s.io&#x2F;nfs-storage created<br>deployment.apps&#x2F;nfs-client-provisioner created<br>serviceaccount&#x2F;nfs-client-provisioner created<br>clusterrole.rbac.authorization.k8s.io&#x2F;nfs-client-provisioner-runner created<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;run-nfs-client-provisioner created<br>role.rbac.authorization.k8s.io&#x2F;leader-locking-nfs-client-provisioner created<br>rolebinding.rbac.authorization.k8s.io&#x2F;leader-locking-nfs-client-provisioner created<br>[root@k8s-master-node1 ~&#x2F;yaml]#</p>
<p>&#96;&#96;&#96;shell</p>
<p>查看是否创建默认存储</p>
<p>&#96;&#96;&#96;shell<br>[root@k8s-master-node1 ~&#x2F;yaml]# kubectl get storageclasses.storage.k8s.io<br>NAME                    PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>nfs-storage (default)   k8s-sigs.io&#x2F;nfs-subdir-external-provisioner   Delete          Immediate           false                  100s<br>[root@k8s-master-node1 ~&#x2F;yaml]#</p>
<p>&#96;&#96;&#96;shell</p>
<p>创建pvc进行测试</p>
<p>&#96;&#96;&#96;shell<br>[root@k8s-master-node1 ~&#x2F;yaml]# vim pvc.yaml<br>[root@k8s-master-node1 ~&#x2F;yaml]# cat pvc.yaml<br>kind: PersistentVolumeClaim<br>apiVersion: v1<br>metadata:<br>  name: nginx-pvc<br>spec:<br>  accessModes:<br>    - ReadWriteMany<br>  resources:<br>    requests:<br>      storage: 200Mi<br>[root@k8s-master-node1 ~&#x2F;yaml]#<br>[root@k8s-master-node1 ~&#x2F;yaml]# kubectl apply -f pvc.yaml<br>persistentvolumeclaim&#x2F;nginx-pvc created<br>[root@k8s-master-node1 ~&#x2F;yaml]#</p>
<p>&#96;&#96;&#96;shell</p>
<p>查看pvc</p>
<p>&#96;&#96;&#96;shell<br>[root@k8s-master-node1 ~&#x2F;yaml]#<br>[root@k8s-master-node1 ~&#x2F;yaml]# kubectl get pvc<br>NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE<br>nginx-pvc   Bound    pvc-8a4b6065-904a-4bae-bef9-1f3b5612986c   200Mi      RWX            nfs-storage    4s<br>[root@k8s-master-node1 ~&#x2F;yaml]#</p>
<p>&#96;&#96;&#96;shell</p>
<p>查看pv</p>
<p>&#96;&#96;&#96;shell<br>[root@k8s-master-node1 ~&#x2F;yaml]# kubectl  get pv<br>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM               STORAGECLASS   REASON   AGE<br>pvc-8a4b6065-904a-4bae-bef9-1f3b5612986c   200Mi      RWX            Delete           Bound    default&#x2F;nginx-pvc   nfs-storage             103s<br>[root@k8s-master-node1 ~&#x2F;yaml]#</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0b73b3f8ded549748ffb927a0e120c9f~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>53篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2009a130c42147f48c799517bde605e5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（七）--- job、CronJob、Secret</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%83%EF%BC%89---_job%E3%80%81CronJob%E3%80%81Secret/</url>
    <content><![CDATA[<h4 id="10、job任务"><a href="#10、job任务" class="headerlink" title="10、job任务"></a>10、job任务</h4><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f3388e96ac1e48e08eb909949fda06ad~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h6 id="使用perl，做pi的圆周率计算"><a href="#使用perl，做pi的圆周率计算" class="headerlink" title="使用perl，做pi的圆周率计算"></a>使用perl，做pi的圆周率计算</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim job.yaml </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat job.yaml </span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: pi</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: pi</span><br><span class="line">        image: perl</span><br><span class="line">        command: [&quot;perl&quot;,  &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;]</span><br><span class="line">      restartPolicy: Never</span><br><span class="line">  backoffLimit: 4</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  apply  -f job.yaml </span><br><span class="line">job.batch/pi created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看任务"><a href="#查看任务" class="headerlink" title="查看任务"></a>查看任务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get pod</span><br><span class="line">NAME                                     READY   STATUS      RESTARTS   AGE</span><br><span class="line">ingress-demo-app-694bf5d965-8rh7f        1/1     Running     0          134m</span><br><span class="line">ingress-demo-app-694bf5d965-swkpb        1/1     Running     0          134m</span><br><span class="line">nfs-client-provisioner-dc5789f74-5bznq   1/1     Running     0          118m</span><br><span class="line">pi--1-k5cbq                              0/1     Completed   0          115s</span><br><span class="line">redis-app-86g4q                          1/1     Running     0          4m14s</span><br><span class="line">redis-app-rt92n                          1/1     Running     0          4m14s</span><br><span class="line">redis-app-vkzft                          1/1     Running     0          4m14s</span><br><span class="line">web-0                                    1/1     Running     0          67m</span><br><span class="line">web-1                                    1/1     Running     0          67m</span><br><span class="line">web-2                                    1/1     Running     0          67m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get job</span><br><span class="line">NAME   COMPLETIONS   DURATION   AGE</span><br><span class="line">pi     1/1           84s        2m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看计算结果"><a href="#查看计算结果" class="headerlink" title="查看计算结果"></a>查看计算结果</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl logs pi--1-k5cbq 3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<h4 id="11、CronJob"><a href="#11、CronJob" class="headerlink" title="11、CronJob"></a>11、CronJob</h4><p>CronJobs 对于创建周期性的、反复重复的任务很有用，例如执行数据备份或者发送邮件。CronJobs 也可以用来计划在指定时间来执行的独立任务，例如计划当集群看起来很空闲时 执行某个 Job。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/af94ef2c0fb3472a9551f2133a63cd98~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h6 id="创建任务"><a href="#创建任务" class="headerlink" title="创建任务"></a>创建任务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim cronjob.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat cronjob.yaml </span><br><span class="line">apiVersion: batch/v1beta1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line">spec:</span><br><span class="line">  schedule: &quot;*/1 * * * *&quot;</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">          - name: hello</span><br><span class="line">            image: busybox</span><br><span class="line">            args:</span><br><span class="line">            - /bin/sh</span><br><span class="line">            - -c</span><br><span class="line">            - date; echo Hello from the Kubernetes cluster</span><br><span class="line">          restartPolicy: OnFailure</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl apply -f cronjob.yaml </span><br><span class="line">Warning: batch/v1beta1 CronJob is deprecated in v1.21+, unavailable in v1.25+; use batch/v1 CronJob</span><br><span class="line">cronjob.batch/hello created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get cronjobs.batch </span><br><span class="line">NAME    SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE</span><br><span class="line">hello   */1 * * * *   False     0        &lt;none&gt;          21s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="查看结果"><a href="#查看结果" class="headerlink" title="查看结果"></a>查看结果</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  logs  hello-27285668--1-zqg92 </span><br><span class="line">Wed Nov 17 09:08:18 UTC 2021</span><br><span class="line">Hello from the Kubernetes cluster</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="12、Secret"><a href="#12、Secret" class="headerlink" title="12、Secret"></a>12、Secret</h4><p>Secret 对象类型用来保存敏感信息，例如密码、OAuth 令牌和 SSH 密钥。将这些信息放在 secret 中比放在 Pod 的定义或者 容‍器镜像 中来说更加安全和灵活。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7c2e0106b4354300a0affc8066ab0fcb~tplv-k3u1fbpfcp-zoom-1.image"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create secret docker-registry regcred \</span><br><span class="line">  --docker-server=&lt;你的镜像仓库服务器&gt; \</span><br><span class="line">  --docker-username=&lt;你的用户名&gt; \</span><br><span class="line">  --docker-password=&lt;你的密码&gt; \</span><br><span class="line">  --docker-email=&lt;你的邮箱地址&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: private-nginx</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: private-nginx</span><br><span class="line">    image: chenbuyun/my-app:v1.0</span><br><span class="line">  imagePullSecrets:</span><br><span class="line">  - name: regcred</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2489298766624ab1ac7836a6f49340f4~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes 安装 Prometheus + Grafana</title>
    <url>/2021/12/30/2021-12-30-kubernetes_%E5%AE%89%E8%A3%85_Prometheus_+_Grafana/</url>
    <content><![CDATA[<p><strong>kubernetes 安装 Prometheus + Grafana</strong></p>
<p>kubernetes install Prometheus + Grafana</p>
<p><strong>官网</strong></p>
<p>Official website</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">https://prometheus.io/</span><br></pre></td></tr></table></figure>

<p><strong>GitHub</strong></p>
<p>GitHub</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">https://github.com/coreos/kube-prometheus</span><br></pre></td></tr></table></figure>

<p><strong>组件说明</strong></p>
<p>Component description</p>
<p><strong>MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如 kubectl,hpa,scheduler等。</strong></p>
<p><strong>PrometheusOperator：是一个系统监测和警报工具箱，用来存储监控数据。</strong></p>
<p><strong>NodeExporter：用于各node的关键度量指标状态数据。</strong></p>
<p><strong>KubeStateMetrics：收集kubernetes集群内资源对象数 据，制定告警规则。</strong></p>
<p><strong>Prometheus：采用pull方式收集apiserver，scheduler，controller-manager，kubelet组件数 据，通过http协议传输。</strong></p>
<p><strong>Grafana：是可视化数据统计和监控平台。</strong></p>
<p>MetricServer: It is an aggregator of the resource usage of the kubernetes cluster, collecting data for use in the kubernetes cluster, such as kubectl, hpa, scheduler, etc.</p>
<p>PrometheusOperator: is a system monitoring and alerting toolbox used to store monitoring data.</p>
<p>NodeExporter: Used for the key metric status data of each node.</p>
<p>KubeStateMetrics: Collect resource object data in the kubernetes cluster and formulate alarm rules.</p>
<p>Prometheus: collect data from apiserver, scheduler, controller-manager, and kubelet components in a pull mode, and transmit it through the http protocol.</p>
<p>Grafana: It is a platform for visual data statistics and monitoring.</p>
<p><strong>安装</strong></p>
<p>Install</p>
<p><strong>配置Google上网环境下的docker，docker会去外网进行下载部分镜像</strong></p>
<p>Configure docker in Google’s Internet environment, docker will go to the external network to download part of the image</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo mkdir -p /etc/systemd/system/docker.service.d</span><br><span class="line">sudo touch /etc/systemd/system/docker.service.d/proxy.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# cat /etc/systemd/system/docker.service.d/proxy.conf</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;HTTP_PROXY=http://192.168.1.6:7890/&quot; </span><br><span class="line">Environment=&quot;HTTPS_PROXY=http://192.168.1.6:7890/&quot; </span><br><span class="line">Environment=&quot;NO_PROXY=localhost,127.0.0.1,.example.com&quot;</span><br></pre></td></tr></table></figure>

<p><strong>dockerd代理的修改比较特殊，它实际上是改systemd的配置，因此需要重载systemd并重启dockerd才能生效。</strong></p>
<p>The modification of the dockerd agent is quite special. It actually changes the configuration of systemd, so systemd needs to be reloaded and dockerd restarted to take effect.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/13d4725ba08148eea28a3ef5a252f1f3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>下载</strong></p>
<p>download</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# git clone https://github.com/coreos/kube-prometheus.git</span><br><span class="line">Cloning into &#x27;kube-prometheus&#x27;...</span><br><span class="line">remote: Enumerating objects: 13409, done.</span><br><span class="line">remote: Counting objects: 100% (1908/1908), done.</span><br><span class="line">remote: Compressing objects: 100% (801/801), done.</span><br><span class="line">remote: Total 13409 (delta 1184), reused 1526 (delta 947), pack-reused 11501</span><br><span class="line">Receiving objects: 100% (13409/13409), 6.65 MiB | 5.21 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (8313/8313), done.</span><br><span class="line">[root@k8s-master-node1 ~]# </span><br><span class="line">[root@k8s-master-node1 ~]# cd kube-prometheus/manifests</span><br><span class="line">[root@k8s-master-node1 ~/kube-prometheus/manifests]# </span><br></pre></td></tr></table></figure>

<p><strong>修改 grafana-service.yaml 文件，使用 nodepode 方式访问 grafana：</strong></p>
<p>Modify the grafana-service.yaml file and use nodepode to access grafana:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/kube-prometheus/manifests]# cat grafana-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/component: grafana</span><br><span class="line">    app.kubernetes.io/name: grafana</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">    app.kubernetes.io/version: 8.1.3</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 3000</span><br><span class="line">    targetPort: http</span><br><span class="line">    nodePort: 31100</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/component: grafana</span><br><span class="line">    app.kubernetes.io/name: grafana</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br></pre></td></tr></table></figure>

<p><strong>修改 prometheus-service.yaml，改为 nodepode：</strong></p>
<p>Modify prometheus-service.yaml to nodepode:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/kube-prometheus/manifests]# cat prometheus-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/component: prometheus</span><br><span class="line">    app.kubernetes.io/name: prometheus</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">    app.kubernetes.io/version: 2.30.0</span><br><span class="line">    prometheus: k8s</span><br><span class="line">  name: prometheus-k8s</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 9090</span><br><span class="line">    targetPort: web</span><br><span class="line">    nodePort: 31200</span><br><span class="line">  - name: reloader-web</span><br><span class="line">    port: 8080</span><br><span class="line">    targetPort: reloader-web</span><br><span class="line">    nodePort: 31300</span><br><span class="line">  selector:</span><br><span class="line">    app: prometheus</span><br><span class="line">    app.kubernetes.io/component: prometheus</span><br><span class="line">    app.kubernetes.io/name: prometheus</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">    prometheus: k8s</span><br><span class="line">  sessionAffinity: ClientIP</span><br></pre></td></tr></table></figure>

<p><strong>修改 alertmanager-service.yaml，改为 nodepode</strong></p>
<p>Modify alertmanager-service.yaml to nodepode</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/kube-prometheus/manifests]# cat alertmanager-service.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    alertmanager: main</span><br><span class="line">    app.kubernetes.io/component: alert-router</span><br><span class="line">    app.kubernetes.io/name: alertmanager</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">    app.kubernetes.io/version: 0.23.0</span><br><span class="line">  name: alertmanager-main</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 9093</span><br><span class="line">    targetPort: web</span><br><span class="line">    nodePort: 31400</span><br><span class="line">  - name: reloader-web</span><br><span class="line">    port: 8080</span><br><span class="line">    targetPort: reloader-web</span><br><span class="line">    nodePort: 31500</span><br><span class="line">  selector:</span><br><span class="line">    alertmanager: main</span><br><span class="line">    app: alertmanager</span><br><span class="line">    app.kubernetes.io/component: alert-router</span><br><span class="line">    app.kubernetes.io/name: alertmanager</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">  sessionAffinity: ClientIP</span><br><span class="line">[root@k8s-master-node1 ~/kube-prometheus/manifests]# </span><br></pre></td></tr></table></figure>

<p><strong>创建名称空间和CRD</strong></p>
<p>Create namespace and CRD</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/kube-prometheus]# kubectl create -f /root/kube-prometheus/manifests/setup</span><br><span class="line">namespace/monitoring created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/prometheus-operator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator created</span><br><span class="line">deployment.apps/prometheus-operator created</span><br><span class="line">service/prometheus-operator created</span><br><span class="line">serviceaccount/prometheus-operator created</span><br></pre></td></tr></table></figure>

<p><strong>等待资源可用后，安装</strong></p>
<p>After waiting for resources to be available, install</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/kube-prometheus]# </span><br><span class="line">[root@k8s-master-node1 ~/kube-prometheus]# </span><br><span class="line">[root@k8s-master-node1 ~/kube-prometheus]# kubectl create -f /root/kube-prometheus/manifests/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---略---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/kube-prometheus]# </span><br></pre></td></tr></table></figure>

<p><strong>访问 Prometheus</strong></p>
<p>Visit Prometheus</p>
<p><a href="http://192.168.1.10:31200/targets">http://192.168.1.10:31200/targets</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5ad294f11c4e4fe686c2072db2dca411~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>访问 Grafana</strong></p>
<p>Visit Grafana</p>
<p><a href="http://192.168.1.10:31100/">http://192.168.1.10:31100/</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f2423377395c46f98d5da67306eb2e98~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>访问报警平台 AlertManager</strong></p>
<p>Visit the alert platform AlertManager</p>
<p><a href="http://192.168.1.10:31400/#/status">http://192.168.1.10:31400/#/status</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/514e8ba382c1456ab570d5083d5ab55c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/48de2e3599d741f1afcd2a7a591ccca3~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>36篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/43dd1851bb5445b79a8cf1b2f59b6a1b~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（三）--- ReplicationController</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89---_ReplicationController/</url>
    <content><![CDATA[<h4 id="5、ReplicationController"><a href="#5、ReplicationController" class="headerlink" title="5、ReplicationController"></a>5、ReplicationController</h4><p>ReplicationController 确保在任何时候都有特定数量的 Pod 副本处于运行状态。换句话说，ReplicationController 确保一个 Pod 或一组同类的 Pod 总是可用的。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5be343bc24594aa8bb04f15fd046c488~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h5 id="ReplicationController-如何工作"><a href="#ReplicationController-如何工作" class="headerlink" title="ReplicationController 如何工作"></a>ReplicationController 如何工作</h5><p>当 Pod 数量过多时，ReplicationController 会终止多余的 Pod。当 Pod 数量太少时，ReplicationController 将会启动新的 Pod。与手动创建的 Pod 不同，由 ReplicationController 创建的 Pod 在失败、被删除或被终止时会被自动替换。例如，在中断性维护（如内核升级）之后，你的 Pod 会在节点上重新创建。因此，即使你的应用程序只需要一个 Pod，你也应该使用 ReplicationController 创建 Pod。ReplicationController 类似于进程管理器，但是 ReplicationController 不是监控单个节点上的单个进程，而是监控跨多个节点的多个 Pod。</p>
<p>在讨论中，ReplicationController 通常缩写为 “rc”，并作为 kubectl 命令的快捷方式。</p>
<p>一个简单的示例是创建一个 ReplicationController 对象来可靠地无限期地运行 Pod 的一个实例。更复杂的用例是运行一个多副本服务（如 web 服务器）的若干相同副本。</p>
<p>示例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim rc.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat  rc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: nginx</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl apply -f rc.yaml </span><br><span class="line">replicationcontroller/nginx created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="查看pod"><a href="#查看pod" class="headerlink" title="查看pod"></a>查看pod</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get pod</span><br><span class="line">NAME                                     READY   STATUS    RESTARTS     AGE</span><br><span class="line">ingress-demo-app-694bf5d965-q4l7m        1/1     Running   0            23h</span><br><span class="line">ingress-demo-app-694bf5d965-v652j        1/1     Running   0            23h</span><br><span class="line">nfs-client-provisioner-dc5789f74-nnk77   1/1     Running   1 (8h ago)   22h</span><br><span class="line">nginx-87sxg                              1/1     Running   0            34s</span><br><span class="line">nginx-kwrqn                              1/1     Running   0            34s</span><br><span class="line">nginx-xk2t6                              1/1     Running   0            34s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="查看rc"><a href="#查看rc" class="headerlink" title="查看rc"></a>查看rc</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl describe replicationcontrollers nginx</span><br><span class="line">Name:         nginx</span><br><span class="line">Namespace:    default</span><br><span class="line">Selector:     app=nginx</span><br><span class="line">Labels:       app=nginx</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Replicas:     3 current / 3 desired</span><br><span class="line">Pods Status:  3 Running / 0 Waiting / 0 Succeeded / 0 Failed</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:  app=nginx</span><br><span class="line">  Containers:</span><br><span class="line">   nginx:</span><br><span class="line">    Image:        nginx</span><br><span class="line">    Port:         80/TCP</span><br><span class="line">    Host Port:    0/TCP</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:       &lt;none&gt;</span><br><span class="line">  Volumes:        &lt;none&gt;</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason            Age   From                    Message</span><br><span class="line">  ----    ------            ----  ----                    -------</span><br><span class="line">  Normal  SuccessfulCreate  102s  replication-controller  Created pod: nginx-xk2t6</span><br><span class="line">  Normal  SuccessfulCreate  102s  replication-controller  Created pod: nginx-kwrqn</span><br><span class="line">  Normal  SuccessfulCreate  102s  replication-controller  Created pod: nginx-87sxg</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/585ffdb69b8845e08edbd1661b18631b~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>59篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cc09e5e4ec734b0ca15756991fedf822~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（九） --- Ingress</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E4%B9%9D%EF%BC%89_---_Ingress/</url>
    <content><![CDATA[<h4 id="14、Ingress"><a href="#14、Ingress" class="headerlink" title="14、Ingress"></a>14、Ingress</h4><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/90d8f35932b0479b850193b4a02195a0~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h5 id="检查是否有安装"><a href="#检查是否有安装" class="headerlink" title="检查是否有安装"></a>检查是否有安装</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get pod,svc -n ingress-nginx</span><br><span class="line">NAME                                           READY   STATUS      RESTARTS   AGE</span><br><span class="line">pod/ingress-nginx-admission-create--1-74mtg    0/1     Completed   0          172m</span><br><span class="line">pod/ingress-nginx-admission-patch--1-5qrct     0/1     Completed   0          172m</span><br><span class="line">pod/ingress-nginx-controller-f97bd58b5-vr8c2   1/1     Running     0          172m</span><br><span class="line"></span><br><span class="line">NAME                                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">service/ingress-nginx-controller             NodePort    10.96.109.80    &lt;none&gt;        80:30127/TCP,443:36903/TCP   172m</span><br><span class="line">service/ingress-nginx-controller-admission   ClusterIP   10.96.215.201   &lt;none&gt;        443/TCP                      172m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<p>若未安装可以查看官网文档：<a href="https://kubernetes.github.io/ingress-nginx/deploy/">https://kubernetes.github.io/ingress-nginx/deploy/</a></p>
<h5 id="创建环境："><a href="#创建环境：" class="headerlink" title="创建环境："></a>创建环境：</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim ingress.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat ingress.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello-server</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-server</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-server</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9000</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  apply  -f ingress.yaml </span><br><span class="line">deployment.apps/hello-server created</span><br><span class="line">deployment.apps/nginx-demo created</span><br><span class="line">service/nginx-demo created</span><br><span class="line">service/hello-server created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看四层负载并测试"><a href="#查看四层负载并测试" class="headerlink" title="查看四层负载并测试"></a>查看四层负载并测试</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get service</span><br><span class="line">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">hello-server       ClusterIP   10.96.246.46    &lt;none&gt;        8000/TCP         21s</span><br><span class="line">ingress-demo-app   ClusterIP   10.96.145.40    &lt;none&gt;        80/TCP           3h1m</span><br><span class="line">kubernetes         ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          3h3m</span><br><span class="line">my-dep             NodePort    10.96.241.162   &lt;none&gt;        8000:32306/TCP   23m</span><br><span class="line">nginx              ClusterIP   None            &lt;none&gt;        80/TCP           115m</span><br><span class="line">nginx-demo         ClusterIP   10.96.162.193   &lt;none&gt;        8000/TCP         21s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl  -I 10.96.162.193:8000</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.4</span><br><span class="line">Date: Wed, 17 Nov 2021 09:49:40 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 02 Nov 2021 14:49:22 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61814ff2-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl  -I 10.96.246.46:8000</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Date: Wed, 17 Nov 2021 09:49:52 GMT</span><br><span class="line">Content-Length: 12</span><br><span class="line">Content-Type: text/plain; charset=utf-8</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h5 id="创建七层"><a href="#创建七层" class="headerlink" title="创建七层"></a>创建七层</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim ingress-7.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat ingress-7.yaml</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx&quot;  # 把请求会转给下面的服务，下面的服务一定要能处理这个路径，不能处理就是404</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo  ## java，比如使用路径重写，去掉前缀nginx</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  apply  -f ingress-7.yaml </span><br><span class="line">ingress.networking.k8s.io/ingress-host-bar created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get ingress</span><br><span class="line">NAME               CLASS    HOSTS                            ADDRESS        PORTS   AGE</span><br><span class="line">ingress-demo-app   &lt;none&gt;   app.demo.com                     192.168.1.62   80      3h14m</span><br><span class="line">ingress-host-bar   nginx    hello.chenby.cn,demo.chenby.cn   192.168.1.62   80      9m50s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  describe ingress  ingress-host-bar </span><br><span class="line">Name:             ingress-host-bar</span><br><span class="line">Namespace:        default</span><br><span class="line">Address:          192.168.1.62</span><br><span class="line">Default backend:  default-http-backend:80 (10.244.2.7:8080)</span><br><span class="line">Rules:</span><br><span class="line">  Host             Path  Backends</span><br><span class="line">  ----             ----  --------</span><br><span class="line">  hello.chenby.cn  </span><br><span class="line">                   /   hello-server:8000 (10.244.2.47:9000,10.244.2.48:9000)</span><br><span class="line">  demo.chenby.cn   </span><br><span class="line">                   /nginx   nginx-demo:8000 (10.244.0.13:80,10.244.1.34:80)</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason  Age                    From                      Message</span><br><span class="line">  ----    ------  ----                   ----                      -------</span><br><span class="line">  Normal  Sync    6m26s (x2 over 6m50s)  nginx-ingress-controller  Scheduled for sync</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="电脑上写死hosts"><a href="#电脑上写死hosts" class="headerlink" title="电脑上写死hosts"></a>电脑上写死hosts</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get service ingress-demo-app </span><br><span class="line">NAME               TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">ingress-demo-app   ClusterIP   10.96.145.40   &lt;none&gt;        80/TCP    3h15m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">10.96.145.40 hello.chenby.cn </span><br><span class="line">10.96.145.40 demo.chenby.cn</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="测试访问"><a href="#测试访问" class="headerlink" title="测试访问"></a>测试访问</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl hello.chenby.cn</span><br><span class="line">Hostname: ingress-demo-app-694bf5d965-8rh7f</span><br><span class="line">IP: 127.0.0.1</span><br><span class="line">IP: 10.244.1.6</span><br><span class="line">RemoteAddr: 192.168.1.61:49809</span><br><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: hello.chenby.cn</span><br><span class="line">User-Agent: curl/7.68.0</span><br><span class="line">Accept: */*</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl demo.chenby.cn</span><br><span class="line">Hostname: ingress-demo-app-694bf5d965-swkpb</span><br><span class="line">IP: 127.0.0.1</span><br><span class="line">IP: 10.244.2.4</span><br><span class="line">RemoteAddr: 192.168.1.61:57797</span><br><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: demo.chenby.cn</span><br><span class="line">User-Agent: curl/7.68.0</span><br><span class="line">Accept: */*</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h5 id="url-重写"><a href="#url-重写" class="headerlink" title="url 重写"></a>url 重写</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim ingress-url</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat ingress-url.yaml</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    nginx.ingress.kubernetes.io/rewrite-target: /$2</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx(/|$)(.*)&quot;  # 把请求会转给下面的服务，下面的服务一定要能处理这个路径，不能处理就是404</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo  ## java，比如使用路径重写，去掉前缀nginx</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  apply -f ingress-url.yaml </span><br><span class="line">ingress.networking.k8s.io/ingress-host-bar created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl hello.chenby.cn</span><br><span class="line">Hostname: ingress-demo-app-694bf5d965-8rh7f</span><br><span class="line">IP: 127.0.0.1</span><br><span class="line">IP: 10.244.1.6</span><br><span class="line">RemoteAddr: 192.168.1.61:42303</span><br><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: hello.chenby.cn</span><br><span class="line">User-Agent: curl/7.68.0</span><br><span class="line">Accept: */*</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl demo.chenby.cn</span><br><span class="line">Hostname: ingress-demo-app-694bf5d965-swkpb</span><br><span class="line">IP: 127.0.0.1</span><br><span class="line">IP: 10.244.2.4</span><br><span class="line">RemoteAddr: 192.168.1.61:1108</span><br><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: demo.chenby.cn</span><br><span class="line">User-Agent: curl/7.68.0</span><br><span class="line">Accept: */*</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="流量限制"><a href="#流量限制" class="headerlink" title="流量限制"></a>流量限制</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim ingress-limit</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat ingress-limit.yaml</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-limit-rate</span><br><span class="line">  annotations:</span><br><span class="line">    nginx.ingress.kubernetes.io/limit-rps: &quot;1&quot;</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;haha.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Exact</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl apply -f ingress-limit.yaml </span><br><span class="line">ingress.networking.k8s.io/ingress-limit-rate created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim /etc/hosts</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl haha.chenby.cn</span><br><span class="line">Hostname: ingress-demo-app-694bf5d965-8rh7f</span><br><span class="line">IP: 127.0.0.1</span><br><span class="line">IP: 10.244.1.6</span><br><span class="line">RemoteAddr: 192.168.1.61:1676</span><br><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: haha.chenby.cn</span><br><span class="line">User-Agent: curl/7.68.0</span><br><span class="line">Accept: */*</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<p>注：可以将server 改为nodeport 即可在外部访问，将 type 改为 NodePort</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get service ingress-demo-app </span><br><span class="line">NAME               TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">ingress-demo-app   ClusterIP   10.96.145.40   &lt;none&gt;        80/TCP    6h27m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  edit service ingress-demo-app </span><br><span class="line">service/ingress-demo-app edited</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get service ingress-demo-app </span><br><span class="line">NAME               TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">ingress-demo-app   NodePort   10.96.145.40   &lt;none&gt;        80:30975/TCP   6h28m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（二）---Pod+ReplicaSet</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89---Pod+ReplicaSet/</url>
    <content><![CDATA[<h4 id="3、pod"><a href="#3、pod" class="headerlink" title="3、pod"></a>3、pod</h4><p>Pod 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8e8a8942405543b1b5db2621d244407a~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>Pod （就像在鲸鱼荚或者豌豆荚中）是一组（一个或多个） 容器；这些容器共享存储、网络、以及怎样运行这些容器的声明。Pod 中的内容总是并置（colocated）的并且一同调度，在共享的上下文中运行。Pod 所建模的是特定于应用的“逻辑主机”，其中包含一个或多个应用容器， 这些容器是相对紧密的耦合在一起的。在非云环境中，在相同的物理机或虚拟机上运行的应用类似于 在同一逻辑主机上运行的云应用。</p>
<p>除了应用容器，Pod 还可以包含在 Pod 启动期间运行的 Init 容器。你也可以在集群中支持临时性容器 的情况外，为调试的目的注入临时性容器。</p>
<h5 id="使用-Pod"><a href="#使用-Pod" class="headerlink" title="使用 Pod"></a>使用 Pod</h5><p>通常你不需要直接创建 Pod，甚至单实例 Pod。相反，你会使用诸如 Deployment 或 Job 这类工作负载资源 来创建 Pod。如果 Pod 需要跟踪状态， 可以考虑 StatefulSet 资源。</p>
<p>Kubernetes 集群中的 Pod 主要有<strong>两种</strong>用法：</p>
<p>运行单个容器的 Pod。”每个 Pod 一个容器”模型是最常见的 Kubernetes 用例；在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。</p>
<p>运行多个协同工作的容器的 Pod。Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。这些位于同一位置的容器可能形成单个内聚的服务单元 —— 一个容器将文件从共享卷提供给公众， 而另一个单独的“挂斗”（sidecar）容器则刷新或更新这些文件。Pod 将这些容器和存储资源打包为一个可管理的实体。</p>
<p>说明：将多个并置、同管的容器组织到一个 Pod 中是一种相对高级的使用场景。只有在一些场景中，容器之间紧密关联时你才应该使用这种模式。</p>
<p>每个 Pod 都旨在运行给定应用程序的单个实例。如果希望横向扩展应用程序（例如，运行多个实例 以提供更多的资源），则应该使用多个 Pod，每个实例使用一个 Pod。在 Kubernetes 中，这通常被称为 副本（Replication）。通常使用一种工作负载资源及其控制器 来创建和管理一组 Pod 副本。</p>
<p>Pod 怎样管理多个容器</p>
<p>Pod 被设计成支持形成内聚服务单元的多个协作过程（形式为容器）。Pod 中的容器被自动安排到集群中的同一物理机或虚拟机上，并可以一起进行调度。容器之间可以共享资源和依赖、彼此通信、协调何时以及何种方式终止自身。</p>
<p>例如，你可能有一个容器，为共享卷中的文件提供 Web 服务器支持，以及一个单独的 “sidecar（挂斗）”容器负责从远端更新这些文件，如下图所示：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b95fa02d2c3140cc982206fb9988e4f6~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h4 id="4、ReplicaSet"><a href="#4、ReplicaSet" class="headerlink" title="4、ReplicaSet"></a>4、ReplicaSet</h4><p>ReplicaSet 的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0048a17c108e438283d95a482ac437a4~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>ReplicaSet 的工作原理</p>
<p>RepicaSet 是通过一组字段来定义的，包括一个用来识别可获得的 Pod 的集合的选择算符，一个用来标明应该维护的副本个数的数值，一个用来指定应该创建新 Pod 以满足副本个数条件时要使用的 Pod 模板等等。每个 ReplicaSet 都通过根据需要创建和 删除 Pod 以使得副本个数达到期望值，进而实现其存在价值。当 ReplicaSet 需要创建 新的 Pod 时，会使用所提供的 Pod 模板。</p>
<p>ReplicaSet 通过 Pod 上的 metadata.ownerReferences 字段连接到附属 Pod，该字段给出当前对象的属主资源。ReplicaSet 所获得的 Pod 都在其 ownerReferences 字段中包含了属主 ReplicaSet 的标识信息。正是通过这一连接，ReplicaSet 知道它所维护的 Pod 集合的状态， 并据此计划其操作行为。</p>
<p>ReplicaSet 使用其选择算符来辨识要获得的 Pod 集合。如果某个 Pod 没有 OwnerReference 或者其 OwnerReference 不是一个 控制器，且其匹配到 某 ReplicaSet 的选择算符，则该 Pod 立即被此 ReplicaSet 获得。</p>
<p>示例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim pod.yaml [root@k8s-master-node1 ~/yaml/test]# cat pod.yaml apiVersion: apps/v1kind: ReplicaSetmetadata:  name: frontend  labels:    app: guestbook    tier: frontendspec:  # modify replicas according to your case  replicas: 3  selector:    matchLabels:      tier: frontend  template:    metadata:      labels:        tier: frontend    spec:      containers:      - name: nginx        image: nginx[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<h5 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl apply -f pod.yaml replicaset.apps/frontend created</span><br></pre></td></tr></table></figure>

<h5 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get podNAME                                     READY   STATUS    RESTARTS     AGEfrontend-8zxxw                           1/1     Running   0            2m26sfrontend-l22df                           1/1     Running   0            2m26sfrontend-qnhkr                           1/1     Running   0            2m26s[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<h5 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl delete -f pod.yaml replicaset.apps &quot;frontend&quot; deleted[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bcb34e25e7bc44959c9255c2b5dc0555~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>k8s集群进行删除并添加node节点</title>
    <url>/2021/12/30/2021-12-30-k8s%E9%9B%86%E7%BE%A4%E8%BF%9B%E8%A1%8C%E5%88%A0%E9%99%A4%E5%B9%B6%E6%B7%BB%E5%8A%A0node%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<p>    在已建立好的k8s集群中删除节点后，进行添加新的节点，可参考用于添加全新node节点，若新的node需要安装docker和k8s基础组件。  </p>
<p>    <strong>建立集群可以参考曾经的文章：</strong><a href="http://mp.weixin.qq.com/s?__biz=MzI0MzA4NTM2NQ==&mid=2247483901&idx=1&sn=54414b634fbeb5b4c411164672b352c0&chksm=e97338a7de04b1b127b93321c5820316beae1c309b1de0672d9e1f093b79cfb4ab9b747c6254&scene=21#wechat_redirect"><strong>CentOS8 搭建Kubernetes</strong></a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/91245c6a9f3640c582c4c84ab2d27296~tplv-k3u1fbpfcp-zoom-1.image">Linux运维交流社区推荐搜索</p>
<p>k8s集群</p>
<p>k8s集群添加节点</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2e7741b987ac4028a80b0d0971e17fa4~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    1. 在master中，查看节点数和要删除的节点数，因集群ip进行了修改，节点出现了异常。  </p>
<p>        [root@k8s-master ~]# kubectl  get nodes</p>
<p>        NAME         STATUS     ROLES    AGE   VERSION</p>
<p>        k8s-master   Ready      master   13d   v1.19.3</p>
<p>        k8s-node1    NotReady   <none>   13d   v1.19.3</p>
<p>        k8s-node2    NotReady   <none>   13d   v1.19.3</p>
<p>    2. 进行删除节点操作。  </p>
<p>        [root@k8s-master ~]# kubectl  delete nodes k8s-node1</p>
<p>        node “k8s-node1” deleted</p>
<p>        [root@k8s-master ~]# kubectl  delete nodes k8s-node2</p>
<p>        node “k8s-node2” deleted</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/edb1bb8ede5e416088ec79d27c2666e7~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    3. 在被删除的node节点中清空集群数据信息。  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@k8s-node1 ~\]# kubeadm reset</span><br><span class="line">\[reset\] WARNING: Changes made to this host by &#x27;kubeadm init&#x27; or &#x27;kubeadm join&#x27; will be reverted.</span><br><span class="line">\[reset\] Are you sure you want to proceed? \[y/N\]: y</span><br><span class="line">\[preflight\] Running pre-flight checks</span><br><span class="line">W1121 05:40:44.876393    9649 removeetcdmember.go:79\] \[reset\] No kubeadm config, using etcd pod spec to get data directory</span><br><span class="line">\[reset\] No etcd config found. Assuming external etcd</span><br><span class="line">\[reset\] Please, manually reset etcd to prevent further issues</span><br><span class="line">\[reset\] Stopping the kubelet service</span><br><span class="line">\[reset\] Unmounting mounted directories in &quot;/var/lib/kubelet&quot;</span><br><span class="line">\[reset\] Deleting contents of config directories: \[/etc/kubernetes/manifests /etc/kubernetes/pki\]</span><br><span class="line">\[reset\] Deleting files: \[/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf\]</span><br><span class="line">\[reset\] Deleting contents of stateful directories: \[/var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni\]</span><br><span class="line"></span><br><span class="line">The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d</span><br><span class="line"></span><br><span class="line">The reset process does not reset or clean up iptables rules or IPVS tables.</span><br><span class="line">If you wish to reset iptables, you must do so manually by using the &quot;iptables&quot; command.</span><br><span class="line"></span><br><span class="line">If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)</span><br><span class="line">to reset your system&#x27;s IPVS tables.</span><br><span class="line"></span><br><span class="line">The reset process does not clean your kubeconfig files and you must remove them manually.</span><br><span class="line">Please, check the contents of the $HOME/.kube/config file.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>    4. 在集群中查看集群的token值</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@k8s-master ~\]# kubeadm token create --print-join-command</span><br><span class="line">W1121 05:38:27.405833   12512 configset.go:348\] WARNING: kubeadm cannot validate component configs for API groups \[kubelet.config.k8s.io kubeproxy.config.k8s.io\]</span><br><span class="line">kubeadm join 10.0.1.48:6443 --token 8xwcaq.qxekio9xd02ed936     --discovery-token-ca-cert-hash sha256:d988ba566675095ae25255d63b21cc4d5a9a69bee9905dc638f58b217c651c14 </span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/75c22d7e80d94e34ab6c949f6245c676~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    5. 将node节点重新添加到k8s集群中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@k8s-node1 ~\]# kubeadm join 10.0.1.48:6443 --token 8xwcaq.qxekio9xd02ed936     --discovery-token-ca-cert-hash sha256:d988ba566675095ae25255d63b21cc4d5a9a69bee9905dc638f58b217c651c14</span><br><span class="line">\[preflight\] Running pre-flight checks</span><br><span class="line">  \[WARNING IsDockerSystemdCheck\]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">\[preflight\] Reading configuration from the cluster...</span><br><span class="line">\[preflight\] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line">\[kubelet-start\] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">\[kubelet-start\] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">\[kubelet-start\] Starting the kubelet</span><br><span class="line">\[kubelet-start\] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">\* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">\* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>    6. 查看pod情况  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@k8s-master ~\]# kubectl get pods -n kube-system -o wide</span><br><span class="line">NAME                                 READY   STATUS              RESTARTS   AGE   IP           NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">coredns-f9fd979d6-c6qrl              0/1     ContainerCreating   1          13d   &lt;none&gt;       k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-f9fd979d6-hmpbj              1/1     Running             0          13d   10.244.2.2   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">etcd-k8s-master                      1/1     Running             5          13d   10.0.1.48    k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running             6          13d   10.0.1.48    k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running             5          13d   10.0.1.48    k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel-ds-5ftj9                1/1     Running             4          13d   10.0.1.48    k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel-ds-bwh28                1/1     Running             0          23m   10.0.1.50    k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel-ds-ttx7c                0/1     Init:0/1            0          23m   10.0.1.49    k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-4xxxh                     0/1     ContainerCreating   2          13d   10.0.1.49    k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-7rs4w                     1/1     Running             0          13d   10.0.1.50    k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-d5hrv                     1/1     Running             4          13d   10.0.1.48    k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running             5          13d   10.0.1.48    k8s-master   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>    7.查看node情况  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@k8s-master ~\]# kubectl  get nodes</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master   Ready    master   13d   v1.19.3</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   24m   v1.19.3</span><br><span class="line">k8s-node2    Ready    &lt;none&gt;   24m   v1.19.3</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/19a338fd86bc46e5bee3ff2d4b8e86de~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>高新科技园</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes（k8s） 中安装kuboard面板</title>
    <url>/2021/12/30/2021-12-30-kubernetes%EF%BC%88k8s%EF%BC%89_%E4%B8%AD%E5%AE%89%E8%A3%85kuboard%E9%9D%A2%E6%9D%BF/</url>
    <content><![CDATA[<p>kubernetes（k8s） 中安装kuboard面板</p>
<p>01</p>
<p>—</p>
<p>背景及安装</p>
<p>Kuboard 是一款专为 Kubernetes 设计的免费管理界面，兼容 Kubernetes 版本 1.13 及以上。Kuboard 每周发布一个 beta 版本，最长每月发布一个正式版本，经过两年的不断迭代和优化，已经具备多集群管理、权限管理、监控套件、日志套件等丰富的功能。</p>
<p>删除之前的版本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker stop $(docker ps -a | grep &quot;eipwork/kuboard&quot; | awk &#x27;&#123;print $1 &#125;&#x27;)</span><br><span class="line">docker rm $(docker ps -a | grep &quot;eipwork/kuboard&quot; | awk &#x27;&#123;print $1 &#125;&#x27;)</span><br></pre></td></tr></table></figure>

<p>安装最新版</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo docker run -d \</span><br><span class="line">--restart=unless-stopped \</span><br><span class="line">--name=kuboard \</span><br><span class="line">-p 80:80/tcp \</span><br><span class="line">-p 10081:10081/udp \</span><br><span class="line">-p 10081:10081/tcp \</span><br><span class="line">-e KUBOARD_ENDPOINT=&quot;http://192.168.1.12:80&quot; \</span><br><span class="line">-e KUBOARD_AGENT_SERVER_UDP_PORT=&quot;10081&quot; \</span><br><span class="line">-e KUBOARD_AGENT_SERVER_TCP_PORT=&quot;10081&quot; \</span><br><span class="line">-v /root/kuboard-data:/data \</span><br><span class="line">eipwork/kuboard:v3.3.0.3</span><br></pre></td></tr></table></figure>

<p>在浏览器输入 <a href="http://192.168.1.12/">http://192.168.1.12</a> 即可访问 Kuboard 的界面，登录方式：</p>
<p>用户名：admin</p>
<p>密 码：Kuboard123</p>
<p><strong>注：可以在 <a href="https://hub.docker.com/r/eipwork/kuboard/tags">https://hub.docker.com/r/eipwork/kuboard/tags</a> 中查看最新版本号</strong></p>
<p>02</p>
<p>—  </p>
<p>访问登录</p>
<p>登录：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6e495a4efb9249dc945f699b42ad43d8~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>添加集群，使用Agent方式添加</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c8be9ff7010d4ea6b1045125f2ef95a3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>获得命令</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/806a45c3f4614b269c283da374d171d2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>在集群master上执行命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~]# curl -k &#x27;http://192.168.1.12:80/kuboard-api/cluster/cby/kind/KubernetesCluster/cby/resource/installAgentToKubernetes?token=zyrsQqY6Krsy3gvWUNHK2kvKWHmJZneL&#x27; &gt; kuboard-agent.yaml</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100  5775    0  5775    0     0   433k      0 --:--:-- --:--:-- --:--:--  433k</span><br><span class="line">[root@hello ~]# </span><br><span class="line">[root@hello ~]# kubectl apply -f ./kuboard-agent.yaml</span><br><span class="line">namespace/kuboard unchanged</span><br><span class="line">serviceaccount/kuboard-admin created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kuboard-admin-crb created</span><br><span class="line">serviceaccount/kuboard-viewer created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kuboard-viewer-crb created</span><br><span class="line">deployment.apps/kuboard-agent-soxwal created</span><br><span class="line">deployment.apps/kuboard-agent-soxwal-2 created</span><br><span class="line">[root@hello ~]#</span><br></pre></td></tr></table></figure>

<p>稍作等待即可在首页看到</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ae5a340f4c484f1cae1cdcff08d48ef3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ef951dcdcc904cfe9861ec7932460b76~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>73篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1e4e175b399b449682b87de6b1133a3c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（五）--- StatefulSets</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%94%EF%BC%89---_StatefulSets/</url>
    <content><![CDATA[<h4 id="7、StatefulSets"><a href="#7、StatefulSets" class="headerlink" title="7、StatefulSets"></a>7、StatefulSets</h4><p>StatefulSet 是用来管理有状态应用的工作负载 API 对象。</p>
<p>StatefulSet 用来管理 Deployment 和扩展一组 Pod，并且能为这些 Pod 提供序号和唯一性保证。</p>
<p>和 Deployment 相同的是，StatefulSet 管理了基于相同容器定义的一组 Pod。但和 Deployment 不同的是，StatefulSet 为它们的每个 Pod 维护了一个固定的 ID。这些 Pod 是基于相同的声明来创建的，但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID。</p>
<p>StatefulSet 和其他控制器使用相同的工作模式。你在 StatefulSet 对象 中定义你期望的状态，然后 StatefulSet 的 控制器 就会通过各种更新来达到那种你想要的状态。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/825bfff1644b4702a283bfcc940eebf0~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h6 id="使用-StatefulSets"><a href="#使用-StatefulSets" class="headerlink" title="使用 StatefulSets"></a>使用 StatefulSets</h6><p>StatefulSets 对于需要满足以下一个或多个需求的应用程序很有价值：</p>
<p>稳定的、唯一的网络标识符。稳定的、持久的存储。有序的、优雅的部署和缩放。有序的、自动的滚动更新。在上面，稳定意味着 Pod 调度或重调度的整个过程是有持久性的。如果应用程序不需要任何稳定的标识符或有序的部署、删除或伸缩，则应该使用由一组无状态的副本控制器提供的工作负载来部署应用程序，比如 Deployment 或者 ReplicaSet 可能更适用于您的无状态应用部署需要。</p>
<h6 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h6><p>给定 Pod 的存储必须由 PersistentVolume 驱动 基于所请求的 storage class 来提供，或者由管理员预先提供。删除或者收缩 StatefulSet 并不会删除它关联的存储卷。这样做是为了保证数据安全，它通常比自动清除 StatefulSet 所有相关的资源更有价值。StatefulSet 当前需要无头服务 来负责 Pod 的网络标识。您需要负责创建此服务。当删除 StatefulSets 时，StatefulSet 不提供任何终止 Pod 的保证。为了实现 StatefulSet 中的 Pod 可以有序和优雅的终止，可以在删除之前将 StatefulSet 缩放为 0。在默认 Pod 管理策略(OrderedReady) 时使用 滚动更新，可能进入需要 人工干预 才能修复的损坏状态。</p>
<h6 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim statefulsets.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat statefulsets.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    name: web</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">---</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pvc-0</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 200Mi</span><br><span class="line">---</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pvc-1</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 200Mi</span><br><span class="line">---</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pvc-2</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 200Mi</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: web</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx # has to match .spec.template.metadata.labels</span><br><span class="line">  serviceName: &quot;nginx&quot;</span><br><span class="line">  replicas: 3 # by default is 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx # has to match .spec.selector.matchLabels</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 10</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          name: web</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: www</span><br><span class="line">          mountPath: /usr/share/nginx/html</span><br><span class="line">      volumes:</span><br><span class="line">        - name: www</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: nginx-pvc-0</span><br><span class="line">      volumes:</span><br><span class="line">        - name: www</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: nginx-pvc-1</span><br><span class="line">      volumes:</span><br><span class="line">        - name: www</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: nginx-pvc-2</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="创建statefulsets"><a href="#创建statefulsets" class="headerlink" title="创建statefulsets"></a>创建statefulsets</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  apply -f statefulsets.yaml </span><br><span class="line">service/nginx created</span><br><span class="line">statefulset.apps/web created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看pod"><a href="#查看pod" class="headerlink" title="查看pod"></a>查看pod</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get pod</span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">ingress-demo-app-694bf5d965-8rh7f        1/1     Running   0          67m</span><br><span class="line">ingress-demo-app-694bf5d965-swkpb        1/1     Running   0          67m</span><br><span class="line">nfs-client-provisioner-dc5789f74-5bznq   1/1     Running   0          52m</span><br><span class="line">web-0                                    1/1     Running   0          93s</span><br><span class="line">web-1                                    1/1     Running   0          85s</span><br><span class="line">web-2                                    1/1     Running   0          66s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看statefulsets"><a href="#查看statefulsets" class="headerlink" title="查看statefulsets"></a>查看statefulsets</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get statefulsets.apps -o wide</span><br><span class="line">NAME   READY   AGE    CONTAINERS   IMAGES</span><br><span class="line">web    3/3     113s   nginx        nginx</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意：前提是解决kubernetes动态分配pv，参考文档：<a href="https://cloud.tencent.com/developer/article/1902519">https://cloud.tencent.com/developer/article/1902519</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ad0194a22f5c42cfb18977a7fd5be1c2~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（四）--- Deployments</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E5%9B%9B%EF%BC%89---_Deployments/</url>
    <content><![CDATA[<h4 id="6、Deployments（重点）"><a href="#6、Deployments（重点）" class="headerlink" title="6、Deployments（重点）"></a>6、Deployments（重点）</h4><p>一个 Deployment 控制器为 Pods和 ReplicaSets提供描述性的更新方式。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/47311f0a2c0c4c7d885590895bd3c03d~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>描述 Deployment 中的 desired state，并且 Deployment 控制器以受控速率更改实际状态，以达到期望状态。可以定义 Deployments 以创建新的 ReplicaSets ，或删除现有 Deployments ，并通过新的 Deployments 使用其所有资源。</p>
<p><strong>用例</strong></p>
<p>以下是典型的 Deployments 用例：</p>
<p>创建 Deployment 以展开 ReplicaSet 。ReplicaSet 在后台创建 Pods。检查 ReplicaSet 展开的状态，查看其是否成功。</p>
<p>声明 Pod 的新状态 通过更新 Deployment 的 PodTemplateSpec。将创建新的 ReplicaSet ，并且 Deployment 管理器以受控速率将 Pod 从旧 ReplicaSet 移动到新 ReplicaSet 。每个新的 ReplicaSet 都会更新 Deployment 的修改历史。</p>
<p>回滚到较早的 Deployment 版本，如果 Deployment 的当前状态不稳定。每次回滚都会更新 Deployment 的修改。</p>
<p>扩展 Deployment 以承担更多负载.</p>
<p>暂停 Deployment 对其 PodTemplateSpec 进行修改，然后恢复它以启动新的展开。</p>
<p>使用 Deployment 状态 作为卡住展开的指示器。</p>
<p>清理较旧的 ReplicaSets ，那些不再需要的。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6087ce839fea44a7b1eff7f2e317c366~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h5 id="1）创建-Deployment"><a href="#1）创建-Deployment" class="headerlink" title="1）创建 Deployment"></a>1）创建 Deployment</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim deployments.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat deployments.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl apply -f deployments.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="含义介绍："><a href="#含义介绍：" class="headerlink" title="含义介绍："></a>含义介绍：</h6><p>在该例中：将创建名为 nginx-deployment 的 Deployment ，由 .metadata.name 字段指示。</p>
<p>Deployment 创建三个复制的 Pods，由 replicas 字段指示。</p>
<p>selector 字段定义 Deployment 如何查找要管理的 Pods。在这种情况下，只需选择在 Pod 模板（app: nginx）中定义的标签。但是，更复杂的选择规则是可能的，只要 Pod 模板本身满足规则。</p>
<h6 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h6><p><code>matchLabels</code> 字段是 {key,value} 的映射。单个 {key,value}在 <code>matchLabels</code> 映射中的值等效于 <code>matchExpressions</code> 的元素，其键字段是“key”，运算符为“In”，值数组仅包含“value”。所有要求，从 <code>matchLabels</code> 和 <code>matchExpressions</code>，必须满足才能匹配。</p>
<h6 id="template-字段包含以下子字段："><a href="#template-字段包含以下子字段：" class="headerlink" title="template 字段包含以下子字段："></a>template 字段包含以下子字段：</h6><p>Pod 标记为app: nginx，使用labels字段。</p>
<p>Pod 模板规范或 .template.spec 字段指示 Pods 运行一个容器， nginx，运行 nginx Docker Hub版本1.7.9的镜像 。</p>
<p>创建一个容器并使用name字段将其命名为 nginx。</p>
<h6 id="查看详细的字段解释："><a href="#查看详细的字段解释：" class="headerlink" title="查看详细的字段解释："></a>查看详细的字段解释：</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# kubectl  explain Deployment.spec</span><br><span class="line">KIND:     Deployment</span><br><span class="line">VERSION:  apps/v1</span><br><span class="line"></span><br><span class="line">RESOURCE: spec &lt;Object&gt;</span><br><span class="line"></span><br><span class="line">DESCRIPTION:</span><br><span class="line">     Specification of the desired behavior of the Deployment.</span><br><span class="line"></span><br><span class="line">     DeploymentSpec is the specification of the desired behavior of the</span><br><span class="line">     Deployment.</span><br><span class="line"></span><br><span class="line">FIELDS:</span><br><span class="line">   minReadySeconds&lt;integer&gt;</span><br><span class="line">     Minimum number of seconds for which a newly created pod should be ready</span><br><span class="line">     without any of its container crashing, for it to be considered available.</span><br><span class="line">     Defaults to 0 (pod will be considered available as soon as it is ready)</span><br><span class="line"></span><br><span class="line">   paused&lt;boolean&gt;</span><br><span class="line">     Indicates that the deployment is paused.</span><br><span class="line"></span><br><span class="line">   progressDeadlineSeconds&lt;integer&gt;</span><br><span class="line">     The maximum time in seconds for a deployment to make progress before it is</span><br><span class="line">     considered to be failed. The deployment controller will continue to process</span><br><span class="line">     failed deployments and a condition with a ProgressDeadlineExceeded reason</span><br><span class="line">     will be surfaced in the deployment status. Note that progress will not be</span><br><span class="line">     estimated during the time a deployment is paused. Defaults to 600s.</span><br><span class="line"></span><br><span class="line">   replicas&lt;integer&gt;</span><br><span class="line">     Number of desired pods. This is a pointer to distinguish between explicit</span><br><span class="line">     zero and not specified. Defaults to 1.</span><br><span class="line"></span><br><span class="line">   revisionHistoryLimit&lt;integer&gt;</span><br><span class="line">     The number of old ReplicaSets to retain to allow rollback. This is a</span><br><span class="line">     pointer to distinguish between explicit zero and not specified. Defaults to</span><br><span class="line">     10.</span><br><span class="line"></span><br><span class="line">   selector &lt;Object&gt; -required-</span><br><span class="line">     Label selector for pods. Existing ReplicaSets whose pods are selected by</span><br><span class="line">     this will be the ones affected by this deployment. It must match the pod</span><br><span class="line">     template&#x27;s labels.</span><br><span class="line"></span><br><span class="line">   strategy&lt;Object&gt;</span><br><span class="line">     The deployment strategy to use to replace existing pods with new ones.</span><br><span class="line"></span><br><span class="line">   template &lt;Object&gt; -required-</span><br><span class="line">     Template describes the pods that will be created.</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看pod"><a href="#查看pod" class="headerlink" title="查看pod"></a>查看pod</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get pod </span><br><span class="line">NAME                                     READY   STATUS        RESTARTS     AGE</span><br><span class="line">ingress-demo-app-694bf5d965-q4l7m        1/1     Terminating   0            23h</span><br><span class="line">ingress-demo-app-694bf5d965-v28sl        1/1     Running       0            3m9s</span><br><span class="line">ingress-demo-app-694bf5d965-v652j        1/1     Running       0            23h</span><br><span class="line">nfs-client-provisioner-dc5789f74-nnk77   1/1     Running       1 (8h ago)   22h</span><br><span class="line">nginx-deployment-66b6c48dd5-5hhjq        1/1     Running       0            3m9s</span><br><span class="line">nginx-deployment-66b6c48dd5-9z2n5        1/1     Running       0            3m19s</span><br><span class="line">nginx-deployment-66b6c48dd5-llq7c        1/1     Running       0            9m10s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看deployments"><a href="#查看deployments" class="headerlink" title="查看deployments"></a>查看deployments</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get deployments.apps </span><br><span class="line">NAME                     READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">ingress-demo-app         2/2     2            2           23h</span><br><span class="line">nfs-client-provisioner   1/1     1            1           22h</span><br><span class="line">nginx-deployment         3/3     3            3           9m45s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="解释说明："><a href="#解释说明：" class="headerlink" title="解释说明："></a>解释说明：</h6><p>检查集群中的 Deployments 时，将显示以下字段：</p>
<p>NAME 列出了集群中 Deployments 的名称。</p>
<p>DESIRED 显示应用程序的所需 副本 数，在创建 Deployment 时定义这些副本。这是 期望状态。</p>
<p>CURRENT显示当前正在运行的副本数。</p>
<p>UP-TO-DATE显示已更新以实现期望状态的副本数。</p>
<p>AVAILABLE显示应用程序可供用户使用的副本数。</p>
<p>AGE 显示应用程序运行的时间量。</p>
<h6 id="查看rs"><a href="#查看rs" class="headerlink" title="查看rs"></a>查看rs</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get replicasets.apps </span><br><span class="line">NAME                               DESIRED   CURRENT   READY   AGE</span><br><span class="line">ingress-demo-app-694bf5d965        2         2         2       23h</span><br><span class="line">nfs-client-provisioner-dc5789f74   1         1         1       23h</span><br><span class="line">nginx-deployment-66b6c48dd5        3         3         3       19m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看pods的标签"><a href="#查看pods的标签" class="headerlink" title="查看pods的标签"></a>查看pods的标签</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get pods --show-labels</span><br><span class="line">NAME                                     READY   STATUS        RESTARTS     AGE   LABELS</span><br><span class="line">ingress-demo-app-694bf5d965-q4l7m        1/1     Terminating   0            23h   app=ingress-demo-app,pod-template-hash=694bf5d965</span><br><span class="line">ingress-demo-app-694bf5d965-v28sl        1/1     Running       0            15m   app=ingress-demo-app,pod-template-hash=694bf5d965</span><br><span class="line">ingress-demo-app-694bf5d965-v652j        1/1     Running       0            23h   app=ingress-demo-app,pod-template-hash=694bf5d965</span><br><span class="line">nfs-client-provisioner-dc5789f74-nnk77   1/1     Running       1 (8h ago)   23h   app=nfs-client-provisioner,pod-template-hash=dc5789f74</span><br><span class="line">nginx-deployment-66b6c48dd5-48k9j        0/1     Terminating   0            21m   app=nginx,pod-template-hash=66b6c48dd5</span><br><span class="line">nginx-deployment-66b6c48dd5-5hhjq        1/1     Running       0            15m   app=nginx,pod-template-hash=66b6c48dd5</span><br><span class="line">nginx-deployment-66b6c48dd5-9z2n5        1/1     Running       0            15m   app=nginx,pod-template-hash=66b6c48dd5</span><br><span class="line">nginx-deployment-66b6c48dd5-kvzft        0/1     Terminating   0            21m   app=nginx,pod-template-hash=66b6c48dd5</span><br><span class="line">nginx-deployment-66b6c48dd5-llq7c        1/1     Running       0            21m   app=nginx,pod-template-hash=66b6c48dd5</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h5 id="2）更新回滚-Deployment"><a href="#2）更新回滚-Deployment" class="headerlink" title="2）更新回滚 Deployment"></a>2）更新回滚 Deployment</h5><h6 id="命令行行升级使用镜像"><a href="#命令行行升级使用镜像" class="headerlink" title="命令行行升级使用镜像"></a>命令行行升级使用镜像</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get deployments -o wide</span><br><span class="line">NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS               IMAGES                                                                                    SELECTOR</span><br><span class="line">ingress-demo-app         2/2     2            2           23h   whoami                   traefik/whoami:v1.6.1                                                                     app=ingress-demo-app</span><br><span class="line">nfs-client-provisioner   1/1     1            1           23h   nfs-client-provisioner   registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/nfs-subdir-external-provisioner:v4.0.2   app=nfs-client-provisioner</span><br><span class="line">nginx-deployment         3/3     3            3           18m   nginx                    nginx:1.14.2                                                                              app=nginx</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl --record deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.20.1</span><br><span class="line">Flag --record has been deprecated, --record will be removed in the future</span><br><span class="line">deployment.apps/nginx-deployment image updated</span><br><span class="line">deployment.apps/nginx-deployment image updated</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get deployments -o wide</span><br><span class="line">NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS               IMAGES                                                                                    SELECTOR</span><br><span class="line">ingress-demo-app         2/2     2            2           23h   whoami                   traefik/whoami:v1.6.1                                                                     app=ingress-demo-app</span><br><span class="line">nfs-client-provisioner   1/1     1            1           23h   nfs-client-provisioner   registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/nfs-subdir-external-provisioner:v4.0.2   app=nfs-client-provisioner</span><br><span class="line">nginx-deployment         3/3     1            3           24m   nginx                    nginx:1.20.1                                                                              app=nginx</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="yaml方式修改镜像"><a href="#yaml方式修改镜像" class="headerlink" title="yaml方式修改镜像"></a>yaml方式修改镜像</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl edit deployments.apps nginx-deployment</span><br><span class="line">Edit cancelled, no changes made.</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看更新过程"><a href="#查看更新过程" class="headerlink" title="查看更新过程"></a>查看更新过程</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl rollout status deployment.v1.apps/nginx-deployment</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">deployment &quot;nginx-deployment&quot; successfully rolled out</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="查看详细信息"><a href="#查看详细信息" class="headerlink" title="查看详细信息"></a>查看详细信息</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl describe deployments</span><br><span class="line">Name:                   ingress-demo-app</span><br><span class="line">Namespace:              default</span><br><span class="line">CreationTimestamp:      Tue, 16 Nov 2021 13:28:26 +0800</span><br><span class="line">Labels:                 app=ingress-demo-app</span><br><span class="line">Annotations:            deployment.kubernetes.io/revision: 1</span><br><span class="line">Selector:               app=ingress-demo-app</span><br><span class="line">Replicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable</span><br><span class="line">StrategyType:           RollingUpdate</span><br><span class="line">MinReadySeconds:        0</span><br><span class="line">RollingUpdateStrategy:  25% max unavailable, 25% max surge</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:  app=ingress-demo-app</span><br><span class="line">  Containers:</span><br><span class="line">   whoami:</span><br><span class="line">    Image:        traefik/whoami:v1.6.1</span><br><span class="line">    Port:         80/TCP</span><br><span class="line">    Host Port:    0/TCP</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:       &lt;none&gt;</span><br><span class="line">  Volumes:        &lt;none&gt;</span><br><span class="line">Conditions:</span><br><span class="line">  Type           Status  Reason</span><br><span class="line">  ----           ------  ------</span><br><span class="line">  Progressing    True    NewReplicaSetAvailable</span><br><span class="line">  Available      True    MinimumReplicasAvailable</span><br><span class="line">OldReplicaSets:  &lt;none&gt;</span><br><span class="line">NewReplicaSet:   ingress-demo-app-694bf5d965 (2/2 replicas created)</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason             Age   From                   Message</span><br><span class="line">  ----    ------             ----  ----                   -------</span><br><span class="line">  Normal  ScalingReplicaSet  23h   deployment-controller  Scaled up replica set ingress-demo-app-694bf5d965 to 2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Name:               nfs-client-provisioner</span><br><span class="line">Namespace:          default</span><br><span class="line">CreationTimestamp:  Tue, 16 Nov 2021 14:07:33 +0800</span><br><span class="line">Labels:             app=nfs-client-provisioner</span><br><span class="line">Annotations:        deployment.kubernetes.io/revision: 1</span><br><span class="line">Selector:           app=nfs-client-provisioner</span><br><span class="line">Replicas:           1 desired | 1 updated | 1 total | 1 available | 0 unavailable</span><br><span class="line">StrategyType:       Recreate</span><br><span class="line">MinReadySeconds:    0</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:           app=nfs-client-provisioner</span><br><span class="line">  Service Account:  nfs-client-provisioner</span><br><span class="line">  Containers:</span><br><span class="line">   nfs-client-provisioner:</span><br><span class="line">    Image:      registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/nfs-subdir-external-provisioner:v4.0.2</span><br><span class="line">    Port:       &lt;none&gt;</span><br><span class="line">    Host Port:  &lt;none&gt;</span><br><span class="line">    Environment:</span><br><span class="line">      PROVISIONER_NAME:  k8s-sigs.io/nfs-subdir-external-provisioner</span><br><span class="line">      NFS_SERVER:        192.168.1.66</span><br><span class="line">      NFS_PATH:          /nfs/</span><br><span class="line">    Mounts:</span><br><span class="line">      /persistentvolumes from nfs-client-root (rw)</span><br><span class="line">  Volumes:</span><br><span class="line">   nfs-client-root:</span><br><span class="line">    Type:      NFS (an NFS mount that lasts the lifetime of a pod)</span><br><span class="line">    Server:    192.168.1.66</span><br><span class="line">    Path:      /nfs/</span><br><span class="line">    ReadOnly:  false</span><br><span class="line">Conditions:</span><br><span class="line">  Type           Status  Reason</span><br><span class="line">  ----           ------  ------</span><br><span class="line">  Progressing    True    NewReplicaSetAvailable</span><br><span class="line">  Available      True    MinimumReplicasAvailable</span><br><span class="line">OldReplicaSets:  &lt;none&gt;</span><br><span class="line">NewReplicaSet:   nfs-client-provisioner-dc5789f74 (1/1 replicas created)</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason             Age   From                   Message</span><br><span class="line">  ----    ------             ----  ----                   -------</span><br><span class="line">  Normal  ScalingReplicaSet  23h   deployment-controller  Scaled up replica set nfs-client-provisioner-dc5789f74 to 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Name:                   nginx-deployment</span><br><span class="line">Namespace:              default</span><br><span class="line">CreationTimestamp:      Wed, 17 Nov 2021 12:54:46 +0800</span><br><span class="line">Labels:                 app=nginx</span><br><span class="line">Annotations:            deployment.kubernetes.io/revision: 3</span><br><span class="line">                        kubernetes.io/change-cause:</span><br><span class="line">                          kubectl deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.20.1 --record=true</span><br><span class="line">Selector:               app=nginx</span><br><span class="line">Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable</span><br><span class="line">StrategyType:           RollingUpdate</span><br><span class="line">MinReadySeconds:        0</span><br><span class="line">RollingUpdateStrategy:  25% max unavailable, 25% max surge</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:  app=nginx</span><br><span class="line">  Containers:</span><br><span class="line">   nginx:</span><br><span class="line">    Image:        nginx:1.16.1</span><br><span class="line">    Port:         80/TCP</span><br><span class="line">    Host Port:    0/TCP</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:       &lt;none&gt;</span><br><span class="line">  Volumes:        &lt;none&gt;</span><br><span class="line">Conditions:</span><br><span class="line">  Type           Status  Reason</span><br><span class="line">  ----           ------  ------</span><br><span class="line">  Available      True    MinimumReplicasAvailable</span><br><span class="line">  Progressing    True    NewReplicaSetAvailable</span><br><span class="line">OldReplicaSets:  &lt;none&gt;</span><br><span class="line">NewReplicaSet:   nginx-deployment-559d658b74 (3/3 replicas created)</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason             Age                From                   Message</span><br><span class="line">  ----    ------             ----               ----                   -------</span><br><span class="line">  Normal  ScalingReplicaSet  30m                deployment-controller  Scaled up replica set nginx-deployment-66b6c48dd5 to 3</span><br><span class="line">  Normal  ScalingReplicaSet  5m55s              deployment-controller  Scaled up replica set nginx-deployment-58b9b8ff79 to 1</span><br><span class="line">  Normal  ScalingReplicaSet  5m27s              deployment-controller  Scaled down replica set nginx-deployment-66b6c48dd5 to 2</span><br><span class="line">  Normal  ScalingReplicaSet  5m27s              deployment-controller  Scaled up replica set nginx-deployment-58b9b8ff79 to 2</span><br><span class="line">  Normal  ScalingReplicaSet  5m                 deployment-controller  Scaled down replica set nginx-deployment-66b6c48dd5 to 1</span><br><span class="line">  Normal  ScalingReplicaSet  5m                 deployment-controller  Scaled up replica set nginx-deployment-58b9b8ff79 to 3</span><br><span class="line">  Normal  ScalingReplicaSet  4m56s              deployment-controller  Scaled down replica set nginx-deployment-66b6c48dd5 to 0</span><br><span class="line">  Normal  ScalingReplicaSet  78s                deployment-controller  Scaled up replica set nginx-deployment-559d658b74 to 1</span><br><span class="line">  Normal  ScalingReplicaSet  63s                deployment-controller  Scaled down replica set nginx-deployment-58b9b8ff79 to 2</span><br><span class="line">  Normal  ScalingReplicaSet  63s                deployment-controller  Scaled up replica set nginx-deployment-559d658b74 to 2</span><br><span class="line">  Normal  ScalingReplicaSet  49s (x3 over 61s)  deployment-controller  (combined from similar events): Scaled down replica set nginx-deployment-58b9b8ff79 to 0</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h5 id="3）-Deployment历史记录"><a href="#3）-Deployment历史记录" class="headerlink" title="3） Deployment历史记录"></a>3） Deployment历史记录</h5><h6 id="查看历史"><a href="#查看历史" class="headerlink" title="查看历史"></a>查看历史</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl rollout history deployment.v1.apps/nginx-deployment</span><br><span class="line">deployment.apps/nginx-deployment </span><br><span class="line">REVISION  CHANGE-CAUSE</span><br><span class="line">1         &lt;none&gt;</span><br><span class="line">2         kubectl deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.20.1 --record=true</span><br><span class="line">3         kubectl deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.20.1 --record=true</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="回滚到上次"><a href="#回滚到上次" class="headerlink" title="回滚到上次"></a>回滚到上次</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl rollout undo deployment.v1.apps/nginx-deployment</span><br><span class="line">deployment.apps/nginx-deployment rolled back</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl rollout status deployment.v1.apps/nginx-deployment</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">deployment &quot;nginx-deployment&quot; successfully rolled out</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h6 id="回滚到指定版本"><a href="#回滚到指定版本" class="headerlink" title="回滚到指定版本"></a>回滚到指定版本</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision=3</span><br><span class="line">deployment.apps/nginx-deployment rolled back</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl rollout status deployment.v1.apps/nginx-deployment</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">deployment &quot;nginx-deployment&quot; successfully rolled out</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<h5 id="4）缩放-Deployment"><a href="#4）缩放-Deployment" class="headerlink" title="4）缩放 Deployment"></a>4）缩放 Deployment</h5><h6 id="扩容到十个pod"><a href="#扩容到十个pod" class="headerlink" title="扩容到十个pod"></a>扩容到十个pod</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl scale deployment.v1.apps/nginx-deployment --replicas=10</span><br><span class="line">deployment.apps/nginx-deployment scaled</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get deployments.apps</span><br><span class="line">NAME                     READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">ingress-demo-app         0/2     2            0           24h</span><br><span class="line">nfs-client-provisioner   0/1     1            0           23h</span><br><span class="line">nginx-deployment         5/10    10           5           45m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<p>假设启用水平自动缩放 Pod在集群中，可以为 Deployment 设置自动缩放器，并选择最小和最大 要基于现有 Pods 的 CPU 利用率运行的 Pods。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl autoscale deployment.v1.apps/nginx-deployment --min=10 --max=15 --cpu-percent=80</span><br><span class="line">horizontalpodautoscaler.autoscaling/nginx-deployment autoscaled</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8fa52ad147be4e6fba60dc8c149f734b~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes（k8s）中部署 efk</title>
    <url>/2021/12/30/2021-12-30-kubernetes%EF%BC%88k8s%EF%BC%89%E4%B8%AD%E9%83%A8%E7%BD%B2_efk/</url>
    <content><![CDATA[<p>Kubernetes 开发了一个 Elasticsearch 附加组件来实现集群的日志管理。这是一个 Elasticsearch、Fluentd 和 Kibana 的组合。</p>
<p>Elasticsearch 是一个搜索引擎，负责存储日志并提供查询接口；</p>
<p>Fluentd 负责从 Kubernetes 搜集日志，每个node节点上面的fluentd监控并收集该节点上面的系统日志，并将处理过后的日志信息发送给Elasticsearch；</p>
<p>Kibana 提供了一个 Web GUI，用户可以浏览和搜索存储在 Elasticsearch 中的日志。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/963904f901324291806e8cad4d701f2c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>从官方github仓库下载yaml文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/efk]# git clone https://github.com/kubernetes/kubernetes.git</span><br><span class="line">[root@hello ~/efk]# kubectl create namespace logging</span><br><span class="line">[root@hello ~/efk]#</span><br></pre></td></tr></table></figure>

<p>执行所有yaml文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/efk]# cd kubernetes/cluster/addons/fluentd-elasticsearch/</span><br><span class="line">[root@hello ~/efk/kubernetes/cluster/addons/fluentd-elasticsearch]# kubectl apply -f ./</span><br><span class="line">namespace/logging created</span><br><span class="line">service/elasticsearch-logging created</span><br><span class="line">serviceaccount/elasticsearch-logging created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/elasticsearch-logging created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/elasticsearch-logging created</span><br><span class="line">statefulset.apps/elasticsearch-logging created</span><br><span class="line">configmap/fluentd-es-config-v0.2.1 created</span><br><span class="line">serviceaccount/fluentd-es created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/fluentd-es created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/fluentd-es created</span><br><span class="line">daemonset.apps/fluentd-es-v3.1.1 created</span><br><span class="line">deployment.apps/kibana-logging created</span><br><span class="line">service/kibana-logging created</span><br></pre></td></tr></table></figure>

<p>查看pod状态：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~]# kubectl  get pod -n logging</span><br><span class="line">NAME                              READY   STATUS    RESTARTS       AGE</span><br><span class="line">elasticsearch-logging-0           1/1     Running   0              2m17s</span><br><span class="line">elasticsearch-logging-1           1/1     Running   0              96s</span><br><span class="line">fluentd-es-v3.1.1-qw9dj           1/1     Running   1 (97s ago)    2m16s</span><br><span class="line">kibana-logging-75bd6cccf5-pskrr   1/1     Running   1 (106s ago)   2m16s</span><br><span class="line">[root@hello ~]#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@hello ~]# kubectl  get service -n logging</span><br><span class="line">NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">elasticsearch-logging   ClusterIP   None            &lt;none&gt;        9200/TCP,9300/TCP   2m41s</span><br><span class="line">kibana-logging          ClusterIP   10.68.145.186   &lt;none&gt;        5601/TCP            2m40s</span><br><span class="line">[root@hello ~]#</span><br></pre></td></tr></table></figure>

<p>访问 kibana</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~]# kubectl proxy --address=&#x27;192.168.1.11&#x27; --port=8086 --accept-hosts=&#x27;^*$&#x27;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">访问</span></span><br><span class="line">http://192.168.1.11:8086//api/v1/namespaces/logging/services/kibana-logging/proxy/</span><br></pre></td></tr></table></figure>

<p>创建一个index-pattern索引</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fc588e1fd00747d49642989fe24226b4~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fb93320695564020a6d77ddb1e4e1ee8~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>默认为 logstash-* 即可，之后这里会看到日志</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/03541d56f5b943cdb720641f0792dd15~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cbb5f77202114ac49968ed4f20a8712d~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>73篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/695c54c6f1414fd8aa8218b23684b95f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes（k8s）中部署dashboard可视化面板</title>
    <url>/2021/12/30/2021-12-30-kubernetes%EF%BC%88k8s%EF%BC%89%E4%B8%AD%E9%83%A8%E7%BD%B2dashboard%E5%8F%AF%E8%A7%86%E5%8C%96%E9%9D%A2%E6%9D%BF/</url>
    <content><![CDATA[<p><strong>Web 界面 (Dashboard)</strong></p>
<p>Dashboard 是基于网页的 Kubernetes 用户界面。你可以使用 Dashboard 将容器应用部署到 Kubernetes 集群中，也可以对容器应用排错，还能管理集群资源。你可以使用 Dashboard 获取运行在集群中的应用的概览信息，也可以创建或者修改 Kubernetes 资源 （如 Deployment，Job，DaemonSet 等等）。例如，你可以对 Deployment 实现弹性伸缩、发起滚动升级、重启 Pod 或者使用向导创建新的应用。</p>
<p>Dashboard 同时展示了 Kubernetes 集群中的资源状态信息和所有报错信息。</p>
<p>kubernetes官方提供的可视化界面</p>
<p><strong><a href="https://github.com/kubernetes/dashboard">https://github.com/kubernetes/dashboard</a></strong></p>
<p><strong>一键执行</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.4.0/aio/deploy/recommended.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>先下载后执行</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~/dashboard# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.4.0/aio/deploy/recommended.yaml</span><br><span class="line">root@master1:~/dashboard# kubectl apply -f recommended.yaml</span><br></pre></td></tr></table></figure>

<p>若下载不下来，可以使用vim添加进去后再次执行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~/dashboard# vim recommended.yaml</span><br><span class="line">root@master1:~/dashboard# </span><br><span class="line">root@master1:~/dashboard# </span><br><span class="line">root@master1:~/dashboard# cat recommended.yaml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Copyright 2017 The Kubernetes Authors.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">you may not use this file except <span class="keyword">in</span> compliance with the License.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">You may obtain a copy of the License at</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">distributed under the License is distributed on an <span class="string">&quot;AS IS&quot;</span> BASIS,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">See the License <span class="keyword">for</span> the specific language governing permissions and</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">limitations under the License.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-certs</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">type: Opaque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-csrf</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  csrf: &quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-key-holder</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">type: Opaque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-settings</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">rules:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Allow Dashboard to get, update and delete Dashboard exclusive secrets.</span></span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;secrets&quot;]</span><br><span class="line">    resourceNames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;, &quot;kubernetes-dashboard-csrf&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;]</span><br><span class="line">    # Allow Dashboard to get and update &#x27;kubernetes-dashboard-settings&#x27; config map.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;configmaps&quot;]</span><br><span class="line">    resourceNames: [&quot;kubernetes-dashboard-settings&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;update&quot;]</span><br><span class="line">    # Allow Dashboard to get metrics.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;services&quot;]</span><br><span class="line">    resourceNames: [&quot;heapster&quot;, &quot;dashboard-metrics-scraper&quot;]</span><br><span class="line">    verbs: [&quot;proxy&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;services/proxy&quot;]</span><br><span class="line">    resourceNames: [&quot;heapster&quot;, &quot;http:heapster:&quot;, &quot;https:heapster:&quot;, &quot;dashboard-metrics-scraper&quot;, &quot;http:dashboard-metrics-scraper&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">rules:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Allow Metrics Scraper to get metrics from the Metrics server</span></span><br><span class="line">  - apiGroups: [&quot;metrics.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;pods&quot;, &quot;nodes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: kubernetes-dashboard</span><br><span class="line">    namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: kubernetes-dashboard</span><br><span class="line">    namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kubernetes-dashboard</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kubernetes-dashboard</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: kubernetes-dashboard</span><br><span class="line">          image: kubernetesui/dashboard:v2.4.0</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8443</span><br><span class="line">              protocol: TCP</span><br><span class="line">          args:</span><br><span class="line">            - --auto-generate-certificates</span><br><span class="line">            - --namespace=kubernetes-dashboard</span><br><span class="line">            # Uncomment the following line to manually specify Kubernetes API server Host</span><br><span class="line">            # If not specified, Dashboard will attempt to auto discover the API server and connect</span><br><span class="line">            # to it. Uncomment only if the default does not work.</span><br><span class="line">            # - --apiserver-host=http://my-address:port</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: kubernetes-dashboard-certs</span><br><span class="line">              mountPath: /certs</span><br><span class="line">              # Create on-disk volume to store exec logs</span><br><span class="line">            - mountPath: /tmp</span><br><span class="line">              name: tmp-volume</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              scheme: HTTPS</span><br><span class="line">              path: /</span><br><span class="line">              port: 8443</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">            readOnlyRootFilesystem: true</span><br><span class="line">            runAsUser: 1001</span><br><span class="line">            runAsGroup: 2001</span><br><span class="line">      volumes:</span><br><span class="line">        - name: kubernetes-dashboard-certs</span><br><span class="line">          secret:</span><br><span class="line">            secretName: kubernetes-dashboard-certs</span><br><span class="line">        - name: tmp-volume</span><br><span class="line">          emptyDir: &#123;&#125;</span><br><span class="line">      serviceAccountName: kubernetes-dashboard</span><br><span class="line">      nodeSelector:</span><br><span class="line">        &quot;kubernetes.io/os&quot;: linux</span><br><span class="line">      # Comment the following tolerations if Dashboard must not be deployed on master</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: node-role.kubernetes.io/master</span><br><span class="line">          effect: NoSchedule</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: dashboard-metrics-scraper</span><br><span class="line">  name: dashboard-metrics-scraper</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8000</span><br><span class="line">      targetPort: 8000</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: dashboard-metrics-scraper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: dashboard-metrics-scraper</span><br><span class="line">  name: dashboard-metrics-scraper</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: dashboard-metrics-scraper</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: dashboard-metrics-scraper</span><br><span class="line">    spec:</span><br><span class="line">      securityContext:</span><br><span class="line">        seccompProfile:</span><br><span class="line">          type: RuntimeDefault</span><br><span class="line">      containers:</span><br><span class="line">        - name: dashboard-metrics-scraper</span><br><span class="line">          image: kubernetesui/metrics-scraper:v1.0.7</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8000</span><br><span class="line">              protocol: TCP</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              scheme: HTTP</span><br><span class="line">              path: /</span><br><span class="line">              port: 8000</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          volumeMounts:</span><br><span class="line">          - mountPath: /tmp</span><br><span class="line">            name: tmp-volume</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">            readOnlyRootFilesystem: true</span><br><span class="line">            runAsUser: 1001</span><br><span class="line">            runAsGroup: 2001</span><br><span class="line">      serviceAccountName: kubernetes-dashboard</span><br><span class="line">      nodeSelector:</span><br><span class="line">        &quot;kubernetes.io/os&quot;: linux</span><br><span class="line">      # Comment the following tolerations if Dashboard must not be deployed on master</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: node-role.kubernetes.io/master</span><br><span class="line">          effect: NoSchedule</span><br><span class="line">      volumes:</span><br><span class="line">        - name: tmp-volume</span><br><span class="line">          emptyDir: &#123;&#125;</span><br><span class="line">root@master1:~/dashboard# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@master1:~/dashboard# kubectl apply -f recommended.yaml </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">查看是否在运行</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@master1:~/dashboard# kubectl get pod -n kubernetes-dashboard</span><br><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class="line">dashboard-metrics-scraper-c45b7869d-2xhx8   1/1     Running   0          2m40s</span><br><span class="line">kubernetes-dashboard-576cb95f94-scrxw       1/1     Running   0          2m40s</span><br><span class="line">root@master1:~/dashboard# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改为nodeIP</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@master1:~/dashboard# kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">service/kubernetes-dashboard edited</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>创建访问账号</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~/dashboard# vim dash.yaml </span><br><span class="line">root@master1:~/dashboard# cat dash.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">root@master1:~/dashboard#</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~/dashboard# kubectl apply -f dash.yaml</span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line">root@master1:~/dashboard#</span><br></pre></td></tr></table></figure>

<p><strong>查看token令牌</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~/dashboard# </span><br><span class="line">root@master1:~/dashboard# kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=&quot;&#123;.secrets[0].name&#125;&quot;) -o go-template=&quot;&#123;&#123;.data.token | base64decode&#125;&#125;&quot;</span><br><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6IlBqb09VbWNDX1hVdldnM3pjcmllQ1NMMXA3bUZQRTBfNEdNTEZnUnhScncifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXd3MmZ2Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI3ODU0YzFkMy0wNWMyLTQwNzAtYjI1OC1hNzRlYTg1ZWRlYTAiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.v1MCLz9q_IvP49sh69XLoBZc0YQ6X1Pbw-lfZYYeeDcw6HqmEkW1Lfs1Soz-b8ir4lbWvNF90h6pGU_1aEE9NkTaV5b6A5FGhKivVk-09gjcx8JC8RDtlJ5Ol-MiHQOqPY67qPO6UzRm3H1luGKXtnNnTA74PTOssGgH3eNsFMKOPqaANt03h6-sjVXQBD2uca3l1pD5ywa-P54WwL_uJraCpIopX98iiFoN5hV_2W6dnPJ09whmaaTl8fJGXQ_0ln5NbdcURQeuL-ZRAC_b5i4RoBKlOHjDg1AREH_27qtwl9GbDNe-HgzSsFGKHzLV93Pqjwo9pI03P6xkyYym9groot@master1:~/dashboard#</span><br></pre></td></tr></table></figure>

<p><strong>查看svc服务ip以及端口</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~/dashboard# kubectl get svc -n kubernetes-dashboard</span><br><span class="line">NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">dashboard-metrics-scraper   ClusterIP   10.233.58.150   &lt;none&gt;        8000/TCP        7m22s</span><br><span class="line">kubernetes-dashboard        NodePort    10.233.38.57    &lt;none&gt;        443:30282/TCP   7m22s</span><br><span class="line">root@master1:~/dashboard#</span><br></pre></td></tr></table></figure>

<p><strong>访问页面</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4a6a0b74e6d048a7850f1e187e6bae01~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5cb0ab5f157d44768ff9c59da6a92fd7~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3041e0d967254f32a16a97f2423df731~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes（k8s）安装命令行自动补全功能</title>
    <url>/2021/12/30/2021-12-30-kubernetes%EF%BC%88k8s%EF%BC%89%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1f6c9c76f1d04d2e9939b271bfcfa0ba~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>Ubuntu下安装命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~# apt install -y bash-completion</span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree      </span><br><span class="line">Reading state information... Done</span><br><span class="line">bash-completion is already the newest version (1:2.10-1ubuntu1).</span><br><span class="line">0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.</span><br></pre></td></tr></table></figure>

<p>centos下安装命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@dss ~]# yum install bash-completion -y</span><br><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * epel: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line">Package 1:bash-completion-2.1-8.el7.noarch already installed and latest version</span><br><span class="line">Nothing to do</span><br><span class="line">[root@dss ~]#</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~# locate bash_completion</span><br><span class="line">/etc/bash_completion</span><br><span class="line">/etc/bash_completion.d</span><br><span class="line">/etc/bash_completion.d/apport_completion</span><br><span class="line">/etc/bash_completion.d/git-prompt</span><br><span class="line">/etc/profile.d/bash_completion.sh</span><br><span class="line">/snap/core18/2128/etc/bash_completion</span><br><span class="line">/snap/core18/2128/usr/share/bash-completion/bash_completion</span><br><span class="line">/snap/core18/2128/usr/share/doc/bash/README.md.bash_completion.gz</span><br><span class="line">/snap/core18/2128/usr/share/perl5/Debian/Debhelper/Sequence/bash_completion.pm</span><br><span class="line">/snap/lxd/21029/etc/bash_completion.d</span><br><span class="line">/snap/lxd/21029/etc/bash_completion.d/snap.lxd.lxc</span><br><span class="line">/usr/share/bash-completion/bash_completion</span><br><span class="line">/usr/share/doc/bash/README.md.bash_completion.gz</span><br><span class="line">/usr/share/perl5/Debian/Debhelper/Sequence/bash_completion.pm</span><br><span class="line">/var/lib/docker/overlay2/0f27e9d2ca7fbe8a3b764a525f1c58990345512fa6dfe4162aba3e05ccff5b56/diff/etc/bash_completion.d</span><br><span class="line">/var/lib/docker/overlay2/5eb1b0cb946881e1081bfa7a608b6fa85dbf2cb7e67f84b038f3b8a85bd13196/diff/usr/local/lib/node_modules/npm/node_modules/dashdash/etc/dashdash.bash_completion.in</span><br><span class="line">/var/lib/docker/overlay2/76c41c1d1eb6eaa7b9259bd822a4bffebf180717a24319d2ffec3b4dcae0e66a/merged/etc/bash_completion.d</span><br><span class="line">/var/lib/docker/overlay2/78b8ab76c0e0ad7ee873daab9ab3987a366ec32fda68a4bb56a218c7f8806a58/merged/etc/profile.d/bash_completion.sh</span><br><span class="line">/var/lib/docker/overlay2/78b8ab76c0e0ad7ee873daab9ab3987a366ec32fda68a4bb56a218c7f8806a58/merged/usr/share/bash-completion/bash_completion</span><br><span class="line">/var/lib/docker/overlay2/802133f75f62596a2c173f1b57231efbe210eddd7a43770a62ca94c86ce2ca56/merged/usr/local/lib/node_modules/npm/node_modules/dashdash/etc/dashdash.bash_completion.in</span><br><span class="line">/var/lib/docker/overlay2/ee672bdd0bf0fdf590f9234a8a784ca12c262c47a0ac8ab91acc0942dfafc339/diff/etc/profile.d/bash_completion.sh</span><br><span class="line">/var/lib/docker/overlay2/ee672bdd0bf0fdf590f9234a8a784ca12c262c47a0ac8ab91acc0942dfafc339/diff/usr/share/bash-completion/bash_completion</span><br></pre></td></tr></table></figure>

<p>临时环境变量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~# source /usr/share/bash-completion/bash_completion</span><br><span class="line">root@master1:~# source &lt;(kubectl completion bash)</span><br><span class="line">root@master1:~#</span><br><span class="line">root@master1:~#</span><br><span class="line">root@master1:~# kubectl</span><br><span class="line">annotate       auth           config         delete         exec           kustomize      plugin         run            uncordon</span><br><span class="line">api-resources  autoscale      cordon         describe       explain        label          port-forward   scale          version</span><br><span class="line">api-versions   certificate    cp             diff           expose         logs           proxy          set            wait</span><br><span class="line">apply          cluster-info   create         drain          get            options        replace        taint          </span><br><span class="line">attach         completion     debug          edit           help           patch          rollout        top            </span><br><span class="line">root@master1:~# kubectl</span><br></pre></td></tr></table></figure>

<p>永久写入环境变量配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@master1:~#</span><br><span class="line">root@master1:~#</span><br><span class="line">root@master1:~# echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br><span class="line">root@master1:~#</span><br><span class="line">root@master1:~# cat ~/.bashrc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">----略----</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">some more <span class="built_in">ls</span> aliases</span></span><br><span class="line">alias ll=&#x27;ls -alF&#x27;</span><br><span class="line">alias la=&#x27;ls -A&#x27;</span><br><span class="line">alias l=&#x27;ls -CF&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Alias definitions.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">You may want to put all your additions into a separate file like</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">~/.bash_aliases, instead of adding them here directly.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">See /usr/share/doc/bash-doc/examples <span class="keyword">in</span> the bash-doc package.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ -f ~/.bash_aliases ]; then</span><br><span class="line">    . ~/.bash_aliases</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">enable</span> programmable completion features (you don<span class="string">&#x27;t need to enable</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">this, if it&#x27;</span>s already enabled <span class="keyword">in</span> /etc/bash.bashrc and /etc/profile</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sources /etc/bash.bashrc).</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="keyword">if</span> [ -f /etc/bash_completion ] &amp;&amp; ! <span class="built_in">shopt</span> -oq posix; <span class="keyword">then</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   . /etc/bash_completion</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="keyword">fi</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">root@master1:~#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f15584c5a770436f943162d88635f215~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（八）--- service</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E5%85%AB%EF%BC%89---_service/</url>
    <content><![CDATA[<h4 id="13、service"><a href="#13、service" class="headerlink" title="13、service"></a>13、service</h4><p>四层网络负载</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d46bc36e09de4cbb93b68b066aa3ea31~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h5 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim my-app.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat my-app.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: my-dep</span><br><span class="line">  name: my-dep</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: my-dep</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: my-dep</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  apply -f my-app.yaml </span><br><span class="line">deployment.apps/my-dep created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get deployments.apps </span><br><span class="line">NAME                     READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">ingress-demo-app         2/2     2            2           155m</span><br><span class="line">my-dep                   3/3     3            3           71s</span><br><span class="line">nfs-client-provisioner   1/1     1            1           140m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="使用标签查找"><a href="#使用标签查找" class="headerlink" title="使用标签查找"></a>使用标签查找</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get pod --show-labels </span><br><span class="line">NAME                                     READY   STATUS              RESTARTS   AGE     LABELS</span><br><span class="line">hello-27285682--1-q2p6x                  0/1     Completed           0          3m15s   controller-uid=5e700c2e-29b3-4099-be17-b005d8077284,job-name=hello-27285682</span><br><span class="line">hello-27285683--1-b2qgn                  0/1     Completed           0          2m15s   controller-uid=d7455e28-bd37-4fdf-bf47-de7ae6b4b7bb,job-name=hello-27285683</span><br><span class="line">hello-27285684--1-glsmp                  0/1     Completed           0          75s     controller-uid=9cc7f28d-e780-49fb-a23a-ab725413ea8a,job-name=hello-27285684</span><br><span class="line">hello-27285685--1-s7ws5                  0/1     ContainerCreating   0          15s     controller-uid=169e3631-6981-4df8-bfee-6a4f4632b713,job-name=hello-27285685</span><br><span class="line">ingress-demo-app-694bf5d965-8rh7f        1/1     Running             0          157m    app=ingress-demo-app,pod-template-hash=694bf5d965</span><br><span class="line">ingress-demo-app-694bf5d965-swkpb        1/1     Running             0          157m    app=ingress-demo-app,pod-template-hash=694bf5d965</span><br><span class="line">my-dep-5b7868d854-kzflw                  1/1     Running             0          2m34s   app=my-dep,pod-template-hash=5b7868d854</span><br><span class="line">my-dep-5b7868d854-pfhps                  1/1     Running             0          2m34s   app=my-dep,pod-template-hash=5b7868d854</span><br><span class="line">my-dep-5b7868d854-v67ll                  1/1     Running             0          2m34s   app=my-dep,pod-template-hash=5b7868d854</span><br><span class="line">nfs-client-provisioner-dc5789f74-5bznq   1/1     Running             0          141m    app=nfs-client-provisioner,pod-template-hash=dc5789f74</span><br><span class="line">pi--1-k5cbq                              0/1     Completed           0          25m     controller-uid=2ecfcafd-f848-403b-b37f-9c145a0dc8cc,job-name=pi</span><br><span class="line">redis-app-86g4q                          1/1     Running             0          27m     controller-revision-hash=77c8899f5d,name=fluentd-redis,pod-template-generation=1</span><br><span class="line">redis-app-rt92n                          1/1     Running             0          27m     controller-revision-hash=77c8899f5d,name=fluentd-redis,pod-template-generation=1</span><br><span class="line">redis-app-vkzft                          1/1     Running             0          27m     controller-revision-hash=77c8899f5d,name=fluentd-redis,pod-template-generation=1</span><br><span class="line">web-0                                    1/1     Running             0          91m     app=nginx,controller-revision-hash=web-57c5cc66df,statefulset.kubernetes.io/pod-name=web-0</span><br><span class="line">web-1                                    1/1     Running             0          91m     app=nginx,controller-revision-hash=web-57c5cc66df,statefulset.kubernetes.io/pod-name=web-1</span><br><span class="line">web-2                                    1/1     Running             0          90m     app=nginx,controller-revision-hash=web-57c5cc66df,statefulset.kubernetes.io/pod-name=web-2</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl get pod -l app=my-dep</span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">my-dep-5b7868d854-kzflw   1/1     Running   0          2m42s</span><br><span class="line">my-dep-5b7868d854-pfhps   1/1     Running   0          2m42s</span><br><span class="line">my-dep-5b7868d854-v67ll   1/1     Running   0          2m42s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="命令行暴露端口"><a href="#命令行暴露端口" class="headerlink" title="命令行暴露端口"></a>命令行暴露端口</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl expose deployment my-dep --port=8000 --target-port=80</span><br><span class="line">service/my-dep exposed</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get service</span><br><span class="line">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">ingress-demo-app   ClusterIP   10.96.145.40    &lt;none&gt;        80/TCP     158m</span><br><span class="line">kubernetes         ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    160m</span><br><span class="line">my-dep             ClusterIP   10.96.241.162   &lt;none&gt;        8000/TCP   11s</span><br><span class="line">nginx              ClusterIP   None            &lt;none&gt;        80/TCP     92m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="yaml文件暴露端口"><a href="#yaml文件暴露端口" class="headerlink" title="yaml文件暴露端口"></a>yaml文件暴露端口</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: my-dep</span><br><span class="line">  name: my-dep</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: my-dep</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="ClusterIP方式暴露"><a href="#ClusterIP方式暴露" class="headerlink" title="ClusterIP方式暴露"></a>ClusterIP方式暴露</h5><h6 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl expose deployment my-dep --port=8000 --target-port=80 --type=ClusterIP</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="yaml方式"><a href="#yaml方式" class="headerlink" title="yaml方式"></a>yaml方式</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: my-dep</span><br><span class="line">  name: my-dep</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">  selector:</span><br><span class="line">    app: my-dep</span><br><span class="line">  type: ClusterIP</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="访问测试"><a href="#访问测试" class="headerlink" title="访问测试"></a>访问测试</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl -I  10.96.241.162:8000</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.4</span><br><span class="line">Date: Wed, 17 Nov 2021 09:30:27 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 02 Nov 2021 14:49:22 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61814ff2-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="NodePort方式暴露"><a href="#NodePort方式暴露" class="headerlink" title="NodePort方式暴露"></a>NodePort方式暴露</h5><h6 id="命令行-1"><a href="#命令行-1" class="headerlink" title="命令行"></a>命令行</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl expose deployment my-dep --port=8000 --target-port=80 --type=NodePort</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="yaml方式-1"><a href="#yaml方式-1" class="headerlink" title="yaml方式"></a>yaml方式</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: my-dep</span><br><span class="line">  name: my-dep</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">  selector:</span><br><span class="line">    app: my-dep</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="查看service"><a href="#查看service" class="headerlink" title="查看service"></a>查看service</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get service</span><br><span class="line">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">ingress-demo-app   ClusterIP   10.96.145.40    &lt;none&gt;        80/TCP           165m</span><br><span class="line">kubernetes         ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          167m</span><br><span class="line">my-dep             NodePort    10.96.241.162   &lt;none&gt;        8000:32306/TCP   7m13s</span><br><span class="line">nginx              ClusterIP   None            &lt;none&gt;        80/TCP           99m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="访问测试-1"><a href="#访问测试-1" class="headerlink" title="访问测试"></a>访问测试</h5><p>使用kubernetes任何node的ip都可以访问</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl -I 192.168.1.62:32306</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.4</span><br><span class="line">Date: Wed, 17 Nov 2021 09:36:50 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 02 Nov 2021 14:49:22 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61814ff2-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl -I 192.168.1.61:32306</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.4</span><br><span class="line">Date: Wed, 17 Nov 2021 09:36:53 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 02 Nov 2021 14:49:22 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61814ff2-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# curl -I 192.168.1.63:32306</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.4</span><br><span class="line">Date: Wed, 17 Nov 2021 09:36:56 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 02 Nov 2021 14:49:22 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61814ff2-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6f717fc23b7a40ff9aab2637fa649ead~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Python安装-在Linux系统中使用编译进行安装</title>
    <url>/2021/12/30/2021-12-30-Python%E5%AE%89%E8%A3%85-%E5%9C%A8Linux%E7%B3%BB%E7%BB%9F%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%BC%96%E8%AF%91%E8%BF%9B%E8%A1%8C%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d2be64bec43d454abe1b2c003d3322cf~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>Python安装-在Linux系统中使用编译进行安装</strong>  </p>
<p>你可以使用Ubuntu自带的Python3，不过你不能自由的控制版本，还要单独安装pip3，如果你想升级pip3，还会出现一些让人不愉快的使用问题。而在CentOS系统中，默认只有Python2，通过yum安装Python3，也同样面临版本落后以及pip3的问题。如果不自己编译安装，还有什么别的方法来一直保持使用最新的版本呢？！除非你用Win系统。</p>
<p>You can use the Python3 that comes with Ubuntu, but you can’t control the version freely. You have to install pip3 separately. If you want to upgrade pip3, there will be some unpleasant usage problems. In the CentOS system, there is only Python2 by default. Installing Python3 through yum also faces the problems of backward version and pip3. If you don’t compile and install it yourself, what other methods are there to keep using the latest version? ! Unless you use Win system.</p>
<p>在CentOS中安装Python3需要的依赖库</p>
<p> Install the dependency libraries required by Python3 in CentOS</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install zlib-devel bzip2-developenssl-devel ncurses-devel sqlite-devel readline-devel tk-devel libffi-develexpat-devel gdbm-devel xz-devel db4-devel libpcap-devel make</span><br></pre></td></tr></table></figure>

<p>在Ubuntu中安装Python3需要的依赖库</p>
<p>Install the dependency libraries required by Python3 in Ubuntu</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo apt install libreadline-gplv2-devlibncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libbz2-devzlib1g-dev libffi-dev liblzma-dev</span><br></pre></td></tr></table></figure>

<p><strong>安装GCC</strong></p>
<p><strong>Install GCC</strong></p>
<p>CentOS的minimal版本，以及Ubuntu，都没有预装gcc，如果你用的是这两个版本，需要确保系统有gcc编译器可以使用。安装和查看gcc的方法：</p>
<p>The minimal version of CentOS and Ubuntu do not have gcc pre-installed. If you are using these two versions, you need to make sure that the system has a gcc compiler that can be used. How to install and view gcc:</p>
<p>   </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo yum install gcc  # install gcc in centos</span><br><span class="line">$ sudo apt install gcc  # install gcc in ubuntu</span><br><span class="line">$ which gcc # check if gcc is there</span><br><span class="line">$ gcc --version  # check gcc version</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ce578f7240e5458ca63771461d0a120c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>下载Python3源码并解压</p>
<p>Download the Python3 source code and unzip it</p>
<p>Python3的官方源码下载页面是：<a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></p>
<p>The official source code download page of Python3 is:</p>
<p><a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></p>
<p>   </p>
<p>使用curl或wget下载，然后解压：</p>
<p>Use curl or wget to download, and then unzip:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Wget https://www.python.org/ftp/python/3.9.2/Python-3.9.2.tgz</span><br><span class="line">tar xvf Python-3.9.2.tgz</span><br></pre></td></tr></table></figure>

<p>执行configure</p>
<p>Execute configure</p>
<p>进入上一步的解压目录，然后执行configure：</p>
<p>Enter the unzipped directory of the previous step, and then execute configure:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cd Python-3.7.3</span><br><span class="line">$ ./configure --prefix=/usr/local/python-3.9.2</span><br></pre></td></tr></table></figure>

<p>make和install</p>
<p>make and install</p>
<p>最后，我们执行make和install的指令。</p>
<p>Finally, we execute the make and install instructions.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>

<p>make install 前要有sudo，因为我们在configure的时候，指定的安装路径为系统路径，不是用户的&#x2F;home&#x2F;user路径。</p>
<p>There must be sudo before make install, because when we configure, the specified installation path is the system path, not the user’s &#x2F;home&#x2F;user path.</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94f2204a9d594c589db6dec5ae3ac221~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ln -s /usr/local/python-3.9.2/bin/python3.9/usr/bin/python3</span><br><span class="line">ln -s /usr/local/python-3.9.2/bin/pip3.9/usr/bin/pip3</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6a62f462b9cc444f836d108ace3c3ba2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>一键部署十个服务脚本--可拆分---java+mysql+redis+nginx+rocketmq..等等</title>
    <url>/2021/12/30/2021-12-30-%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2%E5%8D%81%E4%B8%AA%E6%9C%8D%E5%8A%A1%E8%84%9A%E6%9C%AC--%E5%8F%AF%E6%8B%86%E5%88%86---java+mysql+redis+nginx+rocketmq..%E7%AD%89%E7%AD%89/</url>
    <content><![CDATA[<p>java + mysql +redis + minio + nginx + rocketmq + rocketmq-console + elasticsearch + kibana + logstash 一键部署可拆分</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b8f432488cb04345a43be0a604f9d21c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line">##</span><br><span class="line">##</span><br><span class="line">## 将基本环境yum安装的包放入如下目录</span><br><span class="line">##  /Basic-package/basic-rpm</span><br><span class="line">##</span><br><span class="line">##</span><br><span class="line">## 将基础环境服务包放入如下目录</span><br><span class="line">##  /Basic-package</span><br><span class="line">##</span><br><span class="line">##</span><br><span class="line">##</span><br><span class="line"></span><br><span class="line">function 0-basic-install () &#123;</span><br><span class="line">    </span><br><span class="line">    ## 基础环境安装</span><br><span class="line"></span><br><span class="line">    cd /Basic-package/basic-rpm || exit </span><br><span class="line">    yum -y install *.rpm</span><br><span class="line">    systemctl disable firewalld</span><br><span class="line">    systemctl stop firewalld</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function 1-java-install () &#123;</span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ &quot;$(java -version)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;java\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        ## 安装Java程序</span><br><span class="line"></span><br><span class="line">        cd /Basic-package || exit</span><br><span class="line">        mkdir -p /cby/backend/base-service/</span><br><span class="line">        cp jdk-8u102-linux-x64.tar.gz /cby/backend/base-service/</span><br><span class="line">        cd /cby/backend/base-service/ || exit</span><br><span class="line">        tar -xf jdk-8u102-linux-x64.tar.gz</span><br><span class="line">        mv /cby/backend/base-service/jdk1.8.0_102/ /cby/backend/base-service/jdk8/</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    if [ &quot;$(grep &quot;JAVA_HOME=/usr/local/jdk1.8.0_151&quot; /etc/profile)&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &#x27;JAVA_HOME in profile&#x27;  </span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        ## 添加Java环境变量</span><br><span class="line"></span><br><span class="line">        echo &#x27;export JAVA_HOME=/cby/backend/base-service/jdk8&#x27; &gt;&gt; /etc/profile</span><br><span class="line">        echo -e &#x27;export PATH=$PATH:$JAVA_HOME/bin&#x27; &gt;&gt; /etc/profile</span><br><span class="line">        echo -e &#x27;export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar&#x27; &gt;&gt; /etc/profile </span><br><span class="line">        source /etc/profile</span><br><span class="line"></span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo &quot;java version:&quot;</span><br><span class="line">java -version </span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function 2-mysql-install () &#123;</span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ &quot;$(mysql -V)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;mysql\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">    cd /Basic-package || exit</span><br><span class="line"></span><br><span class="line">    if [ -x &quot;mysql-5.7.34-1.el7.x86_64.rpm-bundle.tar&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;file \&quot;mysql-5.7.34-1.el7.x86_64.rpm-bundle.tar\&quot; is executable&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        ## 解压安装包的文件</span><br><span class="line"></span><br><span class="line">        tar xvf mysql-5.7.34-1.el7.x86_64.rpm-bundle.tar </span><br><span class="line"></span><br><span class="line">        yum install ./*.rpm -y</span><br><span class="line">        </span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    ## 启动服务，并开机自启</span><br><span class="line"></span><br><span class="line">    if [ &quot;$(mysql -V)&quot; ]; then</span><br><span class="line"></span><br><span class="line">        systemctl start mysqld</span><br><span class="line"></span><br><span class="line">        systemctl enable mysqld</span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line">    ## 查看MySQL默认密码</span><br><span class="line"></span><br><span class="line">    echo &#x27;mysql password:&#x27;    </span><br><span class="line">    sudo grep &#x27;temporary password&#x27; /var/log/mysqld.log | awk &#x27;&#123;print $11&#125;&#x27;</span><br><span class="line"></span><br><span class="line">    ## 默认密码获取</span><br><span class="line"></span><br><span class="line">    mysqlpssswd=$(sudo grep &#x27;temporary password&#x27; /var/log/mysqld.log | awk &#x27;&#123;print $11&#125;&#x27;)</span><br><span class="line"></span><br><span class="line">    ## 一系列授权操作</span><br><span class="line"></span><br><span class="line">    mysql -u root -p$mysqlpssswd -e &quot;set global validate_password_length=0;&quot; --connect-expired-password</span><br><span class="line">    mysql -u root -p$mysqlpssswd -e &quot;set global validate_password_policy=0;&quot; --connect-expired-password</span><br><span class="line">    mysql -u root -p$mysqlpssswd -e &quot;set password for &#x27;root&#x27;@&#x27;localhost&#x27; = password(&#x27;123456&#x27;);&quot; --connect-expired-password</span><br><span class="line">    mysql -u root -p$mysqlpssswd -e &quot;use mysql;&quot; --connect-expired-password</span><br><span class="line">    mysql -u root -p$mysqlpssswd -e &quot;grant all privileges on *.* to &#x27;root&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27; with grant option;&quot; --connect-expired-password </span><br><span class="line">    mysql -u root -p123456 -e &quot;flush privileges;&quot; --connect-expired-password</span><br><span class="line"></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function 3-redis-install () &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line">yum install -y gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ &quot;$(redis-server --version)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;redis\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        mkdir -p /cby/backend/base-service/</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line">    </span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/&quot; ]; then</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        ## 解压安装服务 </span><br><span class="line"></span><br><span class="line">        cd /Basic-package || exit</span><br><span class="line">        cp redis-5.0.12.tar.gz /cby/backend/base-service/</span><br><span class="line">        cd /cby/backend/base-service/ || exit</span><br><span class="line">        tar xf redis-5.0.12.tar.gz </span><br><span class="line">        mv /cby/backend/base-service/redis-5.0.12/ /cby/backend/base-service/redis/</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        mkdir -p /cby/backend/base-service/</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/redis/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        cd /cby/backend/base-service/redis/ || exit</span><br><span class="line"></span><br><span class="line">## 写入配置文件</span><br><span class="line"></span><br><span class="line">cat &gt;redis.conf&lt;&lt;EOF</span><br><span class="line">    bind 0.0.0.0</span><br><span class="line">    protected-mode no</span><br><span class="line">    daemonize yes</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">        ## 编译此服务</span><br><span class="line"></span><br><span class="line">        make -j &quot;$(cat /proc/cpuinfo |grep &quot;processor&quot;|wc -l)&quot;</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line">  </span><br><span class="line">    </span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/redis/src/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        cd /cby/backend/base-service/redis/src/ || exit</span><br><span class="line">        make install</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line">    </span><br><span class="line">## 进入安装目录后启动服务</span><br><span class="line"></span><br><span class="line">cd /cby/backend/base-service/redis/ || exit</span><br><span class="line">redis-server redis.conf</span><br><span class="line">    </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function 4-minio-install () &#123;</span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line">if [ &quot;$(/cby/backend/base-service/minio/minio -v)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;minio\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/minio/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/minio/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        ## 添加执行权限并将服务拷贝到目的地</span><br><span class="line"></span><br><span class="line">        cd /Basic-package || exit</span><br><span class="line">        mkdir -p /cby/backend/base-service/minio/</span><br><span class="line">        cp minio /cby/backend/base-service/minio/</span><br><span class="line">        cd /cby/backend/base-service/minio/ || exit</span><br><span class="line">        chmod +x minio</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line">    </span><br><span class="line">    if [ &quot;$(grep &quot;MINIO_ACCESS_KEY&quot; /etc/profile)&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &#x27;MINIO_ACCESS_KEY in profile&#x27;  </span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        ## 将账号密码写入环境变量</span><br><span class="line"></span><br><span class="line">        echo -e &#x27;export MINIO_ACCESS_KEY=minio&#x27; &gt;&gt; /etc/profile</span><br><span class="line">        echo -e &#x27;export MINIO_SECRET_KEY=thinker@123&#x27; &gt;&gt; /etc/profile </span><br><span class="line">        source /etc/profile</span><br><span class="line"></span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/minio/data&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/minio/data\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        mkdir -p /cby/backend/base-service/minio/data</span><br><span class="line"></span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    if [ -x &quot;/cby/backend/base-service/minio/minio&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;file \&quot;/cby/backend/base-service/minio/minio\&quot; is executable&quot;</span><br><span class="line"></span><br><span class="line">        source /etc/profile</span><br><span class="line">        nohup /cby/backend/base-service/minio/minio server --address 0.0.0.0:9000 /cby/backend/base-service/minio/data &gt; minio.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function 5-nginx-install () &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line">if [ &quot;$(/cby/backend/base-service/nginx/sbin/nginx -v)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;nginx\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        mkdir -p /cby/backend/base-service/</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/nginx-1.18.0/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/nginx-1.18.0/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        ## 解压所需包并安装所需依赖</span><br><span class="line"></span><br><span class="line">        cd /Basic-package || exit</span><br><span class="line">        cp nginx-1.18.0.tar.gz /cby/backend/base-service/</span><br><span class="line">        cd /cby/backend/base-service/ || exit</span><br><span class="line">        tar -zxf nginx-1.18.0.tar.gz</span><br><span class="line">        yum install -y gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/nginx&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/nginx\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        mkdir -p /cby/backend/base-service/nginx</span><br><span class="line"></span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/nginx-1.18.0/&quot; ]; then</span><br><span class="line">        </span><br><span class="line">        ## Nginx编译</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/nginx-1.18.0/\&quot; exists&quot;</span><br><span class="line">        cd /cby/backend/base-service/nginx-1.18.0/ || exit</span><br><span class="line">        ./configure --prefix=/cby/backend/base-service/nginx --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module</span><br><span class="line">        make -j &quot;$(cat /proc/cpuinfo |grep &quot;processor&quot;|wc -l)&quot;</span><br><span class="line">        make install</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        exit 1</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    if [ &quot;$(/cby/backend/base-service/nginx/sbin/nginx -v)&quot; ]; then</span><br><span class="line">        echo &quot;command \&quot;nginx\&quot; exists on system&quot;</span><br><span class="line">        echo &#x27;nginx version is :&#x27;        </span><br><span class="line">        /cby/backend/base-service/nginx/sbin/nginx -v</span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function 6-rocketmq-install () &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line">if [ &quot;$(ls /cby/backend/base-service/rocketmq/startup.sh)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;rocketmq\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        mkdir -p /cby/backend/base-service/</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/package/rocketmq/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/package/rocketmq/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        mkdir -p /cby/backend/base-service/package/rocketmq/</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/rocketmq/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/rocketmq/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        cd /Basic-package || exit</span><br><span class="line">        yum -y install unzip</span><br><span class="line">        cp -r rocketmq/ /cby/backend/base-service/package/</span><br><span class="line">        cd /cby/backend/base-service/package/rocketmq/ || exit</span><br><span class="line">        unzip rocketmq-all-4.5.2-bin-release.zip</span><br><span class="line">        mv rocketmq-all-4.5.2-bin-release/ /cby/backend/base-service/rocketmq/</span><br><span class="line">        cp *.sh /cby/backend/base-service/rocketmq/</span><br><span class="line">        cd /cby/backend/base-service/rocketmq/ || exit</span><br><span class="line">        sh /cby/backend/base-service/rocketmq/startup.sh</span><br><span class="line"></span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line">    ## 测试消息</span><br><span class="line"></span><br><span class="line">    if [ -x &quot;/cby/backend/base-service/rocketmq/bin/tools.sh&quot; ]; then</span><br><span class="line">        echo &quot;file \&quot;/cby/backend/base-service/rocketmq/bin/tools.sh\&quot; is executable&quot;</span><br><span class="line"></span><br><span class="line">        echo &#x27;发送测试消息&#x27;         </span><br><span class="line">        bash /cby/backend/base-service/rocketmq/bin/tools.sh  /cby/backend/base-service/rocketmq/org.apache.rocketmq.example.quickstart.Producer</span><br><span class="line"></span><br><span class="line">        echo &#x27;接受测试消息&#x27;</span><br><span class="line">        bash /cby/backend/base-service/rocketmq/bin/tools.sh  /cby/backend/base-service/rocketmq/org.apache.rocketmq.example.quickstart.Consumer</span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function 7-rocketmq-console-install () &#123;</span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line">if [ &quot;$(ls /cby/backend/base-service/rocketmq-console/startup.sh)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;rocketmq-console\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        mkdir -p /cby/backend/base-service/</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/cby/backend/base-service/rocketmq-console&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/cby/backend/base-service/rocketmq-console\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        ## 将所需包拷贝过去并启动</span><br><span class="line"></span><br><span class="line">        cd /Basic-package || exit</span><br><span class="line">        cp -r rocketmq-console/ /cby/backend/base-service/rocketmq-console</span><br><span class="line">        cd /cby/backend/base-service/rocketmq-console/ || exit</span><br><span class="line">        sh startup.sh</span><br><span class="line">    fi</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function 8-Elasticsearch-install () &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ &quot;$(ls /openes/elasticsearch)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;elasticsearch\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 修改一些配置</span><br><span class="line"></span><br><span class="line">    cat &gt;&gt;/etc/security/limits.conf&lt;&lt;EOF</span><br><span class="line">    ## 添加以下内容</span><br><span class="line">    * soft nofile 65536</span><br><span class="line">    * hard nofile 131072</span><br><span class="line">    * soft nproc 4096</span><br><span class="line">    * hard nproc 4096</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">    cat &gt;&quot;$(ls /etc/security/limits.d/*.conf)&quot;&lt;&lt;EOF</span><br><span class="line">    # Default limit for number of user&#x27;s processes to prevent</span><br><span class="line">    # accidental fork bombs.</span><br><span class="line">    # See rhbz #432903 for reasoning.</span><br><span class="line"></span><br><span class="line">    *          soft    nproc     4096</span><br><span class="line">    root       soft    nproc     unlimited</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">    cat &gt;&gt;/etc/sysctl.conf&lt;&lt;EOF</span><br><span class="line">    vm.max_map_count=655360</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    if [ -d &quot;/openes/&quot; ]; then</span><br><span class="line"></span><br><span class="line">        echo &quot;directory \&quot;/openes/\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">    else</span><br><span class="line"></span><br><span class="line">        cd /Basic-package || exit</span><br><span class="line">        mkdir -p /openes/</span><br><span class="line"></span><br><span class="line">        ## 创建目录后将安装包拷贝过去</span><br><span class="line"></span><br><span class="line">        cp elasticsearch-7.13.2-linux-x86_64.tar.gz /openes/</span><br><span class="line"></span><br><span class="line">        ## 添加用户并设置密码</span><br><span class="line"></span><br><span class="line">        useradd openes</span><br><span class="line">        echo &quot;es&quot; | passwd --stdin openes</span><br><span class="line">        chown -R openes:openes /openes/</span><br><span class="line"></span><br><span class="line">        sysctl -p</span><br><span class="line"></span><br><span class="line">        su - openes &lt;&lt;!</span><br><span class="line">        cd /openes</span><br><span class="line">        tar xf elasticsearch-7.13.2-linux-x86_64.tar.gz </span><br><span class="line">        mv elasticsearch-7.13.2/ elasticsearch/</span><br><span class="line"></span><br><span class="line">        if [ -d &quot;/openes/es_repo/data&quot; ]; then</span><br><span class="line"></span><br><span class="line">            echo &quot;directory \&quot;/openes/es_repo/data\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">        else</span><br><span class="line"></span><br><span class="line">            mkdir -p /openes/es_repo/data</span><br><span class="line"></span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line">        if [ -d &quot;/openes/es_repo/logs&quot; ]; then</span><br><span class="line"></span><br><span class="line">            echo &quot;directory \&quot;/openes/es_repo/logs\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">        else</span><br><span class="line"></span><br><span class="line">            mkdir -p /openes/es_repo/logs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cat &gt;&gt;/openes/elasticsearch/config/elasticsearch.yml&lt;&lt;EOF</span><br><span class="line">    ## 修改以下配置</span><br><span class="line">    node.name: node-1</span><br><span class="line">    ## 数据目录位置</span><br><span class="line">    path.data: /openes/es_repo/data</span><br><span class="line">    ## 日志目录位置</span><br><span class="line">    path.logs: /openes/es_repo/logs</span><br><span class="line">    cluster.initial_master_nodes: [&quot;node-1&quot;]</span><br><span class="line">    ## 绑定到0.0.0.0，允许任何ip来访问</span><br><span class="line">    network.host: 0.0.0.0</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">        /openes/elasticsearch/bin/elasticsearch -d</span><br><span class="line">!</span><br><span class="line"></span><br><span class="line">    fi </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sleep 20s</span><br><span class="line">curl -I http://127.0.0.1:9200/</span><br><span class="line">    </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function 9-Kibana-install () &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ &quot;$(ls /openes/kibana)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;elasticsearch\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">    cd /Basic-package || exit </span><br><span class="line">    mkdir -p /openes/</span><br><span class="line">    </span><br><span class="line">    ## 创建目录后将安装包拷贝过去</span><br><span class="line">    ## 并赋予权限</span><br><span class="line"></span><br><span class="line">    cp -r kibana/ /openes/package/</span><br><span class="line">    chown -R openes:openes /openes/</span><br><span class="line">    su - openes &lt;&lt;!</span><br><span class="line">    cd /openes/package/</span><br><span class="line">    tar xf kibana-7.13.2-linux-x86_64.tar.gz </span><br><span class="line">    mv kibana-7.13.2-linux-x86_64/ /openes/kibana/</span><br><span class="line">    mv *.sh /openes/kibana/</span><br><span class="line"></span><br><span class="line">    cat &gt;&gt;/openes/kibana/config/kibana.yml&lt;&lt;EOF</span><br><span class="line">    ## 修改以下配置</span><br><span class="line">    server.port: 5601</span><br><span class="line">    server.host: &quot;0.0.0.0&quot;</span><br><span class="line">    elasticsearch.hosts: [&quot;http://127.0.0.1:9200&quot;]</span><br><span class="line">    kibana.index: &quot;.kibana&quot;</span><br><span class="line">    i18n.locale: &quot;zh-CN&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">    cd /openes/kibana/</span><br><span class="line">    sh startup.sh</span><br><span class="line"></span><br><span class="line">!</span><br><span class="line"></span><br><span class="line">sleep 20s</span><br><span class="line"></span><br><span class="line">## 测试验证</span><br><span class="line"></span><br><span class="line">curl -I http://127.0.0.1:5601/</span><br><span class="line">    </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function 10-Logstash-install () &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 作者：陈步云</span><br><span class="line">## 微信：15648907522</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ &quot;$(ls /openes/logstash)&quot; ]; then</span><br><span class="line"></span><br><span class="line">    echo &quot;command \&quot;logstash\&quot; exists on system&quot;</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">    cd /Basic-package || exit</span><br><span class="line">    mkdir -p /openes/</span><br><span class="line"></span><br><span class="line">    ## 创建目录后将安装包拷贝过去</span><br><span class="line">    ## 并赋予权限</span><br><span class="line"></span><br><span class="line">    cp logstash-7.13.2-linux-x86_64.tar.gz /openes/</span><br><span class="line">    chown -R openes:openes /openes/</span><br><span class="line"></span><br><span class="line">    ## 切换用户在另一个用户中执行</span><br><span class="line"></span><br><span class="line">    su - openes &lt;&lt;!</span><br><span class="line">    cd /openes/</span><br><span class="line">    tar xf logstash-7.13.2-linux-x86_64.tar.gz </span><br><span class="line">    mv logstash-7.13.2/ /openes/logstash/</span><br><span class="line">        </span><br><span class="line">        if [ -d &quot;/openes/es_repo/data&quot; ]; then</span><br><span class="line"></span><br><span class="line">            echo &quot;directory \&quot;/openes/es_repo/data\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">        else</span><br><span class="line"></span><br><span class="line">            mkdir -p /openes/es_repo/data</span><br><span class="line"></span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line">        if [ -d &quot;/openes/es_repo/logs&quot; ]; then</span><br><span class="line"></span><br><span class="line">            echo &quot;directory \&quot;/openes/es_repo/logs\&quot; exists&quot;</span><br><span class="line"></span><br><span class="line">        else</span><br><span class="line"></span><br><span class="line">            mkdir -p /openes/es_repo/logs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line">    cat &gt;&gt;/openes/logstash/config/logstash.yml&lt;&lt;EOF</span><br><span class="line">## 修改以下配置</span><br><span class="line">path.data: /openes/logstash_repo/data</span><br><span class="line">path.logs: /openes/logstash_repo/logs</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cat &gt;/openes/logstash/config/logstash-data-govern.conf&lt;&lt;EOF</span><br><span class="line"></span><br><span class="line">## Sample Logstash configuration for creating a simple</span><br><span class="line">## tcp -&gt; Logstash -&gt; Elasticsearch pipeline.</span><br><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line">    tcp &#123;</span><br><span class="line">        mode =&gt; &quot;server&quot;</span><br><span class="line">        host =&gt; &quot;0.0.0.0&quot;</span><br><span class="line">        port =&gt; 4560</span><br><span class="line">        codec =&gt; json_lines</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;http://127.0.0.1:9200&quot;]</span><br><span class="line">        index =&gt; &quot;data-govern-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cd  /openes/logstash/ || exit</span><br><span class="line"></span><br><span class="line">chown -R openes:openes /openes/</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line">nohup ./bin/logstash -f config/logstash-data-govern.conf &gt; logstash.log  2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;ps -aux|grep logstash&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">0-basic-install</span><br><span class="line">1-java-install</span><br><span class="line">2-mysql-install</span><br><span class="line">3-redis-install</span><br><span class="line">4-minio-install</span><br><span class="line">5-nginx-install</span><br><span class="line">6-rocketmq-install</span><br><span class="line">7-rocketmq-console-install</span><br><span class="line">8-Elasticsearch-install</span><br><span class="line">9-Kibana-install</span><br><span class="line">10-Logstash-install</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/53e1223cb5a64abab63e92712f02dc0e~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>32篇原创内容</p>
<p>公众号</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>人工智能 deepface 换脸技术 学习</title>
    <url>/2021/12/30/2021-12-30-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD_deepface_%E6%8D%A2%E8%84%B8%E6%8A%80%E6%9C%AF_%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5551722f4b254661b22663128f7e538a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>介绍  </p>
<p>Deepface是一个轻量级的python人脸识别和人脸属性分析（年龄、性别、情感和种族）框架。它是一种混合人脸识别框架缠绕状态的最先进的模型：VGG-Face，Google FaceNet，OpenFace，Facebook DeepFace，DeepID，ArcFace和Dlib。那些模型已经达到并通过了人类水平的准确性。该库主要基于 TensorFlow 和 Keras。</p>
<p>环境准备与安装</p>
<p>项目地址：</p>
<p><a href="https://github.com/serengil/deepface">https://github.com/serengil/deepface</a></p>
<p>pycharm环境下载：</p>
<p><a href="https://www.jetbrains.com/pycharm/download/#section=windows">https://www.jetbrains.com/pycharm/download/#section=windows</a></p>
<p>conda虚拟环境：</p>
<p><a href="https://www.anaconda.com/products/individual">https://www.anaconda.com/products/individual</a></p>
<p>数据集：</p>
<p><a href="https://github.com/serengil/deepface/_models/releases/download/v1.0/vgg/_face/_weights.h5">https://github.com/serengil/deepface\_models/releases/download/v1.0/vgg\_face\_weights.h5</a></p>
<p><a href="https://github.com/serengil/deepface/_models/releases/download/v1.0/facial/_expression/_model/_weights.h5">https://github.com/serengil/deepface\_models/releases/download/v1.0/facial\_expression\_model\_weights.h5</a></p>
<p><a href="https://github.com/serengil/deepface/_models/releases/download/v1.0/age/_model/_weights.h5">https://github.com/serengil/deepface\_models/releases/download/v1.0/age\_model\_weights.h5</a></p>
<p><a href="https://github.com/serengil/deepface/_models/releases/download/v1.0/gender/_model/_weights.h5">https://github.com/serengil/deepface\_models/releases/download/v1.0/gender\_model\_weights.h5</a></p>
<p><a href="https://github.com/serengil/deepface/_models/releases/download/v1.0/race/_model/_single/_batch.h5">https://github.com/serengil/deepface\_models/releases/download/v1.0/race\_model\_single\_batch.h5</a></p>
<p>创建项目</p>
<p>使用打开项目目录后，创建时使用conda的Python 3.9虚拟环境</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c75238b7236542c3b67dc3f0999438a1~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>安装pip依赖</p>
<p>创建完成后，在cmd中查看现有的虚拟环境，并进入刚刚创建的虚拟环境</p>
<p>conda env list</p>
<p>activate pythonProject</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6acad22ae9b64ed99174838b5daefced~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>进入环境后在进行安装pip所需依赖，并使用国内源进行安装实现下载加速</p>
<p>pip install deepface -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/58f5096a70834443a804991aaf14f527~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>使用</p>
<p>面部验证</p>
<p>此功能验证同一人或不同人员的面部对。它期望精确的图像路径作为输入。也欢迎通过笨重或基于 64 编码的图像。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd C:\Users\Administrator\PycharmProjects\pythonProject\tests\dataset</span><br><span class="line"></span><br><span class="line">from deepface import DeepFace</span><br><span class="line">result = DeepFace.verify(img1_path = &quot;img1.jpg&quot;, img2_path = &quot;img2.jpg&quot;)</span><br></pre></td></tr></table></figure>

<p>会自动下载数据集，若无法下载数据集</p>
<p>可以提前下载好数据集，放入到 C:\Users\Administrator.deepface\weights\ 目录下</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a60acdc50a9463081d7aad9159d6955~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>面部属性分析</p>
<p>Deepface还配备了一个强大的面部属性分析模块，包括年龄，性别，面部表情（包括愤怒，恐惧，中性，悲伤，厌恶，快乐和惊喜）和种族（包括亚洲，白人，中东，印度，拉丁和黑色）预测。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from deepface import DeepFace</span><br><span class="line">obj = DeepFace.analyze(img_path = &quot;img4.jpg&quot;, actions = [&#x27;age&#x27;, &#x27;gender&#x27;, &#x27;race&#x27;, &#x27;emotion&#x27;])</span><br></pre></td></tr></table></figure>

<p>会自动下载数据集，若无法下载数据集</p>
<p>可以提前下载好数据集，放入到 C:\Users\Administrator.deepface\weights\ 目录下</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de61bf44979c40f58c8d53fb760fd63e~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/579503a2be664b64bb26935ace853f46~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>49篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/59bf3a92e5f04d658066d5cc13b094e3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>从APNIC获取中国IP地址列表</title>
    <url>/2021/12/30/2021-12-30-%E4%BB%8EAPNIC%E8%8E%B7%E5%8F%96%E4%B8%AD%E5%9B%BDIP%E5%9C%B0%E5%9D%80%E5%88%97%E8%A1%A8/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/687a7e51eed640e386cc22bd3091e60a~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>关于APNIC</strong>  </p>
<p>    全球IP地址块被IANA(Internet Assigned Numbers Authority)分配给全球三大地区性IP地址分配机构，它们分别是：</p>
<p><strong>ARIN (American Registry for Internet Numbers)</strong></p>
<p>    负责北美、南美、加勒比以及非洲撒哈啦部分的IP地址分配。同时还要给全球NSP(Network Service Providers)分配地址。</p>
<p><strong>RIPE (Reseaux IP Europeens)</strong></p>
<p>    负责欧洲、中东、北非、西亚部分地区(前苏联)</p>
<p><strong>APNIC (Asia Pacific Network Information Center)</strong></p>
<p>    负责亚洲、太平洋地区</p>
<p><strong>APNIC IP地址分配信息总表的获取：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">APNIC提供了每日更新的亚太地区IPv4，IPv6，AS号分配的信息表：http://ftp.apnic.net/apnic/stats/apnic/delegated-apnic-latest</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">该文件的格式与具体内容参见：ftp://ftp.apnic.net/pub/apnic/stats/apnic/README.TXT</span><br></pre></td></tr></table></figure>

<p>通过该文件我们能够得到APNIC辖下IPv4地址空间的分配情况。</p>
<p><strong>脚本获取IP地址</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">wget -c http://ftp.apnic.net/stats/apnic/delegated-apnic-latest</span><br><span class="line"></span><br><span class="line">cat delegated-apnic-latest | awk -F &#x27;|&#x27; &#x27;/CN/&amp;&amp;/ipv4/ &#123;print $4 &quot;/&quot; 32-log($5)/log(2)&#125;&#x27; | cat &gt; ipv4.txt</span><br><span class="line"></span><br><span class="line">cat delegated-apnic-latest | awk -F &#x27;|&#x27; &#x27;/CN/&amp;&amp;/ipv6/ &#123;print $4 &quot;/&quot; 32-log($5)/log(2)&#125;&#x27; | cat &gt; ipv6.txt</span><br><span class="line"></span><br><span class="line">cat delegated-apnic-latest | awk -F &#x27;|&#x27; &#x27;/HK/&amp;&amp;/ipv4/ &#123;print $4 &quot;/&quot; 32-log($5)/log(2)&#125;&#x27; | cat &gt; ipv4-hk.txt</span><br><span class="line"></span><br><span class="line">cat delegated-apnic-latest | awk -F &#x27;|&#x27; &#x27;/HK/&amp;&amp;/ipv6/ &#123;print $4 &quot;/&quot; 32-log($5)/log(2)&#125;&#x27; | cat &gt; ipv6-hk.txt</span><br></pre></td></tr></table></figure>

<p><strong>执行脚本：</strong>  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@cby cby]# ./ip.sh </span><br><span class="line">--2021-04-29 12:17:13--  http://ftp.apnic.net/stats/apnic/delegated-apnic-latest</span><br><span class="line">Resolving ftp.apnic.net (ftp.apnic.net)... 203.119.102.40, 2001:dd8:8:701::40</span><br><span class="line">Connecting to ftp.apnic.net (ftp.apnic.net)|203.119.102.40|:80... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 3352151 (3.2M) [text/plain]</span><br><span class="line">Saving to: ‘delegated-apnic-latest’</span><br><span class="line"></span><br><span class="line">delegated-apnic-latest            100%[=============================================================&gt;]   3.20M  61.3KB/s    in 44s     </span><br><span class="line"></span><br><span class="line">2021-04-29 12:17:58 (74.0 KB/s) - ‘delegated-apnic-latest’ saved [3352151/3352151]</span><br><span class="line">[root@cby cby]# ls</span><br><span class="line">delegated-apnic-latest  index.html  ip.sh  ipv4-hk.txt  ipv4.txt  ipv6-hk.txt  ipv6.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>每日凌晨十二点十分会进行同步，若需要IP地址，可以访问如下地址：</p>
<p><strong><a href="http://aliyun.chenby.cn/">http://aliyun.chenby.cn/</a></strong></p>
<p><strong>定时任务：</strong>  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@cby cby]# crontab -l</span><br><span class="line">10 0 * * *  /www/server/cron/3ab48c27ec99cb9787749c362afae517 &gt;&gt; /www/server/cron/3ab48c27ec99cb9787749c362afae517.log 2&gt;&amp;1</span><br><span class="line">10 0 * * *  rm -rf /www/wwwroot/www.chenby.cn/cby/ipv4.txt /www/wwwroot/www.chenby.cn/cby/ipv4-hk.txt /www/wwwroot/www.chenby.cn/cby/ipv6.txt /www/wwwroot/www.chenby.cn/cby/ipv6-hk.txt /www/wwwroot/www.chenby.cn/cby/delegated-apnic-latest </span><br><span class="line">11 0 * * *  /www/wwwroot/www.chenby.cn/cby/ip.sh &gt;&gt; /home/ip.txt</span><br></pre></td></tr></table></figure>

<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>使用 Istioctl 安装 istio</title>
    <url>/2021/12/30/2021-12-30-%E4%BD%BF%E7%94%A8_Istioctl_%E5%AE%89%E8%A3%85_istio/</url>
    <content><![CDATA[<p>使用 Istioctl 安装 istio</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8c57e2d07c5e47588442dd1cefd04dab~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>下载 Istio</strong></p>
<p>转到 Istio 发布 页面，下载针对你操作系统的安装文件， 或用自动化工具下载并提取最新版本（Linux 或 macOS）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# curl -L https://istio.io/downloadIstio | sh -</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>若无法下载可以手动写入文件进行执行  </p>
<p><strong>脚本内容：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line"># Copyright Istio Authors</span><br><span class="line">#</span><br><span class="line"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line"># you may not use this file except in compliance with the License.</span><br><span class="line"># You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># This file will be fetched as: curl -L https://git.io/getLatestIstio | sh -</span><br><span class="line"># so it should be pure bourne shell, not bash (and not reference other scripts)</span><br><span class="line">#</span><br><span class="line"># The script fetches the latest Istio release candidate and untars it.</span><br><span class="line"># You can pass variables on the command line to download a specific version</span><br><span class="line"># or to override the processor architecture. For example, to download</span><br><span class="line"># Istio 1.6.8 for the x86_64 architecture,</span><br><span class="line"># run curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.6.8 TARGET_ARCH=x86_64 sh -.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set -e</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Determines the operating system.</span><br><span class="line">OS=&quot;$(uname)&quot;</span><br><span class="line">if [ &quot;x$&#123;OS&#125;&quot; = &quot;xDarwin&quot; ] ; then</span><br><span class="line">  OSEXT=&quot;osx&quot;</span><br><span class="line">else</span><br><span class="line">  OSEXT=&quot;linux&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Determine the latest Istio version by version number ignoring alpha, beta, and rc versions.</span><br><span class="line">if [ &quot;x$&#123;ISTIO_VERSION&#125;&quot; = &quot;x&quot; ] ; then</span><br><span class="line">  ISTIO_VERSION=&quot;$(curl -sL https://github.com/istio/istio/releases | \</span><br><span class="line">                  grep -o &#x27;releases/[0-9]*.[0-9]*.[0-9]*/&#x27; | sort -V | \</span><br><span class="line">                  tail -1 | awk -F&#x27;/&#x27; &#x27;&#123; print $2&#125;&#x27;)&quot;</span><br><span class="line">  ISTIO_VERSION=&quot;$&#123;ISTIO_VERSION##*/&#125;&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LOCAL_ARCH=$(uname -m)</span><br><span class="line">if [ &quot;$&#123;TARGET_ARCH&#125;&quot; ]; then</span><br><span class="line">    LOCAL_ARCH=$&#123;TARGET_ARCH&#125;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">case &quot;$&#123;LOCAL_ARCH&#125;&quot; in</span><br><span class="line">  x86_64)</span><br><span class="line">    ISTIO_ARCH=amd64</span><br><span class="line">    ;;</span><br><span class="line">  armv8*)</span><br><span class="line">    ISTIO_ARCH=arm64</span><br><span class="line">    ;;</span><br><span class="line">  aarch64*)</span><br><span class="line">    ISTIO_ARCH=arm64</span><br><span class="line">    ;;</span><br><span class="line">  armv*)</span><br><span class="line">    ISTIO_ARCH=armv7</span><br><span class="line">    ;;</span><br><span class="line">  amd64|arm64)</span><br><span class="line">    ISTIO_ARCH=$&#123;LOCAL_ARCH&#125;</span><br><span class="line">    ;;</span><br><span class="line">  *)</span><br><span class="line">    echo &quot;This system&#x27;s architecture, $&#123;LOCAL_ARCH&#125;, isn&#x27;t supported&quot;</span><br><span class="line">    exit 1</span><br><span class="line">    ;;</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ &quot;x$&#123;ISTIO_VERSION&#125;&quot; = &quot;x&quot; ] ; then</span><br><span class="line">  printf &quot;Unable to get latest Istio version. Set ISTIO_VERSION env var and re-run. For example: export ISTIO_VERSION=1.0.4&quot;</span><br><span class="line">  exit 1;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NAME=&quot;istio-$ISTIO_VERSION&quot;</span><br><span class="line">URL=&quot;https://github.com/istio/istio/releases/download/$&#123;ISTIO_VERSION&#125;/istio-$&#123;ISTIO_VERSION&#125;-$&#123;OSEXT&#125;.tar.gz&quot;</span><br><span class="line">ARCH_URL=&quot;https://github.com/istio/istio/releases/download/$&#123;ISTIO_VERSION&#125;/istio-$&#123;ISTIO_VERSION&#125;-$&#123;OSEXT&#125;-$&#123;ISTIO_ARCH&#125;.tar.gz&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">with_arch() &#123;</span><br><span class="line">  printf &quot;\nDownloading %s from %s ...\n&quot; &quot;$NAME&quot; &quot;$ARCH_URL&quot;</span><br><span class="line">  if ! curl -o /dev/null -sIf &quot;$ARCH_URL&quot;; then</span><br><span class="line">    printf &quot;\n%s is not found, please specify a valid ISTIO_VERSION and TARGET_ARCH\n&quot; &quot;$ARCH_URL&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line">  curl -fsLO &quot;$ARCH_URL&quot;</span><br><span class="line">  filename=&quot;istio-$&#123;ISTIO_VERSION&#125;-$&#123;OSEXT&#125;-$&#123;ISTIO_ARCH&#125;.tar.gz&quot;</span><br><span class="line">  tar -xzf &quot;$&#123;filename&#125;&quot;</span><br><span class="line">  rm &quot;$&#123;filename&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">without_arch() &#123;</span><br><span class="line">  printf &quot;\nDownloading %s from %s ...&quot; &quot;$NAME&quot; &quot;$URL&quot;</span><br><span class="line">  if ! curl -o /dev/null -sIf &quot;$URL&quot;; then</span><br><span class="line">    printf &quot;\n%s is not found, please specify a valid ISTIO_VERSION\n&quot; &quot;$URL&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line">  curl -fsLO &quot;$URL&quot;</span><br><span class="line">  filename=&quot;istio-$&#123;ISTIO_VERSION&#125;-$&#123;OSEXT&#125;.tar.gz&quot;</span><br><span class="line">  tar -xzf &quot;$&#123;filename&#125;&quot;</span><br><span class="line">  rm &quot;$&#123;filename&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Istio 1.6 and above support arch</span><br><span class="line"># Istio 1.5 and below do not have arch support</span><br><span class="line">ARCH_SUPPORTED=&quot;1.6&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ &quot;$&#123;OS&#125;&quot; = &quot;Linux&quot; ] ; then</span><br><span class="line">  # This checks if ISTIO_VERSION is less than ARCH_SUPPORTED (version-sort&#x27;s before it)</span><br><span class="line">  if [ &quot;$(printf &#x27;%s\n%s&#x27; &quot;$&#123;ARCH_SUPPORTED&#125;&quot; &quot;$&#123;ISTIO_VERSION&#125;&quot; | sort -V | head -n 1)&quot; = &quot;$&#123;ISTIO_VERSION&#125;&quot; ]; then</span><br><span class="line">    without_arch</span><br><span class="line">  else</span><br><span class="line">    with_arch</span><br><span class="line">  fi</span><br><span class="line">elif [ &quot;x$&#123;OS&#125;&quot; = &quot;xDarwin&quot; ] ; then</span><br><span class="line">  without_arch</span><br><span class="line">else</span><br><span class="line">  printf &quot;\n\n&quot;</span><br><span class="line">  printf &quot;Unable to download Istio %s at this moment!\n&quot; &quot;$ISTIO_VERSION&quot;</span><br><span class="line">  printf &quot;Please verify the version you are trying to download.\n\n&quot;</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">printf &quot;&quot;</span><br><span class="line">printf &quot;\nIstio %s Download Complete!\n&quot; &quot;$ISTIO_VERSION&quot;</span><br><span class="line">printf &quot;\n&quot;</span><br><span class="line">printf &quot;Istio has been successfully downloaded into the %s folder on your system.\n&quot; &quot;$NAME&quot;</span><br><span class="line">printf &quot;\n&quot;</span><br><span class="line">BINDIR=&quot;$(cd &quot;$NAME/bin&quot; &amp;&amp; pwd)&quot;</span><br><span class="line">printf &quot;Next Steps:\n&quot;</span><br><span class="line">printf &quot;See https://istio.io/latest/docs/setup/install/ to add Istio to your Kubernetes cluster.\n&quot;</span><br><span class="line">printf &quot;\n&quot;</span><br><span class="line">printf &quot;To configure the istioctl client tool for your workstation,\n&quot;</span><br><span class="line">printf &quot;add the %s directory to your environment path variable with:\n&quot; &quot;$BINDIR&quot;</span><br><span class="line">printf &quot;\t export PATH=\&quot;\$PATH:%s\&quot;\n&quot; &quot;$BINDIR&quot;</span><br><span class="line">printf &quot;\n&quot;</span><br><span class="line">printf &quot;Begin the Istio pre-installation check by running:\n&quot;</span><br><span class="line">printf &quot;\t istioctl x precheck \n&quot;</span><br><span class="line">printf &quot;\n&quot;</span><br><span class="line">printf &quot;Need more information? Visit https://istio.io/latest/docs/setup/install/ \n&quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# bash istio.sh</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>转到 Istio 包目录。例如，如果包是 istio-1.11.4：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# cd istio-1.11.4/</span><br><span class="line">[root@k8s-master-node1 ~/istio-1.11.4]# ll</span><br><span class="line">total 28</span><br><span class="line">drwxr-x---.  2 root root    22 Oct 13 22:50 bin</span><br><span class="line">-rw-r--r--.  1 root root 11348 Oct 13 22:50 LICENSE</span><br><span class="line">drwxr-xr-x.  5 root root    52 Oct 13 22:50 manifests</span><br><span class="line">-rw-r-----.  1 root root   854 Oct 13 22:50 manifest.yaml</span><br><span class="line">-rw-r--r--.  1 root root  5866 Oct 13 22:50 README.md</span><br><span class="line">drwxr-xr-x. 21 root root  4096 Oct 13 22:50 samples</span><br><span class="line">drwxr-xr-x.  3 root root    57 Oct 13 22:50 tools</span><br><span class="line">[root@k8s-master-node1 ~/istio-1.11.4]#</span><br></pre></td></tr></table></figure>

<p><strong>安装目录包含：</strong></p>
<p>samples&#x2F; 目录下的示例应用程序</p>
<p>bin&#x2F; 目录下的 istioctl 客户端二进制文件 .</p>
<p>将 istioctl 客户端加入搜索路径（Linux or macOS）:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ export PATH=$PWD/bin:$PATH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export PATH=/root/istio-1.11.4/bin:$PATH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~/istio-1.11.4]# export PATH=$PWD/bin:$PATH</span><br><span class="line">[root@k8s-master-node1 ~/istio-1.11.4]#</span><br><span class="line">[root@k8s-master-node1 ~/istio-1.11.4]# vim /etc/profile</span><br><span class="line">[root@k8s-master-node1 ~/istio-1.11.4]# tail -n 2 /etc/profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export PATH=/root/istio-1.11.4/bin:$PATH</span><br><span class="line">[root@k8s-master-node1 ~/istio-1.11.4]#</span><br></pre></td></tr></table></figure>

<p><strong>使用默认配置档安装 Istio</strong></p>
<p>最简单的选择是用下面命令安装 Istio 默认 配置档：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# istioctl version</span><br><span class="line">no running Istio pods in &quot;istio-system&quot;</span><br><span class="line">1.11.4</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line">[root@k8s-master-node1 ~]# istioctl install --set profile=demo -y</span><br><span class="line">✔ Istio core installed                                                                                                                                                                                                                                                        </span><br><span class="line">✔ Istiod installed                                                                                                                                                                                                                                                            </span><br><span class="line">✔ Egress gateways installed                                                                                                                                                                                                                                                  </span><br><span class="line">✔ Ingress gateways installed                                                                                                                                                                                                                                                  </span><br><span class="line">✔ Installation complete                                                                                                                                                                                                                                                      </span><br><span class="line">Thank you for installing Istio 1.11.  Please take a few minutes to tell us about your install/upgrade experience!  https://forms.gle/kWULBRjUv7hHci7T6</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br></pre></td></tr></table></figure>

<p><strong>查看istio相应的 namespace 和 pod 是否已经正常创建</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line">[root@k8s-master-node1 ~]# kubectl get pods -n istio-system</span><br><span class="line">NAME                                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">istio-egressgateway-756d4db566-wh949    1/1     Running   0          2m</span><br><span class="line">istio-ingressgateway-8577c57fb6-2vrtg   1/1     Running   0          2m</span><br><span class="line">istiod-5847c59c69-l2dt2                 1/1     Running   0          2m39s</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br></pre></td></tr></table></figure>

<p><strong>检查 istio 的 CRD 和 API 资源</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line">[root@k8s-master-node1 ~]# kubectl get crd |grep istio</span><br><span class="line">authorizationpolicies.security.istio.io    2021-11-01T09:43:55Z</span><br><span class="line">destinationrules.networking.istio.io       2021-11-01T09:43:55Z</span><br><span class="line">envoyfilters.networking.istio.io           2021-11-01T09:43:55Z</span><br><span class="line">gateways.networking.istio.io               2021-11-01T09:43:55Z</span><br><span class="line">istiooperators.install.istio.io            2021-11-01T09:43:55Z</span><br><span class="line">peerauthentications.security.istio.io      2021-11-01T09:43:55Z</span><br><span class="line">requestauthentications.security.istio.io   2021-11-01T09:43:55Z</span><br><span class="line">serviceentries.networking.istio.io         2021-11-01T09:43:55Z</span><br><span class="line">sidecars.networking.istio.io               2021-11-01T09:43:55Z</span><br><span class="line">telemetries.telemetry.istio.io             2021-11-01T09:43:55Z</span><br><span class="line">virtualservices.networking.istio.io        2021-11-01T09:43:55Z</span><br><span class="line">workloadentries.networking.istio.io        2021-11-01T09:43:55Z</span><br><span class="line">workloadgroups.networking.istio.io         2021-11-01T09:43:55Z</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~]# kubectl api-resources |grep istio</span><br><span class="line">istiooperators                    iop,io       install.istio.io/v1alpha1              true         IstioOperator</span><br><span class="line">destinationrules                  dr           networking.istio.io/v1beta1            true         DestinationRule</span><br><span class="line">envoyfilters                                   networking.istio.io/v1alpha3           true         EnvoyFilter</span><br><span class="line">gateways                          gw           networking.istio.io/v1beta1            true         Gateway</span><br><span class="line">serviceentries                    se           networking.istio.io/v1beta1            true         ServiceEntry</span><br><span class="line">sidecars                                       networking.istio.io/v1beta1            true         Sidecar</span><br><span class="line">virtualservices                   vs           networking.istio.io/v1beta1            true         VirtualService</span><br><span class="line">workloadentries                   we           networking.istio.io/v1beta1            true         WorkloadEntry</span><br><span class="line">workloadgroups                    wg           networking.istio.io/v1alpha3           true         WorkloadGroup</span><br><span class="line">authorizationpolicies                          security.istio.io/v1beta1              true         AuthorizationPolicy</span><br><span class="line">peerauthentications               pa           security.istio.io/v1beta1              true         PeerAuthentication</span><br><span class="line">requestauthentications            ra           security.istio.io/v1beta1              true         RequestAuthentication</span><br><span class="line">telemetries                       telemetry    telemetry.istio.io/v1alpha1            true         Telemetry</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br></pre></td></tr></table></figure>

<p><strong>安装 dashboard 组件。命令如下</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# kubectl apply -f /root/istio-1.11.4/samples/addons/ -n istio-system</span><br><span class="line">serviceaccount/grafana created</span><br><span class="line">configmap/grafana created</span><br><span class="line">service/grafana created</span><br><span class="line">deployment.apps/grafana created</span><br><span class="line">configmap/istio-grafana-dashboards created</span><br><span class="line">configmap/istio-services-grafana-dashboards created</span><br><span class="line">deployment.apps/jaeger created</span><br><span class="line">service/tracing created</span><br><span class="line">service/zipkin created</span><br><span class="line">service/jaeger-collector created</span><br><span class="line">serviceaccount/kiali created</span><br><span class="line">configmap/kiali created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kiali-viewer created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kiali created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kiali created</span><br><span class="line">role.rbac.authorization.k8s.io/kiali-controlplane created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kiali-controlplane created</span><br><span class="line">service/kiali created</span><br><span class="line">deployment.apps/kiali created</span><br><span class="line">serviceaccount/prometheus created</span><br><span class="line">configmap/prometheus created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/prometheus created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/prometheus created</span><br><span class="line">service/prometheus created</span><br><span class="line">deployment.apps/prometheus created</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master-node1 ~]# kubectl get pods -n istio-system</span><br><span class="line">NAME                                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">grafana-68cc7d6d78-792cw                1/1     Running   0          88s</span><br><span class="line">istio-egressgateway-756d4db566-wh949    1/1     Running   0          6m9s</span><br><span class="line">istio-ingressgateway-8577c57fb6-2vrtg   1/1     Running   0          6m9s</span><br><span class="line">istiod-5847c59c69-l2dt2                 1/1     Running   0          6m48s</span><br><span class="line">jaeger-5d44bc5c5d-n6zjq                 1/1     Running   0          88s</span><br><span class="line">kiali-fd9f88575-svz7g                   1/1     Running   0          87s</span><br><span class="line">prometheus-77b49cb997-7d4s9             2/2     Running   0          86s</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br></pre></td></tr></table></figure>

<p><strong>将istio-ingressgateway改为NodePort方式，方便访问</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~]# kubectl patch service istio-ingressgateway -n istio-system -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;type&quot;:&quot;NodePort&quot;&#125;&#125;&#x27;</span><br><span class="line">service/istio-ingressgateway patched</span><br><span class="line">[root@k8s-master-node1 ~]#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/532ce5ca82fe4b8e974f283e8c246b3b~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>46篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4294884c6484402aa64f90a153005ce0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes核心实战（六）--- ConfigMap</title>
    <url>/2021/12/30/2021-12-30-kubernetes%E6%A0%B8%E5%BF%83%E5%AE%9E%E6%88%98%EF%BC%88%E5%85%AD%EF%BC%89---_ConfigMap/</url>
    <content><![CDATA[<h4 id="8、ConfigMap"><a href="#8、ConfigMap" class="headerlink" title="8、ConfigMap"></a>8、ConfigMap</h4><p>抽取应用配置，并且可以自动更新</p>
<h6 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim configmap.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat configmap.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">data:   </span><br><span class="line">  redis.conf: |</span><br><span class="line">    appendonly yes</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-conf</span><br><span class="line">  namespace: default</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl apply -f configmap.yaml </span><br><span class="line">configmap/redis-conf created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="查看配置"><a href="#查看配置" class="headerlink" title="查看配置"></a>查看配置</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get configmaps </span><br><span class="line">NAME               DATA   AGE</span><br><span class="line">kube-root-ca.crt   1      110m</span><br><span class="line">redis-conf         1      18s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="9、DaemonSet"><a href="#9、DaemonSet" class="headerlink" title="9、DaemonSet"></a>9、DaemonSet</h4><p>DaemonSet 确保全部（或者某些）节点上运行一个 Pod 的副本。当有节点加入集群时， 也会为他们新增一个 Pod 。当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。</p>
<p>DaemonSet 的一些典型用法：</p>
<p>在每个节点上运行集群存守护进程在每个节点上运行日志收集守护进程在每个节点上运行监控守护进程一种简单的用法是为每种类型的守护进程在所有的节点上都启动一个 DaemonSet。一个稍微复杂的用法是为同一种守护进程部署多个 DaemonSet；每个具有不同的标志， 并且对不同硬件类型具有不同的内存、CPU 要求。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6f346eb21df342eb90fae6fc2f45f178~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h6 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# vim daemonset.yaml</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# cat daemonset.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-app</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: redis-app</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      name: fluentd-redis</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: fluentd-redis</span><br><span class="line">    spec:</span><br><span class="line">      tolerations:</span><br><span class="line">      # this toleration is to have the daemonset runnable on master nodes</span><br><span class="line">      # remove it if your masters can&#x27;t run pods</span><br><span class="line">      - key: node-role.kubernetes.io/master</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      containers:</span><br><span class="line">      - name: fluentd-redis</span><br><span class="line">        image: redis</span><br><span class="line">        command:</span><br><span class="line">          - redis-server</span><br><span class="line">          - &quot;/redis-master/redis.conf&quot;  #指的是redis容器内部的位置</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 6379</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 200Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 200Mi</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: data</span><br><span class="line">          mountPath: /data</span><br><span class="line">        - name: config</span><br><span class="line">          mountPath: /redis-master</span><br><span class="line">          readOnly: true</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: data</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">      - name: config</span><br><span class="line">        configMap: </span><br><span class="line">          name: redis-conf</span><br><span class="line">          items:</span><br><span class="line">          - key: redis.conf</span><br><span class="line">            path: redis.conf</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  apply -f daemonset.yaml </span><br><span class="line">daemonset.apps/redis-app created</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master-node1 ~/yaml/test]# </span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get pod</span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">ingress-demo-app-694bf5d965-8rh7f        1/1     Running   0          130m</span><br><span class="line">ingress-demo-app-694bf5d965-swkpb        1/1     Running   0          130m</span><br><span class="line">nfs-client-provisioner-dc5789f74-5bznq   1/1     Running   0          114m</span><br><span class="line">redis-app-86g4q                          1/1     Running   0          28s</span><br><span class="line">redis-app-rt92n                          1/1     Running   0          28s</span><br><span class="line">redis-app-vkzft                          1/1     Running   0          28s</span><br><span class="line">web-0                                    1/1     Running   0          64m</span><br><span class="line">web-1                                    1/1     Running   0          63m</span><br><span class="line">web-2                                    1/1     Running   0          63m</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]# kubectl  get daemonsets.apps </span><br><span class="line">NAME        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">redis-app   3         3         3       3            3           &lt;none&gt;          38s</span><br><span class="line">[root@k8s-master-node1 ~/yaml/test]#</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0dd563f5511748219158213f3c0c46a1~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>62篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/53fa028ea8904565afb8761f1dec368e~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>人工智能NVIDIA显卡计算（CUDA+CUDNN）平台搭建</title>
    <url>/2021/12/30/2021-12-30-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDNVIDIA%E6%98%BE%E5%8D%A1%E8%AE%A1%E7%AE%97%EF%BC%88CUDA+CUDNN%EF%BC%89%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>    NVIDIA是GPU（图形处理器）的发明者，也是人工智能计算的引领者。我们创建了世界上最大的游戏平台和世界上最快的超级计算机。</p>
<p>      </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1df8d980dd4e4e8280c92cfcace864a3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    第一步，首先安装N卡驱动。  </p>
<p>&#96;&#96;&#96;shell<br>cby@cby-Inspiron-7577:~$ sudo add-apt-repository ppa:graphics-drivers&#x2F;ppa<br>[sudo] cby 的密码：<br>PPA publishes dbgsym, you may need to include ‘main&#x2F;debug’ component<br>Repository: ‘deb <a href="http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu/">http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu/</a> hirsute main’<br>Description:<br>Fresh drivers from upstream, currently shipping Nvidia.</p>
<h2 id="Current-Status"><a href="#Current-Status" class="headerlink" title="Current Status"></a>Current Status</h2><p>Current long-lived branch release: <code>nvidia-430</code> (430.40)<br>Dropped support for Fermi series (<a href="https://nvidia.custhelp.com/app/answers/detail/a_id/4656">https://nvidia.custhelp.com/app/answers/detail/a_id/4656</a>)</p>
<p>Old long-lived branch release: <code>nvidia-390</code> (390.129)</p>
<p>For GF1xx GPUs use <code>nvidia-390</code> (390.129)<br>For G8x, G9x and GT2xx GPUs use <code>nvidia-340</code> (340.107)<br>For NV4x and G7x GPUs use <code>nvidia-304</code> (304.137) End-Of-Life!</p>
<p>Support timeframes for Unix legacy GPU releases:<br><a href="https://nvidia.custhelp.com/app/answers/detail/a_id/3142">https://nvidia.custhelp.com/app/answers/detail/a_id/3142</a></p>
<h2 id="What-we’re-working-on-right-now"><a href="#What-we’re-working-on-right-now" class="headerlink" title="What we’re working on right now:"></a>What we’re working on right now:</h2><ul>
<li>Normal driver updates</li>
<li>Help Wanted: Mesa Updates for Intel&#x2F;AMD users, ping us if you want to help do this work, we’re shorthanded.</li>
</ul>
<h2 id="WARNINGS"><a href="#WARNINGS" class="headerlink" title="WARNINGS:"></a>WARNINGS:</h2><p>This PPA is currently in testing, you should be experienced with packaging before you dive in here:</p>
<p>Volunteers welcome!</p>
<h3 id="How-you-can-help"><a href="#How-you-can-help" class="headerlink" title="How you can help:"></a>How you can help:</h3><h2 id="Install-PTS-and-benchmark-your-gear"><a href="#Install-PTS-and-benchmark-your-gear" class="headerlink" title="Install PTS and benchmark your gear:"></a>Install PTS and benchmark your gear:</h2><p>    sudo apt-get install phoronix-test-suite</p>
<p>Run the benchmark:</p>
<p>    phoronix-test-suite default-benchmark openarena xonotic tesseract gputest unigine-valley</p>
<p>and then say yes when it asks you to submit your results to openbechmarking.org. Then grab a cup of coffee, it takes a bit for the benchmarks to run. Depending on the version of Ubuntu you’re using it might preferable for you to grabs PTS from upstream directly: <a href="http://www.phoronix-test-suite.com/?k=downloads">http://www.phoronix-test-suite.com/?k=downloads</a></p>
<h2 id="Share-your-results-with-the-community"><a href="#Share-your-results-with-the-community" class="headerlink" title="Share your results with the community:"></a>Share your results with the community:</h2><p>Post a link to your results (or any other feedback to): <a href="https://launchpad.net/~graphics-drivers-testers">https://launchpad.net/~graphics-drivers-testers</a></p>
<p>Remember to rerun and resubmit the benchmarks after driver upgrades, this will allow us to gather a bunch of data on performance that we can share with everybody.</p>
<p>If you run into old documentation referring to other PPAs, you can help us by consolidating references to this PPA.</p>
<p>If someone wants to go ahead and start prototyping on <code>software-properties-gtk</code> on what the GUI should look like, please start hacking!</p>
<h2 id="Help-us-Help-You"><a href="#Help-us-Help-You" class="headerlink" title="Help us Help You!"></a>Help us Help You!</h2><p>We use the donation funds to get the developers hardware to test and upload these drivers, please consider donating to the “community” slider on the donation page if you’re loving this PPA:</p>
<p><a href="http://www.ubuntu.com/download/desktop/contribute">http://www.ubuntu.com/download/desktop/contribute</a><br>More info: <a href="https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa">https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa</a><br>Adding repository.<br>Press [ENTER] to continue or Ctrl-c to cancel.<br>Adding deb entry to &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;graphics-drivers-ubuntu-ppa-hirsute.list<br>Adding disabled deb-src entry to &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;graphics-drivers-ubuntu-ppa-hirsute.list<br>Adding key to &#x2F;etc&#x2F;apt&#x2F;trusted.gpg.d&#x2F;graphics-drivers-ubuntu-ppa.gpg with fingerprint 2388FF3BE10A76F638F80723FCAE110B1118213C<br>命中:1 <a href="http://security.ubuntu.com/ubuntu">http://security.ubuntu.com/ubuntu</a> hirsute-security InRelease<br>命中:3 <a href="http://dl.google.com/linux/chrome/deb">http://dl.google.com/linux/chrome/deb</a> stable InRelease<br>获取:4 <a href="http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu">http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu</a> hirsute InRelease [24.4 kB]<br>命中:5 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute InRelease<br>获取:6 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute-updates InRelease [109 kB]<br>获取:7 <a href="http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu">http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu</a> hirsute&#x2F;main amd64 Packages [23.4 kB]<br>命中:8 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute-backports InRelease<br>获取:9 <a href="http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu">http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu</a> hirsute&#x2F;main i386 Packages [10.6 kB]<br>获取:10 <a href="http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu">http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu</a> hirsute&#x2F;main Translation-en [5,880 B]<br>忽略:2 <a href="https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64">https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64</a>  InRelease<br>命中:11 <a href="https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64">https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64</a>  Release<br>已下载 173 kB，耗时 21秒 (8,156 B&#x2F;s)<br>正在读取软件包列表… 完成<br>cby@cby-Inspiron-7577:~$</p>
<p>&#96;&#96;&#96;shell</p>
<p>第二步，更新源同时查看可安装的驱动</p>
<p>&#96;&#96;&#96;shell<br>cby@cby-Inspiron-7577:~$ sudo apt update<br>命中:1 <a href="http://dl.google.com/linux/chrome/deb">http://dl.google.com/linux/chrome/deb</a> stable InRelease<br>命中:2 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute InRelease<br>获取:4 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute-updates InRelease [109 kB]<br>命中:5 <a href="http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu">http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu</a> hirsute InRelease<br>命中:6 <a href="http://security.ubuntu.com/ubuntu">http://security.ubuntu.com/ubuntu</a> hirsute-security InRelease<br>忽略:3 <a href="https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64">https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64</a>  InRelease<br>命中:7 <a href="https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64">https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64</a>  Release<br>命中:8 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute-backports InRelease<br>已下载 109 kB，耗时 2秒 (64.2 kB&#x2F;s)<br>正在读取软件包列表… 完成<br>正在分析软件包的依赖关系树… 完成<br>正在读取状态信息… 完成<br>有 4 个软件包可以升级。请执行 ‘apt list –upgradable’ 来查看它们。</p>
<p>cby@cby-Inspiron-7577:~$ ubuntu-drivers devices<br>WARNING:root:_pkg_get_support nvidia-driver-390: package has invalid Support Legacyheader, cannot determine support level<br>&#x3D;&#x3D; &#x2F;sys&#x2F;devices&#x2F;pci0000:00&#x2F;0000:00:01.0&#x2F;0000:01:00.0 &#x3D;&#x3D;<br>modalias : pci:v000010DEd00001C8Csv00001028sd000007FAbc03sc02i00<br>vendor   : NVIDIA Corporation<br>model    : GP107M [GeForce GTX 1050 Ti Mobile]<br>manual_install: True<br>driver   : nvidia-driver-460 - distro non-free recommended<br>driver   : nvidia-driver-450-server - distro non-free<br>driver   : nvidia-driver-390 - distro non-free<br>driver   : nvidia-driver-465 - distro non-free<br>driver   : nvidia-driver-460-server - distro non-free<br>driver   : nvidia-driver-418-server - distro non-free<br>driver   : xserver-xorg-video-nouveau - distro free builtin</p>
<p>cby@cby-Inspiron-7577:~$ sudo apt install nvidia-driver-465<br>…略…</p>
<p>&#96;&#96;&#96;shell</p>
<p>   </p>
<p>第三步，查看显卡信息  </p>
<p>&#96;&#96;&#96;shell<br>cby@cby-Inspiron-7577:~$ nvidia-smi<br>Sun Jun  6 21:58:45 2021<br>+—————————————————————————–+<br>| NVIDIA-SMI 465.27       Driver Version: 465.27       CUDA Version: 11.3     |<br>|——————————-+———————-+———————-+<br>| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>| Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. |<br>|                               |                      |               MIG M. |<br>|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|<br>|   0  NVIDIA GeForce …  Off  | 00000000:01:00.0 Off |                  N&#x2F;A |<br>| N&#x2F;A   59C    P3    N&#x2F;A &#x2F;  N&#x2F;A |    919MiB &#x2F;  4042MiB |      6%      Default |<br>|                               |                      |                  N&#x2F;A |<br>+——————————-+———————-+———————-+</p>
<p>+—————————————————————————–+<br>| Processes:                                                                  |<br>|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |<br>|        ID   ID                                                   Usage      |<br>|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|<br>|    0   N&#x2F;A  N&#x2F;A      1976      G   &#x2F;usr&#x2F;lib&#x2F;xorg&#x2F;Xorg                351MiB |<br>|    0   N&#x2F;A  N&#x2F;A      2620      G   &#x2F;usr&#x2F;bin&#x2F;gnome-shell              213MiB |<br>|    0   N&#x2F;A  N&#x2F;A      4020      G   gnome-control-center                1MiB |<br>|    0   N&#x2F;A  N&#x2F;A      4258      G   …AAAAAAAAA&#x3D; –shared-files      349MiB |<br>|    0   N&#x2F;A  N&#x2F;A      6333      G   &#x2F;usr&#x2F;bin&#x2F;nvidia-settings            1MiB |<br>+—————————————————————————–+<br>cby@cby-Inspiron-7577:~$</p>
<p>&#96;&#96;&#96;shell</p>
<p>第四步，安装 CUDA Toolkit Archive</p>
<p>&#96;&#96;&#96;shell<br><a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p>
<p>&#96;&#96;&#96;shell</p>
<p>在如上官网中下载安装CUDA  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5ed331476af6408489e1da55e83924ad~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>第五步，根据官方教程进行安装  </p>
<p>&#96;&#96;&#96;shell<br>cby@cby-Inspiron-7577:~$ wget <a href="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin">https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin</a><br>–2021-06-06 21:59:36–  <a href="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin">https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin</a><br>正在解析主机 developer.download.nvidia.com (developer.download.nvidia.com)… 192.254.94.202, 45.43.32.210, 45.43.32.211, …<br>正在连接 developer.download.nvidia.com (developer.download.nvidia.com)|192.254.94.202|:443… 已连接。<br>已发出 HTTP 请求，正在等待回应… 301 Moved Permanently<br>位置：<a href="https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin">https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin</a> [跟随至新的 URL]<br>–2021-06-06 21:59:37–  <a href="https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin">https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin</a><br>正在解析主机 developer.download.nvidia.cn (developer.download.nvidia.cn)… 124.132.138.66, 124.132.138.73, 124.132.138.69<br>正在连接 developer.download.nvidia.cn (developer.download.nvidia.cn)|124.132.138.66|:443… 已连接。<br>已发出 HTTP 请求，正在等待回应… 200 OK<br>长度：190 [application&#x2F;octet-stream]<br>正在保存至: ‘cuda-ubuntu2004.pin’</p>
<p>cuda-ubuntu2004.pin 100%[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;]     190  –.-KB&#x2F;s    用时 0s    </p>
<p>2021-06-06 21:59:37 (26.1 MB&#x2F;s) - 已保存 ‘cuda-ubuntu2004.pin’ [190&#x2F;190])</p>
<p>cby@cby-Inspiron-7577:<del>$ sudo mv cuda-ubuntu2004.pin &#x2F;etc&#x2F;apt&#x2F;preferences.d&#x2F;cuda-repository-pin-600<br>cby@cby-Inspiron-7577:</del>$ wget <a href="https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb">https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb</a><br>–2021-06-06 21:59:48–  <a href="https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb">https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb</a><br>正在解析主机 developer.download.nvidia.com (developer.download.nvidia.com)… 45.43.32.210, 192.254.94.203, 45.43.32.211, …<br>正在连接 developer.download.nvidia.com (developer.download.nvidia.com)|45.43.32.210|:443… 已连接。<br>已发出 HTTP 请求，正在等待回应… 301 Moved Permanently<br>位置：<a href="https://developer.download.nvidia.cn/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb">https://developer.download.nvidia.cn/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb</a> [跟随至新的 URL]<br>–2021-06-06 21:59:48–  <a href="https://developer.download.nvidia.cn/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb">https://developer.download.nvidia.cn/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb</a><br>正在解析主机 developer.download.nvidia.cn (developer.download.nvidia.cn)… 124.132.138.66, 124.132.138.73, 124.132.138.69<br>正在连接 developer.download.nvidia.cn (developer.download.nvidia.cn)|124.132.138.66|:443… 已连接。<br>已发出 HTTP 请求，正在等待回应… 200 OK<br>长度：2374574280 (2.2G) [application&#x2F;x-deb]<br>正在保存至: ‘cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb’</p>
<p>cuda-repo-ubuntu200 100%[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;]   2.21G  44.0MB&#x2F;s    用时 51s   </p>
<p>2021-06-06 22:00:40 (44.3 MB&#x2F;s) - 已保存 ‘cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb’ [2374574280&#x2F;2374574280])</p>
<p>cby@cby-Inspiron-7577:<del>$ sudo dpkg -i cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb<br>正在选中未选择的软件包 cuda-repo-ubuntu2004-11-3-local。<br>(正在读取数据库 … 系统当前共安装有 209119 个文件和目录。)<br>准备解压 cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb  …<br>正在解压 cuda-repo-ubuntu2004-11-3-local (11.3.1-465.19.01-1) …<br>正在设置 cuda-repo-ubuntu2004-11-3-local (11.3.1-465.19.01-1) …<br>cby@cby-Inspiron-7577:</del>$ sudo apt-key add &#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local&#x2F;7fa2af80.pub<br>Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).<br>OK<br>cby@cby-Inspiron-7577:<del>$ sudo apt-get update<br>获取:1 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  InRelease<br>忽略:1 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  InRelease<br>获取:2 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  Release [564 B]<br>获取:2 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  Release [564 B]<br>获取:3 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  Release.gpg [836 B]<br>获取:3 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  Release.gpg [836 B]<br>获取:4 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  Packages [30.4 kB]<br>命中:5 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute InRelease<br>获取:7 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute-updates InRelease [109 kB]<br>命中:8 <a href="http://dl.google.com/linux/chrome/deb">http://dl.google.com/linux/chrome/deb</a> stable InRelease<br>命中:9 <a href="http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu">http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu</a> hirsute InRelease<br>命中:10 <a href="http://security.ubuntu.com/ubuntu">http://security.ubuntu.com/ubuntu</a> hirsute-security InRelease<br>忽略:6 <a href="https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64">https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64</a>  InRelease<br>命中:11 <a href="https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64">https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1604/x86_64</a>  Release<br>命中:13 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute-backports InRelease<br>已下载 109 kB，耗时 2秒 (52.6 kB&#x2F;s)<br>正在读取软件包列表… 完成<br>cby@cby-Inspiron-7577:</del>$<br>cby@cby-Inspiron-7577:<del>$<br>cby@cby-Inspiron-7577:</del>$ sudo apt-get -y install cuda<br>正在读取软件包列表… 完成<br>正在分析软件包的依赖关系树… 完成<br>正在读取状态信息… 完成<br>下列软件包是自动安装的并且现在不需要了：<br>  libaccinj64-11.2 libcub-dev libcublas11 libcublaslt11 libcudart11.0<br>  libcufft10 libcufftw10 libcuinj64-11.2 libcupti-dev libcupti-doc<br>  libcupti11.2 libcurand10 libcusolver11 libcusolvermg11 libcusparse11<br>  libegl-dev libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglvnd-dev<br>  libglx-dev libnppc11 libnppial11 libnppicc11 libnppidei11 libnppif11<br>  libnppig11 libnppim11 libnppist11 libnppisu11 libnppitc11 libnpps11<br>  libnvblas11 libnvjpeg11 libnvrtc11.2 libnvtoolsext1 libnvvm4 libopengl-dev<br>  libopengl0 libpthread-stubs0-dev libthrust-dev libvdpau-dev libx11-dev<br>  libxau-dev libxcb1-dev libxdmcp-dev node-html5shiv nsight-compute<br>  nsight-compute-target nsight-systems nsight-systems-target nvidia-cuda-gdb<br>  nvidia-cuda-toolkit-doc nvidia-opencl-dev nvidia-profiler<br>  nvidia-visual-profiler ocl-icd-opencl-dev opencl-c-headers<br>  opencl-clhpp-headers x11proto-dev xorg-sgml-doctools xtrans-dev<br>使用’sudo apt autoremove’来卸载它(它们)。<br>将会同时安装下列软件：<br>  cuda-11-3 cuda-command-line-tools-11-3 cuda-compiler-11-3 cuda-cudart-11-3<br>  cuda-cudart-dev-11-3 cuda-cuobjdump-11-3 cuda-cupti-11-3<br>  cuda-cupti-dev-11-3 cuda-cuxxfilt-11-3 cuda-demo-suite-11-3<br>  cuda-documentation-11-3 cuda-driver-dev-11-3 cuda-drivers cuda-drivers-465<br>  cuda-gdb-11-3 cuda-libraries-11-3 cuda-libraries-dev-11-3<br>  cuda-memcheck-11-3 cuda-nsight-11-3 cuda-nsight-compute-11-3<br>  cuda-nsight-systems-11-3 cuda-nvcc-11-3 cuda-nvdisasm-11-3<br>  cuda-nvml-dev-11-3 cuda-nvprof-11-3 cuda-nvprune-11-3 cuda-nvrtc-11-3<br>  cuda-nvrtc-dev-11-3 cuda-nvtx-11-3 cuda-nvvp-11-3 cuda-runtime-11-3<br>  cuda-samples-11-3 cuda-sanitizer-11-3 cuda-thrust-11-3 cuda-toolkit-11-3<br>  cuda-toolkit-11-3-config-common cuda-toolkit-11-config-common<br>  cuda-toolkit-config-common cuda-tools-11-3 cuda-visual-tools-11-3<br>  default-jre default-jre-headless libcublas-11-3 libcublas-dev-11-3<br>  libcufft-11-3 libcufft-dev-11-3 libcurand-11-3 libcurand-dev-11-3<br>  libcusolver-11-3 libcusolver-dev-11-3 libcusparse-11-3 libcusparse-dev-11-3<br>  libnpp-11-3 libnpp-dev-11-3 libnvjpeg-11-3 libnvjpeg-dev-11-3<br>  nsight-compute-2021.1.1 nsight-systems-2021.1.3 nvidia-modprobe<br>  nvidia-settings openjdk-11-jre openjdk-11-jre-headless<br>建议安装：<br>  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei<br>  | fonts-wqy-zenhei<br>下列【新】软件包将被安装：<br>  cuda cuda-11-3 cuda-command-line-tools-11-3 cuda-compiler-11-3<br>  cuda-cudart-11-3 cuda-cudart-dev-11-3 cuda-cuobjdump-11-3 cuda-cupti-11-3<br>  cuda-cupti-dev-11-3 cuda-cuxxfilt-11-3 cuda-demo-suite-11-3<br>  cuda-documentation-11-3 cuda-driver-dev-11-3 cuda-drivers cuda-drivers-465<br>  cuda-gdb-11-3 cuda-libraries-11-3 cuda-libraries-dev-11-3<br>  cuda-memcheck-11-3 cuda-nsight-11-3 cuda-nsight-compute-11-3<br>  cuda-nsight-systems-11-3 cuda-nvcc-11-3 cuda-nvdisasm-11-3<br>  cuda-nvml-dev-11-3 cuda-nvprof-11-3 cuda-nvprune-11-3 cuda-nvrtc-11-3<br>  cuda-nvrtc-dev-11-3 cuda-nvtx-11-3 cuda-nvvp-11-3 cuda-runtime-11-3<br>  cuda-samples-11-3 cuda-sanitizer-11-3 cuda-thrust-11-3 cuda-toolkit-11-3<br>  cuda-toolkit-11-3-config-common cuda-toolkit-11-config-common<br>  cuda-toolkit-config-common cuda-tools-11-3 cuda-visual-tools-11-3<br>  default-jre default-jre-headless libcublas-11-3 libcublas-dev-11-3<br>  libcufft-11-3 libcufft-dev-11-3 libcurand-11-3 libcurand-dev-11-3<br>  libcusolver-11-3 libcusolver-dev-11-3 libcusparse-11-3 libcusparse-dev-11-3<br>  libnpp-11-3 libnpp-dev-11-3 libnvjpeg-11-3 libnvjpeg-dev-11-3<br>  nsight-compute-2021.1.1 nsight-systems-2021.1.3 nvidia-modprobe<br>  openjdk-11-jre openjdk-11-jre-headless<br>下列软件包将被升级：<br>  nvidia-settings<br>升级了 1 个软件包，新安装了 62 个软件包，要卸载 0 个软件包，有 5 个软件包未被升级。<br>需要下载 37.4 MB&#x2F;2,162 MB 的归档。<br>解压缩后会消耗 4,934 MB 的额外空间。<br>获取:1 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-toolkit-config-common 11.3.109-1 [16.1 kB]<br>获取:2 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-toolkit-11-config-common 11.3.109-1 [16.1 kB]<br>获取:3 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-toolkit-11-3-config-common 11.3.109-1 [16.1 kB]<br>获取:4 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-cudart-11-3 11.3.109-1 [157 kB]<br>获取:5 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvrtc-11-3 11.3.109-1 [26.1 MB]<br>获取:6 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute-updates&#x2F;main amd64 openjdk-11-jre-headless amd64 11.0.11+9-0ubuntu2 [37.2 MB]<br>获取:7 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcublas-11-3 11.5.1.109-1 [168 MB]<br>获取:8 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcufft-11-3 10.4.2.109-1 [108 MB]<br>获取:9 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcurand-11-3 10.2.4.109-1 [39.4 MB]<br>获取:10 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcusolver-11-3 11.1.2.109-1 [85.5 MB]<br>获取:11 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcusparse-11-3 11.6.0.109-1 [104 MB]<br>获取:12 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libnpp-11-3 11.3.3.95-1 [75.1 MB]<br>获取:13 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libnvjpeg-11-3 11.5.0.109-1 [1,742 kB]<br>获取:14 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-libraries-11-3 11.3.1-1 [2,498 B]<br>获取:15 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  nvidia-modprobe 465.19.01-0ubuntu1 [19.9 kB]<br>获取:16 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  nvidia-settings 465.19.01-0ubuntu1 [928 kB]<br>获取:17 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-drivers-465 465.19.01-1 [2,628 B]<br>获取:18 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-drivers 465.19.01-1 [2,504 B]<br>获取:19 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-runtime-11-3 11.3.1-1 [2,424 B]<br>获取:20 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-cuobjdump-11-3 11.3.58-1 [112 kB]<br>获取:21 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-cuxxfilt-11-3 11.3.58-1 [44.1 kB]<br>获取:22 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-thrust-11-3 11.3.109-1 [981 kB]<br>获取:23 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-driver-dev-11-3 11.3.109-1 [26.2 kB]<br>获取:24 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-cudart-dev-11-3 11.3.109-1 [737 kB]<br>获取:25 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvcc-11-3 11.3.109-1 [46.5 MB]<br>获取:26 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvprune-11-3 11.3.58-1 [54.9 kB]<br>获取:27 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-compiler-11-3 11.3.1-1 [2,430 B]<br>获取:28 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvrtc-dev-11-3 11.3.109-1 [23.4 kB]<br>获取:29 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute&#x2F;main amd64 default-jre-headless amd64 2:1.11-72 [3,192 B]<br>获取:30 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute-updates&#x2F;main amd64 openjdk-11-jre amd64 11.0.11+9-0ubuntu2 [177 kB]<br>获取:31 <a href="http://cn.archive.ubuntu.com/ubuntu">http://cn.archive.ubuntu.com/ubuntu</a> hirsute&#x2F;main amd64 default-jre amd64 2:1.11-72 [1,084 B]<br>获取:32 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcublas-dev-11-3 11.5.1.109-1 [171 MB]<br>获取:33 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcufft-dev-11-3 10.4.2.109-1 [181 MB]<br>获取:34 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcurand-dev-11-3 10.2.4.109-1 [39.9 MB]<br>获取:35 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcusolver-dev-11-3 11.1.2.109-1 [22.2 MB]<br>获取:36 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libcusparse-dev-11-3 11.6.0.109-1 [104 MB]<br>获取:37 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libnpp-dev-11-3 11.3.3.95-1 [71.7 MB]<br>获取:38 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  libnvjpeg-dev-11-3 11.5.0.109-1 [1,435 kB]<br>获取:39 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-libraries-dev-11-3 11.3.1-1 [2,526 B]<br>获取:40 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-cupti-11-3 11.3.111-1 [11.7 MB]<br>获取:41 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-cupti-dev-11-3 11.3.111-1 [2,404 kB]<br>获取:42 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvdisasm-11-3 11.3.58-1 [32.9 MB]<br>获取:43 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-gdb-11-3 11.3.109-1 [3,622 kB]<br>获取:44 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-memcheck-11-3 11.3.109-1 [145 kB]<br>获取:45 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvprof-11-3 11.3.111-1 [1,925 kB]<br>获取:46 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvtx-11-3 11.3.109-1 [51.1 kB]<br>获取:47 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-sanitizer-11-3 11.3.111-1 [7,543 kB]<br>获取:48 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-command-line-tools-11-3 11.3.1-1 [2,478 B]<br>获取:49 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  nsight-compute-2021.1.1 2021.1.1.5-1 [273 MB]<br>获取:50 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nsight-compute-11-3 11.3.1-1 [3,704 B]<br>获取:51 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  nsight-systems-2021.1.3 2021.1.3.14-b695ea9 [248 MB]<br>获取:52 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nsight-systems-11-3 11.3.1-1 [3,296 B]<br>获取:53 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nsight-11-3 11.3.109-1 [119 MB]<br>获取:54 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvml-dev-11-3 11.3.58-1 [73.3 kB]<br>获取:55 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-nvvp-11-3 11.3.111-1 [114 MB]<br>获取:56 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-visual-tools-11-3 11.3.1-1 [2,866 B]<br>获取:57 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-tools-11-3 11.3.1-1 [2,378 B]<br>获取:58 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-samples-11-3 11.3.58-1 [59.2 MB]<br>获取:59 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-documentation-11-3 11.3.111-1 [48.1 kB]<br>获取:60 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-toolkit-11-3 11.3.1-1 [3,300 B]<br>获取:61 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-demo-suite-11-3 11.3.58-1 [3,978 kB]<br>获取:62 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda-11-3 11.3.1-1 [2,450 B]<br>获取:63 file:&#x2F;var&#x2F;cuda-repo-ubuntu2004-11-3-local  cuda 11.3.1-1 [2,396 B]<br>已下载 37.4 MB，耗时 15秒 (2,527 kB&#x2F;s)<br>Requesting to save current system state<br>Successfully saved as “autozsys_el84cc”<br>正在从软件包中解出模板：100%<br>正在选中未选择的软件包 cuda-toolkit-config-common。<br>(正在读取数据库 … 系统当前共安装有 209232 个文件和目录。)<br>准备解压 …&#x2F;00-cuda-toolkit-config-common_11.3.109-1_all.deb  …<br>正在解压 cuda-toolkit-config-common (11.3.109-1) …<br>正在选中未选择的软件包 cuda-toolkit-11-config-common。<br>准备解压 …&#x2F;01-cuda-toolkit-11-config-common_11.3.109-1_all.deb  …<br>正在解压 cuda-toolkit-11-config-common (11.3.109-1) …<br>正在选中未选择的软件包 cuda-toolkit-11-3-config-common。<br>准备解压 …&#x2F;02-cuda-toolkit-11-3-config-common_11.3.109-1_all.deb  …<br>正在解压 cuda-toolkit-11-3-config-common (11.3.109-1) …<br>正在选中未选择的软件包 cuda-cudart-11-3。<br>准备解压 …&#x2F;03-cuda-cudart-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-cudart-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-nvrtc-11-3。<br>准备解压 …&#x2F;04-cuda-nvrtc-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-nvrtc-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 libcublas-11-3。<br>准备解压 …&#x2F;05-libcublas-11-3_11.5.1.109-1_amd64.deb  …<br>正在解压 libcublas-11-3 (11.5.1.109-1) …<br>正在选中未选择的软件包 libcufft-11-3。<br>准备解压 …&#x2F;06-libcufft-11-3_10.4.2.109-1_amd64.deb  …<br>正在解压 libcufft-11-3 (10.4.2.109-1) …<br>正在选中未选择的软件包 libcurand-11-3。<br>准备解压 …&#x2F;07-libcurand-11-3_10.2.4.109-1_amd64.deb  …<br>正在解压 libcurand-11-3 (10.2.4.109-1) …<br>正在选中未选择的软件包 libcusolver-11-3。<br>准备解压 …&#x2F;08-libcusolver-11-3_11.1.2.109-1_amd64.deb  …<br>正在解压 libcusolver-11-3 (11.1.2.109-1) …<br>正在选中未选择的软件包 libcusparse-11-3。<br>准备解压 …&#x2F;09-libcusparse-11-3_11.6.0.109-1_amd64.deb  …<br>正在解压 libcusparse-11-3 (11.6.0.109-1) …<br>正在选中未选择的软件包 libnpp-11-3。<br>准备解压 …&#x2F;10-libnpp-11-3_11.3.3.95-1_amd64.deb  …<br>正在解压 libnpp-11-3 (11.3.3.95-1) …<br>正在选中未选择的软件包 libnvjpeg-11-3。<br>准备解压 …&#x2F;11-libnvjpeg-11-3_11.5.0.109-1_amd64.deb  …<br>正在解压 libnvjpeg-11-3 (11.5.0.109-1) …<br>正在选中未选择的软件包 cuda-libraries-11-3。<br>准备解压 …&#x2F;12-cuda-libraries-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-libraries-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 nvidia-modprobe。<br>准备解压 …&#x2F;13-nvidia-modprobe_465.19.01-0ubuntu1_amd64.deb  …<br>正在解压 nvidia-modprobe (465.19.01-0ubuntu1) …<br>准备解压 …&#x2F;14-nvidia-settings_465.19.01-0ubuntu1_amd64.deb  …<br>正在解压 nvidia-settings (465.19.01-0ubuntu1) 并覆盖 (460.56-0ubuntu2) …<br>正在选中未选择的软件包 cuda-drivers-465。<br>准备解压 …&#x2F;15-cuda-drivers-465_465.19.01-1_amd64.deb  …<br>正在解压 cuda-drivers-465 (465.19.01-1) …<br>正在选中未选择的软件包 cuda-drivers。<br>准备解压 …&#x2F;16-cuda-drivers_465.19.01-1_amd64.deb  …<br>正在解压 cuda-drivers (465.19.01-1) …<br>正在选中未选择的软件包 cuda-runtime-11-3。<br>准备解压 …&#x2F;17-cuda-runtime-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-runtime-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 cuda-cuobjdump-11-3。<br>准备解压 …&#x2F;18-cuda-cuobjdump-11-3_11.3.58-1_amd64.deb  …<br>正在解压 cuda-cuobjdump-11-3 (11.3.58-1) …<br>正在选中未选择的软件包 cuda-cuxxfilt-11-3。<br>准备解压 …&#x2F;19-cuda-cuxxfilt-11-3_11.3.58-1_amd64.deb  …<br>正在解压 cuda-cuxxfilt-11-3 (11.3.58-1) …<br>正在选中未选择的软件包 cuda-thrust-11-3。<br>准备解压 …&#x2F;20-cuda-thrust-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-thrust-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-driver-dev-11-3。<br>准备解压 …&#x2F;21-cuda-driver-dev-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-driver-dev-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-cudart-dev-11-3。<br>准备解压 …&#x2F;22-cuda-cudart-dev-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-cudart-dev-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-nvcc-11-3。<br>准备解压 …&#x2F;23-cuda-nvcc-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-nvcc-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-nvprune-11-3。<br>准备解压 …&#x2F;24-cuda-nvprune-11-3_11.3.58-1_amd64.deb  …<br>正在解压 cuda-nvprune-11-3 (11.3.58-1) …<br>正在选中未选择的软件包 cuda-compiler-11-3。<br>准备解压 …&#x2F;25-cuda-compiler-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-compiler-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 cuda-nvrtc-dev-11-3。<br>准备解压 …&#x2F;26-cuda-nvrtc-dev-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-nvrtc-dev-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 libcublas-dev-11-3。<br>准备解压 …&#x2F;27-libcublas-dev-11-3_11.5.1.109-1_amd64.deb  …<br>正在解压 libcublas-dev-11-3 (11.5.1.109-1) …<br>正在选中未选择的软件包 libcufft-dev-11-3。<br>准备解压 …&#x2F;28-libcufft-dev-11-3_10.4.2.109-1_amd64.deb  …<br>正在解压 libcufft-dev-11-3 (10.4.2.109-1) …<br>正在选中未选择的软件包 libcurand-dev-11-3。<br>准备解压 …&#x2F;29-libcurand-dev-11-3_10.2.4.109-1_amd64.deb  …<br>正在解压 libcurand-dev-11-3 (10.2.4.109-1) …<br>正在选中未选择的软件包 libcusolver-dev-11-3。<br>准备解压 …&#x2F;30-libcusolver-dev-11-3_11.1.2.109-1_amd64.deb  …<br>正在解压 libcusolver-dev-11-3 (11.1.2.109-1) …<br>正在选中未选择的软件包 libcusparse-dev-11-3。<br>准备解压 …&#x2F;31-libcusparse-dev-11-3_11.6.0.109-1_amd64.deb  …<br>正在解压 libcusparse-dev-11-3 (11.6.0.109-1) …<br>正在选中未选择的软件包 libnpp-dev-11-3。<br>准备解压 …&#x2F;32-libnpp-dev-11-3_11.3.3.95-1_amd64.deb  …<br>正在解压 libnpp-dev-11-3 (11.3.3.95-1) …<br>正在选中未选择的软件包 libnvjpeg-dev-11-3。<br>准备解压 …&#x2F;33-libnvjpeg-dev-11-3_11.5.0.109-1_amd64.deb  …<br>正在解压 libnvjpeg-dev-11-3 (11.5.0.109-1) …<br>正在选中未选择的软件包 cuda-libraries-dev-11-3。<br>准备解压 …&#x2F;34-cuda-libraries-dev-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-libraries-dev-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 cuda-cupti-11-3。<br>准备解压 …&#x2F;35-cuda-cupti-11-3_11.3.111-1_amd64.deb  …<br>正在解压 cuda-cupti-11-3 (11.3.111-1) …<br>正在选中未选择的软件包 cuda-cupti-dev-11-3。<br>准备解压 …&#x2F;36-cuda-cupti-dev-11-3_11.3.111-1_amd64.deb  …<br>正在解压 cuda-cupti-dev-11-3 (11.3.111-1) …<br>正在选中未选择的软件包 cuda-nvdisasm-11-3。<br>准备解压 …&#x2F;37-cuda-nvdisasm-11-3_11.3.58-1_amd64.deb  …<br>正在解压 cuda-nvdisasm-11-3 (11.3.58-1) …<br>正在选中未选择的软件包 cuda-gdb-11-3。<br>准备解压 …&#x2F;38-cuda-gdb-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-gdb-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-memcheck-11-3。<br>准备解压 …&#x2F;39-cuda-memcheck-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-memcheck-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-nvprof-11-3。<br>准备解压 …&#x2F;40-cuda-nvprof-11-3_11.3.111-1_amd64.deb  …<br>正在解压 cuda-nvprof-11-3 (11.3.111-1) …<br>正在选中未选择的软件包 cuda-nvtx-11-3。<br>准备解压 …&#x2F;41-cuda-nvtx-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-nvtx-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-sanitizer-11-3。<br>准备解压 …&#x2F;42-cuda-sanitizer-11-3_11.3.111-1_amd64.deb  …<br>正在解压 cuda-sanitizer-11-3 (11.3.111-1) …<br>正在选中未选择的软件包 cuda-command-line-tools-11-3。<br>准备解压 …&#x2F;43-cuda-command-line-tools-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-command-line-tools-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 nsight-compute-2021.1.1。<br>准备解压 …&#x2F;44-nsight-compute-2021.1.1_2021.1.1.5-1_amd64.deb  …<br>正在解压 nsight-compute-2021.1.1 (2021.1.1.5-1) …<br>正在选中未选择的软件包 cuda-nsight-compute-11-3。<br>准备解压 …&#x2F;45-cuda-nsight-compute-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-nsight-compute-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 nsight-systems-2021.1.3。<br>准备解压 …&#x2F;46-nsight-systems-2021.1.3_2021.1.3.14-1_amd64.deb  …<br>正在解压 nsight-systems-2021.1.3 (2021.1.3.14-b695ea9) …<br>正在选中未选择的软件包 cuda-nsight-systems-11-3。<br>准备解压 …&#x2F;47-cuda-nsight-systems-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-nsight-systems-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 openjdk-11-jre-headless:amd64。<br>准备解压 …&#x2F;48-openjdk-11-jre-headless_11.0.11+9-0ubuntu2_amd64.deb  …<br>正在解压 openjdk-11-jre-headless:amd64 (11.0.11+9-0ubuntu2) …<br>正在选中未选择的软件包 default-jre-headless。<br>准备解压 …&#x2F;49-default-jre-headless_2%3a1.11-72_amd64.deb  …<br>正在解压 default-jre-headless (2:1.11-72) …<br>正在选中未选择的软件包 openjdk-11-jre:amd64。<br>准备解压 …&#x2F;50-openjdk-11-jre_11.0.11+9-0ubuntu2_amd64.deb  …<br>正在解压 openjdk-11-jre:amd64 (11.0.11+9-0ubuntu2) …<br>正在选中未选择的软件包 default-jre。<br>准备解压 …&#x2F;51-default-jre_2%3a1.11-72_amd64.deb  …<br>正在解压 default-jre (2:1.11-72) …<br>正在选中未选择的软件包 cuda-nsight-11-3。<br>准备解压 …&#x2F;52-cuda-nsight-11-3_11.3.109-1_amd64.deb  …<br>正在解压 cuda-nsight-11-3 (11.3.109-1) …<br>正在选中未选择的软件包 cuda-nvml-dev-11-3。<br>准备解压 …&#x2F;53-cuda-nvml-dev-11-3_11.3.58-1_amd64.deb  …<br>正在解压 cuda-nvml-dev-11-3 (11.3.58-1) …<br>正在选中未选择的软件包 cuda-nvvp-11-3。<br>准备解压 …&#x2F;54-cuda-nvvp-11-3_11.3.111-1_amd64.deb  …<br>正在解压 cuda-nvvp-11-3 (11.3.111-1) …<br>正在选中未选择的软件包 cuda-visual-tools-11-3。<br>准备解压 …&#x2F;55-cuda-visual-tools-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-visual-tools-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 cuda-tools-11-3。<br>准备解压 …&#x2F;56-cuda-tools-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-tools-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 cuda-samples-11-3。<br>准备解压 …&#x2F;57-cuda-samples-11-3_11.3.58-1_amd64.deb  …<br>正在解压 cuda-samples-11-3 (11.3.58-1) …<br>正在选中未选择的软件包 cuda-documentation-11-3。<br>准备解压 …&#x2F;58-cuda-documentation-11-3_11.3.111-1_amd64.deb  …<br>正在解压 cuda-documentation-11-3 (11.3.111-1) …<br>正在选中未选择的软件包 cuda-toolkit-11-3。<br>准备解压 …&#x2F;59-cuda-toolkit-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-toolkit-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 cuda-demo-suite-11-3。<br>准备解压 …&#x2F;60-cuda-demo-suite-11-3_11.3.58-1_amd64.deb  …<br>正在解压 cuda-demo-suite-11-3 (11.3.58-1) …<br>正在选中未选择的软件包 cuda-11-3。<br>准备解压 …&#x2F;61-cuda-11-3_11.3.1-1_amd64.deb  …<br>正在解压 cuda-11-3 (11.3.1-1) …<br>正在选中未选择的软件包 cuda。<br>准备解压 …&#x2F;62-cuda_11.3.1-1_amd64.deb  …<br>正在解压 cuda (11.3.1-1) …<br>正在设置 cuda-toolkit-config-common (11.3.109-1) …<br>正在设置 cuda-cuxxfilt-11-3 (11.3.58-1) …<br>正在设置 cuda-toolkit-11-3-config-common (11.3.109-1) …<br>Setting alternatives<br>update-alternatives: 使用 &#x2F;usr&#x2F;local&#x2F;cuda-11.3 来在自动模式中提供 &#x2F;usr&#x2F;local&#x2F;cuda (cuda)<br>update-alternatives: 使用 &#x2F;usr&#x2F;local&#x2F;cuda-11.3 来在自动模式中提供 &#x2F;usr&#x2F;local&#x2F;cuda-11 (cuda-11)<br>正在设置 cuda-toolkit-11-config-common (11.3.109-1) …<br>正在设置 cuda-nvtx-11-3 (11.3.109-1) …<br>正在设置 cuda-memcheck-11-3 (11.3.109-1) …<br>正在设置 cuda-nvprune-11-3 (11.3.58-1) …<br>正在设置 cuda-driver-dev-11-3 (11.3.109-1) …<br>正在设置 openjdk-11-jre-headless:amd64 (11.0.11+9-0ubuntu2) …<br>update-alternatives: 使用 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64&#x2F;bin&#x2F;java 来在自动模式中提供 &#x2F;usr&#x2F;bin&#x2F;java (java)<br>update-alternatives: 使用 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64&#x2F;bin&#x2F;jjs 来在自动模式中提供 &#x2F;usr&#x2F;bin&#x2F;jjs (jjs)<br>update-alternatives: 使用 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64&#x2F;bin&#x2F;keytool 来在自动模式中提供 &#x2F;usr&#x2F;bin&#x2F;keytool (keytool)<br>update-alternatives: 使用 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64&#x2F;bin&#x2F;rmid 来在自动模式中提供 &#x2F;usr&#x2F;bin&#x2F;rmid (rmid)<br>update-alternatives: 使用 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64&#x2F;bin&#x2F;rmiregistry 来在自动模式中提供 &#x2F;usr&#x2F;bin&#x2F;rmiregistry (rmiregistry)<br>update-alternatives: 使用 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64&#x2F;bin&#x2F;pack200 来在自动模式中提供 &#x2F;usr&#x2F;bin&#x2F;pack200 (pack200)<br>update-alternatives: 使用 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64&#x2F;bin&#x2F;unpack200 来在自动模式中提供 &#x2F;usr&#x2F;bin&#x2F;unpack200 (unpack200)<br>update-alternatives: 使用 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-11-openjdk-amd64&#x2F;lib&#x2F;jexec 来在自动模式中提供 &#x2F;usr&#x2F;bin&#x2F;jexec (jexec)<br>正在设置 openjdk-11-jre:amd64 (11.0.11+9-0ubuntu2) …<br>正在设置 libnvjpeg-11-3 (11.5.0.109-1) …<br>正在设置 cuda-nvprof-11-3 (11.3.111-1) …<br>正在设置 nvidia-modprobe (465.19.01-0ubuntu1) …<br>正在设置 cuda-thrust-11-3 (11.3.109-1) …<br>正在设置 cuda-nvml-dev-11-3 (11.3.58-1) …<br>正在设置 libnvjpeg-dev-11-3 (11.5.0.109-1) …<br>正在设置 cuda-cudart-11-3 (11.3.109-1) …<br>正在设置 cuda-cudart-dev-11-3 (11.3.109-1) …<br>正在设置 nsight-compute-2021.1.1 (2021.1.1.5-1) …<br>正在设置 libnpp-11-3 (11.3.3.95-1) …<br>正在设置 libcusparse-11-3 (11.6.0.109-1) …<br>正在设置 nsight-systems-2021.1.3 (2021.1.3.14-b695ea9) …<br>update-alternatives: 使用 &#x2F;opt&#x2F;nvidia&#x2F;nsight-systems&#x2F;2021.1.3&#x2F;target-linux-x64&#x2F;nsys 来在自动模式中提供 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;nsys (nsys)<br>update-alternatives: 错误: alternative path &#x2F;opt&#x2F;nvidia&#x2F;nsight-systems&#x2F;2021.1.3&#x2F;host-linux-x64&#x2F;nsight-sys doesn’t exist<br>update-alternatives: 错误: 无 nsight-sys 的候选项<br>update-alternatives: 使用 &#x2F;opt&#x2F;nvidia&#x2F;nsight-systems&#x2F;2021.1.3&#x2F;host-linux-x64&#x2F;nsys-ui 来在自动模式中提供 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;nsys-ui (nsys-ui)<br>正在设置 cuda-nvdisasm-11-3 (11.3.58-1) …<br>正在设置 nvidia-settings (465.19.01-0ubuntu1) …<br>正在设置 libcurand-11-3 (10.2.4.109-1) …<br>正在设置 cuda-cuobjdump-11-3 (11.3.58-1) …<br>正在设置 libcufft-11-3 (10.4.2.109-1) …<br>正在设置 libcusparse-dev-11-3 (11.6.0.109-1) …<br>正在设置 cuda-nvrtc-11-3 (11.3.109-1) …<br>正在设置 cuda-sanitizer-11-3 (11.3.111-1) …<br>正在设置 libcusolver-11-3 (11.1.2.109-1) …<br>正在设置 libcublas-11-3 (11.5.1.109-1) …<br>正在设置 cuda-nsight-systems-11-3 (11.3.1-1) …<br>正在设置 cuda-nvrtc-dev-11-3 (11.3.109-1) …<br>正在设置 libcurand-dev-11-3 (10.2.4.109-1) …<br>正在设置 default-jre-headless (2:1.11-72) …<br>正在设置 libcublas-dev-11-3 (11.5.1.109-1) …<br>正在设置 cuda-nsight-compute-11-3 (11.3.1-1) …<br>正在设置 cuda-nvcc-11-3 (11.3.109-1) …<br>正在设置 cuda-drivers-465 (465.19.01-1) …<br>正在设置 libnpp-dev-11-3 (11.3.3.95-1) …<br>正在设置 cuda-libraries-11-3 (11.3.1-1) …<br>正在设置 cuda-gdb-11-3 (11.3.109-1) …<br>正在设置 default-jre (2:1.11-72) …<br>正在设置 cuda-compiler-11-3 (11.3.1-1) …<br>正在设置 cuda-drivers (465.19.01-1) …<br>正在设置 libcufft-dev-11-3 (10.4.2.109-1) …<br>正在设置 cuda-nvvp-11-3 (11.3.111-1) …<br>正在设置 libcusolver-dev-11-3 (11.1.2.109-1) …<br>正在设置 cuda-runtime-11-3 (11.3.1-1) …<br>正在设置 cuda-cupti-11-3 (11.3.111-1) …<br>正在设置 cuda-nsight-11-3 (11.3.109-1) …<br>正在设置 cuda-demo-suite-11-3 (11.3.58-1) …<br>正在设置 cuda-cupti-dev-11-3 (11.3.111-1) …<br>正在设置 cuda-libraries-dev-11-3 (11.3.1-1) …<br>正在设置 cuda-visual-tools-11-3 (11.3.1-1) …<br>正在设置 cuda-samples-11-3 (11.3.58-1) …<br>正在设置 cuda-command-line-tools-11-3 (11.3.1-1) …<br>正在设置 cuda-documentation-11-3 (11.3.111-1) …<br>正在设置 cuda-tools-11-3 (11.3.1-1) …<br>正在设置 cuda-toolkit-11-3 (11.3.1-1) …<br>Setting alternatives<br>正在设置 cuda-11-3 (11.3.1-1) …<br>正在设置 cuda (11.3.1-1) …<br>正在处理用于 libc-bin (2.33-0ubuntu5) 的触发器 …<br>正在处理用于 man-db (2.9.4-2) 的触发器 …<br>正在处理用于 mailcap (3.68ubuntu1) 的触发器 …<br>正在处理用于 desktop-file-utils (0.26-1ubuntu1) 的触发器 …<br>正在处理用于 hicolor-icon-theme (0.17-2) 的触发器 …<br>正在处理用于 gnome-menus (3.36.0-1ubuntu1) 的触发器 …<br>ZSys is adding automatic system snapshot to GRUB menu</p>
<p>&#96;&#96;&#96;shell</p>
<p>第六步，配置环境变量  </p>
<p>&#96;&#96;&#96;shell<br>cby@cby-Inspiron-7577:<del>$ vim ~&#x2F;.bashrc<br>cby@cby-Inspiron-7577:</del>$ cat ~&#x2F;.bashrc</p>
<h1 id="…略…"><a href="#…略…" class="headerlink" title="…略…"></a>…略…</h1><p>export LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;usr&#x2F;local&#x2F;cuda-11.3&#x2F;lib64</p>
<p>export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;cuda-11.3&#x2F;bin</p>
<p>export CUDA_HOME&#x3D;$CUDA_HOME:&#x2F;usr&#x2F;local&#x2F;cuda-11.3</p>
<p>cby@cby-Inspiron-7577:~$ source ~&#x2F;.bashrc</p>
<p>&#96;&#96;&#96;shell</p>
<p>第七步，下载安装CUDNN  </p>
<p>&#96;&#96;&#96;shell<br><a href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a></p>
<p>&#96;&#96;&#96;shell</p>
<p>访问如向连接，进行注册英伟达开发者，注册完成后下载安装包</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/428a416f9f334cbe95e8c787f00e7d1a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>第八步，下载完成后进入目录后进行安装刚刚下载的安装包  </p>
<p>&#96;&#96;&#96;shell<br>cby@cby-Inspiron-7577:<del>&#x2F;Downloads$ ls<br>libcudnn8_8.2.0.53-1+cuda11.3_amd64.deb<br>libcudnn8-dev_8.2.0.53-1+cuda11.3_amd64.deb<br>libcudnn8-samples_8.2.0.53-1+cuda11.3_amd64.deb<br>pycharm-community-2021.1.2.tar.gz<br>cby@cby-Inspiron-7577:</del>&#x2F;Downloads$ sudo apt install .&#x2F;libcudnn8*<br>正在读取软件包列表… 完成<br>正在分析软件包的依赖关系树… 完成<br>正在读取状态信息… 完成<br>注意，选中 ‘libcudnn8’ 而非 ‘.&#x2F;libcudnn8_8.2.0.53-1+cuda11.3_amd64.deb’<br>注意，选中 ‘libcudnn8-dev’ 而非 ‘.&#x2F;libcudnn8-dev_8.2.0.53-1+cuda11.3_amd64.deb’<br>注意，选中 ‘libcudnn8-samples’ 而非 ‘.&#x2F;libcudnn8-samples_8.2.0.53-1+cuda11.3_amd64.deb’<br>下列软件包是自动安装的并且现在不需要了：<br>  libaccinj64-11.2 libcub-dev libcublas11 libcublaslt11 libcudart11.0<br>  libcufft10 libcufftw10 libcuinj64-11.2 libcupti-dev libcupti-doc<br>  libcupti11.2 libcurand10 libcusolver11 libcusolvermg11 libcusparse11<br>  libegl-dev libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglvnd-dev<br>  libglx-dev libnppc11 libnppial11 libnppicc11 libnppidei11 libnppif11<br>  libnppig11 libnppim11 libnppist11 libnppisu11 libnppitc11 libnpps11<br>  libnvblas11 libnvjpeg11 libnvrtc11.2 libnvtoolsext1 libnvvm4 libopengl-dev<br>  libopengl0 libpthread-stubs0-dev libthrust-dev libvdpau-dev libx11-dev<br>  libxau-dev libxcb1-dev libxdmcp-dev node-html5shiv nsight-compute<br>  nsight-compute-target nsight-systems nsight-systems-target nvidia-cuda-gdb<br>  nvidia-cuda-toolkit-doc nvidia-opencl-dev nvidia-profiler<br>  nvidia-visual-profiler ocl-icd-opencl-dev opencl-c-headers<br>  opencl-clhpp-headers x11proto-dev xorg-sgml-doctools xtrans-dev<br>使用’sudo apt autoremove’来卸载它(它们)。<br>下列【新】软件包将被安装：<br>  libcudnn8 libcudnn8-dev libcudnn8-samples<br>升级了 0 个软件包，新安装了 3 个软件包，要卸载 0 个软件包，有 5 个软件包未被升级。<br>需要下载 0 B&#x2F;823 MB 的归档。<br>解压缩后会消耗 2,899 MB 的额外空间。<br>获取:1 &#x2F;home&#x2F;cby&#x2F;Downloads&#x2F;libcudnn8_8.2.0.53-1+cuda11.3_amd64.deb libcudnn8 amd64 8.2.0.53-1+cuda11.3 [454 MB]<br>获取:2 &#x2F;home&#x2F;cby&#x2F;Downloads&#x2F;libcudnn8-dev_8.2.0.53-1+cuda11.3_amd64.deb libcudnn8-dev amd64 8.2.0.53-1+cuda11.3 [366 MB]<br>获取:3 &#x2F;home&#x2F;cby&#x2F;Downloads&#x2F;libcudnn8-samples_8.2.0.53-1+cuda11.3_amd64.deb libcudnn8-samples amd64 8.2.0.53-1+cuda11.3 [1,672 kB]<br>Requesting to save current system state<br>Successfully saved as “autozsys_mptxg3”<br>正在选中未选择的软件包 libcudnn8。<br>(正在读取数据库 … 系统当前共安装有 216273 个文件和目录。)<br>准备解压 …&#x2F;libcudnn8_8.2.0.53-1+cuda11.3_amd64.deb  …<br>正在解压 libcudnn8 (8.2.0.53-1+cuda11.3) …<br>正在选中未选择的软件包 libcudnn8-dev。<br>准备解压 …&#x2F;libcudnn8-dev_8.2.0.53-1+cuda11.3_amd64.deb  …<br>正在解压 libcudnn8-dev (8.2.0.53-1+cuda11.3) …<br>正在选中未选择的软件包 libcudnn8-samples。<br>准备解压 …&#x2F;libcudnn8-samples_8.2.0.53-1+cuda11.3_amd64.deb  …<br>正在解压 libcudnn8-samples (8.2.0.53-1+cuda11.3) …<br>正在设置 libcudnn8 (8.2.0.53-1+cuda11.3) …<br>正在设置 libcudnn8-dev (8.2.0.53-1+cuda11.3) …<br>update-alternatives: 使用 &#x2F;usr&#x2F;include&#x2F;x86_64-linux-gnu&#x2F;cudnn_v8.h 来在自动模<br>式中提供 &#x2F;usr&#x2F;include&#x2F;cudnn.h (libcudnn)<br>正在设置 libcudnn8-samples (8.2.0.53-1+cuda11.3) …<br>正在处理用于 libc-bin (2.33-0ubuntu5) 的触发器 …<br>ZSys is adding automatic system snapshot to GRUB menu<br>N: 由于文件’&#x2F;home&#x2F;cby&#x2F;Downloads&#x2F;libcudnn8_8.2.0.53-1+cuda11.3_amd64.deb’无法被用户’_apt’访问，已脱离沙盒并提权为根用户来进行下载。- pkgAcquire::Run (13: 权限不够)<br>cby@cby-Inspiron-7577:~&#x2F;Downloads$</p>
<p>&#96;&#96;&#96;shell</p>
<p>第九步，进行验证  </p>
<p>&#96;&#96;&#96;shell<br>cby@cby-Inspiron-7577:~&#x2F;Downloads$ python<br>Python 3.9.5 (default, May 11 2021, 08:20:37)<br>[GCC 10.3.0] on linux<br>Type “help”, “copyright”, “credits” or “license” for more information.</p>
<blockquote>
<blockquote>
<blockquote>
<p>import paddle<br>paddle.utils.run_check()<br>Running verify PaddlePaddle program …<br>W0606 22:39:35.543371 63149 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.3, Runtime API Version: 10.2<br>W0606 22:39:35.572693 63149 device_context.cc:422] device: 0, cuDNN Version: 8.2.<br>PaddlePaddle works well on 1 GPU.<br>PaddlePaddle works well on 1 GPUs.<br>PaddlePaddle is installed successfully! Let’s start deep learning with PaddlePaddle now.</p>
</blockquote>
</blockquote>
</blockquote>
<p>&#96;&#96;&#96;shell</p>
<p>第十步，运行情感训练模型，查看结果  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ba97d1a1f81c4459b6278b8ce8523ec8~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>至此，已完成安装，需要注意的是：  </p>
<ol>
<li><p>在windows下安装及其困难，部分工具无法安装，导致无法正常运行  </p>
</li>
<li><p>AMD的显卡是无法使用GPU进行人工智能计算的</p>
</li>
<li><p>特别注意IDE开发环境中的PYTHON和系统中的环境</p>
</li>
</ol>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1a9888139cb74759b7d6470032bbeee2~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>27篇原创内容</p>
<p>公众号</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>使用frp进行内网穿透</title>
    <url>/2021/12/30/2021-12-30-%E4%BD%BF%E7%94%A8frp%E8%BF%9B%E8%A1%8C%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/</url>
    <content><![CDATA[<p>    frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。</p>
<p>    **frp is a high-performance reverse proxy application focusing on intranet penetration, supporting multiple protocols such as TCP, UDP, HTTP, and HTTPS. Intranet services can be exposed to the public network through a relay with public network IP nodes in a safe and convenient way.<br>**</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c43d130b17f0466cb879fde903b9b75f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>为什么使用 frp ？</strong></p>
<p><strong>Why use frp?</strong></p>
<p>    通过在具有公网 IP 的节点上部署 frp 服务端，可以轻松地将内网服务穿透到公网，同时提供诸多专业的功能特性，这包括：</p>
<p>    <strong>By deploying the frp server on a node with a public network IP, you can easily penetrate the internal network service to the public network, while providing many professional features, including:</strong>  </p>
<p>    客户端服务端通信支持 TCP、KCP 以及 Websocket 等多种协议。</p>
<p>    <strong>The client-server communication supports multiple protocols such as TCP, KCP, and Websocket.</strong>  </p>
<p>    采用 TCP 连接流式复用，在单个连接间承载更多请求，节省连接建立时间。</p>
<p>    <strong>Use TCP connection streaming multiplexing to carry more requests between a single connection, saving connection establishment time.</strong>  </p>
<p>    代理组间的负载均衡。</p>
<p>    <strong>Load balancing between proxy groups.</strong>  </p>
<p>    端口复用，多个服务通过同一个服务端端口暴露。</p>
<p>    <strong>Port reuse, multiple services are exposed through the same server port.</strong>  </p>
<p>    多个原生支持的客户端插件（静态文件查看，HTTP、SOCK5 代理等）便于独立使用 frp 客户端完成某些工作。</p>
<p>    <strong>Multiple natively supported client plug-ins (static file viewing, HTTP, SOCK5 proxy, etc.) facilitate independent use of frp client to complete certain tasks.</strong>  </p>
<p>    高度扩展性的服务端插件系统，方便结合自身需求进行功能扩展。</p>
<p>    <strong>The highly extensible server-side plug-in system facilitates functional expansion according to your own needs.</strong>  </p>
<p>    服务端和客户端 UI 页面。</p>
<p>     <strong>Server and client UI pages.</strong>  </p>
<p>    简单来说，frp是一个反向代理软件，他的体积小巧功能强大，讲内网IP进行frp反向代理后，即可使用代理IP进行访问内网机器的服务，例如远程桌面，虽然远程桌面有第三方软件来代替，例如向日葵，teamviewer，等一些软件进行远程，这些软件都有一些诟病，向日葵没有会员会限速，而tv登录远程连接会比较慢。所以可以考虑到使用内网穿透或者反向代理。</p>
<p>  <strong>To put it simply, frp is a reverse proxy software, its size is small and powerful, after talking about the intranet IP for frp reverse proxy, you can use the proxy IP to access the services of the intranet machine, such as remote desktop, although remote desktop There are third-party software to replace, such as Sunflower, teamviewer, and other software for remote. These softwares have some criticisms. Sunflower does not have a membership rate limit, and the tv login remote connection will be slow. So you can consider using intranet penetration or reverse proxy.</strong></p>
<p>    内网穿透可参考：<a href="http://mp.weixin.qq.com/s?__biz=MzI0MzA4NTM2NQ==&mid=2247483964&idx=1&sn=2b857cb34f7b678c1d1a5492cfee7efd&chksm=e9733b66de04b27024387be235f680f85165e69b5152960a08fc45f653d397a10381e71a5ebb&scene=21#wechat_redirect">有一个公网IP地址</a> </p>
<p> <strong>Intranet penetration can refer to: there is a public IP address</strong></p>
<p>使用端口进行访问时，原理如下  </p>
<p><strong>When using the port for access, the principle is as follows</strong>  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/addffe28d90e4e76a54d1ef079971a16~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>准备工作：</strong></p>
<p><strong>Ready to work:</strong>  </p>
<p>    1、首先得有一台云服务器进行提供网络带宽，frp代理带宽一般受限于该服务器带宽  </p>
<p>    2、一台目标机器，也就是需要反向代理的机器</p>
<p> **  1. First, there must be a cloud server to provide network bandwidth, and the frp proxy bandwidth is generally limited by the server bandwidth**</p>
<p> <strong>2. A target machine, that is, a machine that needs a reverse proxy</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/755f0bc472fb46608a89945de95ad5b6~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>云服务器端配置：</strong>  </p>
<p>**Cloud server configuration:<br>**</p>
<p>    使用命令查看云服务器的架构，一般云服务器架构为x86</p>
<p> <strong>Use commands to view the architecture of the cloud server, the general cloud server architecture is x86</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@cby ~]# arch<br>x86_64</p>
<p>&#96;&#96;&#96;shell</p>
<p>    使用命令下载frp软件包  </p>
<p> <strong>Use command to download frp package</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@cby ~]# wget <a href="https://github.com/fatedier/frp/releases/download/v0.35.1/frp_0.35.1_linux_amd64.tar.gz">https://github.com/fatedier/frp/releases/download/v0.35.1/frp_0.35.1_linux_amd64.tar.gz</a></p>
<p>&#96;&#96;&#96;shell</p>
<p>    下载完成后进行解压</p>
<p> <strong>Unzip after downloading</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@cby ~]# tar -xvf frp_0.35.1_linux_amd64.tar.gz<br>frp_0.35.1_linux_amd64&#x2F;<br>frp_0.35.1_linux_amd64&#x2F;frps.ini<br>frp_0.35.1_linux_amd64&#x2F;frps_full.ini<br>frp_0.35.1_linux_amd64&#x2F;systemd&#x2F;<br>frp_0.35.1_linux_amd64&#x2F;systemd&#x2F;frpc@.service<br>frp_0.35.1_linux_amd64&#x2F;systemd&#x2F;frpc.service<br>frp_0.35.1_linux_amd64&#x2F;systemd&#x2F;frps.service<br>frp_0.35.1_linux_amd64&#x2F;systemd&#x2F;frps@.service<br>frp_0.35.1_linux_amd64&#x2F;frpc<br>frp_0.35.1_linux_amd64&#x2F;frpc_full.ini<br>frp_0.35.1_linux_amd64&#x2F;frps<br>frp_0.35.1_linux_amd64&#x2F;frpc.ini<br>frp_0.35.1_linux_amd64&#x2F;LICENSE</p>
<p>&#96;&#96;&#96;shell</p>
<p>    修改文件夹名称  </p>
<p>    <strong>Modify folder name</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@cby ~]# cp -r frp_0.35.1_linux_amd64 frp</p>
<p>[root@cby ~]#<br>[root@cby ~]# ll<br>total 8508<br>drwxr-xr-x 3 root  root    4096 Feb 19 22:13 frp<br>drwxr-xr-x 3 mysql  116    4096 Jan 25 16:25 frp_0.35.1_linux_amd64<br>-rw-r–r– 1 root  root 8695632 Jan 25 16:25 frp_0.35.1_linux_amd64.tar.gz</p>
<p>&#96;&#96;&#96;shell</p>
<p>‍</p>
<p>    只需要关注如下几个文件</p>
<p>    <strong>Only need to pay attention to the following files</strong>  </p>
<p>&#96;&#96;&#96;shell<br>frps<br>frps.ini<br>frpc<br>frpc.ini</p>
<p>&#96;&#96;&#96;shell</p>
<p>    frps 、frps.ini 这俩个文件是服务端的配置文件和启动程序</p>
<p>    frpc、frpc.ini 这俩个文件是客户端的配置文件和启动程序</p>
<p> <strong>The two files frps and frps.ini are the configuration files and startup programs of the server</strong></p>
<p> <strong>The two files frpc and frpc.ini are the configuration files and startup programs of the client</strong></p>
<p>    编辑并添加以下内容  </p>
<p>    <strong>Edit and add the following</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@cby frp]# vim frps.ini<br>[root@cby frp]# cat frps.ini<br>[common]<br>bind_port &#x3D; 7000<br>dashboard_port &#x3D; 7500<br>token &#x3D; 12345678<br>dashboard_user &#x3D; admin<br>dashboard_pwd &#x3D; admin<br>vhost_http_port &#x3D; 10080<br>vhost_https_port &#x3D; 10443</p>
<p>&#96;&#96;&#96;shell</p>
<p>    解释如下  </p>
<p>    <strong>Explain as follows</strong>  </p>
<p>&#96;&#96;&#96;shell<br>“bind_port”表示用于客户端和服务端连接的端口，这个端口号我们之后在配置客户端的时候要用到。<br>“dashboard_port”是服务端仪表板的端口，若使用7500端口，在配置完成服务启动后可以通过浏览器访问 x.x.x.x:7500 （其中x.x.x.x为VPS的IP）查看frp服务运行信息。<br>“token”是用于客户端和服务端连接的口令，请自行设置并记录，稍后会用到。<br>“dashboard_user”和“dashboard_pwd”表示打开仪表板页面登录的用户名和密码，自行设置即可。<br>“vhost_http_port”和“vhost_https_port”用于反向代理HTTP主机时使用，本文不涉及HTTP协议，因而照抄或者删除这两条均可。</p>
<p>&#96;&#96;&#96;shell</p>
<p>    文件修改完成后即可使用该命令进行启动  </p>
<p>    <strong>After the file is modified, you can use this command to start</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@cby frp]# .&#x2F;frps -c frps.ini<br>2021&#x2F;02&#x2F;19 22:18:45 [I] [root.go:108] frps uses config file: frps.ini<br>2021&#x2F;02&#x2F;19 22:18:45 [I] [service.go:190] frps tcp listen on 0.0.0.0:7000<br>2021&#x2F;02&#x2F;19 22:18:45 [I] [service.go:232] http service listen on 0.0.0.0:10080<br>2021&#x2F;02&#x2F;19 22:18:45 [I] [service.go:253] https service listen on 0.0.0.0:10443<br>2021&#x2F;02&#x2F;19 22:18:45 [I] [service.go:289] Dashboard listen on 0.0.0.0:7500<br>2021&#x2F;02&#x2F;19 22:18:45 [I] [root.go:217] frps started successfully</p>
<p>&#96;&#96;&#96;shell</p>
<p>    若使用云服务器记得需要放行所需端口  </p>
<p>    <strong>If you use cloud server, remember to release the required port</strong>  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ae9842ca26144c09874396b07dd3f9ca~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    此时访问 x.x.x.x:7500 并使用自己设置的用户名密码登录，即可看到仪表板界面</p>
<p>    <strong>At this time, visit x.x.x.x:7500 and log in with the username and password you set, you can see the dashboard interface</strong>  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/838bf4d05d234ce08f08a50dd7ef67c7~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    把服务在后台运行即可  </p>
<p>    <strong>Just run the service in the background</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@cby frp]# nohup .&#x2F;frps -c frps.ini &amp;<br>[1] 4852<br>[root@cby frp]# jobs<br>[1]+  Running                 nohup .&#x2F;frps -c frps.ini &amp;</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>客户端配置</strong>  </p>
<p><strong>Client configuration</strong>  </p>
<p>    Windows系统下即可下载这个：  </p>
<p>    You can download this under Windows system:  </p>
<p>&#96;&#96;&#96;shell<br><a href="https://github.com/fatedier/frp/releases/download/v0.35.1/frp_0.35.1_windows_amd64.zip">https://github.com/fatedier/frp/releases/download/v0.35.1/frp_0.35.1_windows_amd64.zip</a></p>
<p>&#96;&#96;&#96;shell</p>
<p>    frpc.ini文件内容为  </p>
<p>    <strong>The content of the frpc.ini file is</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[common]<br>server_addr &#x3D; 123.56.237.11<br>server_port &#x3D; 7000<br>token &#x3D; 12345678<br>[rdp]<br>type &#x3D; tcp<br>local_ip &#x3D; 127.0.0.1<br>local_port &#x3D; 3389<br>remote_port &#x3D; 7001<br>[smb]<br>type &#x3D; tcp<br>local_ip &#x3D; 127.0.0.1<br>local_port &#x3D; 445<br>remote_port &#x3D; 7002</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/308ee32d14064e239254b7605de5e1d4~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    含义解释  </p>
<p>    <strong>Meaning interpretation</strong>  </p>
<p>&#96;&#96;&#96;shell<br>“server_addr”为服务端IP地址，填入即可。<br>“server_port”为服务器端口，填入你设置的端口号即可，如果未改变就是7000<br>“token”是你在服务器上设置的连接口令，原样填入即可。</p>
<p>&#96;&#96;&#96;shell</p>
<p>    自定义规则如下  </p>
<p>    <strong>The custom rules are as follows</strong>  </p>
<p>&#96;&#96;&#96;shell<br>“[xxx]”表示一个规则名称，自己定义，便于查询即可。<br>“type”表示转发的协议类型，有TCP和UDP等选项可以选择，如有需要请自行查询frp手册。<br>“local_port”是本地应用的端口号，按照实际应用工作在本机的端口号填写即可。<br>“remote_port”是该条规则在服务端开放的端口号，自己填写并记录即可。</p>
<p>&#96;&#96;&#96;shell</p>
<p>    客户端的启动是需要使用命令行进行启动的， 无法使用双击EXE进行启动。</p>
<p>    <strong>The startup of the client needs to use the command line to start, it cannot be started by double-clicking the EXE.</strong>  </p>
<p>&#96;&#96;&#96;shell<br>C:\Users\Administrator&gt;cd c:<br>c:&gt;cd frp<br>c:\frp&gt;frpc.exe -c frpc.ini<br>2021&#x2F;02&#x2F;19 22:35:49 [I] [service.go:290] [bf2998700defd7c5] login to server success, get run id [bf2998700defd7c5], server udp port [0]<br>2021&#x2F;02&#x2F;19 22:35:49 [I] [proxy_manager.go:144] [bf2998700defd7c5] proxy added: [rdp smb]<br>2021&#x2F;02&#x2F;19 22:35:49 [I] [control.go:180] [bf2998700defd7c5] [rdp] start proxy success<br>2021&#x2F;02&#x2F;19 22:35:49 [I] [control.go:180] [bf2998700defd7c5] [smb] start proxy success</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d1483ad6cb9f4f8aab81a4c718983ad8~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    配置完成后即可在面板上看到该规则  </p>
<p>    <strong>After the configuration is complete, you can see the rule on the panel</strong>  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/265c7819ce534820be45b97dabe1572c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    同时使用远程连接工具使用IP或者域名即可进行连接</p>
<p>    但是Windows客户端的cmd是无法关闭的，关闭后就无法使用了，所以需要设置开机自启，使用bat脚本即可做到</p>
<p> <strong>At the same time, use the remote connection tool to connect using IP or domain name</strong></p>
<p> <strong>However, the cmd of the Windows client cannot be closed, and it cannot be used after it is closed, so you need to set the boot to start automatically, and you can use the bat script</strong></p>
<p>&#96;&#96;&#96;shell<br>@echo off<br>if “%1” &#x3D;&#x3D; “h” goto begin<br>mshta vbscript:createobject(“wscript.shell”).run(“””%~nx0”” h”,0)(window.close)&amp;&amp;exit<br>:begin<br>REM<br>cd C:\frp<br>frpc.exe -c frpc.ini<br>exit</p>
<p>&#96;&#96;&#96;shell</p>
<p>写完之后直接把文件扔到Windows的开机启动文件夹即可</p>
<p><strong>After writing, throw the file directly into the Windows startup folder.</strong>  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5a8bc24841a44df6b5cdd0912485a6d0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/092306b1ce9e41d69ecbbc9a2987570a~tplv-k3u1fbpfcp-zoom-1.image">Linux运维交流社区推荐搜索关键词列表：Linuxfrp</p>
<p>汉威国际</p>
<p>位置：</p>
<p>北京市丰台区丰科西路|九号路</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>内网搭建DNS服务器</title>
    <url>/2021/12/30/2021-12-30-%E5%86%85%E7%BD%91%E6%90%AD%E5%BB%BADNS%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<h1 id="DNS-Domain-Name-Service，域名解析服务"><a href="#DNS-Domain-Name-Service，域名解析服务" class="headerlink" title="DNS:Domain Name Service，域名解析服务"></a>DNS:Domain Name Service，域名解析服务</h1><p>监听端口：udp&#x2F;53，tcp&#x2F;53</p>
<p>应用程序：bind</p>
<p>根域：.</p>
<p>一级域：</p>
<p>组织域：.com, .org, .net, .mil, .edu, .gov, .info, .cc, .me, .tv</p>
<p>国家域：.cn, .us, .uk, .jp, .tw, .hk, .iq, .ir</p>
<p>反向域：.in-addr.arpa</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3d0171623b2441a4b070fe95db0a1a4e~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>DNS 记录类型</strong>：DNS 域名数据库由资源记录和区文件指令组成。</p>
<p><strong>SOA 记录</strong>：起始授权机构记录，SOA 备注说明了众多 NS（name server）记录中谁是主名称服务器，不参与功能，但是不能缺少。</p>
<p><strong>NS 记录</strong>：域授权记录，当请求到达根域的时候，通过 NS 记录找到对应的域。</p>
<p><strong>A 记录</strong>：当通过 NS 记录到达域以后，比如访问 <a href="http://www.baidu.com,通过/">www.baidu.com，通过</a> NS 我们找到了 baidu.com，此时就需要通过 A 记录找到 www。</p>
<p><strong>MX</strong>：将该域下的所有邮件服务器地址指向邮件服务器。</p>
<p><strong>AAAA 记录</strong>：A 记录处理 IPV4，AAAA 处理 IPV6。</p>
<p><strong>PTR 记录</strong>：反向解析，将 IP 解析成域名。</p>
<p><strong>CNAME</strong>：别名记录，允许多个名字映射到另外一个域名。比如我们 ping 百度的时候可以发现返回其实是 <a href="http://www.a.shifen.com/">www.a.shifen.com</a> 这个域名返回。所有 <a href="http://www.baidu.com/">www.baidu.com</a> 其实是个别名。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d28428c41d754b6cac837fc3abf9f32a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="安装dns服务并配置"><a href="#安装dns服务并配置" class="headerlink" title="安装dns服务并配置"></a>安装dns服务并配置</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@jhr-hub ~]# yum -y install bind-utils bind bind-devel bind-libs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@jhr-hub ~]# vim /etc/named.rfc1912.zones</span><br><span class="line">[root@jhr-hub ~]# </span><br><span class="line">[root@jhr-hub ~]# </span><br><span class="line">[root@jhr-hub ~]# </span><br><span class="line">[root@jhr-hub ~]# tail -n 10 /etc/named.rfc1912.zones</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">zone &quot;chenby.cn&quot; IN &#123;     </span><br><span class="line">        type master;</span><br><span class="line">        file &quot;chenby.cn.zone&quot;;  </span><br><span class="line">&#125;;</span><br><span class="line">[root@jhr-hub ~]# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@jhr-hub ~]# cd /var/named/</span><br><span class="line">[root@jhr-hub named]# ls</span><br><span class="line">data  dynamic  named.ca  named.empty  named.localhost  named.loopback  pakho.zone  slaves</span><br><span class="line">[root@jhr-hub named]# </span><br><span class="line">[root@jhr-hub named]# cp named.localhost chenby.cn.zone</span><br><span class="line">[root@jhr-hub named]# </span><br><span class="line">[root@jhr-hub named]# chown named.named chenby.cn.zone</span><br><span class="line">[root@jhr-hub named]# </span><br><span class="line">[root@jhr-hub named]# vim chenby.cn.zone</span><br><span class="line">[root@jhr-hub named]#</span><br></pre></td></tr></table></figure>

<h1 id="检查配置文件"><a href="#检查配置文件" class="headerlink" title="检查配置文件"></a>检查配置文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@jhr-hub named]# named-checkconf /etc/named.conf</span><br><span class="line">[root@jhr-hub named]# </span><br><span class="line">[root@jhr-hub named]# </span><br><span class="line">[root@jhr-hub named]# named-checkzone chenby.cn /var/named/chenby.cn.zone </span><br><span class="line">zone chenby.cn/IN: loaded serial 0</span><br><span class="line">OK</span><br><span class="line">[root@jhr-hub named]#</span><br></pre></td></tr></table></figure>

<h1 id="启动服务，并设置开机自启"><a href="#启动服务，并设置开机自启" class="headerlink" title="启动服务，并设置开机自启"></a>启动服务，并设置开机自启</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@jhr-hub named]# systemctl restart named</span><br><span class="line">[root@jhr-hub named]# </span><br><span class="line">[root@jhr-hub named]# systemctl enable named</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/named.service to /usr/lib/systemd/system/named.service.</span><br><span class="line">[root@jhr-hub named]# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">测试是否可行</span><br><span class="line"></span><br><span class="line">[root@jhr-hub named]# dig @3.7.191.1 www.chenby.cn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7_9.7 &lt;&lt;&gt;&gt; @3.7.191.1 www.chenby.cn</span><br><span class="line">; (1 server found)</span><br><span class="line">;; global options: +cmd</span><br><span class="line">;; Got answer:</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 5275</span><br><span class="line">;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">;; OPT PSEUDOSECTION:</span><br><span class="line">; EDNS: version: 0, flags:; udp: 4096</span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;www.chenby.cn.                 IN      A</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">www.chenby.cn.          86400   IN      A       3.7.191.1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">;; AUTHORITY SECTION:</span><br><span class="line">chenby.cn.              86400   IN      NS      chenby.cn.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">;; ADDITIONAL SECTION:</span><br><span class="line">chenby.cn.              86400   IN      A       127.0.0.1</span><br><span class="line">chenby.cn.              86400   IN      AAAA    ::1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">;; Query time: 0 msec</span><br><span class="line">;; SERVER: 3.7.191.1#53(3.7.191.1)</span><br><span class="line">;; WHEN: Thu Dec 09 14:44:51 CST 2021</span><br><span class="line">;; MSG SIZE  rcvd: 116</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@jhr-hub named]#</span><br></pre></td></tr></table></figure>

<h1 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h1><h1 id="1-name-conf文件详解"><a href="#1-name-conf文件详解" class="headerlink" title="1.name.conf文件详解"></a>1.name.conf文件详解</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">options &#123;</span><br><span class="line">listen-on port 53 &#123; 127.0.0.1; &#125;;      //设置named服务器监听端口及IP地址</span><br><span class="line">listen-on-v6 port 53 &#123; ::1; &#125;;</span><br><span class="line">directory       &quot;/var/named&quot;;    //设置区域数据库文件的默认存放地址</span><br><span class="line">dump-file       &quot;/var/named/data/cache_dump.db&quot;;</span><br><span class="line">statistics-file &quot;/var/named/data/named_stats.txt&quot;;</span><br><span class="line">memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">allow-query     &#123; any; &#125;;   //允许DNS查询客户端</span><br><span class="line">allow-query-cache &#123; any; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">logging &#123;</span><br><span class="line">channel default_debug &#123;</span><br><span class="line">file &quot;data/named.run&quot;;</span><br><span class="line">severity dynamic;</span><br><span class="line">&#125;;</span><br><span class="line">&#125;;</span><br><span class="line">view localhost_resolver &#123;</span><br><span class="line">match-clients      &#123; any; &#125;;</span><br><span class="line">match-destinations &#123; any; &#125;;</span><br><span class="line">recursion yes;                  //设置允许递归查询</span><br><span class="line">include &quot;/etc/named.rfc1912.zones&quot;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h1 id="2-区域配置文件-x2F-etc-x2F-named-rfc1912-zones"><a href="#2-区域配置文件-x2F-etc-x2F-named-rfc1912-zones" class="headerlink" title="2.区域配置文件&#x2F;etc&#x2F;named.rfc1912.zones"></a>2.区域配置文件&#x2F;etc&#x2F;named.rfc1912.zones</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zone &quot;.&quot; IN &#123;    //定义了根域</span><br><span class="line">type hint;       //定义服务器类型为hint</span><br><span class="line">file &quot;named.ca&quot;;  //定义根域的配置文件名</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">zone &quot;localdomain&quot; IN &#123;   //定义正向DNS区域</span><br><span class="line">type master;              //定义区域类型</span><br><span class="line">file &quot;localdomain.zone&quot;;  //设置对应的正向区域地址数据库文件</span><br><span class="line">allow-update &#123; none; &#125;;   //设置允许动态更新的客户端地址（none为禁止）</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">zone &quot;localhost&quot; IN &#123;</span><br><span class="line">type master;</span><br><span class="line">file &quot;localhost.zone&quot;;</span><br><span class="line">allow-update &#123; none; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">zone &quot;0.0.127.in-addr.arpa&quot; IN &#123;   //设置反向DNS区域</span><br><span class="line">type master;</span><br><span class="line">file &quot;named.local&quot;;</span><br><span class="line">allow-update &#123; none; &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h1 id="3-根域配置文件named-ca"><a href="#3-根域配置文件named-ca" class="headerlink" title="3.根域配置文件named.ca"></a>3.根域配置文件named.ca</h1><p>根域配置文件设定根域的域名数据库，包括根域中13台DNS服务器的信息。几乎所有系统的这个文件都是一样的，用户不需要进行修改。</p>
<h1 id="4-正向域名解析数据库文件"><a href="#4-正向域名解析数据库文件" class="headerlink" title="4.正向域名解析数据库文件"></a>4.正向域名解析数据库文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">TTL 600</span></span><br><span class="line">@        IN   SOA    dns.cwlinux.com   dnsadmin.cwlinux.com. (//SOA字段</span><br><span class="line">                          2015031288   //版本号    同步一次  +1</span><br><span class="line">                             1H        //更新时间</span><br><span class="line">                             2M        // 更新失败，重试更新时间</span><br><span class="line">                             2D        // 更新失败多长时间后此DNS失效时间</span><br><span class="line">                             1D        //解析不到请求不予回复时间</span><br><span class="line">)</span><br><span class="line">         IN    NS   dns            //有两域名服务器</span><br><span class="line">         IN    NS   ns2</span><br><span class="line">         IN    MX  10 mial        // 定义邮件服务器，10指优先级  0-99 数字越小优先级越高</span><br><span class="line">ns2      IN    A    192.168.1.113  //ns2域名服务器的ip地址</span><br><span class="line">dns      IN    A    192.168.1.10   //dns域名服务器的ip地址</span><br><span class="line">mail     IN    A    192.168.1.111   //邮件服务器的ip地址</span><br><span class="line">www      IN    A    192.168.1.112   //www.cwlinux.com的ip地址</span><br><span class="line">pop      IN   CNAME  mail         //pop的正式名字是mail</span><br><span class="line">ftp      IN   CNAME  www         //ftp的正式名字是www</span><br></pre></td></tr></table></figure>

<h1 id="5-反向域名解析数据库文件"><a href="#5-反向域名解析数据库文件" class="headerlink" title="5.反向域名解析数据库文件"></a>5.反向域名解析数据库文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">TTL 600</span></span><br><span class="line">@         IN   SOA    dns.cwlinux.com.   dnsadmin.cwlinux.com. (</span><br><span class="line">                             2014031224</span><br><span class="line">                             1H</span><br><span class="line">                             2M</span><br><span class="line">                             2D</span><br><span class="line">                             1D</span><br><span class="line">)</span><br><span class="line">         IN   NS      dns.cwlinux.com.</span><br><span class="line">10       IN   PTR     dns.cwlinux.com.     //反向解析PTR格式</span><br><span class="line">111       IN   PTR     mail.cwlinux.com.</span><br><span class="line">112       IN   PTR     www.cwlinux.com.</span><br><span class="line">// 声明域的时候已经有了，192.168.1 所以我们只需要输入10即代表192.168.1.10jc</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e089abc85d4e4ae780d6c279920d3203~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>71篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2610ee80e6064d94a0f79dcdccf19b0b~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>华为 A800-9000 服务器 离线安装MindX DL</title>
    <url>/2021/12/30/2021-12-30-%E5%8D%8E%E4%B8%BA_A800-9000_%E6%9C%8D%E5%8A%A1%E5%99%A8_%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85MindX_DL/</url>
    <content><![CDATA[<p>    MindX DL（昇腾深度学习组件）是支持 Atlas 800 训练服务器、Atlas 800 推理服务器的深度学习组件参考设计，提供昇腾 AI 处理器资源管理和监控、昇腾 AI 处理器优化调度、分布式训练集合通信配置生成等基础功能，快速使能合作伙伴进行深度学习平台开发。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/16e4b9f7084840538d445b2d1d907fa5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    操作系统使用的是Ubuntu-1804，CPU是华为自研ARM架构。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d03504939ec94b649d970864ee829a47~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>一、安装前准备</p>
<ol>
<li>配置apt网络源</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hello@ubuntu:/etc/apt$ sudo cp sources.list~ sources.list</span><br><span class="line"></span><br><span class="line">hello@ubuntu:/etc/apt$ cat sources.list</span><br><span class="line"></span><br><span class="line"># </span><br><span class="line"></span><br><span class="line"># deb cdrom:[Ubuntu-Server 18.04.5 LTS _Bionic Beaver_ - Release arm64 (20200810)]/ bionic main restricted</span><br><span class="line"></span><br><span class="line">#deb cdrom:[Ubuntu-Server 18.04.5 LTS _Bionic Beaver_ - Release arm64 (20200810)]/ bionic main restricted</span><br><span class="line"></span><br><span class="line"># See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to</span><br><span class="line"># newer versions of the distribution.</span><br><span class="line">deb http://cn.ports.ubuntu.com/ubuntu-ports/ bionic main restricted</span><br><span class="line"># deb-src http://cn.ports.ubuntu.com/ubuntu-ports/ bionic main restricted</span><br><span class="line"></span><br><span class="line">## Major bug fix updates produced after the final release of the</span><br><span class="line">## distribution.</span><br><span class="line">deb http://cn.ports.ubuntu.com/ubuntu-ports/ bionic-updates main restricted</span><br><span class="line"># deb-src http://cn.ports.ubuntu.com/ubuntu-ports/ bionic-updates main restricted</span><br><span class="line"></span><br><span class="line">## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu</span><br><span class="line">## team. Also, please note that software in universe WILL NOT receive any</span><br><span class="line">## review or updates from the Ubuntu security team.</span><br><span class="line">deb http://cn.ports.ubuntu.com/ubuntu-ports/ bionic universe</span><br><span class="line"># deb-src http://cn.ports.ubuntu.com/ubuntu-ports/ bionic universe</span><br><span class="line">deb http://cn.ports.ubuntu.com/ubuntu-ports/ bionic-updates universe</span><br><span class="line"># deb-src http://cn.ports.ubuntu.com/ubuntu-ports/ bionic-updates universe</span><br><span class="line"></span><br><span class="line">## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu </span><br><span class="line">## team, and may not be under a free licence. Please satisfy yourself as to </span><br><span class="line">## your rights to use the software. Also, please note that software in </span><br><span class="line">## multiverse WILL NOT receive any review or updates from the Ubuntu</span><br><span class="line">## security team.</span><br><span class="line">deb http://cn.ports.ubuntu.com/ubuntu-ports/ bionic multiverse</span><br><span class="line"># deb-src http://cn.ports.ubuntu.com/ubuntu-ports/ bionic multiverse</span><br><span class="line">deb http://cn.ports.ubuntu.com/ubuntu-ports/ bionic-updates multiverse</span><br><span class="line"># deb-src http://cn.ports.ubuntu.com/ubuntu-ports/ bionic-updates multiverse</span><br><span class="line"></span><br><span class="line">## N.B. software from this repository may not have been tested as</span><br><span class="line">## extensively as that contained in the main release, although it includes</span><br><span class="line">## newer versions of some applications which may provide useful features.</span><br><span class="line">## Also, please note that software in backports WILL NOT receive any review</span><br><span class="line">## or updates from the Ubuntu security team.</span><br><span class="line">deb http://cn.ports.ubuntu.com/ubuntu-ports/ bionic-backports main restricted universe multiverse</span><br><span class="line"># deb-src http://cn.ports.ubuntu.com/ubuntu-ports/ bionic-backports main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">## Uncomment the following two lines to add software from Canonical&#x27;s</span><br><span class="line">## &#x27;partner&#x27; repository.</span><br><span class="line">## This software is not part of Ubuntu, but is offered by Canonical and the</span><br><span class="line">## respective vendors as a service to Ubuntu users.</span><br><span class="line"># deb http://archive.canonical.com/ubuntu bionic partner</span><br><span class="line"># deb-src http://archive.canonical.com/ubuntu bionic partner</span><br><span class="line"></span><br><span class="line">deb http://ports.ubuntu.com/ubuntu-ports bionic-security main restricted</span><br><span class="line"># deb-src http://ports.ubuntu.com/ubuntu-ports bionic-security main restricted</span><br><span class="line">deb http://ports.ubuntu.com/ubuntu-ports bionic-security universe</span><br><span class="line"># deb-src http://ports.ubuntu.com/ubuntu-ports bionic-security universe</span><br><span class="line">deb http://ports.ubuntu.com/ubuntu-ports bionic-security multiverse</span><br><span class="line"># deb-src http://ports.ubuntu.com/ubuntu-ports bionic-security multiverse</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>    2.配置kubernetes网络源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/123/offline-pkg-arm64# cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">&gt; deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span><br><span class="line">&gt; EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>    3.创建目录并下载基础包  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/123# mkdir offline-pkg-arm64</span><br><span class="line">root@ubuntu:~/123# cd offline-pkg-arm64/</span><br><span class="line">root@ubuntu:~/123/offline-pkg-arm64# sudo apt update</span><br><span class="line">root@ubuntu:~/123/offline-pkg-arm64# apt-get download conntrack cri-tools haveged keyutils libhavege1 libltdl7 libnfsidmap2 libtirpc-dev libtirpc1 nfs-common nfs-kernel-server rpcbind socat sshpass</span><br><span class="line">root@ubuntu:~/123/offline-pkg-arm64# wget --no-check-certificate https://download.docker.com/linux/ubuntu/dists/bionic/pool/stable/arm64/docker-ce_18.06.3~ce~3-0~ubuntu_arm64.deb</span><br><span class="line">root@ubuntu:~/123/offline-pkg-arm64# apt-get download kubelet=1.17.3-00 kubeadm=1.17.3-00 kubectl=1.17.3-00 kubernetes-cni=0.8.6-00</span><br></pre></td></tr></table></figure>

<p>    4.下载docker镜像并导出保存  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/123# mkdir docker_images</span><br><span class="line">root@ubuntu:~/123# cd docker_images/</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull calico/node:v3.11.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o calico-node_arm64.tar.gz calico/node:v3.11.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull calico/pod2daemon-flexvol:v3.11.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o calico-pod2daemon-flexvol_arm64.tar.gz calico/pod2daemon-flexvol:v3.11.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull calico/cni:v3.11.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o calico-cni_arm64.tar.gz calico/cni:v3.11.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull calico/kube-controllers:v3.11.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o calico-kube-controllers_arm64.tar.gz calico/kube-controllers:v3.11.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull coredns/coredns:1.6.5</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o coredns_arm64.tar.gz coredns/coredns:1.6.5</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull cruse/etcd-arm64:3.4.3-0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o etcd_arm64.tar.gz cruse/etcd-arm64:3.4.3-0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull cruse/kube-apiserver-arm64:v1.17.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o kube-apiserver_arm64.tar.gz cruse/kube-apiserver-arm64:v1.17.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull cruse/kube-controller-manager-arm64:v1.17.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o kube-controller-manager_arm64.tar.gz  cruse/kube-controller-manager-arm64:v1.17.3</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull cruse/kube-proxy-arm64:v1.17.3-beta.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o kube-proxy_arm64.tar.gz cruse/kube-proxy-arm64:v1.17.3-beta.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull cruse/kube-scheduler-arm64:v1.17.3-beta.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o kube-scheduler_arm64.tar.gz cruse/kube-scheduler-arm64:v1.17.3-beta.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull cruse/pause-arm64:3.1</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o pause_arm64.tar.gz cruse/pause-arm64:3.1</span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# docker login -u 15648907522 -p RtZOXgmpYAQd5cj93uFCabNXUWB7wOftGw4pFdcal4XZH4bf06hvFxTOrYtr1nRao ascendhub.huawei.com</span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull ascendhub.huawei.com/public-ascendhub/vc-controller-manager_arm64:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull ascendhub.huawei.com/public-ascendhub/vc-scheduler_arm64:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull ascendhub.huawei.com/public-ascendhub/vc-webhook-manager_arm64:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull ascendhub.huawei.com/public-ascendhub/vc-webhook-manager-base_arm64:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull ascendhub.huawei.com/public-ascendhub/hccl-controller_arm64:v20.2.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull ascendhub.huawei.com/public-ascendhub/ascend-k8sdeviceplugin_arm64:v20.2.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker pull ascendhub.huawei.com/public-ascendhub/cadvisor_arm64:v0.34.0-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# docker tag ascendhub.huawei.com/public-ascendhub/vc-controller-manager_arm64:v1.0.1-r40 volcanosh/vc-controller-manager:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker tag ascendhub.huawei.com/public-ascendhub/vc-scheduler_arm64:v1.0.1-r40 volcanosh/vc-scheduler:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker tag ascendhub.huawei.com/public-ascendhub/vc-webhook-manager_arm64:v1.0.1-r40 volcanosh/vc-webhook-manager:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker tag ascendhub.huawei.com/public-ascendhub/vc-webhook-manager-base_arm64:v1.0.1-r40 volcanosh/vc-webhook-manager-base:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker tag ascendhub.huawei.com/public-ascendhub/hccl-controller_arm64:v20.2.0 hccl-controller:v20.2.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker tag ascendhub.huawei.com/public-ascendhub/ascend-k8sdeviceplugin_arm64:v20.2.0 ascend-k8sdeviceplugin:v20.2.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker tag ascendhub.huawei.com/public-ascendhub/cadvisor_arm64:v0.34.0-r40 google/cadvisor:v0.34.0-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker rmi ascendhub.huawei.com/public-ascendhub/vc-controller-manager_arm64:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker rmi ascendhub.huawei.com/public-ascendhub/vc-scheduler_arm64:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker rmi ascendhub.huawei.com/public-ascendhub/vc-webhook-manager_arm64:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker rmi ascendhub.huawei.com/public-ascendhub/vc-webhook-manager-base_arm64:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker rmi ascendhub.huawei.com/public-ascendhub/hccl-controller_arm64:v20.2.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker rmi ascendhub.huawei.com/public-ascendhub/ascend-k8sdeviceplugin_arm64:v20.2.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker rmi ascendhub.huawei.com/public-ascendhub/cadvisor_arm64:v0.34.0-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# </span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o Ascend-K8sDevicePlugin-v20.2.0-arm64-Docker.tar.gz ascend-k8sdeviceplugin:v20.2.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o hccl-controller-v20.2.0-arm64.tar.gz hccl-controller:v20.2.0</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o huawei-cadvisor-v0.34.0-r40-arm64.tar.gz google/cadvisor:v0.34.0-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o vc-controller-manager-v1.0.1-r40-arm64.tar.gz volcanosh/vc-controller-manager:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o vc-scheduler-v1.0.1-r40-arm64.tar.gz volcanosh/vc-scheduler:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o vc-webhook-manager-base-v1.0.1-r40-arm64.tar.gz volcanosh/vc-webhook-manager-base:v1.0.1-r40</span><br><span class="line">root@ubuntu:~/123/docker_images# docker save -o vc-webhook-manager-v1.0.1-r40-arm64.tar.gz volcanosh/vc-webhook-manager:v1.0.1-r40</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>注* 其中部分镜像是需要在华为hub里面进行获取权限后进行下载</strong>  </p>
<p><a href="https://support.huaweicloud.com/usermanual-mindxdl202/atlasmindx/_03/_0047.html">https://support.huaweicloud.com/usermanual-mindxdl202/atlasmindx\_03\_0047.html</a></p>
<p>    5.完成后的目录  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/123# tree</span><br><span class="line">.</span><br><span class="line">├── docker_images</span><br><span class="line">│   ├── Ascend-K8sDevicePlugin-v20.2.0-arm64-Docker.tar.gz</span><br><span class="line">│   ├── calico-cni_arm64.tar.gz</span><br><span class="line">│   ├── calico-kube-controllers_arm64.tar.gz</span><br><span class="line">│   ├── calico-node_arm64.tar.gz</span><br><span class="line">│   ├── calico-pod2daemon-flexvol_arm64.tar.gz</span><br><span class="line">│   ├── coredns_arm64.tar.gz</span><br><span class="line">│   ├── etcd_arm64.tar.gz</span><br><span class="line">│   ├── hccl-controller-v20.2.0-arm64.tar.gz</span><br><span class="line">│   ├── huawei-cadvisor-v0.34.0-r40-arm64.tar.gz</span><br><span class="line">│   ├── kube-apiserver_arm64.tar.gz</span><br><span class="line">│   ├── kube-controller-manager_arm64.tar.gz</span><br><span class="line">│   ├── kube-proxy_arm64.tar.gz</span><br><span class="line">│   ├── kube-scheduler_arm64.tar.gz</span><br><span class="line">│   ├── pause_arm64.tar.gz</span><br><span class="line">│   ├── vc-controller-manager-v1.0.1-r40-arm64.tar.gz</span><br><span class="line">│   ├── vc-scheduler-v1.0.1-r40-arm64.tar.gz</span><br><span class="line">│   ├── vc-webhook-manager-base-v1.0.1-r40-arm64.tar.gz</span><br><span class="line">│   └── vc-webhook-manager-v1.0.1-r40-arm64.tar.gz</span><br><span class="line">├── offline-pkg-arm64</span><br><span class="line">│   ├── conntrack_1%3a1.4.4+snapshot20161117-6ubuntu2_arm64.deb</span><br><span class="line">│   ├── cri-tools_1.13.0-01_arm64.deb</span><br><span class="line">│   ├── docker-ce_18.06.3~ce~3-0~ubuntu_arm64.deb</span><br><span class="line">│   ├── haveged_1.9.1-6_arm64.deb</span><br><span class="line">│   ├── keyutils_1.5.9-9.2ubuntu2_arm64.deb</span><br><span class="line">│   ├── kubeadm_1.17.3-00_arm64.deb</span><br><span class="line">│   ├── kubectl_1.17.3-00_arm64.deb</span><br><span class="line">│   ├── kubelet_1.17.3-00_arm64.deb</span><br><span class="line">│   ├── kubernetes-cni_0.8.6-00_arm64.deb</span><br><span class="line">│   ├── libhavege1_1.9.1-6_arm64.deb</span><br><span class="line">│   ├── libltdl7_2.4.6-2_arm64.deb</span><br><span class="line">│   ├── libnfsidmap2_0.25-5.1_arm64.deb</span><br><span class="line">│   ├── libtirpc1_0.2.5-1.2ubuntu0.1_arm64.deb</span><br><span class="line">│   ├── libtirpc-dev_0.2.5-1.2ubuntu0.1_arm64.deb</span><br><span class="line">│   ├── nfs-common_1%3a1.3.4-2.1ubuntu5.5_arm64.deb</span><br><span class="line">│   ├── nfs-kernel-server_1%3a1.3.4-2.1ubuntu5.5_arm64.deb</span><br><span class="line">│   ├── rpcbind_0.2.3-0.6ubuntu0.18.04.4_arm64.deb</span><br><span class="line">│   ├── socat_1.7.3.2-2ubuntu2_arm64.deb</span><br><span class="line">│   └── sshpass_1.06-1_arm64.deb</span><br><span class="line">├── offline-pkg-arm64.zip</span><br><span class="line">└── yamls</span><br><span class="line">    ├── ascendplugin-310-v20.2.0.yaml</span><br><span class="line">    ├── ascendplugin-volcano-v20.2.0.yaml</span><br><span class="line">    ├── cadvisor-v0.34.0-r40.yaml</span><br><span class="line">    ├── calico.yaml</span><br><span class="line">    ├── hccl-controller-v20.2.0.yaml</span><br><span class="line">    ├── npu-exporter-v20.2.0.yaml</span><br><span class="line">    └── volcano-v1.0.1-r40.yaml</span><br><span class="line"></span><br><span class="line">3 directories, 46 files</span><br><span class="line">root@ubuntu:~/123#</span><br></pre></td></tr></table></figure>

<p>注* 其中yamls文件在下方链接中下载  </p>
<p><a href="https://gitee.com/ascend/mindxdl-deploy/tree/20201230-V20.2.0/">https://gitee.com/ascend/mindxdl-deploy/tree/20201230-V20.2.0/</a></p>
<p>    6.配置免密登陆  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~# ssh-keygen</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/root/.ssh/id_rsa): </span><br><span class="line">Created directory &#x27;/root/.ssh&#x27;.</span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:07dTbsAycQqT2w7HdCwjIyJig5T20FQ/eHZGxWg7pbY root@ubuntu</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">| .+...   .+.     |</span><br><span class="line">|o+ .  o .+ +     |</span><br><span class="line">|+o+ ...=BoO +    |</span><br><span class="line">|...o .o.+/ O     |</span><br><span class="line">|        S @ + .  |</span><br><span class="line">|         E + =   |</span><br><span class="line">|          . o o  |</span><br><span class="line">|             o   |</span><br><span class="line">|                 |</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line">root@ubuntu:~# </span><br><span class="line">root@ubuntu:~# ssh-copy-id -i 127.0.0.1</span><br></pre></td></tr></table></figure>

<p>    7.配置安装ansible  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~# </span><br><span class="line">root@ubuntu:~# apt install ansible</span><br><span class="line">root@ubuntu:~# vim /etc/ansible/hosts</span><br><span class="line"></span><br><span class="line">#配置内容如下</span><br><span class="line">[all:vars]</span><br><span class="line"># default shared directory, you can change it as yours</span><br><span class="line">nfs_shared_dir=/data/atlas_dls</span><br><span class="line"></span><br><span class="line"># NFS service IP</span><br><span class="line">nfs_service_ip=192.168.1.110</span><br><span class="line"></span><br><span class="line"># Master IP</span><br><span class="line">master_ip=192.168.1.110</span><br><span class="line"></span><br><span class="line"># dls install package dir</span><br><span class="line">dls_root_dir=/root/123</span><br><span class="line"></span><br><span class="line"># set proxy</span><br><span class="line">proxy=&quot;&quot;</span><br><span class="line"></span><br><span class="line"># Command for logging in to the Asend hub</span><br><span class="line">ascendhub_login_command=&quot;login_command&quot;</span><br><span class="line"></span><br><span class="line"># Generally, you do not need to change the value or delete it.</span><br><span class="line">ascendhub_prefix=&quot;ascendhub.huawei.com/public-ascendhub&quot;</span><br><span class="line"></span><br><span class="line"># versions</span><br><span class="line">deviceplugin_version=&quot;v20.2.0&quot;</span><br><span class="line">cadvisor_version=&quot;v0.34.0-r40&quot;</span><br><span class="line">volcano_version=&quot;v1.0.1-r40&quot;</span><br><span class="line">hccl_version=&quot;v20.2.0&quot;</span><br><span class="line"></span><br><span class="line">[nfs_server]</span><br><span class="line">ubuntu ansible_host=192.168.1.110 ansible_ssh_user=&quot;root&quot; ansible_ssh_pass=&quot;123123&quot;</span><br><span class="line"></span><br><span class="line">[localnode]</span><br><span class="line">ubuntu ansible_host=192.168.1.110 ansible_ssh_user=&quot;root&quot; ansible_ssh_pass=&quot;123123&quot;</span><br><span class="line"></span><br><span class="line">[training_node]</span><br><span class="line">ubuntu ansible_host=192.168.1.110 ansible_ssh_user=&quot;root&quot; ansible_ssh_pass=&quot;123123&quot;</span><br><span class="line"></span><br><span class="line">[inference_node]</span><br><span class="line"></span><br><span class="line">[A300T_node]</span><br><span class="line"></span><br><span class="line">[arm]</span><br><span class="line">ubuntu ansible_host=192.168.1.110 ansible_ssh_user=&quot;root&quot; ansible_ssh_pass=&quot;123123&quot;</span><br><span class="line"></span><br><span class="line">[x86]</span><br><span class="line"></span><br><span class="line">[workers:children]</span><br><span class="line">training_node</span><br><span class="line">inference_node</span><br><span class="line">A300T_node</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@ubuntu:~/mindxdl/deploy/offline/steps# vim /etc/ansible/ansible.cfg</span><br><span class="line">log_path = /var/log/ansible.log</span><br><span class="line">host_key_checking = False</span><br><span class="line">deprecation_warnings = False</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注* 参数说明，请根据实际写入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nfs-host-ip：NFS节点服务器IP地址，即服务器IP地址，如果不安装NFS可设置为空字符串，如：&quot;&quot;。</span><br><span class="line">master-host-ip：管理节点服务器IP地址，即服务器IP地址。</span><br><span class="line">install_dir：基础软件包、镜像包和yamls文件夹的上传目录。</span><br><span class="line">proxy_address：代理地址，请根据实际情况配置，如果不需要代理，设置为空字符串，如：&quot;&quot;。</span><br><span class="line">login_command：从Ascend Hub中心获取镜像需要使用的登录命令，仅在线安装需要配置，如：&quot;docker login -u xxxxxx@xxxxxx -p xxxxxxxx ascendhub.huawei.com&quot;，注意不要遗漏命令前后的引号，获取方式请参见获取MindX DL镜像中1~2。离线安装可设置为空字符串，如：&quot;&quot;。</span><br><span class="line">single-node-host-name：请使用单节点主机名，可通过hostname命令查看。</span><br><span class="line">IP：服务器IP地址。</span><br><span class="line">username：登录服务器的用户名。建议使用root用户，避免权限不足。</span><br><span class="line">passwd：登录服务器的用户密码。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>二、一键安装  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~/sshpass# apt install sshpass</span><br><span class="line">root@ubuntu:~/mindxdl/deploy/offline/steps# dos2unix *</span><br><span class="line">root@ubuntu:~/mindxdl/deploy/offline/steps# chmod 500 entry.sh</span><br><span class="line">root@ubuntu:~/mindxdl/deploy/offline/steps# bash -x entry.sh</span><br></pre></td></tr></table></figure>

<p>三、安装后进行验证  </p>
<p>    1.docker信息查看  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~# docker info</span><br><span class="line">Containers: 35</span><br><span class="line"> Running: 30</span><br><span class="line"> Paused: 0</span><br><span class="line"> Stopped: 5</span><br><span class="line">Images: 18</span><br><span class="line">Server Version: 18.06.3-ce</span><br><span class="line">Storage Driver: overlay2</span><br><span class="line"> Backing Filesystem: extfs</span><br><span class="line"> Supports d_type: true</span><br><span class="line"> Native Overlay Diff: true</span><br><span class="line">Logging Driver: json-file</span><br><span class="line">Cgroup Driver: systemd</span><br><span class="line">Plugins:</span><br><span class="line"> Volume: local</span><br><span class="line"> Network: bridge host macvlan null overlay</span><br><span class="line"> Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog</span><br><span class="line">Swarm: inactive</span><br><span class="line">Runtimes: ascend runc</span><br><span class="line">Default Runtime: ascend</span><br><span class="line">Init Binary: docker-init</span><br><span class="line">containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e</span><br><span class="line">runc version: a592beb5bc4c4092b1b1bac971afed27687340c5</span><br><span class="line">init version: fec3683</span><br><span class="line">Security Options:</span><br><span class="line"> apparmor</span><br><span class="line"> seccomp</span><br><span class="line">  Profile: default</span><br><span class="line">Kernel Version: 4.15.0-112-generic</span><br><span class="line">Operating System: Ubuntu 18.04.5 LTS</span><br><span class="line">OSType: linux</span><br><span class="line">Architecture: aarch64</span><br><span class="line">CPUs: 192</span><br><span class="line">Total Memory: 503.6GiB</span><br><span class="line">Name: ubuntu</span><br><span class="line">ID: MUTU:QOYU:2P6F:P2QB:4JKZ:QNKE:PPMQ:PQLL:3PDG:QEYU:LMDK:KNMF</span><br><span class="line">Docker Root Dir: /var/lib/docker</span><br><span class="line">Debug Mode (client): false</span><br><span class="line">Debug Mode (server): false</span><br><span class="line">Registry: https://index.docker.io/v1/</span><br><span class="line">Labels:</span><br><span class="line">Experimental: false</span><br><span class="line">Insecure Registries:</span><br><span class="line"> docker.mirrors.ustc.edu.cn</span><br><span class="line"> 127.0.0.0/8</span><br><span class="line">Registry Mirrors:</span><br><span class="line"> https://dockerhub.azk8s.cn/</span><br><span class="line"> https://docker.mirrors.ustc.edu.cn/</span><br><span class="line"> http://hub-mirror.c.163.com/</span><br><span class="line">Live Restore Enabled: false</span><br><span class="line"></span><br><span class="line">WARNING: No swap limit support</span><br></pre></td></tr></table></figure>

<p>    2. kubectl的pod信息查看  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~# kubectl get pod --all-namespaces</span><br><span class="line">NAMESPACE        NAME                                       READY   STATUS      RESTARTS   AGE</span><br><span class="line">cadvisor         cadvisor-nsn4r                             1/1     Running     0          5m23s</span><br><span class="line">default          hccl-controller-645bb466f-5fqq6            1/1     Running     0          5m34s</span><br><span class="line">kube-system      ascend-device-plugin-daemonset-vxj8s       1/1     Running     0          5m23s</span><br><span class="line">kube-system      calico-kube-controllers-8464785d6b-bnjdn   1/1     Running     0          5m50s</span><br><span class="line">kube-system      calico-node-blshl                          1/1     Running     0          5m51s</span><br><span class="line">kube-system      coredns-6955765f44-5jr59                   1/1     Running     0          5m50s</span><br><span class="line">kube-system      coredns-6955765f44-wbzvz                   1/1     Running     0          5m50s</span><br><span class="line">kube-system      etcd-ubuntu                                1/1     Running     0          5m43s</span><br><span class="line">kube-system      kube-apiserver-ubuntu                      1/1     Running     0          5m43s</span><br><span class="line">kube-system      kube-controller-manager-ubuntu             1/1     Running     0          5m43s</span><br><span class="line">kube-system      kube-proxy-b78fm                           1/1     Running     0          5m51s</span><br><span class="line">kube-system      kube-scheduler-ubuntu                      1/1     Running     0          5m43s</span><br><span class="line">volcano-system   volcano-admission-74776688c8-g9p9q         1/1     Running     0          5m31s</span><br><span class="line">volcano-system   volcano-admission-init-sbktn               0/1     Completed   0          5m31s</span><br><span class="line">volcano-system   volcano-controllers-6786db54f-vn797        1/1     Running     0          5m31s</span><br><span class="line">volcano-system   volcano-scheduler-844f9b547b-xxjm7         1/1     Running     0          5m31s</span><br><span class="line">root@ubuntu:~# </span><br><span class="line">root@ubuntu:~# kubectl describe node ubuntu</span><br><span class="line">Name:               ubuntu</span><br><span class="line">Roles:              master,worker</span><br><span class="line">Labels:             accelerator=huawei-Ascend910</span><br><span class="line">                    beta.kubernetes.io/arch=arm64</span><br><span class="line">                    beta.kubernetes.io/os=linux</span><br><span class="line">                    host-arch=huawei-arm</span><br><span class="line">                    kubernetes.io/arch=arm64</span><br><span class="line">                    kubernetes.io/hostname=ubuntu</span><br><span class="line">                    kubernetes.io/os=linux</span><br><span class="line">                    masterselector=dls-master-node</span><br><span class="line">                    node-role.kubernetes.io/master=</span><br><span class="line">                    node-role.kubernetes.io/worker=worker</span><br><span class="line">                    workerselector=dls-worker-node</span><br><span class="line">Annotations:        huawei.com/Ascend910: Ascend910-1,Ascend910-2,Ascend910-3,Ascend910-0</span><br><span class="line">                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock</span><br><span class="line">                    node.alpha.kubernetes.io/ttl: 0</span><br><span class="line">                    projectcalico.org/IPv4Address: 192.168.1.110/24</span><br><span class="line">                    projectcalico.org/IPv4IPIPTunnelAddr: 10.30.243.192</span><br><span class="line">                    volumes.kubernetes.io/controller-managed-attach-detach: true</span><br><span class="line">CreationTimestamp:  Thu, 05 Aug 2021 16:34:33 +0800</span><br><span class="line">Taints:             &lt;none&gt;</span><br><span class="line">Unschedulable:      false</span><br><span class="line">Lease:</span><br><span class="line">  HolderIdentity:  ubuntu</span><br><span class="line">  AcquireTime:     &lt;unset&gt;</span><br><span class="line">  RenewTime:       Thu, 05 Aug 2021 16:41:29 +0800</span><br><span class="line">Conditions:</span><br><span class="line">  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----                 ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  NetworkUnavailable   False   Thu, 05 Aug 2021 16:35:06 +0800   Thu, 05 Aug 2021 16:35:06 +0800   CalicoIsUp                   Calico is running on this node</span><br><span class="line">  MemoryPressure       False   Thu, 05 Aug 2021 16:40:30 +0800   Thu, 05 Aug 2021 16:34:27 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure         False   Thu, 05 Aug 2021 16:40:30 +0800   Thu, 05 Aug 2021 16:34:27 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure</span><br><span class="line">  PIDPressure          False   Thu, 05 Aug 2021 16:40:30 +0800   Thu, 05 Aug 2021 16:34:27 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready                True    Thu, 05 Aug 2021 16:40:30 +0800   Thu, 05 Aug 2021 16:35:19 +0800   KubeletReady                 kubelet is posting ready status. AppArmor enabled</span><br><span class="line">Addresses:</span><br><span class="line">  InternalIP:  192.168.1.110</span><br><span class="line">  Hostname:    ubuntu</span><br><span class="line">Capacity:</span><br><span class="line">  cpu:                   192</span><br><span class="line">  ephemeral-storage:     920422204Ki</span><br><span class="line">  huawei.com/Ascend910:  4</span><br><span class="line">  hugepages-2Mi:         0</span><br><span class="line">  memory:                528101392Ki</span><br><span class="line">  pods:                  110</span><br><span class="line">Allocatable:</span><br><span class="line">  cpu:                   192</span><br><span class="line">  ephemeral-storage:     848261101802</span><br><span class="line">  huawei.com/Ascend910:  4</span><br><span class="line">  hugepages-2Mi:         0</span><br><span class="line">  memory:                527998992Ki</span><br><span class="line">  pods:                  110</span><br><span class="line">System Info:</span><br><span class="line">  Machine ID:                 3996e745414f461b9e0e990f6d0b597e</span><br><span class="line">  System UUID:                CD56756C-607E-BD02-EB11-5292EAFB068C</span><br><span class="line">  Boot ID:                    adb96127-7fdc-4d84-8867-a13005f9b535</span><br><span class="line">  Kernel Version:             4.15.0-112-generic</span><br><span class="line">  OS Image:                   Ubuntu 18.04.5 LTS</span><br><span class="line">  Operating System:           linux</span><br><span class="line">  Architecture:               arm64</span><br><span class="line">  Container Runtime Version:  docker://18.6.3</span><br><span class="line">  Kubelet Version:            v1.17.3</span><br><span class="line">  Kube-Proxy Version:         v1.17.3</span><br><span class="line">PodCIDR:                      10.30.0.0/24</span><br><span class="line">PodCIDRs:                     10.30.0.0/24</span><br><span class="line">Non-terminated Pods:          (15 in total)</span><br><span class="line">  Namespace                   Name                                        CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE</span><br><span class="line">  ---------                   ----                                        ------------  ----------  ---------------  -------------  ---</span><br><span class="line">  cadvisor                    cadvisor-nsn4r                              500m (0%)     1 (0%)      300Mi (0%)       2000Mi (0%)    6m17s</span><br><span class="line">  default                     hccl-controller-645bb466f-5fqq6             500m (0%)     500m (0%)   300Mi (0%)       300Mi (0%)     6m28s</span><br><span class="line">  kube-system                 ascend-device-plugin-daemonset-vxj8s        500m (0%)     500m (0%)   500Mi (0%)       500Mi (0%)     6m17s</span><br><span class="line">  kube-system                 calico-kube-controllers-8464785d6b-bnjdn    0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m44s</span><br><span class="line">  kube-system                 calico-node-blshl                           250m (0%)     0 (0%)      0 (0%)           0 (0%)         6m45s</span><br><span class="line">  kube-system                 coredns-6955765f44-5jr59                    100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     6m44s</span><br><span class="line">  kube-system                 coredns-6955765f44-wbzvz                    100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     6m44s</span><br><span class="line">  kube-system                 etcd-ubuntu                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m37s</span><br><span class="line">  kube-system                 kube-apiserver-ubuntu                       250m (0%)     0 (0%)      0 (0%)           0 (0%)         6m37s</span><br><span class="line">  kube-system                 kube-controller-manager-ubuntu              200m (0%)     0 (0%)      0 (0%)           0 (0%)         6m37s</span><br><span class="line">  kube-system                 kube-proxy-b78fm                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m45s</span><br><span class="line">  kube-system                 kube-scheduler-ubuntu                       100m (0%)     0 (0%)      0 (0%)           0 (0%)         6m37s</span><br><span class="line">  volcano-system              volcano-admission-74776688c8-g9p9q          500m (0%)     500m (0%)   300Mi (0%)       300Mi (0%)     6m25s</span><br><span class="line">  volcano-system              volcano-controllers-6786db54f-vn797         500m (0%)     500m (0%)   300Mi (0%)       300Mi (0%)     6m25s</span><br><span class="line">  volcano-system              volcano-scheduler-844f9b547b-xxjm7          500m (0%)     500m (0%)   300Mi (0%)       300Mi (0%)     6m25s</span><br><span class="line">Allocated resources:</span><br><span class="line">  (Total limits may be over 100 percent, i.e., overcommitted.)</span><br><span class="line">  Resource              Requests     Limits</span><br><span class="line">  --------              --------     ------</span><br><span class="line">  cpu                   4 (2%)       3500m (1%)</span><br><span class="line">  memory                2140Mi (0%)  4040Mi (0%)</span><br><span class="line">  ephemeral-storage     0 (0%)       0 (0%)</span><br><span class="line">  huawei.com/Ascend910  0            0</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason                   Age                    From                Message</span><br><span class="line">  ----    ------                   ----                   ----                -------</span><br><span class="line">  Normal  NodeHasSufficientMemory  7m10s (x8 over 7m11s)  kubelet, ubuntu     Node ubuntu status is now: NodeHasSufficientMemory</span><br><span class="line">  Normal  NodeHasNoDiskPressure    7m10s (x7 over 7m11s)  kubelet, ubuntu     Node ubuntu status is now: NodeHasNoDiskPressure</span><br><span class="line">  Normal  NodeHasSufficientPID     7m10s (x6 over 7m11s)  kubelet, ubuntu     Node ubuntu status is now: NodeHasSufficientPID</span><br><span class="line">  Normal  Starting                 6m37s                  kubelet, ubuntu     Starting kubelet.</span><br><span class="line">  Normal  NodeHasSufficientMemory  6m37s                  kubelet, ubuntu     Node ubuntu status is now: NodeHasSufficientMemory</span><br><span class="line">  Normal  NodeHasNoDiskPressure    6m37s                  kubelet, ubuntu     Node ubuntu status is now: NodeHasNoDiskPressure</span><br><span class="line">  Normal  NodeHasSufficientPID     6m37s                  kubelet, ubuntu     Node ubuntu status is now: NodeHasSufficientPID</span><br><span class="line">  Normal  NodeAllocatableEnforced  6m37s                  kubelet, ubuntu     Updated Node Allocatable limit across pods</span><br><span class="line">  Normal  Starting                 6m33s                  kube-proxy, ubuntu  Starting kube-proxy.</span><br><span class="line">  Normal  NodeReady                6m17s                  kubelet, ubuntu     Node ubuntu status is now: NodeReady</span><br><span class="line">root@ubuntu:~#</span><br></pre></td></tr></table></figure>

<p>注* 再此信息中可以看到CPU和加速卡的信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Capacity:</span><br><span class="line">  cpu:                   192</span><br><span class="line">  ephemeral-storage:     920422204Ki</span><br><span class="line">  huawei.com/Ascend910:  4</span><br><span class="line">  hugepages-2Mi:         0</span><br><span class="line">  memory:                528101392Ki</span><br><span class="line">  pods:                  110</span><br><span class="line">Allocatable:</span><br><span class="line">  cpu:                   192</span><br><span class="line">  ephemeral-storage:     848261101802</span><br><span class="line">  huawei.com/Ascend910:  4</span><br><span class="line">  hugepages-2Mi:         0</span><br><span class="line">  memory:                527998992Ki</span><br><span class="line">  pods:                  110</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5192ab3e43e640fd8d935795ea96b768~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>**详情可以查看华为官方文档：<br>**</p>
<p><strong><a href="https://support.huaweicloud.com/mindxdl201/">https://support.huaweicloud.com/mindxdl201/</a></strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ce668ce68dbc4666a4b7ad3a8f24d97e~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/18e44bcfb97e4d2b8d720b70f986d10e~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>30篇原创内容</p>
<p>公众号</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>华为人工智能atlasA800-9000物理服务器离线安装及CANN安装和MindSpore安装和Tensorflow安装</title>
    <url>/2021/12/30/2021-12-30-%E5%8D%8E%E4%B8%BA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDatlasA800-9000%E7%89%A9%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E5%8F%8ACANN%E5%AE%89%E8%A3%85%E5%92%8CMindSpore%E5%AE%89%E8%A3%85%E5%92%8CTensorflow%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>目录</p>
<p>华为人工智能atlas A800-9000 物理服务器全程离线安装驱动以及CANN安装部署和MindSpore安装部署和Tensorflow安装部署</p>
<p>A800-9000 物理服务器安装驱动</p>
<p>使用镜像配置本地apt源</p>
<p>创建普通用户并设置密码</p>
<p>安装驱动以及固件</p>
<p>验证是否安装成功</p>
<p>CANN开发环境部署安装</p>
<p>安装环境以及依赖</p>
<p>安装完成后查看版本</p>
<p>安装Python3.7.5</p>
<p>使用Python3.7.5环境安装pip依赖包</p>
<p>安装开发套件包</p>
<p>CANN训练环境部署安装</p>
<p>说明</p>
<p>安装训练软件包</p>
<p>安装MindSpore</p>
<p>安装whl包</p>
<p>配置环境变量</p>
<p>测试是否可行</p>
<p>安装mindinsight</p>
<p>安装whl包</p>
<p>配置环境变量</p>
<p>启动及使用</p>
<p>安装Tensorflow</p>
<p>编译hdf5</p>
<p>配置环境变量及软连接</p>
<p>安装whl包</p>
<p>安装Pytorch</p>
<p><strong>华为人工智能atlas A800-9000 物理服务器全程离线安装驱动以及CANN安装部署和MindSpore安装部署和Tensorflow安装部署</strong></p>
<p>背景</p>
<p>Atlas 800 训练服务器（型号：9000）是基于华为鲲鹏920+昇腾910处理器的AI训练服务器，具有最强算力密度、超高能效与高速网络带宽等特点。该服务器广泛应用于深度学习模型开发和训练，适用于智慧城市、智慧医疗、天文探索、石油勘探等需要大算力的行业领域。</p>
<p>链接：</p>
<p>&#96;&#96;&#96;shell<br><a href="https://e.huawei.com/cn/products/cloud-computing-dc/atlas/atlas-800-training-9000">https://e.huawei.com/cn/products/cloud-computing-dc/atlas/atlas-800-training-9000</a></p>
<p>&#96;&#96;&#96;shell</p>
<p>CANN (Compute Architecture for Neural Networks)</p>
<p>是华为公司针对AI场景推出的异构计算架构，通过提供多层次的编程接口，支持用户快速构建基于昇腾平台的AI应用和业务。</p>
<p>链接：  </p>
<p>&#96;&#96;&#96;shell<br><a href="https://e.huawei.com/cn/products/cloud-computing-dc/atlas/cann">https://e.huawei.com/cn/products/cloud-computing-dc/atlas/cann</a></p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1f089f5ea12d4b2a96f1bc04c4b417d9~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>MindSpore，新一代AI开源计算框架。</p>
<p>创新编程范式，AI科学家和工程师更易使用，便于开放式创新；该计算框架可满足终端、边缘计算、云全场景需求，能更好保护数据隐私；可开源，形成广阔应用生态。</p>
<p>链接：  </p>
<p>&#96;&#96;&#96;shell<br><a href="https://www.mindspore.cn/">https://www.mindspore.cn/</a></p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b5b21ad3d5d04fc8816abcd6a6bd80b9~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>TensorFlow最初由谷歌大脑团队开发，用于Google的研究和生产，于2015年11月9日在Apache 2.0开源许可证下发布。  </p>
<p>链接：  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3fcf527d2f6b47a9bdff1e349a3ee280~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>&#96;&#96;&#96;shell<br><a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a></p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>A800-9000****物理服务器安装驱动</strong></p>
<p><strong>使用镜像配置本地apt源</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;etc&#x2F;apt# mkdir&#x2F;media&#x2F;cdrom<br>root@ubuntu:&#x2F;etc&#x2F;apt# mount&#x2F;home&#x2F;cby&#x2F;ubuntu-18.04.5-server-arm64.iso &#x2F;media&#x2F;cdrom<br>mount: &#x2F;media&#x2F;chrom: WARNING:device write-protected, mounted read-only.<br>root@ubuntu:&#x2F;etc&#x2F;apt# apt-cdrom-m -d&#x3D;&#x2F;media&#x2F;cdrom&#x2F; add<br>root@ubuntu:&#x2F;etc&#x2F;apt# cat&#x2F;etc&#x2F;apt&#x2F;sources.list</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>创建普通用户并设置密码</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:<del>#groupadd HwHiAiUser<br>root@ubuntu:</del>#useradd -g HwHiAiUser -d &#x2F;home&#x2F;HwHiAiUser -m HwHiAiUser<br>root@ubuntu:~#passwd HwHiAiUser<br>Enter newUNIX password:<br>Retype newUNIX password:<br>passwd:password updated successfully</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>安装驱动以及固件</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:~# cd &#x2F;home&#x2F;cby&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby# ll<br>total 98324<br>drwxr-xr-x 4 cby  cby     4096 Apr 21 21:41 .&#x2F;<br>drwxr-xr-x 4 root root     4096 Apr 21 21:44 ..&#x2F;<br>-rw-r–r– 1 cby  cby 99728721 Apr 21 21:41A800-9000-npu-driver_20.2.0_ubuntu18.04-aarch64.run<br>-rw-r–r– 1 cby  cby   912335 Apr 21 21:41 A800-9000-npu-firmware_1.76.22.3.220.run<br>root@ubuntu:&#x2F;home&#x2F;cby# chmod +x*.run<br>root@ubuntu:&#x2F;home&#x2F;cby# ll<br>total 98324<br>drwxr-xr-x 4 cby  cby     4096 Apr 21 21:41 .&#x2F;<br>drwxr-xr-x 4 root root     4096 Apr 21 21:44 ..&#x2F;<br>-rwxr-xr-x 1 cby  cby 99728721 Apr 21 21:41 A800-9000-npu-driver_20.2.0_ubuntu18.04-aarch64.run*<br>-rwxr-xr-x 1 cby  cby   912335 Apr 21 21:41 A800-9000-npu-firmware_1.76.22.3.220.run*<br>root@ubuntu:&#x2F;home&#x2F;cby# aptinstall gcc<br>root@ubuntu:&#x2F;home&#x2F;cby# aptinstall make<br>root@ubuntu:&#x2F;home&#x2F;cby#.&#x2F;A800-9000-npu-driver_20.2.0_ubuntu18.04-aarch64.run –run<br>root@ubuntu:&#x2F;home&#x2F;cby#.&#x2F;A800-9000-npu-firmware_1.76.22.3.220.run –run</p>
<p>&#96;&#96;&#96;shell</p>
<p>*注意：安装完成后需要重启服务器</p>
<p><strong>验证是否安装成功</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby#npu-smi info</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1066a0a3d8d644b98b26c8196c6044fc~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>CANN****开发环境部署安装</strong>  </p>
<p><strong>安装环境以及依赖</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby# apt install g++<br>root@ubuntu:&#x2F;home&#x2F;cby# cd cmake&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cmake# ll<br>total 4356<br>drwxr-xr-x 2 root root    4096 Apr 21 23:48 .&#x2F;<br>drwxr-xr-x 7 cby  cby    4096 Apr 21 23:48 ..&#x2F;<br>-rw-r–r– 1 cby  cby 2971248 Apr 21 23:45 cmake_3.10.2-1ubuntu2.18.04.1_arm64.deb<br>-rw-r–r– 1 cby  cby 1331524 Apr 21 23:45 cmake-data_3.10.2-1ubuntu2.18.04.1_all.deb<br>-rw-r–r– 1 cby  cby   69166 Apr 21 23:47 libjsoncpp1_1.7.4-3_arm64.deb<br>-rw-r–r– 1 cby  cby   71788 Apr 21 23:48 librhash0_1.3.6-2_arm64.deb<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cmake# apt install.&#x2F;*<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cmake# make–version</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby# apt install.&#x2F;zlib1g-dev_1%3a1.2.11.dfsg-0ubuntu2_arm64.deb<br>root@ubuntu:&#x2F;home&#x2F;cby# apt install.&#x2F;libbz2-dev_1.0.6-8.1ubuntu0.2_arm64.deb<br>root@ubuntu:&#x2F;home&#x2F;cby# apt install .&#x2F;libsqlite3-dev_3.22.0-1ubuntu0.4_arm64.deb</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby# cd libssl-dev&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;libssl-dev#apt install .&#x2F;*</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby# cd libxslt1-dev&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;libxslt1-dev#ll<br>total 13596<br>drwxr-xr-x  2 root root   4096 Apr 22 00:37 .&#x2F;<br>drwxr-xr-x 10 cby  cby    4096 Apr 22 00:37 ..&#x2F;<br>-rw-r–r–  1 cby cby    18528 Apr 22 00:30gir1.2-harfbuzz-0.0_1.7.2-1ubuntu1_arm64.deb<br>-rw-r–r–  1 cby cby   170204 Apr 22 00:27icu-devtools_60.2-3ubuntu3.1_arm64.deb<br>-rw-r–r–  1 cby cby   983364 Apr 22 00:37libglib2.0-0_2.56.4-0ubuntu0.18.04.8_arm64.deb<br>-rw-r–r–  1 cby cby    61832 Apr 22 00:33libglib2.0-bin_2.56.4-0ubuntu0.18.04.8_arm64.deb<br>-rw-r–r–  1 cby cby  1297600 Apr 22 00:31libglib2.0-dev_2.56.4-0ubuntu0.18.04.8_arm64.deb<br>-rw-r–r–  1 cby cby    99676 Apr 22 00:31libglib2.0-dev-bin_2.56.4-0ubuntu0.18.04.8_arm64.deb<br>-rw-r–r–  1 cby cby    14528 Apr 22 00:32libgraphite2-dev_1.3.11-2_arm64.deb<br>-rw-r–r–  1 cby cby   280584 Apr 22 00:28libharfbuzz-dev_1.7.2-1ubuntu1_arm64.deb<br>-rw-r–r–  1 cby cby    12556 Apr 22 00:30libharfbuzz-gobject0_1.7.2-1ubuntu1_arm64.deb<br>-rw-r–r–  1 cby cby     5348 Apr 22 00:29libharfbuzz-icu0_1.7.2-1ubuntu1_arm64.deb<br>-rw-r–r–  1 cby cby  8890124 Apr 22 00:26libicu-dev_60.2-3ubuntu3.1_arm64.deb<br>-rw-r–r–  1 cby cby    14412 Apr 22 00:28libicu-le-hb0_1.0.3+git161113-4_arm64.deb<br>-rw-r–r–  1 cby cby    29760 Apr 22 00:27libicu-le-hb-dev_1.0.3+git161113-4_arm64.deb<br>-rw-r–r–  1 cby cby    18756 Apr 22 00:26libiculx60_60.2-3ubuntu3.1_arm64.deb<br>-rw-r–r–  1 cby cby   120696 Apr 22 00:35libpcre16-3_2%3a8.39-9_arm64.deb<br>-rw-r–r–  1 cby cby   113240 Apr 22 00:35libpcre32-3_2%3a8.39-9_arm64.deb<br>-rw-r–r–  1 cby cby   459316 Apr 22 00:33libpcre3-dev_2%3a8.39-9_arm64.deb<br>-rw-r–r–  1 cby cby    15124 Apr 22 00:35libpcrecpp0v5_2%3a8.39-9_arm64.deb<br>-rw-r–r–  1 cby cby   673384 Apr 22 00:25libxml2-dev_2.9.4+dfsg1-6.1ubuntu1.3_arm64.deb<br>-rw-r–r–  1 cby cby   395564 Apr 22 00:24libxslt1-dev_1.1.29-5ubuntu0.2_arm64.deb<br>-rw-r–r–  1 cby cby    42802 Apr 22 00:33pkg-config_0.29.1-0ubuntu2_arm64.deb<br>-rw-r–r–  1 cby cby   144176 Apr 22 00:37python3-distutils_3.6.9-1~18.04_all.deb<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;libxslt1-dev#apt install .&#x2F;*</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby# cd libffi-dev&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;libffi-dev#ls<br>libffi-dev_3.2.1-8_arm64.deb<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;libffi-dev#apt install .&#x2F;*</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby#apt install unzip<br>root@ubuntu:&#x2F;home&#x2F;cby# apt install.&#x2F;libblas-dev_3.7.1-4ubuntu1_arm64.deb</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby# cd gfortran&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;gfortran#ll<br>total 7844<br>drwxr-xr-x  2 root root   4096 Apr 22 00:50 .&#x2F;<br>drwxr-xr-x 12cby  cby     4096 Apr 22 00:50 ..&#x2F;<br>-rw-r–r–  1 cby cby     1344 Apr 22 00:48gfortran_4%3a7.4.0-1ubuntu2.3_arm64.deb<br>-rw-r–r–  1 cby cby  7464740 Apr 22 00:48gfortran-7_7.5.0-3ubuntu1<del>18.04_arm64.deb<br>-rw-r–r–  1 cby cby   248176 Apr 22 00:50libgfortran4_7.5.0-3ubuntu1</del>18.04_arm64.deb<br>-rw-r–r–  1 cby cby   300500 Apr 22 00:49libgfortran-7-dev_7.5.0-3ubuntu1~18.04_arm64.deb<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;gfortran#apt install .&#x2F;*</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby# cd libblas3&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;libblas3#apt install .&#x2F;libblas3_3.7.1-4ubuntu1_arm64.deb</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby# cdlibopenblas-dev&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;libopenblas-dev#ll<br>total 3412<br>drwxr-xr-x  2 root root   4096 Apr 22 00:56 .&#x2F;<br>drwxr-xr-x 14cby  cby     4096 Apr 22 00:56 ..&#x2F;<br>-rw-r–r–  1 cby cby  1813748 Apr 22 00:55libopenblas-base_0.2.20+ds-4_arm64.deb<br>-rw-r–r–  1 cby cby  1668126 Apr 22 00:54libopenblas-dev_0.2.20+ds-4_arm64.deb<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;libopenblas-dev#apt install .&#x2F;*</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>安装完成后查看版本</strong></p>
<p>&#96;&#96;&#96;shell<br>gcc –version<br>g++ –version<br>make –version<br>cmake –version<br>dpkg -l zlib1g| grepzlib1g| grep ii<br>dpkg -l zlib1g-dev|grep zlib1g-dev| grep ii<br>dpkg -l libbz2-dev|grep libbz2-dev| grep ii<br>dpkg -llibsqlite3-dev| grep libsqlite3-dev| grep ii<br>dpkg -l openssl| grepopenssl| grep ii<br>dpkg -l libssl-dev|grep libssl-dev| grep ii<br>dpkg -l libxslt1-dev|grep libxslt1-dev| grep ii<br>dpkg -l libffi-dev|grep libffi-dev| grep ii<br>dpkg -l unzip| grepunzip| grep ii<br>dpkg -l pciutils|grep pciutils| grep ii<br>dpkg -l net-tools|grep net-tools| grep ii<br>dpkg -l libblas-dev|grep libblas-dev| grep ii<br>dpkg -l gfortran|grep gfortran| grep ii<br>dpkg -l libblas3|grep libblas3| grep ii<br>dpkg -llibopenblas-dev| grep libopenblas-dev| grep ii</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>安装Python3.7.5</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;python#tar xvf Python3.7.5.tar<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;python# cdPython-3.7.5&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;python&#x2F;Python-3.7.5#.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;python3.7.5 –enable-loadable-sqlite-extensions–enable-shared<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;python&#x2F;Python-3.7.5#make<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;python&#x2F;Python-3.7.5#make install</p>
<p>root@ubuntu:&#x2F;home&#x2F;cby# sudo ln -s&#x2F;usr&#x2F;local&#x2F;python3.7.5&#x2F;bin&#x2F;pip3 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;pip3.7.5<br>root@ubuntu:&#x2F;home&#x2F;cby# sudo ln-s &#x2F;usr&#x2F;local&#x2F;python3.7.5&#x2F;bin&#x2F;python3 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;python3.7.5<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cann_xunlian#sudo ln -s &#x2F;usr&#x2F;local&#x2F;python3.7.5&#x2F;bin&#x2F;python3 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;python3.7<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cann_xunlian#sudo ln -s &#x2F;usr&#x2F;local&#x2F;python3.7.5&#x2F;bin&#x2F;pip3 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;pip3.7</p>
<p>root@ubuntu:&#x2F;home&#x2F;cby# vim ~&#x2F;.bashrc<br>exportLD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;python3.7.5&#x2F;lib:$LD_LIBRARY_PATH</p>
<p>root@ubuntu:&#x2F;home&#x2F;cby#python3.7.5 –version<br>Python 3.7.5<br>root@ubuntu:&#x2F;home&#x2F;cby# pip3.7.5–version<br>pip 19.2.3 from &#x2F;usr&#x2F;local&#x2F;python3.7.5&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;pip(python 3.7)</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>使用Python3.7.5环境安装pip依赖包</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack# tar xvfpip_pack.tar<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;attrs-20.3.0-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;numpy-1.17.2-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;decorator-5.0.6-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;mpmath-1.2.1-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;sympy-1.4-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;pycparser-2.20-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;cffi-1.12.3.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;PyYAML-5.3.1.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;six-1.15.0-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;pathlib2-2.3.5-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;psutil-5.8.0.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;protobuf-3.15.8-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;scipy-1.6.0-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;chardet-3.0.4-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;idna-2.10-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;urllib3-1.25.10-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;certifi-2020.6.20-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;certifi-2020.6.20-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;requests-2.24.0-py2.py3-none-any.wh<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pip-pack&#x2F;pip_pack#pip3.7.5 install .&#x2F;xlrd-1.2.0-py2.py3-none-any.whl</p>
<p>&#96;&#96;&#96;shell</p>
<p> <strong>*注意：以上pip包的安装必须以该顺序依次进行安装</strong></p>
<p><strong>安装开发套件包</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cann#.&#x2F;Ascend-cann-tfplugin_20.2.rc1_linux-aarch64.run –install<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cann#.&#x2F;Ascend-cann-toolkit_20.2.rc1_linux-aarch64.run –install</p>
<p>&#96;&#96;&#96;shell</p>
<p>    出现install success后表示安装成功。  </p>
<p><strong>CANN****训练环境部署安装</strong></p>
<p><strong>说明</strong></p>
<p>       训练环境的Python3.7.5和环境以及依赖，和开发环境下的安装方式一样，可参考《CANN开发环境部署安装》文档进行安装。在已经搭建好的开发环境中，进行安装训练环境仅需安装一下训练软件包和实用工具包即可。</p>
<p><strong>安装训练软件包</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cann_xunlian# chmod+x .&#x2F;*.run<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cann_xunlian# .&#x2F;Ascend-cann-nnae_20.2.rc1_linux-aarch64.run–install<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;cann_xunlian#.&#x2F;Ascend-cann-toolbox_20.2.rc1_linux-aarch64.run –install</p>
<p>&#96;&#96;&#96;shell</p>
<p>       出现install success后表示安装成功。</p>
<p><strong>安装MindSpore</strong></p>
<p><strong>安装whl包</strong></p>
<p>        安装Ascend 910 AI处理器配套软件包提供的whl包，whl包随配套软件包发布，升级配套软件包之后需要重新安装。</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend#pip3.7.5 install &#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;ascend-toolkit&#x2F;latest&#x2F;fwkacllib&#x2F;lib64&#x2F;hccl-0.1.0-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend#pip3.7.5 install &#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;ascend-toolkit&#x2F;latest&#x2F;fwkacllib&#x2F;lib64&#x2F;te-0.4.0-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend#pip3.7.5 install &#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;ascend-toolkit&#x2F;latest&#x2F;fwkacllib&#x2F;lib64&#x2F;topi-0.4.0-py3-none-any.whl</p>
<p>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install easydict-1.9.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install .&#x2F;wheel-0.36.2-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install .&#x2F;astunparse-1.6.3-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install .&#x2F;Pillow-8.2.0-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install .&#x2F;asttokens-2.0.4-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install .&#x2F;cffi-1.14.5-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install .&#x2F;pyparsing-2.4.7-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install .&#x2F;packaging-20.9-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindspore_ascend&#x2F;pip#pip3.7.5 install ..&#x2F;mindspore_ascend-1.1.1-cp37-cp37m-linux_aarch64.whl</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>*注意：安装时必须以此顺序进行安装</strong></p>
<p><strong>配置环境变量</strong></p>
<p>&#96;&#96;&#96;shell<br># control log level.0-DEBUG, 1-INFO, 2-WARNING, 3-ERROR, default level is WARNING.</p>
<p>export GLOG_v&#x3D;2</p>
<h1 id="Conda-environmentaloptions"><a href="#Conda-environmentaloptions" class="headerlink" title="Conda environmentaloptions"></a>Conda environmentaloptions</h1><p>LOCAL_ASCEND&#x3D;&#x2F;usr&#x2F;local&#x2F;Ascend</p>
<h1 id="the-root-directoryof-run-package"><a href="#the-root-directoryof-run-package" class="headerlink" title="the root directoryof run package"></a>the root directoryof run package</h1><h1 id="lib-libraries-thatthe-run-package-depends-on"><a href="#lib-libraries-thatthe-run-package-depends-on" class="headerlink" title="lib libraries thatthe run package depends on"></a>lib libraries thatthe run package depends on</h1><p>exportLD_LIBRARY_PATH&#x3D;${LOCAL_ASCEND}&#x2F;add-ons&#x2F;:${LOCAL_ASCEND}&#x2F;ascend-toolkit&#x2F;latest&#x2F;fwkacllib&#x2F;lib64:${LOCAL_ASCEND}&#x2F;driver&#x2F;lib64:${LOCAL_ASCEND}&#x2F;opp&#x2F;op_impl&#x2F;built-in&#x2F;ai_core&#x2F;tbe&#x2F;op_tiling:${LD_LIBRARY_PATH}</p>
<h1 id="Environmentvariables-that-must-be-configured"><a href="#Environmentvariables-that-must-be-configured" class="headerlink" title="Environmentvariables that must be configured"></a>Environmentvariables that must be configured</h1><p>exportTBE_IMPL_PATH&#x3D;${LOCAL_ASCEND}&#x2F;ascend-toolkit&#x2F;latest&#x2F;opp&#x2F;op_impl&#x2F;built-in&#x2F;ai_core&#x2F;tbe</p>
<h1 id="TBE-operatorimplementation-tool-path"><a href="#TBE-operatorimplementation-tool-path" class="headerlink" title="TBE operatorimplementation tool path"></a>TBE operatorimplementation tool path</h1><p>exportASCEND_OPP_PATH&#x3D;${LOCAL_ASCEND}&#x2F;ascend-toolkit&#x2F;latest&#x2F;opp</p>
<h1 id="OPP-path"><a href="#OPP-path" class="headerlink" title="OPP path"></a>OPP path</h1><p>exportPATH&#x3D;${LOCAL_ASCEND}&#x2F;ascend-toolkit&#x2F;latest&#x2F;fwkacllib&#x2F;ccec_compiler&#x2F;bin&#x2F;:${PATH}</p>
<h1 id="TBE-operatorcompilation-tool-path"><a href="#TBE-operatorcompilation-tool-path" class="headerlink" title="TBE operatorcompilation tool path"></a>TBE operatorcompilation tool path</h1><p>exportPYTHONPATH&#x3D;${TBE_IMPL_PATH}:${PYTHONPATH}</p>
<h1 id="Python-library-thatTBE-implementation-depends-on"><a href="#Python-library-thatTBE-implementation-depends-on" class="headerlink" title="Python library thatTBE implementation depends on"></a>Python library thatTBE implementation depends on</h1><p>&#96;&#96;&#96;shell</p>
<p><strong>测试是否可行</strong></p>
<p>Python代码内容：</p>
<p>&#96;&#96;&#96;shell<br>import numpy as np<br>from mindspore importTensor<br>import mindspore.opsas ops<br>importmindspore.context as context</p>
<p>context.set_context(device_target&#x3D;”Ascend”)</p>
<p>x &#x3D;Tensor(np.ones([1,3,3,4]).astype(np.float32))<br>y &#x3D;Tensor(np.ones([1,3,3,4]).astype(np.float32))<br>print(ops.tensor_add(x,y))</p>
<p>&#96;&#96;&#96;shell</p>
<p>出现此结果即是安装部署完成</p>
<p>&#96;&#96;&#96;shell<br>[[[[2. 2. 2. 2.]<br>   [2. 2. 2. 2.]<br>   [2. 2. 2. 2.]]</p>
<p>  [[2. 2. 2. 2.]<br>   [2. 2. 2. 2.]<br>   [2. 2. 2. 2.]]</p>
<p>  [[2. 2. 2. 2.]<br>   [2. 2. 2. 2.]<br>   [2. 2. 2. 2.]]]]</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>安装mindinsight</strong></p>
<p><strong>安装whl包</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;itsdangerous-1.1.0-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;Werkzeug-1.0.1-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;MarkupSafe-1.1.1-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;Jinja2-2.11.3-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;click-7.1.2-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;Flask-1.1.2-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;Flask_Cors-3.0.10-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;yapf-0.31.0-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;future-0.18.2.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;treelib-1.6.1.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;grpcio-1.37.0-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;google_pasta-0.2.0-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;pytz-2021.1-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;python_dateutil-2.8.1-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;pandas-1.2.3-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;gunicorn-20.1.0.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;marshmallow-3.11.1-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;threadpoolctl-2.1.0-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;joblib-1.0.1-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;scikit_learn-0.24.1-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;mindinsight&#x2F;Mindinsight#pip3.7.5 install .&#x2F;mindinsight-1.1.1-cp37-cp37m-linux_aarch64.whl</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>*注意：安装必须以此顺序进安装</strong></p>
<p><strong>配置环境变量</strong></p>
<p>在配置文件中配置如下变量</p>
<p>&#96;&#96;&#96;shell<br>PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;python3.7.5&#x2F;bin&#x2F;</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby#source &#x2F;etc&#x2F;profile</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>启动及使用</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby#mindinsight start<br>Workspace:&#x2F;root&#x2F;mindinsight<br>Webaddress: <a href="http://127.0.0.1:8080/">http://127.0.0.1:8080</a><br>servicestart state: success</p>
<p>&#96;&#96;&#96;shell</p>
<p>    出现该消息后，说明可视化已经启动成功，若需要外机访问的话，需要进行反向代理到0.0.0.0上面即可，比如frp工具即可实现该操作</p>
<p>    在训练完成的Python代码目录下，使以下命令即可启动并展示该目录下的训练数据，debugger的参数可使用false或者true</p>
<p>&#96;&#96;&#96;shell<br>mindinsightstart –summary-base-dir . –port 8080 –enable-debugger True –debugger-port50051</p>
<p>&#96;&#96;&#96;shell</p>
<p>使用如下命令即可启动训练</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;lenet&#x2F;lenet#python3.7.5 lenet.py –device_target&#x3D;Ascend</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>安装Tensorflow</strong></p>
<p><strong>编译hdf5</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#cd hdf5-1.10.5&#x2F;<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow&#x2F;hdf5-1.10.5#.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;include&#x2F;hdf5<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow&#x2F;hdf5-1.10.5#make<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow&#x2F;hdf5-1.10.5#make install</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>配置环境变量及软连接</strong></p>
<p>&#96;&#96;&#96;shell<br>exportCPATH&#x3D;”&#x2F;usr&#x2F;include&#x2F;hdf5&#x2F;include&#x2F;:&#x2F;usr&#x2F;include&#x2F;hdf5&#x2F;lib&#x2F;“<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow&#x2F;hdf5-1.10.5#ln -s &#x2F;usr&#x2F;include&#x2F;hdf5&#x2F;lib&#x2F;libhdf5.so &#x2F;usr&#x2F;lib&#x2F;libhdf5.so<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow&#x2F;hdf5-1.10.5#ln -s &#x2F;usr&#x2F;include&#x2F;hdf5&#x2F;lib&#x2F;libhdf5_hl.so &#x2F;usr&#x2F;lib&#x2F;libhdf5_hl.so</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>安装whl包</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;Cython-0.29.21-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;h5py-2.10.0-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;grpcio-1.30.0.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;gast-0.2.2.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;opt_einsum-3.3.0-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;Keras_Applications-1.0.8-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;Keras_Preprocessing-1.1.2-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;astor-0.8.1-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;typing_extensions-3.7.4.3-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;zipp-3.4.1-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;importlib_metadata-3.10.1-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;Markdown-3.2.2-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;tensorboard-1.15.0-py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;wrapt-1.12.1.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;tensorflow_estimator-1.15.1-py2.py3-none-any.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;termcolor-1.1.0.tar.gz<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;Tensorflow&#x2F;Tensorflow#pip3.7.5 install .&#x2F;tensorflow-1.15.0-cp37-cp37m-linux_aarch64.whl</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>注意：必须依次安装</strong></p>
<p><strong>安装Pytorch</strong></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pytorch&#x2F;Pytorch#pip3.7.5 install .&#x2F;apex-0.1+ascend-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pytorch&#x2F;Pytorch#pip3.7.5 install .&#x2F;torch-1.5.0+ascend.post2-cp37-cp37m-linux_aarch64.whl<br>root@ubuntu:&#x2F;home&#x2F;cby&#x2F;pytorch&#x2F;Pytorch#pip3.7.5 install .&#x2F;future-0.18.2.tar.gz</p>
<p>&#96;&#96;&#96;shell</p>
<p>该文章所配套的软件包关注微信公众号回复 ai 即可获取所需要的所有软件包  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/77094ff7a2294266a68d51827856684e~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>20篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2db21b727fad415d83915de139e7faa1~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>在Kubernetes（k8s）中使用GPU</title>
    <url>/2021/12/30/2021-12-30-%E5%9C%A8Kubernetes%EF%BC%88k8s%EF%BC%89%E4%B8%AD%E4%BD%BF%E7%94%A8GPU/</url>
    <content><![CDATA[<p><strong>介绍</strong></p>
<p>Kubernetes 支持对节点上的 AMD 和 NVIDIA GPU （图形处理单元）进行管理，目前处于实验状态。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9fc5a51a80554d3da93e0f810a67e9d3~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>修改docker配置文件</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;default-runtime&quot;: &quot;nvidia&quot;,</span><br><span class="line">    &quot;runtimes&quot;: &#123;</span><br><span class="line">        &quot;nvidia&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span><br><span class="line">            &quot;runtimeArgs&quot;: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">  &quot;data-root&quot;: &quot;/var/lib/docker&quot;,</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;registry-mirrors&quot;: [</span><br><span class="line">    &quot;https://docker.mirrors.ustc.edu.cn&quot;,</span><br><span class="line">    &quot;http://hub-mirror.c.163.com&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;insecure-registries&quot;: [&quot;127.0.0.1/8&quot;],</span><br><span class="line">  &quot;max-concurrent-downloads&quot;: 10,</span><br><span class="line">  &quot;live-restore&quot;: true,</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-level&quot;: &quot;warn&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;50m&quot;,</span><br><span class="line">    &quot;max-file&quot;: &quot;1&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;</span><br><span class="line">&#125;</span><br><span class="line">root@hello:~#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# systemctl  daemon-reload</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# systemctl  start docker</span><br></pre></td></tr></table></figure>

<p><strong>添加标签</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl label nodes 192.168.1.56 nvidia.com/gpu.present=true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl get nodes -L nvidia.com/gpu.present</span><br><span class="line">NAME           STATUS                     ROLES    AGE    VERSION   GPU.PRESENT</span><br><span class="line">192.168.1.55   Ready,SchedulingDisabled   master   128m   v1.22.2  </span><br><span class="line">192.168.1.56   Ready                      node     127m   v1.22.2   true</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><strong>安装helm仓库</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -</span><br><span class="line">root@hello:~# sudo apt-get install apt-transport-https --yes</span><br><span class="line">root@hello:~# echo &quot;deb https://baltocdn.com/helm/stable/debian/ all main&quot; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list</span><br><span class="line">root@hello:~# sudo apt-get update</span><br><span class="line">root@hello:~# sudo apt-get install helm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">helm install \</span><br><span class="line">    --version=0.10.0 \</span><br><span class="line">    --generate-name \</span><br><span class="line">    nvdp/nvidia-device-plugin</span><br></pre></td></tr></table></figure>

<p><strong>查看是否有nvidia</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl describe node 192.168.1.56 | grep nv</span><br><span class="line">                    nvidia.com/gpu.present=true</span><br><span class="line">  nvidia.com/gpu:     1</span><br><span class="line">  nvidia.com/gpu:     1</span><br><span class="line">  kube-system                 nvidia-device-plugin-1637728448-fgg2d         0 (0%)        0 (0%)      0 (0%)           0 (0%)         50s</span><br><span class="line">  nvidia.com/gpu     0           0</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><strong>下载镜像</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker pull registry.cn-beijing.aliyuncs.com/ai-samples/tensorflow:1.5.0-devel-gpu</span><br><span class="line">root@hello:~# docker save -o tensorflow-gpu.tar  registry.cn-beijing.aliyuncs.com/ai-samples/tensorflow:1.5.0-devel-gpu</span><br><span class="line">root@hello:~# docker load -i tensorflow-gpu.tar</span><br></pre></td></tr></table></figure>

<p><strong>创建tensorflow测试pod</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# vim gpu-test.yaml</span><br><span class="line">root@hello:~# cat gpu-test.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-gpu</span><br><span class="line">  labels:</span><br><span class="line">    test-gpu: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: training</span><br><span class="line">    image: registry.cn-beijing.aliyuncs.com/ai-samples/tensorflow:1.5.0-devel-gpu</span><br><span class="line">    command:</span><br><span class="line">    - python</span><br><span class="line">    - tensorflow-sample-code/tfjob/docker/mnist/main.py</span><br><span class="line">    - --max_steps=300</span><br><span class="line">    - --data_dir=tensorflow-sample-code/data</span><br><span class="line">    resources:</span><br><span class="line">      limits:</span><br><span class="line">        nvidia.com/gpu: 1</span><br><span class="line">  tolerations:</span><br><span class="line">  - effect: NoSchedule</span><br><span class="line">    operator: Exists</span><br><span class="line">root@hello:~#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  apply -f gpu-test.yaml</span><br><span class="line">pod/test-gpu created</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><strong>查看日志</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl logs test-gpu</span><br><span class="line">WARNING:tensorflow:From tensorflow-sample-code/tfjob/docker/mnist/main.py:120: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.</span><br><span class="line">Instructions for updating:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Future major versions of TensorFlow will allow gradients to flow</span><br><span class="line">into the labels input on backprop by default.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">See tf.nn.softmax_cross_entropy_with_logits_v2.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2021-11-24 04:38:50.846973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2021-11-24 04:38:50.847698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:</span><br><span class="line">name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59</span><br><span class="line">pciBusID: 0000:00:10.0</span><br><span class="line">totalMemory: 14.75GiB freeMemory: 14.66GiB</span><br><span class="line">2021-11-24 04:38:50.847759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: Tesla T4, pci bus id: 0000:00:10.0, compute capability: 7.5)</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5c125f7c59124bb8a5fcdf44a1c4bad8~tplv-k3u1fbpfcp-zoom-1.image">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>在 Linux 上以 All-in-One 模式安装 KubeSphere</title>
    <url>/2021/12/30/2021-12-30-%E5%9C%A8_Linux_%E4%B8%8A%E4%BB%A5_All-in-One_%E6%A8%A1%E5%BC%8F%E5%AE%89%E8%A3%85_KubeSphere/</url>
    <content><![CDATA[<p><strong>在 Linux 上以 All-in-One 模式安装 KubeSphere</strong></p>
<p>Install KubeSphere in All-in-One mode on Linux</p>
<p><strong>背景</strong></p>
<p>KubeSphere 是在Kubernetes 之上构建的面向云原生应用的分布式操作系统，完全开源，支持多云与多集群管理，提供全栈的IT 自动化运维能力，简化公司的DevOps 工作流。… 作为全栈的多租户容器平台，KubeSphere 提供了运维友好的向导式操作界面，帮助公司快速构建一个强大和功能丰富的容器云平台。</p>
<p>KubeSphere is a distributed operating system for cloud-native applications built on Kubernetes. It is fully open source, supports multi-cloud and multi-cluster management, provides full-stack IT automated operation and maintenance capabilities, and simplifies the company’s DevOps workflow. … As a full-stack multi-tenant container platform, KubeSphere provides an operation and maintenance-friendly guided operation interface to help the company quickly build a powerful and feature-rich container cloud platform.</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2726cdd76c2945b2be33b877b2ced175~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>一、安装 docker</strong></p>
<p>One, install docker</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br><span class="line">----略----</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# docker -v</span><br><span class="line">Docker version 20.10.9, build c2ea9bc</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><strong>二，下载安装 KubeKey</strong></p>
<p>Second, download and install KubeKey</p>
<p>从源代码生成二进制文件</p>
<p>Generate binary files from source code</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# git clone https://github.com/kubesphere/kubekey.git</span><br><span class="line">Cloning into &#x27;kubekey&#x27;...</span><br><span class="line">remote: Enumerating objects: 13438, done.</span><br><span class="line">remote: Counting objects: 100% (899/899), done.</span><br><span class="line">remote: Compressing objects: 100% (238/238), done.</span><br><span class="line">remote: Total 13438 (delta 745), reused 662 (delta 661), pack-reused 12539</span><br><span class="line">Receiving objects: 100% (13438/13438), 34.95 MiB | 10.14 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (5424/5424), done.</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# cd kubekey</span><br><span class="line">root@hello:~/kubekey# </span><br><span class="line">root@hello:~/kubekey# </span><br><span class="line">root@hello:~/kubekey# ./build.sh -p</span><br><span class="line">----略----</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p>Notice:</p>
<p>在构建之前，需要先安装 Docker。</p>
<p>如果无法访问 <a href="https://proxy.golang.org/%EF%BC%8C%E6%AF%94%E5%A6%82%E5%9C%A8%E5%A2%99%E5%86%85%EF%BC%8C%E8%AF%B7%E6%89%A7%E8%A1%8C">https://proxy.golang.org/，比如在墙内，请执行</a> build.sh -p。</p>
<p>Before building, you need to install Docker.</p>
<p>If you cannot access <a href="https://proxy.golang.org/">https://proxy.golang.org/</a>, such as inside a firewall, please execute build.sh -p.</p>
<p><strong>三、 安装所需工具</strong></p>
<p>Three， Tools required for installation</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# apt install sudo -y</span><br><span class="line">root@hello:~# apt install curl -y</span><br><span class="line">root@hello:~# apt install openssl -y</span><br><span class="line">root@hello:~# apt install ebtables -y</span><br><span class="line">root@hello:~# apt install socat -y</span><br><span class="line">root@hello:~# apt install ipset -y</span><br><span class="line">root@hello:~# apt install conntrack -y</span><br><span class="line">root@hello:~# apt install nfs-common -y</span><br></pre></td></tr></table></figure>

<p>四、创建集群</p>
<p>Fourth, create a cluster</p>
<p>同时安装 Kubernetes 和 KubeSphere</p>
<p>Install Kubernetes and KubeSphere at the same time</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# export KKZONE=cn</span><br><span class="line">root@hello:~# /root/kubekey/output/kk create cluster --with-kubernetes v1.20.4 --with-kubesphere v3.1.1</span><br><span class="line">+-------+------+------+---------+----------+-------+-------+-----------+---------+------------+-------------+------------------+--------------+</span><br><span class="line">| name  | sudo | curl | openssl | ebtables | socat | ipset | conntrack | docker  | nfs client | ceph client | glusterfs client | time         |</span><br><span class="line">+-------+------+------+---------+----------+-------+-------+-----------+---------+------------+-------------+------------------+--------------+</span><br><span class="line">| hello | y    | y    | y       | y        | y     | y     | y         | 20.10.9 | y          |             |                  | UTC 02:50:57 |</span><br><span class="line">+-------+------+------+---------+----------+-------+-------+-----------+---------+------------+-------------+------------------+--------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">This is a simple check of your environment.</span><br><span class="line">Before installation, you should ensure that your machines meet all requirements specified at</span><br><span class="line">https://github.com/kubesphere/kubekey#requirements-and-recommendations</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Continue this installation? [yes/no]: yes</span><br><span class="line">INFO[02:51:00 UTC] Downloading Installation Files               </span><br><span class="line">INFO[02:51:00 UTC] Downloading kubeadm ...    </span><br><span class="line">----略----</span><br></pre></td></tr></table></figure>

<p><strong>五、验证安装结果</strong></p>
<p>Five, verify the installation results</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br><span class="line">----略----</span><br><span class="line">#####################################################</span><br><span class="line">###              Welcome to KubeSphere!           ###</span><br><span class="line">#####################################################</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Console: http://192.168.1.20:30880</span><br><span class="line">Account: admin</span><br><span class="line">Password: P@88w0rd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES：</span><br><span class="line">  1. After you log into the console, please check the</span><br><span class="line">     monitoring status of service components in</span><br><span class="line">     &quot;Cluster Management&quot;. If any service is not</span><br><span class="line">     ready, please wait patiently until all components </span><br><span class="line">     are up and running.</span><br><span class="line">  2. Please change the default password after login.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#####################################################</span><br><span class="line">https://kubesphere.io             2021-10-11 03:04:53</span><br><span class="line">#####################################################</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/01946623a981490880a25cba41758d86~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>注意：</p>
<p>Notice:</p>
<p>输出信息会显示 Web 控制台的 IP 地址和端口号，默认的 NodePort 是 30880。现在，您可以使用默认的帐户和密码 (admin&#x2F;P@88w0rd) 通过 <NodeIP>:30880 访问控制台</p>
<p>The output information will display the IP address and port number of the Web console. The default NodePort is 30880. Now you can use the default account and password (admin&#x2F;P@88w0rd) to access the console via <NodeIP>:30880</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a3d34a9731814326865c5e325943451f~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>39篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e8493e3afea74dfa8e4498ce7802dec9~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>利用 kubeadm 创建 kubernetes 的高可用集群</title>
    <url>/2021/12/30/2021-12-30-%E5%88%A9%E7%94%A8_kubeadm_%E5%88%9B%E5%BB%BA_kubernetes_%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p><strong>引言</strong>：</p>
<p>kubeadm提供了两种不同的高可用方案。</p>
<p>    堆叠方案：etcd服务和控制平面被部署在同样的节点中，对基础设施的要求较低，对故障的应对能力也较低</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1f5cf8d9a83145b8900eb99ae15498d2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>堆叠方案</p>
<p>    最小三个Master（也称工作平面），因为Etcd使用RAFT算法选主，节点数量需要为2n+1个。</p>
<p>    外置etcd方案：etcd和控制平面被分离，需要更多的硬件，也有更好的保障能力</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eba922ac2e764f6bb181581e87ebf1c3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>外置etcd方案</p>
<p><strong>一、资源环境</strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/41a7d4791c9d42f29a380bd2e61f31b0~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
<p>    下面采用的是kubeadm的堆叠方案搭建k8s集群，也就是说如果3台Master宕了2台时，集群将不可用，可能收到如下错误信息”Error from server: etcdserver: request timed out”。</p>
<p><strong>二、系统设置（所有主机）</strong></p>
<p>   设置主机名  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname master-\*</span><br><span class="line">hostnamectl set-hostname node-\*</span><br></pre></td></tr></table></figure>

<p>    设置静态IP  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@localhost ~\]# vim /etc/sysconfig/network-scripts/ifcfg-ens18 </span><br><span class="line">\[root@localhost ~\]# </span><br><span class="line">\[root@localhost ~\]# </span><br><span class="line">\[root@localhost ~\]# </span><br><span class="line">\[root@localhost ~\]# cat /etc/sysconfig/network-scripts/ifcfg-ens18</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY\_METHOD=none</span><br><span class="line">BROWSER\_ONLY=no</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=10.0.0.11</span><br><span class="line">NETMASK=255.0.0.0</span><br><span class="line">GATEWAY=10.0.0.1</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4\_FAILURE\_FATAL=no</span><br><span class="line">IPV6INIT=yes</span><br><span class="line">IPV6\_AUTOCONF=yes</span><br><span class="line">IPV6\_DEFROUTE=yes</span><br><span class="line">IPV6\_FAILURE\_FATAL=no</span><br><span class="line">IPV6\_ADDR\_GEN\_MODE=stable-privacy</span><br><span class="line">NAME=ens18</span><br><span class="line">UUID=555fe27b-19eb-4958-aca7-c9c71365432f</span><br><span class="line">DEVICE=ens18</span><br><span class="line">ONBOOT=yes</span><br><span class="line">\[root@localhost ~\]# reboot</span><br></pre></td></tr></table></figure>

<p>    配置主机名  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 ~\]# cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">10.0.0.11 master-01</span><br><span class="line">10.0.0.12 master-02</span><br><span class="line">10.0.0.13 master-03</span><br><span class="line">10.0.0.14 node-01</span><br><span class="line">10.0.0.15 master-01</span><br><span class="line">10.0.0.16 master-01</span><br></pre></td></tr></table></figure>

<p>    安装依赖  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@node-01 ~\]# yum update -y</span><br><span class="line">Repository AppStream is listed more than once in the configuration</span><br><span class="line">Repository extras is listed more than once in the configuration</span><br><span class="line">Repository PowerTools is listed more than once in the configuration</span><br><span class="line">Repository centosplus is listed more than once in the configuration</span><br><span class="line">Last metadata expiration check: 0:19:42 ago on Sat 28 Nov 2020 04:25:04 PM CST.</span><br><span class="line">Dependencies resolved.</span><br><span class="line">Nothing to do.</span><br><span class="line">Complete!</span><br><span class="line"></span><br><span class="line">\[root@node-01 ~\]# yum install -y conntrack ipvsadm ipset jq sysstat curl iptables libseccomp bind-utils</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>    关闭防火墙、swap、selinux</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 ~\]# systemctl stop firewalld &amp;&amp; systemctl disable firewalld</span><br><span class="line">Removed /etc/systemd/system/multi-user.target.wants/firewalld.service.</span><br><span class="line">Removed /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</span><br><span class="line">\[root@master-01 ~\]# swapoff -a</span><br><span class="line">\[root@master-01 ~\]# iptables -F &amp;&amp; iptables -X &amp;&amp; iptables -F -t nat &amp;&amp; iptables -X -t nat &amp;&amp; iptables -P FORWARD ACCEPT</span><br><span class="line">\[root@master-01 ~\]# sed -i &#x27;/swap/s/^\\(.\*\\)$/#\\1/g&#x27; /etc/fstab</span><br><span class="line">\[root@master-01 ~\]# cat /etc/fstab</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># /etc/fstab</span><br><span class="line"># Created by anaconda on Mon Nov 23 08:19:33 2020</span><br><span class="line">#</span><br><span class="line"># Accessible filesystems, by reference, are maintained under &#x27;/dev/disk/&#x27;.</span><br><span class="line"># See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.</span><br><span class="line">#</span><br><span class="line"># After editing this file, run &#x27;systemctl daemon-reload&#x27; to update systemd</span><br><span class="line"># units generated from this file.</span><br><span class="line">#</span><br><span class="line">/dev/mapper/cl-root     /                       xfs     defaults        0 0</span><br><span class="line">UUID=46ea6159-eda5-4931-ae11-73095cf284c1 /boot                   ext4    defaults        1 2</span><br><span class="line">#/dev/mapper/cl-swap     swap                    swap    defaults        0 0</span><br><span class="line">\[root@master-01 ~\]# setenforce 0</span><br><span class="line">\[root@master-01 ~\]# vim /etc/sysconfig/selinux</span><br><span class="line">\[root@master-01 ~\]# cat /etc/sysconfig/selinux</span><br><span class="line"></span><br><span class="line"># This file controls the state of SELinux on the system.</span><br><span class="line"># SELINUX= can take one of these three values:</span><br><span class="line">#     enforcing - SELinux security policy is enforced.</span><br><span class="line">#     permissive - SELinux prints warnings instead of enforcing.</span><br><span class="line">#     disabled - No SELinux policy is loaded.</span><br><span class="line">SELINUX=disabled</span><br><span class="line"># SELINUXTYPE= can take one of these three values:</span><br><span class="line">#     targeted - Targeted processes are protected,</span><br><span class="line">#     minimum - Modification of targeted policy. Only selected processes are protected. </span><br><span class="line">#     mls - Multi Level Security protection.</span><br><span class="line">SELINUXTYPE=targeted</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>高新科技园</p>
<p>广东省深圳市南山区科文路4附近</p>
<p>   系统参数设置  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\# 开启ipvs模块</span><br><span class="line">\[root@master-01 ~\]#  cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class="line">&gt; #!/bin/bash</span><br><span class="line">&gt; modprobe -- ip\_vs</span><br><span class="line">&gt; modprobe -- ip\_vs\_rr</span><br><span class="line">&gt; modprobe -- ip\_vs\_wrr</span><br><span class="line">&gt; modprobe -- ip\_vs\_sh</span><br><span class="line">&gt; modprobe -- nf\_conntrack\_ipv4</span><br><span class="line">&gt; modprobe br\_netfilter</span><br><span class="line">&gt; EOF</span><br><span class="line"></span><br><span class="line"># 生效文件</span><br><span class="line">\[root@master-01 ~\]# chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip\_vs -e nf\_conntrack\_ipv4</span><br><span class="line">ip\_vs\_sh               16384  0</span><br><span class="line">ip\_vs\_wrr              16384  0</span><br><span class="line">ip\_vs\_rr               16384  0</span><br><span class="line">ip\_vs                 172032  6 ip\_vs\_rr,ip\_vs\_sh,ip\_vs\_wrr</span><br><span class="line">nf\_defrag\_ipv6         20480  2 nf\_conntrack\_ipv6,ip\_vs</span><br><span class="line">nf\_conntrack\_ipv4      16384  1</span><br><span class="line">nf\_defrag\_ipv4         16384  1 nf\_conntrack\_ipv4</span><br><span class="line">nf\_conntrack          155648  7 nf\_conntrack\_ipv6,nf\_conntrack\_ipv4,nf\_nat,nft\_ct,nf\_nat\_ipv6,nf\_nat\_ipv4,ip\_vs</span><br><span class="line">libcrc32c              16384  4 nf\_conntrack,nf\_nat,xfs,ip\_vs</span><br><span class="line"></span><br><span class="line"># 制作配置文件</span><br><span class="line">\[root@master-01 ~\]# cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt;EOF</span><br><span class="line">&gt; net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">&gt; net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line">&gt; net.ipv4.ip\_forward=1</span><br><span class="line">&gt; net.ipv4.tcp\_tw\_recycle=1 # 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。</span><br><span class="line">&gt; net.ipv4.tcp\_keepalive\_time=600 # 超过这个时间没有数据传输，就开始发送存活探测包</span><br><span class="line">&gt; net.ipv4.tcp\_keepalive\_intvl=15 # keepalive探测包的发送间隔</span><br><span class="line">&gt; net.ipv4.tcp\_keepalive\_probes=3 # 如果对方不予应答，探测包的发送次数</span><br><span class="line">&gt; vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它</span><br><span class="line">&gt; vm.overcommit\_memory=1 # 不检查物理内存是否够用</span><br><span class="line">&gt; vm.panic\_on\_oom=0 # 开启 OOM</span><br><span class="line">&gt; fs.inotify.max\_user\_instances=8192</span><br><span class="line">&gt; fs.inotify.max\_user\_watches=1048576</span><br><span class="line">&gt; fs.file-max=52706963</span><br><span class="line">&gt; fs.nr\_open=52706963</span><br><span class="line">&gt; net.ipv6.conf.all.disable\_ipv6=1</span><br><span class="line">&gt; net.netfilter.nf\_conntrack\_max=2310720</span><br><span class="line">&gt; EOF</span><br><span class="line"></span><br><span class="line"># 生效配置文件</span><br><span class="line">\[root@master-01 ~\]# sysctl -p /etc/sysctl.d/kubernetes.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.ipv4.ip\_forward = 1</span><br><span class="line">sysctl: cannot stat /proc/sys/net/ipv4/tcp\_tw\_recycle: No such file or directory</span><br><span class="line">net.ipv4.tcp\_keepalive\_time = 600 # 超过这个时间没有数据传输，就开始发送存活探测包</span><br><span class="line">net.ipv4.tcp\_keepalive\_intvl = 15 # keepalive探测包的发送间隔</span><br><span class="line">net.ipv4.tcp\_keepalive\_probes = 3 # 如果对方不予应答，探测包的发送次数</span><br><span class="line">vm.swappiness = 0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它</span><br><span class="line">vm.overcommit\_memory = 1 # 不检查物理内存是否够用</span><br><span class="line">vm.panic\_on\_oom = 0 # 开启 OOM</span><br><span class="line">fs.inotify.max\_user\_instances = 8192</span><br><span class="line">fs.inotify.max\_user\_watches = 1048576</span><br><span class="line">fs.file-max = 52706963</span><br><span class="line">fs.nr\_open = 52706963</span><br><span class="line">net.ipv6.conf.all.disable\_ipv6 = 1</span><br><span class="line">net.netfilter.nf\_conntrack\_max = 2310720</span><br><span class="line"></span><br><span class="line"># 调整系统 TimeZone</span><br><span class="line">\[root@master-01 ~\]# timedatectl set-timezone Asia/Shanghai</span><br><span class="line"></span><br><span class="line"># 将当前的 UTC 时间写入硬件时钟</span><br><span class="line">\[root@master-01 ~\]#  timedatectl set-local-rtc 0</span><br><span class="line"></span><br><span class="line"># 重启依赖于系统时间的服务</span><br><span class="line">\[root@master-01 ~\]# systemctl restart rsyslog &amp;&amp; systemctl restart crond</span><br><span class="line"></span><br><span class="line"># 关闭无关的服务</span><br><span class="line">\[root@master-01 ~\]#  systemctl stop postfix &amp;&amp; systemctl disable postfix</span><br><span class="line">Failed to stop postfix.service: Unit postfix.service not loaded.</span><br><span class="line"># 设置 rsyslogd 和 systemd journald</span><br><span class="line">\[root@master-01 ~\]# mkdir /var/log/journal</span><br><span class="line">\[root@master-01 ~\]# mkdir /etc/systemd/journald.conf.d</span><br><span class="line"></span><br><span class="line">\[root@master-01 ~\]# cat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF</span><br><span class="line">&gt; \[Journal\]</span><br><span class="line">&gt; # 持久化保存到磁盘</span><br><span class="line">&gt; Storage=persistent</span><br><span class="line">&gt; </span><br><span class="line">&gt; # 压缩历史日志</span><br><span class="line">&gt; Compress=yes</span><br><span class="line">&gt; </span><br><span class="line">&gt; SyncIntervalSec=5m</span><br><span class="line">&gt; RateLimitInterval=30s</span><br><span class="line">&gt; RateLimitBurst=1000</span><br><span class="line">&gt; </span><br><span class="line">&gt; # 最大占用空间 10G</span><br><span class="line">&gt; SystemMaxUse=10G</span><br><span class="line">&gt; </span><br><span class="line">&gt; # 单日志文件最大 200M</span><br><span class="line">&gt; SystemMaxFileSize=200M</span><br><span class="line">&gt; </span><br><span class="line">&gt; # 日志保存时间 2 周</span><br><span class="line">&gt; MaxRetentionSec=2week</span><br><span class="line">&gt; </span><br><span class="line">&gt; # 不将日志转发到 syslog</span><br><span class="line">&gt; ForwardToSyslog=no</span><br><span class="line">&gt; EOF</span><br><span class="line">\[root@master-01 ~\]# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>**三、安装docker<br>**</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-02 ~\]# wget https://download.docker.com/linux/centos/8/x86\_64/stable/Packages/containerd.io-1.3.7-3.1.el8.x86\_64.rpm</span><br><span class="line">--2020-11-28 17:47:12--  https://download.docker.com/linux/centos/8/x86\_64/stable/Packages/containerd.io-1.3.7-3.1.el8.x86\_64.rpm</span><br><span class="line">Resolving download.docker.com (download.docker.com)... 99.84.206.7, 99.84.206.109, 99.84.206.25, ...</span><br><span class="line">Connecting to download.docker.com (download.docker.com)|99.84.206.7|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 30388860 (29M) \[binary/octet-stream\]</span><br><span class="line">Saving to: ‘containerd.io-1.3.7-3.1.el8.x86\_64.rpm’</span><br><span class="line"></span><br><span class="line">containerd.io-1.3.7-3.1 100%\[===============================&gt;\]  28.98M   188KB/s    in 3m 15s  </span><br><span class="line"></span><br><span class="line">2020-11-28 17:50:27 (153 KB/s) - ‘containerd.io-1.3.7-3.1.el8.x86\_64.rpm’ saved \[30388860/30388860\]</span><br><span class="line"></span><br><span class="line">\[root@node-02 ~\]# yum install ./containerd.io-1.3.7-3.1.el8.x86\_64.rpm </span><br><span class="line">Repository AppStream is listed more than once in the configuration</span><br><span class="line">Repository extras is listed more than once in the configuration</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">\[root@node-01 ~\]# sudo yum -y install docker-ce</span><br><span class="line">Repository AppStream is listed more than once in the configuration</span><br><span class="line">Repository extras is listed more than once in the configuration</span><br><span class="line">Repository PowerTools is listed more than once in the configuration</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">\[root@master-01 ~\]# systemctl start docker &amp;&amp; systemctl enable docker</span><br></pre></td></tr></table></figure>

<p><strong>四、安装必要工具，在主节点安装kubectl即可，其他节点无需进行安装</strong>kubectl****</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 ~\]# cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">\[kubernetes\]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86\_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo\_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">\[root@master-01 ~\]# yum install -y kubelet kubeadm kubectl</span><br><span class="line">\[root@master-01 ~\]# systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e28f4bbb0fbc49dda0a53de9cf81adb3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>五、安装LVS和keepalived</strong>  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@vip ~\]# yum -y install keepalived</span><br><span class="line"></span><br><span class="line"># 备份并编辑</span><br><span class="line">\[root@vip ~\]# cp /etc/keepalived/keepalived.conf&#123;,.back&#125;</span><br><span class="line">\[root@vip ~\]# vim /etc/keepalived/keepalived.conf </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\[root@vip ~\]# echo &quot;&quot; &gt; /etc/keepalived/keepalived.conf</span><br><span class="line">\[root@vip ~\]# vim /etc/keepalived/keepalived.conf </span><br><span class="line">\[root@vip ~\]# systemctl enable keepalived &amp;&amp; service keepalived start</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/keepalived.service → /usr/lib/systemd/system/keepalived.service.</span><br><span class="line">Redirecting to /bin/systemctl start keepalived.service</span><br><span class="line">\[root@vip ~\]# </span><br><span class="line">\[root@vip ~\]# </span><br><span class="line">\[root@vip ~\]# cat /etc/keepalived/keepalived.conf</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global\_defs &#123;</span><br><span class="line">   router\_id keepalived-master</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp\_instance vip\_1 &#123;</span><br><span class="line">  state MASTER</span><br><span class="line">  ! 注意这是网卡名称，使用ip a命令查看自己的局域网网卡名称</span><br><span class="line">  interface ens18</span><br><span class="line">  ! keepalived主备router\_id必须一致</span><br><span class="line">  virtual\_router\_id 88</span><br><span class="line">  ! 优先级，keepalived主节点优先级要比备节点高</span><br><span class="line">  priority 100</span><br><span class="line">  advert\_int 3</span><br><span class="line">  ! 配置虚拟ip地址</span><br><span class="line">  virtual\_ipaddress &#123;</span><br><span class="line">    10.0.0.99</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual\_server 10.0.0.99 6443 &#123;</span><br><span class="line">  delay\_loop 6</span><br><span class="line">  lb\_algo rr</span><br><span class="line">  lb\_kind DR</span><br><span class="line">  persistence\_timeout 0</span><br><span class="line">  protocol TCP</span><br><span class="line">    </span><br><span class="line">  real\_server 10.0.0.12 6443 &#123;</span><br><span class="line">    weight 1</span><br><span class="line">    TCP\_CHECK &#123;</span><br><span class="line">      connect\_timeout 10</span><br><span class="line">      nb\_get\_retry 3</span><br><span class="line">      delay\_before\_retry 3</span><br><span class="line">      connect\_port 6443</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  real\_server 10.0.0.13 6443 &#123;</span><br><span class="line">    weight 1</span><br><span class="line">    TCP\_CHECK &#123;</span><br><span class="line">      connect\_timeout 10</span><br><span class="line">      nb\_get\_retry 3</span><br><span class="line">      delay\_before\_retry 3</span><br><span class="line">      connect\_port 6443</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  real\_server 10.0.0.11 6443 &#123;</span><br><span class="line">    weight 1</span><br><span class="line">    TCP\_CHECK &#123;</span><br><span class="line">      connect\_timeout 10</span><br><span class="line">      nb\_get\_retry 3</span><br><span class="line">      delay\_before\_retry 3</span><br><span class="line">      connect\_port 6443</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>添加本地回环  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 rs\]# vim /opt/rs/rs.sh </span><br><span class="line">\[root@master-01 rs\]# cat /opt/rs/rs.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line"># 虚拟ip</span><br><span class="line">vip=10.0.0.99</span><br><span class="line"># 停止以前的lo:0</span><br><span class="line">ifconfig lo:0 down</span><br><span class="line">echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip\_forward</span><br><span class="line">echo &quot;0&quot; &gt; /proc/sys/net/ipv4/conf/all/arp\_announce</span><br><span class="line"># 启动一个回环地址并绑定给vip</span><br><span class="line">ifconfig lo:0 $vip broadcast $vip netmask 255.0.0.0 up</span><br><span class="line">route add -host $vip dev lo:0</span><br><span class="line">echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp\_ignore</span><br><span class="line">echo &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp\_announce</span><br><span class="line">echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/all/arp\_ignore</span><br><span class="line">echo &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/all/arp\_announce</span><br><span class="line"># ens33是主网卡名</span><br><span class="line">echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/ens18/arp\_ignore</span><br><span class="line">echo &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/ens18/arp\_announce</span><br><span class="line"></span><br><span class="line"># 脚本不可以的话，使用命令吧</span><br><span class="line">ifconfig lo:0 10.0.0.99 broadcast 10.0.0.99 netmask 255.255.255.255 up</span><br><span class="line">route add -host 10.0.0.99 dev lo:0</span><br><span class="line"></span><br><span class="line"># 设置开机自启</span><br><span class="line">\[root@vip ~\]# echo &#x27;/opt/rs/rs.sh&#x27;  &gt;&gt; /etc/rc.d/rc.local</span><br><span class="line">\[root@vip ~\]# chmod +x /etc/rc.d/rc.local</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>keepalived</strong> backup 设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@vip ~\]# </span><br><span class="line">\[root@vip ~\]# vim /etc/keepalived/keepalived.conf </span><br><span class="line">\[root@vip ~\]# systemctl enable keepalived &amp;&amp; service keepalived start</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/keepalived.service → /usr/lib/systemd/system/keepalived.service.</span><br><span class="line">Redirecting to /bin/systemctl start keepalived.service</span><br><span class="line">\[root@vip ~\]# </span><br><span class="line">\[root@vip ~\]# </span><br><span class="line">\[root@vip ~\]# cat /etc/keepalived/keepalived.conf </span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global\_defs &#123;</span><br><span class="line">   router\_id keepalived-master</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp\_instance vip\_1 &#123;</span><br><span class="line">  state BACKUP</span><br><span class="line">  ! 注意这是网卡名称，使用ip a命令查看自己的局域网网卡名称</span><br><span class="line">  interface ens18</span><br><span class="line">  ! keepalived主备router\_id必须一致</span><br><span class="line">  virtual\_router\_id 88</span><br><span class="line">  ! 优先级，keepalived主节点优先级要比备节点高</span><br><span class="line">  priority 99 </span><br><span class="line">  advert\_int 3</span><br><span class="line">  ! 配置虚拟ip地址</span><br><span class="line">  virtual\_ipaddress &#123;</span><br><span class="line">    10.0.0.99</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual\_server 10.0.0.99 6443 &#123;</span><br><span class="line">  delay\_loop 6</span><br><span class="line">  lb\_algo rr</span><br><span class="line">  lb\_kind DR</span><br><span class="line">  persistence\_timeout 0</span><br><span class="line">  protocol TCP</span><br><span class="line">    </span><br><span class="line">  real\_server 10.0.0.12 6443 &#123;</span><br><span class="line">    weight 1</span><br><span class="line">    TCP\_CHECK &#123;</span><br><span class="line">      connect\_timeout 10</span><br><span class="line">      nb\_get\_retry 3</span><br><span class="line">      delay\_before\_retry 3</span><br><span class="line">      connect\_port 6443</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  real\_server 10.0.0.13 6443 &#123;</span><br><span class="line">    weight 1</span><br><span class="line">    TCP\_CHECK &#123;</span><br><span class="line">      connect\_timeout 10</span><br><span class="line">      nb\_get\_retry 3</span><br><span class="line">      delay\_before\_retry 3</span><br><span class="line">      connect\_port 6443</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  real\_server 10.0.0.11 6443 &#123;</span><br><span class="line">    weight 1</span><br><span class="line">    TCP\_CHECK &#123;</span><br><span class="line">      connect\_timeout 10</span><br><span class="line">      nb\_get\_retry 3</span><br><span class="line">      delay\_before\_retry 3</span><br><span class="line">      connect\_port 6443</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed6583742cb34b1fa59ab9b2dba73f27~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>六、kubeadm搭建集群（区分节点）</strong>  </p>
<p>master-01  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 ~\]# cd /opt/kubernetes/</span><br><span class="line">\[root@master-01 kubernetes\]# </span><br><span class="line">\[root@master-01 kubernetes\]# cat kubeadm-config.yaml </span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line"># k8s的版本号，必须跟安装的Kubeadm版本等保持一致，否则启动报错</span><br><span class="line">kubernetesVersion: v1.19.4</span><br><span class="line"># docker镜像仓库地址，k8s.gcr.io需要翻墙才可以下载镜像，这里使用镜像服务器下载http://mirror.azure.cn/help/gcr-proxy-cache.html</span><br><span class="line"># imageRepository: k8s.gcr.io/google\_containers</span><br><span class="line"># 集群名称</span><br><span class="line">clusterName: kubernetes</span><br><span class="line"># apiServer的集群访问地址，填写vip地址即可 #</span><br><span class="line">controlPlaneEndpoint: &quot;10.0.0.99:6443&quot;</span><br><span class="line">networking:</span><br><span class="line">  # pod的网段</span><br><span class="line">  podSubnet: 10.10.0.0/16</span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">---</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line"># kube-proxy模式指定为ipvs，需要提前在节点上安装ipvs的依赖并开启相关模块</span><br><span class="line">mode: ipvs</span><br><span class="line"></span><br><span class="line"># 拉去镜像</span><br><span class="line">\[root@master-01 kubernetes\]# kubeadm config images pull</span><br><span class="line">W1128 20:33:21.822265    4536 configset.go:348\] WARNING: kubeadm cannot validate component configs for API groups \[kubelet.config.k8s.io kubeproxy.config.k8s.io\]</span><br><span class="line">\[config/images\] Pulled k8s.gcr.io/kube-apiserver:v1.19.4</span><br><span class="line">\[config/images\] Pulled k8s.gcr.io/kube-controller-manager:v1.19.4</span><br><span class="line">\[config/images\] Pulled k8s.gcr.io/kube-scheduler:v1.19.4</span><br><span class="line">\[config/images\] Pulled k8s.gcr.io/kube-proxy:v1.19.4</span><br><span class="line">\[config/images\] Pulled k8s.gcr.io/pause:3.2</span><br><span class="line">\[config/images\] Pulled k8s.gcr.io/etcd:3.4.13-0</span><br><span class="line"></span><br><span class="line"># 记得：</span><br><span class="line">\[root@master-01 kubernetes\]# swapoff -a &amp;&amp; kubeadm reset  &amp;&amp; systemctl daemon-reload &amp;&amp; systemctl restart kubelet  &amp;&amp; iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</span><br><span class="line"></span><br><span class="line"># 初始化</span><br><span class="line">\[root@master-01 kubernetes\]# kubeadm init --config=kubeadm-config.yaml  --upload-certs</span><br><span class="line">...</span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f \[podnetwork\].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 10.0.0.99:6443 --token dtkoyq.8ciqez70nj1ysdix \\</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:f65ee972a9e9d0b8784f7db583a9cdf9865253459aa96a9b3529be2517570155 \\</span><br><span class="line">    --control-plane --certificate-key 0dc20030f8dfdede8cbb3b0906eda1a3a140e91f7e6ebb6eac1ad02ac65389d3</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</span><br><span class="line">&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 10.0.0.99:6443 --token dtkoyq.8ciqez70nj1ysdix \\</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:f65ee972a9e9d0b8784f7db583a9cdf9865253459aa96a9b3529be2517570155 </span><br><span class="line"></span><br><span class="line"># 安装网络组件</span><br><span class="line">\[root@master-01 kubernetes\]# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line">podsecuritypolicy.policy/psp.flannel.unprivileged created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/flannel created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/flannel created</span><br><span class="line">serviceaccount/flannel created</span><br><span class="line">configmap/kube-flannel-cfg created</span><br><span class="line">daemonset.apps/kube-flannel-ds created</span><br><span class="line">\[root@master-01 kubernetes\]# </span><br><span class="line">\[root@master-01 kubernetes\]# </span><br><span class="line">\[root@master-01 kubernetes\]# </span><br><span class="line">\[root@master-01 kubernetes\]# kubectl get pods --all-namespaces</span><br><span class="line">NAMESPACE     NAME                                READY   STATUS     RESTARTS   AGE</span><br><span class="line">kube-system   coredns-f9fd979d6-2hs76             0/1     Pending    0          5m18s</span><br><span class="line">kube-system   coredns-f9fd979d6-5j4w8             0/1     Pending    0          5m18s</span><br><span class="line">kube-system   etcd-master-01                      1/1     Running    0          5m29s</span><br><span class="line">kube-system   kube-apiserver-master-01            1/1     Running    0          5m30s</span><br><span class="line">kube-system   kube-controller-manager-master-01   1/1     Running    0          5m30s</span><br><span class="line">kube-system   kube-flannel-ds-grhh6               0/1     Init:0/1   0          5s</span><br><span class="line">kube-system   kube-proxy-pl74w                    1/1     Running    0          5m18s</span><br><span class="line">kube-system   kube-scheduler-master-01            1/1     Running    0          5m30s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>配置master-02和03</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 加入master组</span><br><span class="line">\[root@master-03 ~\]#   kubeadm join 10.0.0.99:6443 --token dtkoyq.8ciqez70nj1ysdix     --discovery-token-ca-cert-hash sha256:f65ee972a9e9d0b8784f7db583a9cdf9865253459aa96a9b3529be2517570155     --control-plane --certificate-key 0dc20030f8dfdede8cbb3b0906eda1a3a140e91f7e6ebb6eac1ad02ac65389d3</span><br><span class="line">...</span><br><span class="line">等到pull镜像比较慢，耐心等待一下</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"># 加入完成后</span><br><span class="line">\[root@master-03 ~\]#  mkdir -p $HOME/.kube</span><br><span class="line">\[root@master-03 ~\]#  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">\[root@master-03 ~\]#  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">\[root@master-01 kubernetes\]# kubectl get pods --all-namespaces</span><br><span class="line">NAMESPACE     NAME                                READY   STATUS              RESTARTS   AGE</span><br><span class="line">kube-system   coredns-f9fd979d6-2hs76             1/1     Running             0          45m</span><br><span class="line">kube-system   coredns-f9fd979d6-5j4w8             1/1     Running             0          45m</span><br><span class="line">kube-system   etcd-master-01                      1/1     Running             0          45m</span><br><span class="line">kube-system   etcd-master-02                      1/1     Running             0          17m</span><br><span class="line">kube-system   etcd-master-03                      0/1     Running             0          49s</span><br><span class="line">kube-system   kube-apiserver-master-01            1/1     Running             0          45m</span><br><span class="line">kube-system   kube-apiserver-master-02            1/1     Running             0          17m</span><br><span class="line">kube-system   kube-apiserver-master-03            1/1     Running             0          51s</span><br><span class="line">kube-system   kube-controller-manager-master-01   1/1     Running             1          45m</span><br><span class="line">kube-system   kube-controller-manager-master-02   1/1     Running             0          17m</span><br><span class="line">kube-system   kube-controller-manager-master-03   0/1     Running             0          51s</span><br><span class="line">kube-system   kube-flannel-ds-76vcb               0/1     Init:0/1            0          17s</span><br><span class="line">kube-system   kube-flannel-ds-8tqlh               1/1     Running             0          17m</span><br><span class="line">kube-system   kube-flannel-ds-fq8kz               0/1     Init:0/1            0          17s</span><br><span class="line">kube-system   kube-flannel-ds-grhh6               1/1     Running             0          40m</span><br><span class="line">kube-system   kube-flannel-ds-hqj25               1/1     Running             0          52s</span><br><span class="line">kube-system   kube-flannel-ds-rlg4z               0/1     Init:0/1            0          17s</span><br><span class="line">kube-system   kube-proxy-8kf2r                    1/1     Running             0          17m</span><br><span class="line">kube-system   kube-proxy-9n6p4                    0/1     ContainerCreating   0          17s</span><br><span class="line">kube-system   kube-proxy-9xdrl                    1/1     Running             0          52s</span><br><span class="line">kube-system   kube-proxy-pl74w                    1/1     Running             0          45m</span><br><span class="line">kube-system   kube-proxy-vtm97                    0/1     ContainerCreating   0          17s</span><br><span class="line">kube-system   kube-proxy-wdrpx                    0/1     ContainerCreating   0          17s</span><br><span class="line">kube-system   kube-scheduler-master-01            1/1     Running             1          45m</span><br><span class="line">kube-system   kube-scheduler-master-02            1/1     Running             0          17m</span><br><span class="line">kube-system   kube-scheduler-master-03            0/1     Running             0          51s</span><br></pre></td></tr></table></figure>

<p>node节点进行加入  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@node-01 ~\]# kubeadm join 10.0.0.99:6443 --token dtkoyq.8ciqez70nj1ysdix \\</span><br><span class="line">&gt;     --discovery-token-ca-cert-hash sha256:f65ee972a9e9d0b8784f7db583a9cdf9865253459aa96a9b3529be2517570155 </span><br><span class="line"></span><br><span class="line">\[root@node-01 ~\]#  mkdir -p $HOME/.kube</span><br><span class="line">\[root@node-01 ~\]#  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">\[root@node-01 ~\]#  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">\[root@master-01 kubernetes\]# kubectl get nodes</span><br><span class="line">NAME        STATUS   ROLES    AGE    VERSION</span><br><span class="line">master-01   Ready    master   46m    v1.19.4</span><br><span class="line">master-02   Ready    master   18m    v1.19.4</span><br><span class="line">master-03   Ready    master   107s   v1.19.4</span><br><span class="line">node-01     Ready    &lt;none&gt;   72s    v1.19.4</span><br><span class="line">node-02     Ready    &lt;none&gt;   72s    v1.19.4</span><br><span class="line">node-03     Ready    &lt;none&gt;   72s    v1.19.4</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>至此，高可用集群已部署完毕。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4ea372e66c104e20b191f545339f151d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>七、部署Dashboard管理k8s集群</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 ~\]# wget -P /etc/kubernetes/addons https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc1/aio/deploy/recommended.yaml &amp;&amp; cd /etc/kubernetes/addons</span><br><span class="line"></span><br><span class="line">\[root@master-01 addons\]# kubectl apply -f recommended.yaml</span><br><span class="line">namespace/kubernetes-dashboard created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-csrf created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/dashboard-metrics-scraper created</span><br><span class="line">deployment.apps/dashboard-metrics-scraper created</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>部署管理员  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[root@master-01 addons\]# cat &lt;&lt;E0F &gt; dashboard-adminuser.yaml</span><br><span class="line">&gt; apiVersion: v1</span><br><span class="line">&gt; kind: ServiceAccount</span><br><span class="line">&gt; metadata:</span><br><span class="line">&gt;   name: admin-user</span><br><span class="line">&gt;   namespace: kubernetes-dashboard</span><br><span class="line">&gt; </span><br><span class="line">&gt; ---</span><br><span class="line">&gt; </span><br><span class="line">&gt; apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">&gt; kind: ClusterRoleBinding</span><br><span class="line">&gt; metadata:</span><br><span class="line">&gt;   name: admin-user</span><br><span class="line">&gt; roleRef:</span><br><span class="line">&gt;   apiGroup: rbac.authorization.k8s.io</span><br><span class="line">&gt;   kind: ClusterRole</span><br><span class="line">&gt;   name: cluster-admin</span><br><span class="line">&gt; subjects:</span><br><span class="line">&gt; - kind: ServiceAccount</span><br><span class="line">&gt;   name: admin-user</span><br><span class="line">&gt;   namespace: kubernetes-dashboard</span><br><span class="line">&gt; E0F</span><br><span class="line">\[root@master-01 addons\]# kubectl apply -f dashboard-adminuser.yaml</span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">查看token</span><br><span class="line">\[root@master-01 addons\]# kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;) | grep -E &#x27;^token&#x27; | awk &#x27;&#123;print $2&#125;&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>高新科技园</p>
<p>广东省深圳市南山区科文路4附近</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>在k8s（kubernetes） 上安装 ingress V1.1.0</title>
    <url>/2021/12/30/2021-12-30-%E5%9C%A8k8s%EF%BC%88kubernetes%EF%BC%89_%E4%B8%8A%E5%AE%89%E8%A3%85_ingress_V1.1.0/</url>
    <content><![CDATA[<p>Ingress 公开了从集群外部到集群内服务的 HTTP 和 HTTPS 路由。流量路由由 Ingress 资源上定义的规则控制。</p>
<p>下面是一个将所有流量都发送到同一 Service 的简单 <strong>Ingress</strong> 示例：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e05c7cbd7ca6401b8765d7d737028364~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="在使用-ingress-创建后发现没有默认HTTP"><a href="#在使用-ingress-创建后发现没有默认HTTP" class="headerlink" title="在使用  ingress 创建后发现没有默认HTTP"></a>在使用  ingress 创建后发现没有默认HTTP</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml/nginx]# kubectl  describe ingress</span><br><span class="line">Name:             ingress-host-bar</span><br><span class="line">Namespace:        default</span><br><span class="line">Address:          </span><br><span class="line">Default backend:  default-http-backend:80 (&lt;error: endpoints &quot;default-http-backend&quot; not found&gt;)</span><br><span class="line">Rules:</span><br><span class="line">  Host             Path  Backends</span><br><span class="line">  ----             ----  --------</span><br><span class="line">  hello.chenby.cn  </span><br><span class="line">                   /   hello-server:8000 (172.20.1.13:9000,172.20.1.14:9000)</span><br><span class="line">  demo.chenby.cn  </span><br><span class="line">                   /nginx   nginx-demo:8000 (172.20.2.14:80,172.20.2.15:80)</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason  Age   From                      Message</span><br><span class="line">  ----    ------  ----  ----                      -------</span><br><span class="line">  Normal  Sync    43m   nginx-ingress-controller  Scheduled for sync</span><br><span class="line">[root@hello ~/yaml/nginx]#</span><br></pre></td></tr></table></figure>

<p>出现该问题后是因为没有创建默认的后端，需要卸载之前安装的，之前用什么方式安装就用对应的方式卸载</p>
<h1 id="写入配置文件，并执行"><a href="#写入配置文件，并执行" class="headerlink" title="写入配置文件，并执行"></a><strong>写入配置文件，并执行</strong></h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@hello</span> <span class="string">~/yaml</span>]<span class="comment"># vim deploy.yaml</span></span><br><span class="line">[<span class="string">root@hello</span> <span class="string">~/yaml</span>]<span class="comment">#</span></span><br><span class="line">[<span class="string">root@hello</span> <span class="string">~/yaml</span>]<span class="comment">#</span></span><br><span class="line">[<span class="string">root@hello</span> <span class="string">~/yaml</span>]<span class="comment"># cat deploy.yaml</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/controller-serviceaccount.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">automountServiceAccountToken:</span> <span class="literal">true</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/controller-configmap.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-controller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">allow-snippet-annotations:</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/clusterrole.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">configmaps</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">endpoints</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">nodes</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">secrets</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">namespaces</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">nodes</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">services</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">networking.k8s.io</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingresses</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">events</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">networking.k8s.io</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingresses/status</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">networking.k8s.io</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingressclasses</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/clusterrolebinding.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/controller-role.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">namespaces</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">configmaps</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">secrets</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">endpoints</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">services</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">networking.k8s.io</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingresses</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">networking.k8s.io</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingresses/status</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">networking.k8s.io</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingressclasses</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">configmaps</span></span><br><span class="line">    <span class="attr">resourceNames:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingress-controller-leader</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">configmaps</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">events</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/controller-rolebinding.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/controller-service-webhook.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-controller-admission</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https-webhook</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="string">webhook</span></span><br><span class="line">      <span class="attr">appProtocol:</span> <span class="string">https</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/controller-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-controller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">externalTrafficPolicy:</span> <span class="string">Local</span></span><br><span class="line">  <span class="attr">ipFamilyPolicy:</span> <span class="string">SingleStack</span></span><br><span class="line">  <span class="attr">ipFamilies:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">IPv4</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">appProtocol:</span> <span class="string">http</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">appProtocol:</span> <span class="string">https</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/controller-deployment.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-controller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">minReadySeconds:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirst</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">controller</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">k8s.gcr.io/ingress-nginx/controller:v1.1.0@sha256:f766669fdcf3dc26347ed273a55e754b427eb4411ee075a53f30718b4499076a</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">lifecycle:</span></span><br><span class="line">            <span class="attr">preStop:</span></span><br><span class="line">              <span class="attr">exec:</span></span><br><span class="line">                <span class="attr">command:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">/wait-shutdown</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">/nginx-ingress-controller</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--election-id=ingress-controller-leader</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--controller-class=k8s.io/ingress-nginx</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--configmap=$(POD_NAMESPACE)/ingress-nginx-controller</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--validating-webhook=:8443</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--validating-webhook-certificate=/usr/local/certificates/cert</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--validating-webhook-key=/usr/local/certificates/key</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">capabilities:</span></span><br><span class="line">              <span class="attr">drop:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">ALL</span></span><br><span class="line">              <span class="attr">add:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">NET_BIND_SERVICE</span></span><br><span class="line">            <span class="attr">runAsUser:</span> <span class="number">101</span></span><br><span class="line">            <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">LD_PRELOAD</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">/usr/local/lib/libmimalloc.so</span></span><br><span class="line">          <span class="attr">livenessProbe:</span></span><br><span class="line">            <span class="attr">failureThreshold:</span> <span class="number">5</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/healthz</span></span><br><span class="line">              <span class="attr">port:</span> <span class="number">10254</span></span><br><span class="line">              <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">10</span></span><br><span class="line">            <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br><span class="line">            <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">            <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">          <span class="attr">readinessProbe:</span></span><br><span class="line">            <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/healthz</span></span><br><span class="line">              <span class="attr">port:</span> <span class="number">10254</span></span><br><span class="line">              <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">10</span></span><br><span class="line">            <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br><span class="line">            <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">            <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">443</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">webhook</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">8443</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">webhook-cert</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/usr/local/certificates/</span></span><br><span class="line">              <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">90Mi</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">ingress-nginx</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">300</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">webhook-cert</span></span><br><span class="line">          <span class="attr">secret:</span></span><br><span class="line">            <span class="attr">secretName:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/controller-ingressclass.yaml</span></span><br><span class="line"><span class="comment"># We don&#x27;t support namespaced ingressClass yet</span></span><br><span class="line"><span class="comment"># So a ClusterRole and a ClusterRoleBinding is required</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">IngressClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">controller</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">controller:</span> <span class="string">k8s.io/ingress-nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/admission-webhooks/validating-webhook.yaml</span></span><br><span class="line"><span class="comment"># before changing this value, check the required kubernetes version</span></span><br><span class="line"><span class="comment"># https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">admissionregistration.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ValidatingWebhookConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line"><span class="attr">webhooks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">validate.nginx.ingress.kubernetes.io</span></span><br><span class="line">    <span class="attr">matchPolicy:</span> <span class="string">Equivalent</span></span><br><span class="line">    <span class="attr">rules:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">networking.k8s.io</span></span><br><span class="line">        <span class="attr">apiVersions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">v1</span></span><br><span class="line">        <span class="attr">operations:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">CREATE</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">UPDATE</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">ingresses</span></span><br><span class="line">    <span class="attr">failurePolicy:</span> <span class="string">Fail</span></span><br><span class="line">    <span class="attr">sideEffects:</span> <span class="string">None</span></span><br><span class="line">    <span class="attr">admissionReviewVersions:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">clientConfig:</span></span><br><span class="line">      <span class="attr">service:</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">ingress-nginx-controller-admission</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/networking/v1/ingresses</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">helm.sh/hook:</span> <span class="string">pre-install,pre-upgrade,post-install,post-upgrade</span></span><br><span class="line">    <span class="attr">helm.sh/hook-delete-policy:</span> <span class="string">before-hook-creation,hook-succeeded</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">helm.sh/hook:</span> <span class="string">pre-install,pre-upgrade,post-install,post-upgrade</span></span><br><span class="line">    <span class="attr">helm.sh/hook-delete-policy:</span> <span class="string">before-hook-creation,hook-succeeded</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">admissionregistration.k8s.io</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">validatingwebhookconfigurations</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">helm.sh/hook:</span> <span class="string">pre-install,pre-upgrade,post-install,post-upgrade</span></span><br><span class="line">    <span class="attr">helm.sh/hook-delete-policy:</span> <span class="string">before-hook-creation,hook-succeeded</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/admission-webhooks/job-patch/role.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">helm.sh/hook:</span> <span class="string">pre-install,pre-upgrade,post-install,post-upgrade</span></span><br><span class="line">    <span class="attr">helm.sh/hook-delete-policy:</span> <span class="string">before-hook-creation,hook-succeeded</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">secrets</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">helm.sh/hook:</span> <span class="string">pre-install,pre-upgrade,post-install,post-upgrade</span></span><br><span class="line">    <span class="attr">helm.sh/hook-delete-policy:</span> <span class="string">before-hook-creation,hook-succeeded</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission-create</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">helm.sh/hook:</span> <span class="string">pre-install,pre-upgrade</span></span><br><span class="line">    <span class="attr">helm.sh/hook-delete-policy:</span> <span class="string">before-hook-creation,hook-succeeded</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">ingress-nginx-admission-create</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">create</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--namespace=$(POD_NAMESPACE)</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--secret-name=ingress-nginx-admission</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">securityContext:</span></span><br><span class="line">        <span class="attr">runAsNonRoot:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">runAsUser:</span> <span class="number">2000</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Source: ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx-admission-patch</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">helm.sh/hook:</span> <span class="string">post-install,post-upgrade</span></span><br><span class="line">    <span class="attr">helm.sh/hook-delete-policy:</span> <span class="string">before-hook-creation,hook-succeeded</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">ingress-nginx-admission-patch</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">helm.sh/chart:</span> <span class="string">ingress-nginx-4.0.10</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/instance:</span> <span class="string">ingress-nginx</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/version:</span> <span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">Helm</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/component:</span> <span class="string">admission-webhook</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">patch</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--webhook-name=ingress-nginx-admission</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--namespace=$(POD_NAMESPACE)</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--patch-mutating=false</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--secret-name=ingress-nginx-admission</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--patch-failure-policy=Fail</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">ingress-nginx-admission</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">securityContext:</span></span><br><span class="line">        <span class="attr">runAsNonRoot:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">runAsUser:</span> <span class="number">2000</span></span><br><span class="line">[<span class="string">root@hello</span> <span class="string">~/yaml</span>]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<h1 id="启用后端，写入配置文件执行"><a href="#启用后端，写入配置文件执行" class="headerlink" title="启用后端，写入配置文件执行"></a><strong>启用后端，写入配置文件执行</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim backend.yaml</span><br><span class="line">[root@hello ~/yaml]# cat backend.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: default-http-backend</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: default-http-backend</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      containers:</span><br><span class="line">      - name: default-http-backend</span><br><span class="line">        image: k8s.gcr.io/defaultbackend-amd64:1.5</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /healthz</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">[root@hello ~/yaml]#</span><br></pre></td></tr></table></figure>

<h1 id="安装测试应用"><a href="#安装测试应用" class="headerlink" title="安装测试应用"></a><strong>安装测试应用</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim ingress-demo-app.yaml</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# cat ingress-demo-app.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello-server</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-server</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-server</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx&quot;  </span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# kubectl  get ingress</span><br><span class="line">NAME               CLASS    HOSTS                            ADDRESS        PORTS   AGE</span><br><span class="line">ingress-demo-app   &lt;none&gt;   app.demo.com                     192.168.1.11   80      20m</span><br><span class="line">ingress-host-bar   nginx    hello.chenby.cn,demo.chenby.cn   192.168.1.11   80      2m17s</span><br><span class="line">[root@hello ~/yaml]#</span><br></pre></td></tr></table></figure>

<h1 id="过滤查看ingress端口"><a href="#过滤查看ingress端口" class="headerlink" title="过滤查看ingress端口"></a>过滤查看ingress端口</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  get svc -A | grep ingress</span><br><span class="line">default         ingress-demo-app                     ClusterIP   10.68.231.41    &lt;none&gt;        80/TCP                       51m</span><br><span class="line">ingress-nginx   ingress-nginx-controller             NodePort    10.68.93.71     &lt;none&gt;        80:32746/TCP,443:30538/TCP   32m</span><br><span class="line">ingress-nginx   ingress-nginx-controller-admission   ClusterIP   10.68.146.23    &lt;none&gt;        443/TCP                      32m</span><br><span class="line">[root@hello ~/yaml]#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eb6660fb73f04890aa50b68b4b694a28~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>70篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ecae03814adf47b98b448cf9acf12fdf~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>学习docker看此文足以</title>
    <url>/2021/12/30/2021-12-30-%E5%AD%A6%E4%B9%A0docker%E7%9C%8B%E6%AD%A4%E6%96%87%E8%B6%B3%E4%BB%A5/</url>
    <content><![CDATA[<h3 id="什么是-Docker"><a href="#什么是-Docker" class="headerlink" title="什么是 Docker"></a>什么是 Docker</h3><p>Docker 最初是 dotCloud 公司创始人  在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 ，主要项目代码在  上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 。</p>
<p>Docker 自开源后受到广泛的关注和讨论，至今其  已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0d8004eb674b46c4a7d0f62143504ea4~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<h3 id="为什么要用-Docker"><a href="#为什么要用-Docker" class="headerlink" title="为什么要用 Docker"></a>为什么要用 Docker</h3><p>作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。</p>
<p><strong>更高效的利用系统资源</strong></p>
<p>由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。</p>
<p><strong>更快速的启动时间</strong></p>
<p>传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。</p>
<p><strong>一致的运行环境</strong></p>
<p>开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。</p>
<p><strong>持续交付和部署</strong></p>
<p>对开发和运维（）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。</p>
<p>使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过  来进行镜像构建，并结合  系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合  系统进行自动部署。</p>
<p>而且使用  使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。</p>
<p><strong>更轻松的迁移</strong></p>
<p>由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。</p>
<p><strong>更轻松的维护和扩展</strong></p>
<p>Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 ，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。</p>
<h3 id="docker一键安装"><a href="#docker一键安装" class="headerlink" title="docker一键安装"></a>docker一键安装</h3><p>&#96;&#96;&#96;shell<br>curl -fsSL <a href="https://get.docker.com/">https://get.docker.com</a> | bash -s docker –mirror Aliyun</p>
<p>&#96;&#96;&#96;shell</p>
<h3 id="Docker命令实战"><a href="#Docker命令实战" class="headerlink" title="Docker命令实战"></a>Docker命令实战</h3><h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><h3 id="基础实战"><a href="#基础实战" class="headerlink" title="基础实战"></a>基础实战</h3><h4 id="1、镜像"><a href="#1、镜像" class="headerlink" title="1、镜像"></a>1、镜像</h4><h5 id="下载最新版镜像"><a href="#下载最新版镜像" class="headerlink" title="下载最新版镜像"></a>下载最新版镜像</h5><p>&#96;&#96;&#96;shell<br>root@hello:~# docker pull nginx<br>Using default tag: latest<br>latest: Pulling from library&#x2F;nginx<br>7d63c13d9b9b: Pull complete<br>5cb019b641b5: Pull complete<br>d477de77abf8: Pull complete<br>c60e7d4c1c30: Pull complete<br>365a49996569: Pull complete<br>039c6e901970: Pull complete<br>Digest: sha256:168a6a2be5c65d4aafa7a78ca98ff8b110fe44c6ca41e7ccb4314ed481e32288<br>Status: Downloaded newer image for nginx:latest<br>docker.io&#x2F;library&#x2F;nginx:latest</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="查看本地镜像"><a href="#查看本地镜像" class="headerlink" title="查看本地镜像"></a>查看本地镜像</h5><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker images<br>REPOSITORY   TAG       IMAGE ID       CREATED       SIZE<br>nginx       latest   e9ce56a96f8e   8 hours ago   141MB<br>root@hello:</del></p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h5><p>&#96;&#96;&#96;shell<br>root@hello:~# docker images</p>
<p>REPOSITORY  TAG    IMAGE ID    CREATED    SIZE</p>
<p>nginx     latest   e9ce56a96f8e  8 hours ago  141MB</p>
<p>root@hello:~# </p>
<p>root@hello:~# docker rmi e9ce56a96f8e</p>
<p>Untagged: nginx:latest</p>
<p>Untagged: nginx@sha256:168a6a2be5c65d4aafa7a78ca98ff8b110fe44c6ca41e7ccb4314ed481e32288</p>
<p>Deleted: sha256:e9ce56a96f8e0e9f75051f258a595d1257bd6bb91913b79455ea77e67e686c5c</p>
<p>Deleted: sha256:6e5a463ea9608e4712465e1c575b2932dde96f99fa2c2fc31a5bacbe69c725cb</p>
<p>Deleted: sha256:a12cc243b903b34c8137e57160d206d6c1ee76a1ab6011a1cebdceb8b6ff8768</p>
<p>Deleted: sha256:a562e4589c72b0706526e13eed9c4f037ab5d1f50eb4529b38670abe353248f2</p>
<p>Deleted: sha256:fd67efaafabe1a0b146e9f7d958de79ec8fcec9aa6ee13ca3052b4acd8a3b81a</p>
<p>Deleted: sha256:c3967df88e47f739c3048492985aafaafecd5806de6c6870cbd76997fc0c68b0</p>
<p>Deleted: sha256:e8b689711f21f9301c40bf2131ce1a1905c3aa09def1de5ec43cf0adf652576e</p>
<p>root@hello:~# </p>
<p>root@hello:~# docker images</p>
<p>REPOSITORY  TAG    IMAGE ID  CREATED  SIZE</p>
<p>root@hello:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="下载指定版本镜像"><a href="#下载指定版本镜像" class="headerlink" title="下载指定版本镜像"></a>下载指定版本镜像</h5><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker pull nginx:1.20.1<br>1.20.1: Pulling from library&#x2F;nginx<br>b380bbd43752: Pull complete<br>83acae5e2daa: Pull complete<br>33715b419f9b: Pull complete<br>eb08b4d557d8: Pull complete<br>74d5bdecd955: Pull complete<br>0820d7f25141: Pull complete<br>Digest: sha256:a98c2360dcfe44e9987ed09d59421bb654cb6c4abe50a92ec9c912f252461483<br>Status: Downloaded newer image for nginx:1.20.1<br>docker.io&#x2F;library&#x2F;nginx:1.20.1<br>root@hello:</del># docker images<br>REPOSITORY   TAG       IMAGE ID       CREATED       SIZE<br>nginx        1.20.1    c8d03f6b8b91   5 weeks ago   133MB<br>root@hello:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h4 id="2、容器"><a href="#2、容器" class="headerlink" title="2、容器"></a>2、容器</h4><p>&#96;&#96;&#96;shell<br>docker run [OPTIONS] IMAGE [COMMAND] [ARG…]</p>
<p>【docker run  设置项  镜像名  】 镜像启动运行的命令（镜像里面默认有的，一般不会写）</p>
<h1 id="d：后台运行"><a href="#d：后台运行" class="headerlink" title="-d：后台运行"></a>-d：后台运行</h1><h1 id="–restart-x3D-always-开机自启"><a href="#–restart-x3D-always-开机自启" class="headerlink" title="–restart&#x3D;always: 开机自启"></a>–restart&#x3D;always: 开机自启</h1><h1 id="p-主机端口：容器端口"><a href="#p-主机端口：容器端口" class="headerlink" title="-p 主机端口：容器端口"></a>-p 主机端口：容器端口</h1><p>root@hello:<del># docker run –name&#x3D;myningx -d –restart&#x3D;always -p 88:80 nginx<br>Unable to find image ‘nginx:latest’ locally<br>latest: Pulling from library&#x2F;nginx<br>7d63c13d9b9b: Pull complete<br>5cb019b641b5: Pull complete<br>d477de77abf8: Pull complete<br>c60e7d4c1c30: Pull complete<br>365a49996569: Pull complete<br>039c6e901970: Pull complete<br>Digest: sha256:168a6a2be5c65d4aafa7a78ca98ff8b110fe44c6ca41e7ccb4314ed481e32288<br>Status: Downloaded newer image for nginx:latest<br>15db0ba492cf2b86714e3e29723d413b97e64cc2ee361d4109f4216b2e0cba60<br>root@hello:</del>#<br>root@hello:~# curl -I 127.0.0.1:88<br>HTTP&#x2F;1.1 200 OK<br>Server: nginx&#x2F;1.21.4<br>Date: Wed, 17 Nov 2021 02:03:13 GMT<br>Content-Type: text&#x2F;html<br>Content-Length: 615<br>Last-Modified: Tue, 02 Nov 2021 14:49:22 GMT<br>Connection: keep-alive<br>ETag: “61814ff2-267”<br>Accept-Ranges: bytes</p>
<p>root@hello:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="查看当前运行的容器"><a href="#查看当前运行的容器" class="headerlink" title="查看当前运行的容器"></a>查看当前运行的容器</h5><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker ps<br>CONTAINER ID   IMAGE     COMMAND                  CREATED              STATUS              PORTS                               NAMES<br>15db0ba492cf   nginx     “&#x2F;docker-entrypoint.…”   About a minute ago   Up About a minute   0.0.0.0:88-&gt;80&#x2F;tcp, :::88-&gt;80&#x2F;tcp   myningx<br>root@hello:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="停止容器"><a href="#停止容器" class="headerlink" title="停止容器"></a>停止容器</h5><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker stop 15db0ba492cf<br>15db0ba492cf<br>root@hello:</del>#<br>root@hello:<del># docker  ps<br>CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES<br>root@hello:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="查看所有容器"><a href="#查看所有容器" class="headerlink" title="查看所有容器"></a>查看所有容器</h5><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker  ps -a<br>CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS                      PORTS     NAMES<br>15db0ba492cf   nginx     “&#x2F;docker-entrypoint.…”   2 minutes ago   Exited (0) 12 seconds ago             myningx<br>root@hello:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h5><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker start 15db0ba492cf<br>15db0ba492cf<br>root@hello:</del># docker  ps<br>CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                               NAMES<br>15db0ba492cf   nginx     “&#x2F;docker-entrypoint.…”   2 minutes ago   Up 3 seconds   0.0.0.0:88-&gt;80&#x2F;tcp, :::88-&gt;80&#x2F;tcp   myningx<br>root@hello:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="删除容器，在运行中无法删除"><a href="#删除容器，在运行中无法删除" class="headerlink" title="删除容器，在运行中无法删除"></a>删除容器，在运行中无法删除</h5><p>&#96;&#96;&#96;shell<br>root@hello:~# docker rm 15db0ba492cf<br>Error response from daemon: You cannot remove a running container 15db0ba492cf2b86714e3e29723d413b97e64cc2ee361d4109f4216b2e0cba60. Stop the container before attempting removal or force remove</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h5 id="强制删除容器"><a href="#强制删除容器" class="headerlink" title="强制删除容器"></a>强制删除容器</h5><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker rm -f 15db0ba492cf<br>15db0ba492cf<br>root@hello:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h4 id="3、进入容器操作容器"><a href="#3、进入容器操作容器" class="headerlink" title="3、进入容器操作容器"></a>3、进入容器操作容器</h4><p>&#96;&#96;&#96;shell<br>root@hello:~# docker exec -it b1d72657b &#x2F;bin&#x2F;bash<br>root@b1d72657b272:&#x2F;#<br>root@b1d72657b272:&#x2F;#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h4 id="4、修改容器内容"><a href="#4、修改容器内容" class="headerlink" title="4、修改容器内容"></a>4、修改容器内容</h4><p>&#96;&#96;&#96;shell<br>root@hello:~# docker exec -it b1d72657b &#x2F;bin&#x2F;bash<br>root@b1d72657b272:&#x2F;# echo “123” &gt; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html<br>root@b1d72657b272:&#x2F;#<br>root@b1d72657b272:&#x2F;# echo “cby” &gt; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html </p>
<p>root@hello:<del># curl 127.0.0.1:88<br>123<br>root@hello:</del># </p>
<p>root@hello:~# docker exec -it b1d72657b &#x2F;bin&#x2F;bash<br>root@b1d72657b272:&#x2F;# echo “cby” &gt; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html </p>
<p>root@hello:<del># curl 127.0.0.1:88<br>cby<br>root@hello:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h4 id="5、挂载外部数据"><a href="#5、挂载外部数据" class="headerlink" title="5、挂载外部数据"></a>5、挂载外部数据</h4><p>&#96;&#96;&#96;shell<br>root@hello:~# docker run –name&#x3D;myningx -d –restart&#x3D;always -p 88:80 -v &#x2F;data&#x2F;html:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F; nginx  </p>
<p>e3788cdd7be695fe9a1bebd7306c131d6380da215a416d19c162c609b8f108ae</p>
<p>root@hello:~# </p>
<p>root@hello:~# </p>
<p>root@hello:~# curl 127.0.0.1:88</p>
<html>

<head><title>403 Forbidden</title></head>

<body>

<center><h1>403 Forbidden</h1></center>

<hr><center>nginx/1.21.4</center>

</body>

</html>

<p>root@hello:~# </p>
<p>root@hello:~# echo “cby” &gt; &#x2F;data&#x2F;html&#x2F;index.html</p>
<p>root@hello:~# </p>
<p>root@hello:~# </p>
<p>root@hello:~# curl 127.0.0.1:88</p>
<p>cby</p>
<p>root@hello:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h4 id="6、将运行中的容器构建为镜像"><a href="#6、将运行中的容器构建为镜像" class="headerlink" title="6、将运行中的容器构建为镜像"></a>6、将运行中的容器构建为镜像</h4><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker ps<br>CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                               NAMES<br>e3788cdd7be6   nginx     “&#x2F;docker-entrypoint.…”   4 minutes ago   Up 4 minutes   0.0.0.0:88-&gt;80&#x2F;tcp, :::88-&gt;80&#x2F;tcp   myningx<br>root@hello:</del>#<br>root@hello:<del># docker commit -a “cby” -m “my app” e3788cdd7be6 myapp:v1.0<br>sha256:07a7b54c914c79dfbd402029a3d144201235eca72a4f26c92e2ec7780c485226<br>root@hello:</del>#<br>root@hello:<del># docker images<br>REPOSITORY   TAG       IMAGE ID       CREATED         SIZE<br>myapp        v1.0      07a7b54c914c   4 seconds ago   141MB<br>nginx        latest    e9ce56a96f8e   8 hours ago     141MB<br>root@hello:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h4 id="7、镜像保存与导入"><a href="#7、镜像保存与导入" class="headerlink" title="7、镜像保存与导入"></a>7、镜像保存与导入</h4><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker save -o cby.tar myapp:v1.0<br>root@hello:</del># ll cby.tar<br>-rw——- 1 root root 145910784 Nov 17 02:21 cby.tar<br>root@hello:<del>#<br>root@hello:</del># docker load -i cby.tar<br>Loaded image: myapp:v1.0<br>root@hello:<del>#<br>root@hello:</del># docker images<br>REPOSITORY   TAG       IMAGE ID       CREATED         SIZE<br>myapp        v1.0      07a7b54c914c   3 minutes ago   141MB<br>nginx        latest    e9ce56a96f8e   8 hours ago     141MB<br>nginx        1.20.1    c8d03f6b8b91   5 weeks ago     133MB<br>root@hello:~#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<h4 id="8、推送到DockerHub，并在其他主机上可拉去该镜像"><a href="#8、推送到DockerHub，并在其他主机上可拉去该镜像" class="headerlink" title="8、推送到DockerHub，并在其他主机上可拉去该镜像"></a>8、推送到DockerHub，并在其他主机上可拉去该镜像</h4><p>&#96;&#96;&#96;shell<br>root@hello:<del># docker tag myapp:v1.0 chenbuyun&#x2F;myapp:v1.0<br>root@hello:</del>#<br>root@hello:~# docker login<br>Login with your Docker ID to push and pull images from Docker Hub. If you don’t have a Docker ID, head over to <a href="https://hub.docker.com/">https://hub.docker.com</a> to create one.<br>Username: chenbuyun<br>Password:<br>WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.<br>Configure a credential helper to remove this warning. See<br><a href="https://docs.docker.com/engine/reference/commandline/login/#credentials-store">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</a></p>
<p>Login Succeeded<br>root@hello:<del># docker push chenbuyun&#x2F;myapp:v1.0<br>The push refers to repository [docker.io&#x2F;chenbuyun&#x2F;myapp]<br>799aefeaf6b1: Pushed<br>fd688ba2259e: Mounted from library&#x2F;nginx<br>c731fe3d8126: Mounted from library&#x2F;nginx<br>3b1690d8cd86: Mounted from library&#x2F;nginx<br>03f105433dc8: Mounted from library&#x2F;nginx<br>bd7b2912e0ab: Mounted from library&#x2F;nginx<br>e8b689711f21: Mounted from library&#x2F;nginx<br>v1.0: digest: sha256:f085a533e36cccd27a21fe4de7c87f652fe9346e1ed86e3d82856d5d4434c0a0 size: 1777<br>root@hello:</del>#<br>root@hello:<del># docker logout<br>Removing login credentials for <a href="https://index.docker.io/v1/">https://index.docker.io/v1/</a><br>root@hello:</del>#<br>root@hello:<del># docker pull chenbuyun&#x2F;myapp:v1.0<br>v1.0: Pulling from chenbuyun&#x2F;myapp<br>Digest: sha256:f085a533e36cccd27a21fe4de7c87f652fe9346e1ed86e3d82856d5d4434c0a0<br>Status: Downloaded newer image for chenbuyun&#x2F;myapp:v1.0<br>docker.io&#x2F;chenbuyun&#x2F;myapp:v1.0<br>root@hello:</del>#<br>root@hello:<del># docker images<br>REPOSITORY        TAG       IMAGE ID       CREATED         SIZE<br>chenbuyun&#x2F;myapp   v1.0      07a7b54c914c   9 minutes ago   141MB<br>myapp             v1.0      07a7b54c914c   9 minutes ago   141MB<br>nginx             latest    e9ce56a96f8e   8 hours ago     141MB<br>nginx             1.20.1    c8d03f6b8b91   5 weeks ago     133MB<br>root@hello:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>&#96;&#96;&#96;shell</p>
<p>以上仅为常用命令，更多docker相关知识可在：<a href="https://www.runoob.com/docker/docker-tutorial.html">https://www.runoob.com/docker/docker-tutorial.html</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bb60b2788966407595c25096531fe639~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>55篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a71a46d98cd74dc19af67b43b6de547a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>华为 A800-9000 服务器 离线安装MindX DL 可视化环境+监控</title>
    <url>/2021/12/30/2021-12-30-%E5%8D%8E%E4%B8%BA_A800-9000_%E6%9C%8D%E5%8A%A1%E5%99%A8_%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85MindX_DL_%E5%8F%AF%E8%A7%86%E5%8C%96%E7%8E%AF%E5%A2%83+%E7%9B%91%E6%8E%A7/</url>
    <content><![CDATA[<p>    MindX DL Sample主要应用于企业的数据中心或超算中心机房中，针对不同的应用场景为客户提供AI深度学习端到端解决方案。</p>
<p>    传统行业：用户无自建深度学习平台，希望能够提供简单易用、软硬件一体化的深度学习平台。</p>
<p>    互联网和安防行业：用户有自建深度学习平台，希望提供适配客户深度学习平台的开源插件，快速上线昇腾系列AI处理器的深度学习。</p>
<p>    超算中心和公有云行业：用户无AI深度学习集群，希望提供大规模AI深度学习集群、支持超高密部署、整柜交付，缩短项目交付周期，加速业务上线，节省安装部署及调测成本。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1b9e7276bdb94153a970476da4185a75~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>    说明：此文档需要先将基础kubernetes环境下的DL搭建完成，参考《华为 A800-9000 服务器 离线安装MindX DL》  </p>
<p>一、 修改ansible配置文件  </p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;etc&#x2F;ansible# vim hosts<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible# cat &#x2F;etc&#x2F;ansible&#x2F;hosts<br>[all:vars]</p>
<h1 id="NFS-service-IP"><a href="#NFS-service-IP" class="headerlink" title="NFS service IP"></a>NFS service IP</h1><p>nfs_service_ip&#x3D;192.168.1.99</p>
<h1 id="Master-IP"><a href="#Master-IP" class="headerlink" title="Master IP"></a>Master IP</h1><p>master_ip&#x3D;192.168.1.99</p>
<p>[workers]<br>localnode ansible_host&#x3D;192.168.1.99 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;123123</p>
<p>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible# vi &#x2F;etc&#x2F;ansible&#x2F;ansible.cfg</p>
<h1 id="取消以下两行内容的注释并更改deprecation-warnings为“False”。"><a href="#取消以下两行内容的注释并更改deprecation-warnings为“False”。" class="headerlink" title="取消以下两行内容的注释并更改deprecation_warnings为“False”。"></a>取消以下两行内容的注释并更改deprecation_warnings为“False”。</h1><p>host_key_checking &#x3D; False<br>deprecation_warnings &#x3D; False</p>
<p>&#96;&#96;&#96;shell</p>
<p>二、下载基础镜像  </p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:&#x2F;etc&#x2F;ansible# docker pull redis:5.0.8<br>5.0.8: Pulling from library&#x2F;redis<br>3d48095d71a3: Pull complete<br>773882920678: Pull complete<br>b04905edf724: Pull complete<br>90e236b4682b: Pull complete<br>fb7d8181d1c6: Pull complete<br>532c81fe8c61: Pull complete<br>Digest: sha256:96bdb5e2984b15e3cf4de74077f650c911cb26ec0981e0772df35a1a5cb19798<br>Status: Downloaded newer image for redis:5.0.8<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible# docker pull prom&#x2F;prometheus:v2.10.0<br>v2.10.0: Pulling from prom&#x2F;prometheus<br>596fa44d463e: Pull complete<br>ae7a0e9c5457: Pull complete<br>3e3e880277a4: Pull complete<br>d884b32e16d7: Pull complete<br>6f45dfbc8251: Pull complete<br>e7275b596775: Pull complete<br>d3c1f1d7d1d1: Pull complete<br>f040a278aa08: Pull complete<br>403fefd2b7ea: Pull complete<br>Digest: sha256:b89e9c7ffbfbc8efebd6d8ff89b33175625bb2c7ae2751fbcd89f0884cfbdcab<br>Status: Downloaded newer image for prom&#x2F;prometheus:v2.10.0<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible# docker pull mysql&#x2F;mysql-server:8.0.13<br>8.0.13: Pulling from mysql&#x2F;mysql-server<br>5530262403b2: Pull complete<br>01c05f6b9ab3: Pull complete<br>f521094e248f: Pull complete<br>495eb6103d23: Pull complete<br>Digest: sha256:59a5854dca16488305aee60c8dea4d88b68d816aee627de022b19d9bead48d04<br>Status: Downloaded newer image for mysql&#x2F;mysql-server:8.0.13<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible# docker pull grafana&#x2F;grafana:7.0.2<br>7.0.2: Pulling from grafana&#x2F;grafana<br>29e5d40040c1: Pull complete<br>c33923c8c811: Pull complete<br>3fd85f7a4ab6: Pull complete<br>987cf1afe976: Pull complete<br>a27d86f46de8: Pull complete<br>285316502f38: Pull complete<br>Digest: sha256:5b9c9e18a8279a818144d90431ac0631bc17f520aa5c2fd6dd70bf767b48e632<br>Status: Downloaded newer image for grafana&#x2F;grafana:7.0.2<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible# docker pull python:3.7.5<br>3.7.5: Pulling from library&#x2F;python<br>af4800279257: Pull complete<br>8fae2ec46cd5: Pull complete<br>8a8718b9412e: Pull complete<br>4908f8b44725: Pull complete<br>54e0fac9e6c6: Pull complete<br>2b1da11f97bb: Pull complete<br>d93a637093d0: Pull complete<br>c79746565cc4: Pull complete<br>3dfacccebd97: Pull complete<br>Digest: sha256:88d11783cbbfa06f1c12ca50c73c340b0bff34bf599c6e1dd27fb836a8de506d<br>Status: Downloaded newer image for python:3.7.5<br>root@ubuntu:&#x2F;etc&#x2F;ansible#<br>root@ubuntu:&#x2F;etc&#x2F;ansible# docker pull ubuntu:18.04<br>18.04: Pulling from library&#x2F;ubuntu<br>fda1cca7a3cc: Pull complete<br>Digest: sha256:7bd7a9ca99f868bf69c4b6212f64f2af8e243f97ba13abb3e641e03a7ceb59e8<br>Status: Downloaded newer image for ubuntu:18.04<br>root@ubuntu:&#x2F;etc&#x2F;ansible#</p>
<p>&#96;&#96;&#96;shell</p>
<p>三、配置NGINX镜像配置  </p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;nginx# vim Dockerfile<br>FROM ubuntu:18.04</p>
<p>#(可选Part1)如用户环境需要配置代理连接网络，此处需要按如下示例配置代理，可直接取消注释并填写相应字段（大括号不保留）。</p>
<h1 id="ENV-http-proxy-http-x2F-x2F-username-password-IP-port"><a href="#ENV-http-proxy-http-x2F-x2F-username-password-IP-port" class="headerlink" title="ENV http_proxy http:&#x2F;&#x2F;{username}:{password}@{IP}:{port}"></a>ENV http_proxy http:&#x2F;&#x2F;{username}:{password}@{IP}:{port}</h1><h1 id="ENV-https-proxy-http-x2F-x2F-username-password-IP-port"><a href="#ENV-https-proxy-http-x2F-x2F-username-password-IP-port" class="headerlink" title="ENV https_proxy http:&#x2F;&#x2F;{username}:{password}@{IP}:{port}"></a>ENV https_proxy http:&#x2F;&#x2F;{username}:{password}@{IP}:{port}</h1><p>#(可选Part2)如用户环境需要配置代理连接网络，此处需要按如下示例配置代理，可直接取消注释并填写相应字段（大括号不保留）。</p>
<h1 id="RUN-echo-‘Acquire-http-Proxy-“http-x2F-x2F-username-password-IP-port-”-Acquire-https-Proxy-“http-x2F-x2F-username-password-IP-port-”-’-gt-x2F-etc-x2F-apt-x2F-apt-conf-d-x2F-80proxy"><a href="#RUN-echo-‘Acquire-http-Proxy-“http-x2F-x2F-username-password-IP-port-”-Acquire-https-Proxy-“http-x2F-x2F-username-password-IP-port-”-’-gt-x2F-etc-x2F-apt-x2F-apt-conf-d-x2F-80proxy" class="headerlink" title="RUN echo ‘Acquire::http::Proxy “http:&#x2F;&#x2F;{username}:{password}@{IP}:{port}”; Acquire::https::Proxy “http:&#x2F;&#x2F;{username}:{password}@{IP}:{port}”;’ &gt; &#x2F;etc&#x2F;apt&#x2F;apt.conf.d&#x2F;80proxy"></a>RUN echo ‘Acquire::http::Proxy “http:&#x2F;&#x2F;{username}:{password}@{IP}:{port}”; Acquire::https::Proxy “http:&#x2F;&#x2F;{username}:{password}@{IP}:{port}”;’ &gt; &#x2F;etc&#x2F;apt&#x2F;apt.conf.d&#x2F;80proxy</h1><p>##(可选Part3)配置apt源，ARM环境示例，请根据环境架构在Part3和Part4中二选一<br>#RUN echo ‘deb <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic main restricted universe multiverse \n<br>#deb <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic-security main restricted universe multiverse \n<br>#deb <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic-updates main restricted universe multiverse \n<br>#deb <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic-proposed main restricted universe multiverse \n<br>#deb <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic-backports main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic-security main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic-updates main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic-proposed main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu-ports/">http://mirrors.aliyun.com/ubuntu-ports/</a> bionic-backports main restricted universe multiverse’  &gt; &#x2F;etc&#x2F;apt&#x2F;sources.list</p>
<p>##(可选Part4)配置apt源，x86环境示例，请根据环境架构在Part3和Part4中二选一<br>#RUN echo ‘deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic main restricted universe multiverse \n<br>#deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic-security main restricted universe multiverse \n<br>#deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic-updates main restricted universe multiverse \n<br>#deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic-proposed main restricted universe multiverse \n<br>#deb <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic-backports main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic-security main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic-updates main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic-proposed main restricted universe multiverse \n<br>#deb-src <a href="http://mirrors.aliyun.com/ubuntu/">http://mirrors.aliyun.com/ubuntu/</a> bionic-backports main restricted universe multiverse’  &gt; &#x2F;etc&#x2F;apt&#x2F;sources.list</p>
<p>RUN echo ‘deb <a href="http://cn.ports.ubuntu.com/ubuntu-ports/">http://cn.ports.ubuntu.com/ubuntu-ports/</a> bionic main restricted \n<br>deb <a href="http://cn.ports.ubuntu.com/ubuntu-ports/">http://cn.ports.ubuntu.com/ubuntu-ports/</a> bionic-updates main restricted \n<br>deb <a href="http://cn.ports.ubuntu.com/ubuntu-ports/">http://cn.ports.ubuntu.com/ubuntu-ports/</a> bionic universe \n<br>deb <a href="http://cn.ports.ubuntu.com/ubuntu-ports/">http://cn.ports.ubuntu.com/ubuntu-ports/</a> bionic-updates universe \n<br>deb <a href="http://cn.ports.ubuntu.com/ubuntu-ports/">http://cn.ports.ubuntu.com/ubuntu-ports/</a> bionic multiverse \n<br>deb <a href="http://cn.ports.ubuntu.com/ubuntu-ports/">http://cn.ports.ubuntu.com/ubuntu-ports/</a> bionic-updates multiverse \n<br>deb <a href="http://cn.ports.ubuntu.com/ubuntu-ports/">http://cn.ports.ubuntu.com/ubuntu-ports/</a> bionic-backports main restricted universe multiverse \n<br>deb <a href="http://ports.ubuntu.com/ubuntu-ports">http://ports.ubuntu.com/ubuntu-ports</a> bionic-security main restricted \n\<br>deb <a href="http://ports.ubuntu.com/ubuntu-ports">http://ports.ubuntu.com/ubuntu-ports</a> bionic-security universe \n<br>deb <a href="http://ports.ubuntu.com/ubuntu-ports">http://ports.ubuntu.com/ubuntu-ports</a> bionic-security multiverse’ &gt; &#x2F;etc&#x2F;apt&#x2F;sources.list</p>
<p>RUN apt-get update &amp;&amp; <br>    apt-get install -y build-essential &amp;&amp; <br>    apt-get install -y libtool &amp;&amp; <br>    apt-get install -y libpcre3 libpcre3-dev &amp;&amp; <br>    apt-get install -y zlib1g-dev &amp;&amp; <br>    apt-get install -y openssl &amp;&amp; <br>    apt-get install libssl-dev &amp;&amp; <br>    apt-get install -y wget &amp;&amp; <br>    apt-get install -y git</p>
<p>RUN export GIT_SSL_NO_VERIFY&#x3D;1 &amp;&amp; <br>    git clone <a href="https://github.com/masterzen/nginx-upload-progress-module.git">https://github.com/masterzen/nginx-upload-progress-module.git</a> &amp;&amp; <br>    git clone <a href="https://github.com/fdintino/nginx-upload-module.git">https://github.com/fdintino/nginx-upload-module.git</a> &amp;&amp; <br>    wget –no-check-certificate <a href="http://nginx.org/download/nginx-1.17.3.tar.gz">http://nginx.org/download/nginx-1.17.3.tar.gz</a> &amp;&amp; <br>    tar -zxvf nginx-1.17.3.tar.gz &amp;&amp; <br>    cd nginx-1.17.3 &amp;&amp; <br>    .&#x2F;configure –add-module&#x3D;..&#x2F;nginx-upload-module&#x2F; –add-module&#x3D;..&#x2F;nginx-upload-progress-module&#x2F; –prefix&#x3D;&#x2F;etc&#x2F;nginx –sbin-path&#x3D;&#x2F;usr&#x2F;sbin&#x2F;nginx –modules-path&#x3D;&#x2F;usr&#x2F;lib&#x2F;nginx&#x2F;modules –conf-path&#x3D;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf –error-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log –http-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log –pid-path&#x3D;&#x2F;var&#x2F;run&#x2F;nginx.pid –lock-path&#x3D;&#x2F;var&#x2F;run&#x2F;nginx.lock –http-client-body-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;client_temp –http-proxy-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;proxy_temp –http-fastcgi-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;fastcgi_temp –http-uwsgi-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;uwsgi_temp –http-scgi-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;scgi_temp –user&#x3D;nginx –group&#x3D;nginx –with-compat –with-file-aio –with-threads –with-http_addition_module –with-http_auth_request_module –with-http_dav_module –with-http_flv_module –with-http_gunzip_module –with-http_gzip_static_module –with-http_mp4_module –with-http_random_index_module –with-http_realip_module –with-http_secure_link_module –with-http_slice_module –with-http_ssl_module –with-http_stub_status_module –with-http_sub_module –with-http_v2_module –with-mail –with-mail_ssl_module –with-stream –with-stream_realip_module –with-stream_ssl_module –with-stream_ssl_preread_module –with-cc-opt&#x3D;’-g -O2 -fdebug-prefix-map&#x3D;&#x2F;tmp&#x2F;tmp.UI0oSlj34i&#x2F;nginx-1.17.10&#x3D;. -fstack-protector-strong -Wformat -Werror&#x3D;format-security -Wp,-D_FORTIFY_SOURCE&#x3D;2 -fPIC’ –with-ld-opt&#x3D;’-Wl,-z,relro -Wl,-z,now -Wl,–as-needed -pie’ &amp;&amp; <br>    make &amp;&amp; make install &amp;&amp; ln -s &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx &#x2F;usr&#x2F;bin&#x2F;nginx &amp;&amp; <br>    mkdir -pv &#x2F;var&#x2F;cache&#x2F;nginx&#x2F;client_temp  &amp;&amp; <br>    cd ..</p>
<p>#RUN rm &#x2F;etc&#x2F;apt&#x2F;apt.conf.d&#x2F;80proxy &#x2F;etc&#x2F;apt&#x2F;sources.list &amp;&amp; \</p>
<h1 id="rm-nginx-1-17-3-tar-gz-amp-amp"><a href="#rm-nginx-1-17-3-tar-gz-amp-amp" class="headerlink" title="rm nginx-1.17.3.tar.gz &amp;&amp; \"></a>rm nginx-1.17.3.tar.gz &amp;&amp; \</h1><h1 id="rm-rf-nginx-1-17-3-nginx-upload-module-nginx-upload-progress-module"><a href="#rm-rf-nginx-1-17-3-nginx-upload-module-nginx-upload-progress-module" class="headerlink" title="rm -rf nginx-1.17.3 nginx-upload-module nginx-upload-progress-module"></a>rm -rf nginx-1.17.3 nginx-upload-module nginx-upload-progress-module</h1><p>#(可选Part5)如在Part1中配置了代理，需要取消下面两行注释取消对应代理配置。<br>#ENV http_proxy “”<br>#ENV https_proxy “”</p>
<p>#(可选Part6)如在Part2中配置了代理，需要取消下面一行注释取消对应代理配置。<br>#RUN echo “” &gt; &#x2F;etc&#x2F;apt&#x2F;apt.conf.d&#x2F;80proxy</p>
<p>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;nginx# docker build -t nginx-upload:v1 .</p>
<p>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;nginx# docker images | grep ng<br>nginx-upload                          v1                  15bbdc3677d7        4 minutes ago       372MB</p>
<p>&#96;&#96;&#96;shell</p>
<p>四、安装前端所需工具，并编译前端代码  </p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# curl -o- <a href="https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh">https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh</a> | bash<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# nvm install node<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# apt install -y npm<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# apt install -y node<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# wget -qO- <a href="https://raw.githubusercontent.com/creationix/nvm/v0.33.6/install.sh">https://raw.githubusercontent.com/creationix/nvm/v0.33.6/install.sh</a> | bash<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# nvm install node<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# npm config set registry <a href="http://r.cnpmjs.org/">http://r.cnpmjs.org/</a>;<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# npm install –global vue-cli;<br>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;src&#x2F;webgui# npm install webpack -g;</p>
<p>&#96;&#96;&#96;shell</p>
<p>五、修改TJM配置文件</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls# vim tjm.yaml<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls#<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls#<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls#<br>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls# cat tjm.yaml<br>apiVersion: apps&#x2F;v1<br>kind: Deployment<br>metadata:<br>  name: tjm<br>  namespace: default<br>  labels:<br>    app: tjm<br>spec:<br>  replicas: 1<br>  selector:<br>    matchLabels:<br>      app: tjm<br>  template:<br>    metadata:<br>      labels:<br>        app: tjm<br>    spec:<br>      nodeSelector:<br>        masterselector: dls-master-node<br>      containers:<br>        - image: tjm:v0.0.1<br>          name: tjm-core<br>          imagePullPolicy: IfNotPresent<br>          command:<br>            - “&#x2F;bin&#x2F;bash”<br>            - “-c”<br>            - “&#x2F;bin&#x2F;bash &#x2F;tjm&#x2F;start.sh”<br>          env:<br>            # The following env variables set up basic auth twith the default admin user and admin password.<br>            - name: NFS_IP<br>              value: 192.168.1.99<br>            - name: NFS_ROOT_DIR<br>              value: “&#x2F;data&#x2F;atlas_dls”<br>            - name: INCLUSTER_FLAG<br>              value: “TRUE”<br>            - name: SERVICE_DOMAIN_NAME<br>              value: 192.168.1.99<br>            - name: CONTAINER_ROOT_DIR<br>              value: “&#x2F;datanfs”<br>            - name: TENSORBOARD_IMAGE<br>              value: “tensorboard:latest”<br>            - name: TENSORBOARD_CPU<br>              value: “190”<br>            - name: TENSORBOARD_MEMORY<br>              value: “200Mi”<br>            - name: MINDINSIGHT_IMAGE<br>              value: “mindinsight:latest”<br>            - name: MINDINSIGHT_CPU<br>              value: “190”<br>            - name: MINDINSIGHT_MEMORY<br>              value: “2048Mi”<br>            - name: TIMEZONE<br>              value: “8”<br>          volumeMounts:<br>            - name: dls-data<br>              mountPath: &#x2F;datanfs<br>            - name: localtime<br>              mountPath: &#x2F;etc&#x2F;localtime<br>            - name: dls-log<br>              mountPath: &#x2F;var&#x2F;log&#x2F;atlas_dls&#x2F;tjm<br>          resources:<br>            requests:<br>              cpu: “500m”<br>              memory: “100Mi”<br>            limits:<br>              cpu: “5000m”<br>              memory: “50000Mi”<br>      volumes:<br>        - name: dls-data<br>          nfs:<br>            server: 192.168.1.99<br>            path: &#x2F;data&#x2F;atlas_dls<br>        - name: localtime<br>          hostPath:<br>            path: &#x2F;etc&#x2F;localtime<br>        - name: dls-log<br>          hostPath:<br>            path: &#x2F;var&#x2F;log&#x2F;atlas_dls&#x2F;tjm</p>
<hr>
<p>kind: Service<br>apiVersion: v1<br>metadata:<br>  labels:<br>    app: tjm<br>  name: tjm<br>  namespace: default<br>spec:<br>  ports:<br>    - port: 5003<br>      targetPort: 5003<br>  selector:<br>    app: tjm<br>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls# </p>
<p>tjm.yaml</p>
<p>修改env字段中以下参数配置：</p>
<ul>
<li>name: TENSORBOARD_IMAGE<br>value: “tensorboard:latest”  #Tensorboard镜像名和版本。</li>
<li>name: TENSORBOARD_CPU<br>value: “1”  #Tensorboard任务运行所需CPU，建议≥1。</li>
<li>name: TENSORBOARD_MEMORY<br>value: “200Mi”  #Tensorboard任务运行所需内存，建议≥100Mi。</li>
<li>name: MINDINSIGHT_IMAGE<br>value: “mindinsight:latest”  #Mindinsight镜像名和版本。</li>
<li>name: MINDINSIGHT_CPU<br>value: “4”  #Mindinsight任务运行所需CPU，建议≥4。</li>
<li>name: MINDINSIGHT_MEMORY<br>value: “2048Mi”  #Mindinsight任务运行所需内存，建议≥2048Mi。</li>
<li>name: TIMEZONE<br>value: “8”   #默认为8（东八区），根据实际配置时区。</li>
</ul>
<p>&#96;&#96;&#96;shell</p>
<p>六、修改MMS配置文件  </p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls# vim mms.yaml<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls# cat mms.yaml<br>apiVersion: apps&#x2F;v1<br>kind: Deployment<br>metadata:<br>  name: dls-mms-deploy<br>  namespace: default<br>spec:<br>  replicas: 1<br>  selector:<br>    matchLabels:<br>      app: dls-mms<br>  template:<br>    metadata:<br>      labels:<br>        app: dls-mms<br>    spec:<br>      nodeSelector:<br>        masterselector: dls-master-node<br>      containers:<br>        - name: dls-mms<br>          image: mms:v0.0.1<br>          imagePullPolicy: IfNotPresent<br>          command: [ “&#x2F;bin&#x2F;bash”, “-c”, “–” ]<br>          args: [ “chmod 550 &#x2F;data&#x2F;mms&#x2F;start.sh;&#x2F;data&#x2F;mms&#x2F;start.sh” ]<br>          ports:<br>            - containerPort: 5000<br>          env:<br>            - name: NFS_IP<br>              value: 192.168.1.99<br>            - name: NFS_ROOT_DIR<br>              value: “&#x2F;data&#x2F;atlas_dls”<br>            - name: INCLUSTER_FLAG<br>              value: “TRUE”<br>            - name: CONTAINER_ROOT_DIR<br>              value: “&#x2F;datanfs”<br>            - name: MODEL_CONVERT_IMAGE<br>              value: “tf-c73:b033-with-atc”<br>          volumeMounts:<br>            - name: dls-data<br>              mountPath: &#x2F;datanfs<br>            - name: dls-log<br>              mountPath: &#x2F;var&#x2F;log&#x2F;atlas_dls&#x2F;mms<br>            - name: localtime<br>              mountPath: &#x2F;etc&#x2F;localtime<br>          resources:<br>            requests:<br>              cpu: “500m”<br>              memory: “100Mi”<br>            limits:<br>              cpu: “5000m”<br>              memory: “50000Mi”</p>
<pre><code>  volumes:
    - name: dls-data
      nfs:
        server: 192.168.1.99
        path: &quot;/data/atlas_dls&quot;
    - name: dls-log
      hostPath:
        path: /var/log/atlas_dls/mms
    - name: localtime
      hostPath:
        path: /etc/localtime
</code></pre>
<hr>
<p>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: dls-mms<br>  namespace: default<br>  labels:<br>    app: atlas-dls<br>spec:<br>  ports:<br>    - name: dls-mms<br>      port: 5002<br>      protocol: TCP<br>      targetPort: 5002<br>  selector:<br>    app:  dls-mms<br>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;yamls# </p>
<p>mms.yaml</p>
<p>修改env字段中以下参数配置：</p>
<ul>
<li>name: MODEL_CONVERT_IMAGE<br>value: “tf-c73:b033-with-atc”  #模型转换镜像名<br>&#96;&#96;&#96;shell</li>
</ul>
<p>七、自动化安装，SHELL回显略</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;playbooks# ansible-playbook deploy.yaml</p>
<p>&#96;&#96;&#96;shell</p>
<p>八、拉去训练镜像  </p>
<p><a href="https://ascendhub.huawei.com/#/index">https://ascendhub.huawei.com/#/index</a></p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;playbooks# docker login -u 15648907522 -p tDYqC45NFQ2VVb1Wk48C0AK4PC02SBjBpoUDOjo7oqIpdjBSaPzZyR112lzbzBWve ascendhub.huawei.com<br>WARNING! Using –password via the CLI is insecure. Use –password-stdin.<br>WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.<br>Configure a credential helper to remove this warning. See<br><a href="https://docs.docker.com/engine/reference/commandline/login/#credentials-store">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</a></p>
<p>Login Succeeded<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;playbooks# docker pull ascendhub.huawei.com&#x2F;public-ascendhub&#x2F;ascend-mindspore-arm:21.0.1.spc001<br>21.0.1.spc001: Pulling from public-ascendhub&#x2F;ascend-mindspore-arm<br>fda1cca7a3cc: Already exists<br>11c90fde7ae4: Pull complete<br>7253b5e27781: Pull complete<br>bbd60ae31b0e: Pull complete<br>5ff0775b62ee: Pull complete<br>4bd7bd3ffee1: Pull complete<br>8f7e244558aa: Pull complete<br>2782e4575e5b: Pull complete<br>6082e54e59ee: Pull complete<br>bd1b2e5f115e: Pull complete<br>53142cd42310: Pull complete<br>d746749ab006: Pull complete<br>691a8a68558b: Pull complete<br>ecbb81572dc3: Pull complete<br>65d85230814c: Pull complete<br>Digest: sha256:29069b29542554d5ac8f79c2be3ba78ace77751546bfad24b480acf782e39fa7<br>Status: Downloaded newer image for ascendhub.huawei.com&#x2F;public-ascendhub&#x2F;ascend-mindspore-arm:21.0.1.spc001<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;playbooks# docker pull ascendhub.huawei.com&#x2F;public-ascendhub&#x2F;ascend-tensorflow-arm:21.0.1<br>21.0.1: Pulling from public-ascendhub&#x2F;ascend-tensorflow-arm<br>04da93b342eb: Pull complete<br>b235194751de: Pull complete<br>606a67bb8db9: Pull complete<br>4af9b0a6671e: Pull complete<br>aa86c517c858: Pull complete<br>7d232de65c7f: Pull complete<br>396a8ab7f029: Pull complete<br>bc0d0369a1f9: Pull complete<br>86f265d63edf: Pull complete<br>0cef5083e917: Pull complete<br>360419151a16: Pull complete<br>06436a96fc81: Pull complete<br>13611bc87943: Pull complete<br>2127513261ef: Pull complete<br>Digest: sha256:0e6fac7ec1cb09bb57bbd076d6b6054f44f91afe6dfadfca2270a51ba2fc53e0<br>Status: Downloaded newer image for ascendhub.huawei.com&#x2F;public-ascendhub&#x2F;ascend-tensorflow-arm:21.0.1<br>root@ubuntu:<del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;playbooks# docker pull ascendhub.huawei.com&#x2F;public-ascendhub&#x2F;ascend-pytorch-arm:21.0.1<br>21.0.1: Pulling from public-ascendhub&#x2F;ascend-pytorch-arm<br>04da93b342eb: Already exists<br>b235194751de: Already exists<br>606a67bb8db9: Already exists<br>e93c757bff45: Pull complete<br>3cf04b2262e0: Pull complete<br>b747b6b075df: Pull complete<br>9d1ca426ec5d: Pull complete<br>6709e46dffeb: Pull complete<br>c9a5fa495f7c: Pull complete<br>88232903df71: Pull complete<br>ef57b6fb083b: Pull complete<br>ea40e63aedc6: Pull complete<br>fb00b3f33bf9: Pull complete<br>7fa0e069227a: Pull complete<br>c875eb36de84: Pull complete<br>Digest: sha256:57f724d4b938753102d09d0ffbab5b0c0697cf3e37b1e8ac948bb8a8df356958<br>Status: Downloaded newer image for ascendhub.huawei.com&#x2F;public-ascendhub&#x2F;ascend-pytorch-arm:21.0.1<br>root@ubuntu:</del>&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;playbooks#<br>root@ubuntu:~&#x2F;123&#x2F;mindxdl-sample-20210715-V2.0.2&#x2F;deploy&#x2F;playbooks#</p>
<p>&#96;&#96;&#96;shell</p>
<p>九、构建jupyter-notebook镜像  </p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:<del>&#x2F;123# mkdir jupyter-notebook<br>root@ubuntu:</del>&#x2F;123#<br>root@ubuntu:<del>&#x2F;123# cd jupyter-notebook&#x2F;<br>root@ubuntu:</del>&#x2F;123&#x2F;jupyter-notebook# ls<br>root@ubuntu:<del>&#x2F;123&#x2F;jupyter-notebook#<br>root@ubuntu:</del>&#x2F;123&#x2F;jupyter-notebook#<br>root@ubuntu:<del>&#x2F;123&#x2F;jupyter-notebook# vi Dockerfile<br>root@ubuntu:</del>&#x2F;123&#x2F;jupyter-notebook#<br>root@ubuntu:<del>&#x2F;123&#x2F;jupyter-notebook#<br>root@ubuntu:</del>&#x2F;123&#x2F;jupyter-notebook# docker build -t notebook .^C<br>root@ubuntu:<del>&#x2F;123&#x2F;jupyter-notebook#<br>root@ubuntu:</del>&#x2F;123&#x2F;jupyter-notebook#<br>root@ubuntu:<del>&#x2F;123&#x2F;jupyter-notebook#<br>root@ubuntu:</del>&#x2F;123&#x2F;jupyter-notebook# cat Dockerfile<br>From python:3.7.5</p>
<h1 id="————————-Optional-Configure-the-proxy-and-source-———————–"><a href="#————————-Optional-Configure-the-proxy-and-source-———————–" class="headerlink" title="————————-(Optional) Configure the proxy and source.———————–"></a>————————-(Optional) Configure the proxy and source.———————–</h1><p>#ENV http_proxy http:&#x2F;&#x2F;<user>:<password>@ip:port<br>#ENV https_proxy http:&#x2F;&#x2F;<user>:<password>@ip:port<br>#ENV ftp_proxy ftp:&#x2F;&#x2F;<user>:<password>@ip:port</p>
<p>RUN mkdir -p ~&#x2F;.pip <br>&amp;&amp; echo ‘[global] \n\<br>index-url&#x3D;<a href="https://pypi.doubanio.com/simple//n/">https://pypi.doubanio.com/simple/\n\</a><br>trusted-host&#x3D;pypi.doubanio.com’ &gt;&gt; ~&#x2F;.pip&#x2F;pip.conf </p>
<p>RUN pip install jupyter <br>&amp;&amp; jupyter notebook –generate-config \<br>&amp;&amp; echo “c.NotebookApp.ip&#x3D;’0.0.0.0’ \n<br>c.NotebookApp.open_browser &#x3D; False \n<br>c.NotebookApp.token &#x3D; ‘’ \n<br>c.NotebookApp.port &#x3D;8888” &gt;&gt; ~&#x2F;.jupyter&#x2F;jupyter_notebook_config.py</p>
<p>RUN apt-get update <br>&amp;&amp; apt-get install -y openssh-server</p>
<p>RUN sed -ri ‘s&#x2F;UsePAM yes&#x2F;#UsePAM yes&#x2F;g’ &#x2F;etc&#x2F;ssh&#x2F;sshd_config <br>&amp;&amp; sed -ri ‘s&#x2F;^#?PermitRootLogin\s+.*&#x2F;PermitRootLogin yes&#x2F;‘ &#x2F;etc&#x2F;ssh&#x2F;sshd_config </p>
<p>ENV http_proxy ‘’<br>ENV https_proxy ‘’<br>ENV ftp_proxy ‘’</p>
<p>RUN useradd -d &#x2F;home&#x2F;hwMindX -u 9000 -m -s &#x2F;bin&#x2F;bash hwMindX &amp;&amp; <br>    useradd -d &#x2F;home&#x2F;HwHiAiUser -u 1000 -m -s &#x2F;bin&#x2F;bash HwHiAiUser &amp;&amp; <br>    usermod -a -G HwHiAiUser hwMindX</p>
<p>RUN echo root:123123 | chpasswd </p>
<p>USER hwMindX</p>
<p>ENTRYPOINT jupyter notebook –allow-root</p>
<p>root@ubuntu:<del>&#x2F;123&#x2F;jupyter-notebook# docker build -t notebook .<br>Sending build context to Docker daemon  3.072kB<br>Step 1&#x2F;12 : From python:3.7.5<br> —&gt; a4356c370cda<br>Step 2&#x2F;12 : RUN mkdir -p ~&#x2F;.pip &amp;&amp; echo ‘[global] \nindex-url&#x3D;<a href="https://pypi.doubanio.com/simple//ntrusted-host=pypi.doubanio.com&#39;">https://pypi.doubanio.com/simple/\ntrusted-host=pypi.doubanio.com&#39;</a> &gt;&gt; ~&#x2F;.pip&#x2F;pip.conf<br> —&gt; Running in 841fef0bfec2<br>Removing intermediate container 841fef0bfec2<br> —&gt; 2e9619b95f3c<br>Step 3&#x2F;12 : RUN pip install jupyter &amp;&amp; jupyter notebook –generate-config &amp;&amp; echo “c.NotebookApp.ip&#x3D;’0.0.0.0’ \nc.NotebookApp.open_browser &#x3D; False \nc.NotebookApp.token &#x3D; ‘’ \nc.NotebookApp.port &#x3D;8888” &gt;&gt; ~&#x2F;.jupyter&#x2F;jupyter_notebook_config.py<br> —&gt; Running in e8a384542bf2<br>Looking in indexes: <a href="https://pypi.doubanio.com/simple/">https://pypi.doubanio.com/simple/</a><br>Collecting jupyter<br>  Downloading <a href="https://pypi.doubanio.com/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl</a><br>Collecting nbconvert<br>  Downloading <a href="https://pypi.doubanio.com/packages/fd/12/7b225ea00a5fe32df30b2c303dcc8c21c8db533ea7c0e38b4ac5a41bd8f0/nbconvert-6.1.0-py3-none-any.whl">https://pypi.doubanio.com/packages/fd/12/7b225ea00a5fe32df30b2c303dcc8c21c8db533ea7c0e38b4ac5a41bd8f0/nbconvert-6.1.0-py3-none-any.whl</a> (551kB)<br>Collecting qtconsole<br>  Downloading <a href="https://pypi.doubanio.com/packages/3a/57/c8fc1fc6fb6bc03caca20ace9cd0ac0e16cc052b51cbe3acbeeb53abcb18/qtconsole-5.1.1-py3-none-any.whl">https://pypi.doubanio.com/packages/3a/57/c8fc1fc6fb6bc03caca20ace9cd0ac0e16cc052b51cbe3acbeeb53abcb18/qtconsole-5.1.1-py3-none-any.whl</a> (119kB)<br>Collecting ipykernel<br>  Downloading <a href="https://pypi.doubanio.com/packages/d4/9a/59010716573b2aae10ccf88ea275c9a50943a7f8d4a123ad3c6f385a6c94/ipykernel-6.2.0-py3-none-any.whl">https://pypi.doubanio.com/packages/d4/9a/59010716573b2aae10ccf88ea275c9a50943a7f8d4a123ad3c6f385a6c94/ipykernel-6.2.0-py3-none-any.whl</a> (122kB)<br>Collecting ipywidgets<br>  Downloading <a href="https://pypi.doubanio.com/packages/11/53/084940a83a8158364e630a664a30b03068c25ab75243224d6b488800d43a/ipywidgets-7.6.3-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/11/53/084940a83a8158364e630a664a30b03068c25ab75243224d6b488800d43a/ipywidgets-7.6.3-py2.py3-none-any.whl</a> (121kB)<br>Collecting notebook<br>  Downloading <a href="https://pypi.doubanio.com/packages/3c/0e/9883ebfa204c7328fab473e04bda8066b00960fadc6698972afa62ddf0ce/notebook-6.4.3-py3-none-any.whl">https://pypi.doubanio.com/packages/3c/0e/9883ebfa204c7328fab473e04bda8066b00960fadc6698972afa62ddf0ce/notebook-6.4.3-py3-none-any.whl</a> (9.9MB)<br>Collecting jupyter-console<br>  Downloading <a href="https://pypi.doubanio.com/packages/59/cd/aa2670ffc99eb3e5bbe2294c71e4bf46a9804af4f378d09d7a8950996c9b/jupyter_console-6.4.0-py3-none-any.whl">https://pypi.doubanio.com/packages/59/cd/aa2670ffc99eb3e5bbe2294c71e4bf46a9804af4f378d09d7a8950996c9b/jupyter_console-6.4.0-py3-none-any.whl</a><br>Collecting nbformat&gt;&#x3D;4.4<br>  Downloading <a href="https://pypi.doubanio.com/packages/e7/c7/dd50978c637a7af8234909277c4e7ec1b71310c13fb3135f3c8f5b6e045f/nbformat-5.1.3-py3-none-any.whl">https://pypi.doubanio.com/packages/e7/c7/dd50978c637a7af8234909277c4e7ec1b71310c13fb3135f3c8f5b6e045f/nbformat-5.1.3-py3-none-any.whl</a> (178kB)<br>Collecting testpath<br>  Downloading <a href="https://pypi.doubanio.com/packages/ac/87/5422f6d056bfbded920ccf380a65de3713a3b95a95ba2255be2a3fb4f464/testpath-0.5.0-py3-none-any.whl">https://pypi.doubanio.com/packages/ac/87/5422f6d056bfbded920ccf380a65de3713a3b95a95ba2255be2a3fb4f464/testpath-0.5.0-py3-none-any.whl</a> (84kB)<br>Collecting traitlets&gt;&#x3D;5.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/f6/7d/3ecb0ebd0ce8dcdfa7bd47ab85c1d4a521e6770ef283d0824f5804994dfe/traitlets-5.0.5-py3-none-any.whl">https://pypi.doubanio.com/packages/f6/7d/3ecb0ebd0ce8dcdfa7bd47ab85c1d4a521e6770ef283d0824f5804994dfe/traitlets-5.0.5-py3-none-any.whl</a> (100kB)<br>Collecting mistune&lt;2,&gt;&#x3D;0.8.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/09/ec/4b43dae793655b7d8a25f76119624350b4d65eb663459eb9603d7f1f0345/mistune-0.8.4-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/09/ec/4b43dae793655b7d8a25f76119624350b4d65eb663459eb9603d7f1f0345/mistune-0.8.4-py2.py3-none-any.whl</a><br>Collecting defusedxml<br>  Downloading <a href="https://pypi.doubanio.com/packages/07/6c/aa3f2f849e01cb6a001cd8554a88d4c77c5c1a31c95bdf1cf9301e6d9ef4/defusedxml-0.7.1-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/07/6c/aa3f2f849e01cb6a001cd8554a88d4c77c5c1a31c95bdf1cf9301e6d9ef4/defusedxml-0.7.1-py2.py3-none-any.whl</a><br>Collecting bleach<br>  Downloading <a href="https://pypi.doubanio.com/packages/b6/23/d06c0bddcef0df58dd2c9ac02f8639533a6671bed0ef3e236888bb3b0a3c/bleach-4.0.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/b6/23/d06c0bddcef0df58dd2c9ac02f8639533a6671bed0ef3e236888bb3b0a3c/bleach-4.0.0-py2.py3-none-any.whl</a> (146kB)<br>Collecting pandocfilters&gt;&#x3D;1.4.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/28/78/bd59a9adb72fa139b1c9c186e6f65aebee52375a747e4b6a6dcf0880956f/pandocfilters-1.4.3.tar.gz">https://pypi.doubanio.com/packages/28/78/bd59a9adb72fa139b1c9c186e6f65aebee52375a747e4b6a6dcf0880956f/pandocfilters-1.4.3.tar.gz</a><br>Collecting entrypoints&gt;&#x3D;0.2.2<br>  Downloading <a href="https://pypi.doubanio.com/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl</a><br>Collecting jupyter-core<br>  Downloading <a href="https://pypi.doubanio.com/packages/53/40/5af36bffa0af3ac71d3a6fc6709de10e4f6ff7c01745b8bc4715372189c9/jupyter_core-4.7.1-py3-none-any.whl">https://pypi.doubanio.com/packages/53/40/5af36bffa0af3ac71d3a6fc6709de10e4f6ff7c01745b8bc4715372189c9/jupyter_core-4.7.1-py3-none-any.whl</a> (82kB)<br>Collecting pygments&gt;&#x3D;2.4.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/78/c8/8d9be2f72d8f465461f22b5f199c04f7ada933add4dae6e2468133c17471/Pygments-2.10.0-py3-none-any.whl">https://pypi.doubanio.com/packages/78/c8/8d9be2f72d8f465461f22b5f199c04f7ada933add4dae6e2468133c17471/Pygments-2.10.0-py3-none-any.whl</a> (1.0MB)<br>Collecting jupyterlab-pygments<br>  Downloading <a href="https://pypi.doubanio.com/packages/a8/6f/c34288766797193b512c6508f5994b830fb06134fdc4ca8214daba0aa443/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/a8/6f/c34288766797193b512c6508f5994b830fb06134fdc4ca8214daba0aa443/jupyterlab_pygments-0.1.2-py2.py3-none-any.whl</a><br>Collecting nbclient&lt;0.6.0,&gt;&#x3D;0.5.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/a7/ed/b764fa931614cb7ed9bebbc42532daecef405d6bef660eeda882f6c23b98/nbclient-0.5.4-py3-none-any.whl">https://pypi.doubanio.com/packages/a7/ed/b764fa931614cb7ed9bebbc42532daecef405d6bef660eeda882f6c23b98/nbclient-0.5.4-py3-none-any.whl</a> (66kB)<br>Collecting jinja2&gt;&#x3D;2.4<br>  Downloading <a href="https://pypi.doubanio.com/packages/80/21/ae597efc7ed8caaa43fb35062288baaf99a7d43ff0cf66452ddf47604ee6/Jinja2-3.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/80/21/ae597efc7ed8caaa43fb35062288baaf99a7d43ff0cf66452ddf47604ee6/Jinja2-3.0.1-py3-none-any.whl</a> (133kB)<br>Collecting ipython-genutils<br>  Downloading <a href="https://pypi.doubanio.com/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl</a><br>Collecting pyzmq&gt;&#x3D;17.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/61/48/308d03af40bf44c86ef826d942b12bdab5fbae6282e858bdff8bd55b0818/pyzmq-22.2.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/61/48/308d03af40bf44c86ef826d942b12bdab5fbae6282e858bdff8bd55b0818/pyzmq-22.2.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl</a> (1.8MB)<br>Collecting jupyter-client&gt;&#x3D;4.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/b0/21/2104133f07e34f58712c87f0feaacdd38b5baff1ddb6ab72bb4baf16fc4a/jupyter_client-7.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/b0/21/2104133f07e34f58712c87f0feaacdd38b5baff1ddb6ab72bb4baf16fc4a/jupyter_client-7.0.1-py3-none-any.whl</a> (122kB)<br>Collecting qtpy<br>  Downloading <a href="https://pypi.doubanio.com/packages/21/0d/1cc56aa1df049d9f989520ee8214a6ccfd236095d56060967afdb0b8f0d8/QtPy-1.10.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/21/0d/1cc56aa1df049d9f989520ee8214a6ccfd236095d56060967afdb0b8f0d8/QtPy-1.10.0-py2.py3-none-any.whl</a> (54kB)<br>Collecting tornado&lt;7.0,&gt;&#x3D;4.2<br>  Downloading <a href="https://pypi.doubanio.com/packages/27/27/95912ec1ecbd5f3cc1ce76a8d62cb63d62ebee575acf02116814d42ea5eb/tornado-6.1-cp37-cp37m-manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/27/27/95912ec1ecbd5f3cc1ce76a8d62cb63d62ebee575acf02116814d42ea5eb/tornado-6.1-cp37-cp37m-manylinux2014_aarch64.whl</a> (428kB)<br>Collecting importlib-metadata&lt;5; python_version &lt; “3.8.0”<br>  Downloading <a href="https://pypi.doubanio.com/packages/c0/72/4512a88e402d4dc3bab49a845130d95ac48936ef3a9469b55cc79a60d84d/importlib_metadata-4.6.4-py3-none-any.whl">https://pypi.doubanio.com/packages/c0/72/4512a88e402d4dc3bab49a845130d95ac48936ef3a9469b55cc79a60d84d/importlib_metadata-4.6.4-py3-none-any.whl</a><br>Collecting ipython&lt;8.0,&gt;&#x3D;7.23.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/25/a0/e0b850415984ac29f14775b075efc54d73b38f0d50c6ebdea7820ffb1c12/ipython-7.26.0-py3-none-any.whl">https://pypi.doubanio.com/packages/25/a0/e0b850415984ac29f14775b075efc54d73b38f0d50c6ebdea7820ffb1c12/ipython-7.26.0-py3-none-any.whl</a> (786kB)<br>Collecting argcomplete&gt;&#x3D;1.12.3; python_version &lt; “3.8.0”<br>  Downloading <a href="https://pypi.doubanio.com/packages/b7/9e/9dc74d330c07866d72f62d553fe8bdbe32786ff247a14e68b5659963e6bd/argcomplete-1.12.3-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/b7/9e/9dc74d330c07866d72f62d553fe8bdbe32786ff247a14e68b5659963e6bd/argcomplete-1.12.3-py2.py3-none-any.whl</a><br>Collecting debugpy&lt;2.0,&gt;&#x3D;1.0.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/c5/2d/876b1140b1544fe2187235ae9f52cdcd1e77d2bad641ea2aef413e882751/debugpy-1.4.1-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/c5/2d/876b1140b1544fe2187235ae9f52cdcd1e77d2bad641ea2aef413e882751/debugpy-1.4.1-py2.py3-none-any.whl</a> (4.2MB)<br>Collecting matplotlib-inline&lt;0.2.0,&gt;&#x3D;0.1.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/7f/de/6c111d687335729cf8c156394c8d119b0dc3c34b6966ff2a2f7fe4aa79cf/matplotlib_inline-0.1.2-py3-none-any.whl">https://pypi.doubanio.com/packages/7f/de/6c111d687335729cf8c156394c8d119b0dc3c34b6966ff2a2f7fe4aa79cf/matplotlib_inline-0.1.2-py3-none-any.whl</a><br>Collecting jupyterlab-widgets&gt;&#x3D;1.0.0; python_version &gt;&#x3D; “3.6”<br>  Downloading <a href="https://pypi.doubanio.com/packages/18/b5/3473d275e3b2359efdf5768e9df95537308b93a31ad94fa92814ac565826/jupyterlab_widgets-1.0.0-py3-none-any.whl">https://pypi.doubanio.com/packages/18/b5/3473d275e3b2359efdf5768e9df95537308b93a31ad94fa92814ac565826/jupyterlab_widgets-1.0.0-py3-none-any.whl</a> (243kB)<br>Collecting widgetsnbextension</del>&#x3D;3.5.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/6c/7b/7ac231c20d2d33c445eaacf8a433f4e22c60677eb9776c7c5262d7ddee2d/widgetsnbextension-3.5.1-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/6c/7b/7ac231c20d2d33c445eaacf8a433f4e22c60677eb9776c7c5262d7ddee2d/widgetsnbextension-3.5.1-py2.py3-none-any.whl</a> (2.2MB)<br>Collecting argon2-cffi<br>  Downloading <a href="https://pypi.doubanio.com/packages/74/fd/d78e003a79c453e8454197092fce9d1c6099445b7e7da0b04eb4fe1dbab7/argon2-cffi-20.1.0.tar.gz">https://pypi.doubanio.com/packages/74/fd/d78e003a79c453e8454197092fce9d1c6099445b7e7da0b04eb4fe1dbab7/argon2-cffi-20.1.0.tar.gz</a> (1.8MB)<br>  Installing build dependencies: started<br>  Installing build dependencies: finished with status ‘done’<br>  Getting requirements to build wheel: started<br>  Getting requirements to build wheel: finished with status ‘done’<br>    Preparing wheel metadata: started<br>    Preparing wheel metadata: finished with status ‘done’<br>Collecting terminado&gt;&#x3D;0.8.3<br>  Downloading <a href="https://pypi.doubanio.com/packages/5b/a8/0c428a9a2432b611566b0309d1a50a051f4ec965ce274528c4ba6b6c0205/terminado-0.11.1-py3-none-any.whl">https://pypi.doubanio.com/packages/5b/a8/0c428a9a2432b611566b0309d1a50a051f4ec965ce274528c4ba6b6c0205/terminado-0.11.1-py3-none-any.whl</a><br>Collecting Send2Trash&gt;&#x3D;1.5.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/47/26/3435896d757335ea53dce5abf8d658ca80757a7a06258451b358f10232be/Send2Trash-1.8.0-py3-none-any.whl">https://pypi.doubanio.com/packages/47/26/3435896d757335ea53dce5abf8d658ca80757a7a06258451b358f10232be/Send2Trash-1.8.0-py3-none-any.whl</a><br>Collecting prometheus-client<br>  Downloading <a href="https://pypi.doubanio.com/packages/09/da/4e8471ff825769581593b5b84769d32f58e5373b59fccaf355d3529ad530/prometheus_client-0.11.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/09/da/4e8471ff825769581593b5b84769d32f58e5373b59fccaf355d3529ad530/prometheus_client-0.11.0-py2.py3-none-any.whl</a> (56kB)<br>Collecting prompt-toolkit!&#x3D;3.0.0,!&#x3D;3.0.1,&lt;3.1.0,&gt;&#x3D;2.0.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/c6/37/ec72228971dbaf191243b8ee383c6a3834b5cde23daab066dfbfbbd5438b/prompt_toolkit-3.0.20-py3-none-any.whl">https://pypi.doubanio.com/packages/c6/37/ec72228971dbaf191243b8ee383c6a3834b5cde23daab066dfbfbbd5438b/prompt_toolkit-3.0.20-py3-none-any.whl</a> (370kB)<br>Collecting jsonschema!&#x3D;2.5.0,&gt;&#x3D;2.4<br>  Downloading <a href="https://pypi.doubanio.com/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl</a> (56kB)<br>Collecting webencodings<br>  Downloading <a href="https://pypi.doubanio.com/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl</a><br>Collecting packaging<br>  Downloading <a href="https://pypi.doubanio.com/packages/3c/77/e2362b676dc5008d81be423070dd9577fa03be5da2ba1105811900fda546/packaging-21.0-py3-none-any.whl">https://pypi.doubanio.com/packages/3c/77/e2362b676dc5008d81be423070dd9577fa03be5da2ba1105811900fda546/packaging-21.0-py3-none-any.whl</a> (40kB)<br>Collecting six&gt;&#x3D;1.9.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl</a><br>Collecting nest-asyncio<br>  Downloading <a href="https://pypi.doubanio.com/packages/52/e2/9b37da54e6e9094d2f558ae643d1954a0fa8215dfee4fa261f31c5439796/nest_asyncio-1.5.1-py3-none-any.whl">https://pypi.doubanio.com/packages/52/e2/9b37da54e6e9094d2f558ae643d1954a0fa8215dfee4fa261f31c5439796/nest_asyncio-1.5.1-py3-none-any.whl</a><br>Collecting MarkupSafe&gt;&#x3D;2.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/a3/01/8d5fd91ccc1a61b7a9e2803819b8b60c3bac37290bbbd3df33d8d548f9c1/MarkupSafe-2.0.1-cp37-cp37m-manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/a3/01/8d5fd91ccc1a61b7a9e2803819b8b60c3bac37290bbbd3df33d8d548f9c1/MarkupSafe-2.0.1-cp37-cp37m-manylinux2014_aarch64.whl</a><br>Collecting python-dateutil&gt;&#x3D;2.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl</a> (247kB)<br>Collecting zipp&gt;&#x3D;0.5<br>  Downloading <a href="https://pypi.doubanio.com/packages/92/d9/89f433969fb8dc5b9cbdd4b4deb587720ec1aeb59a020cf15002b9593eef/zipp-3.5.0-py3-none-any.whl">https://pypi.doubanio.com/packages/92/d9/89f433969fb8dc5b9cbdd4b4deb587720ec1aeb59a020cf15002b9593eef/zipp-3.5.0-py3-none-any.whl</a><br>Collecting typing-extensions&gt;&#x3D;3.6.4; python_version &lt; “3.8”<br>  Downloading <a href="https://pypi.doubanio.com/packages/2e/35/6c4fff5ab443b57116cb1aad46421fb719bed2825664e8fe77d66d99bcbc/typing_extensions-3.10.0.0-py3-none-any.whl">https://pypi.doubanio.com/packages/2e/35/6c4fff5ab443b57116cb1aad46421fb719bed2825664e8fe77d66d99bcbc/typing_extensions-3.10.0.0-py3-none-any.whl</a><br>Collecting backcall<br>  Downloading <a href="https://pypi.doubanio.com/packages/4c/1c/ff6546b6c12603d8dd1070aa3c3d273ad4c07f5771689a7b69a550e8c951/backcall-0.2.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/4c/1c/ff6546b6c12603d8dd1070aa3c3d273ad4c07f5771689a7b69a550e8c951/backcall-0.2.0-py2.py3-none-any.whl</a><br>Collecting pexpect&gt;4.3; sys_platform !&#x3D; “win32”<br>  Downloading <a href="https://pypi.doubanio.com/packages/39/7b/88dbb785881c28a102619d46423cb853b46dbccc70d3ac362d99773a78ce/pexpect-4.8.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/39/7b/88dbb785881c28a102619d46423cb853b46dbccc70d3ac362d99773a78ce/pexpect-4.8.0-py2.py3-none-any.whl</a> (59kB)<br>Collecting jedi&gt;&#x3D;0.16<br>  Downloading <a href="https://pypi.doubanio.com/packages/f9/36/7aa67ae2663025b49e8426ead0bad983fee1b73f472536e9790655da0277/jedi-0.18.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/f9/36/7aa67ae2663025b49e8426ead0bad983fee1b73f472536e9790655da0277/jedi-0.18.0-py2.py3-none-any.whl</a> (1.4MB)<br>Requirement already satisfied: setuptools&gt;&#x3D;18.5 in &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.7&#x2F;site-packages (from ipython&lt;8.0,&gt;&#x3D;7.23.1-&gt;ipykernel-&gt;jupyter) (41.6.0)<br>Collecting pickleshare<br>  Downloading <a href="https://pypi.doubanio.com/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl</a><br>Collecting decorator<br>  Downloading <a href="https://pypi.doubanio.com/packages/6a/36/b1b9bfdf28690ae01d9ca0aa5b0d07cb4448ac65fb91dc7e2d094e3d992f/decorator-5.0.9-py3-none-any.whl">https://pypi.doubanio.com/packages/6a/36/b1b9bfdf28690ae01d9ca0aa5b0d07cb4448ac65fb91dc7e2d094e3d992f/decorator-5.0.9-py3-none-any.whl</a><br>Collecting cffi&gt;&#x3D;1.0.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/7c/d7/027b40eab051119083fa64be7f86c40fc96643c627fd5068462b88f72111/cffi-1.14.6-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/7c/d7/027b40eab051119083fa64be7f86c40fc96643c627fd5068462b88f72111/cffi-1.14.6-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl</a> (206kB)<br>Collecting ptyprocess; os_name !&#x3D; “nt”<br>  Downloading <a href="https://pypi.doubanio.com/packages/22/a6/858897256d0deac81a172289110f31629fc4cee19b6f01283303e18c8db3/ptyprocess-0.7.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/22/a6/858897256d0deac81a172289110f31629fc4cee19b6f01283303e18c8db3/ptyprocess-0.7.0-py2.py3-none-any.whl</a><br>Collecting wcwidth<br>  Downloading <a href="https://pypi.doubanio.com/packages/59/7c/e39aca596badaf1b78e8f547c807b04dae603a433d3e7a7e04d67f2ef3e5/wcwidth-0.2.5-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/59/7c/e39aca596badaf1b78e8f547c807b04dae603a433d3e7a7e04d67f2ef3e5/wcwidth-0.2.5-py2.py3-none-any.whl</a><br>Collecting pyrsistent&gt;&#x3D;0.14.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/f4/d7/0fa558c4fb00f15aabc6d42d365fcca7a15fcc1091cd0f5784a14f390b7f/pyrsistent-0.18.0.tar.gz">https://pypi.doubanio.com/packages/f4/d7/0fa558c4fb00f15aabc6d42d365fcca7a15fcc1091cd0f5784a14f390b7f/pyrsistent-0.18.0.tar.gz</a> (104kB)<br>  Installing build dependencies: started<br>  Installing build dependencies: finished with status ‘done’<br>  Getting requirements to build wheel: started<br>  Getting requirements to build wheel: finished with status ‘done’<br>    Preparing wheel metadata: started<br>    Preparing wheel metadata: finished with status ‘done’<br>Collecting attrs&gt;&#x3D;17.4.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/20/a9/ba6f1cd1a1517ff022b35acd6a7e4246371dfab08b8e42b829b6d07913cc/attrs-21.2.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/20/a9/ba6f1cd1a1517ff022b35acd6a7e4246371dfab08b8e42b829b6d07913cc/attrs-21.2.0-py2.py3-none-any.whl</a> (53kB)<br>Collecting pyparsing&gt;&#x3D;2.0.2<br>  Downloading <a href="https://pypi.doubanio.com/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl</a> (67kB)<br>Collecting parso&lt;0.9.0,&gt;&#x3D;0.8.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/a9/c4/d5476373088c120ffed82f34c74b266ccae31a68d665b837354d4d8dc8be/parso-0.8.2-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/a9/c4/d5476373088c120ffed82f34c74b266ccae31a68d665b837354d4d8dc8be/parso-0.8.2-py2.py3-none-any.whl</a> (94kB)<br>Collecting pycparser<br>  Downloading <a href="https://pypi.doubanio.com/packages/ae/e7/d9c3a176ca4b02024debf82342dab36efadfc5776f9c8db077e8f6e71821/pycparser-2.20-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/ae/e7/d9c3a176ca4b02024debf82342dab36efadfc5776f9c8db077e8f6e71821/pycparser-2.20-py2.py3-none-any.whl</a> (112kB)<br>Building wheels for collected packages: argon2-cffi, pyrsistent<br>  Building wheel for argon2-cffi (PEP 517): started<br>  Building wheel for argon2-cffi (PEP 517): finished with status ‘done’<br>  Created wheel for argon2-cffi: filename&#x3D;argon2_cffi-20.1.0-cp37-abi3-linux_aarch64.whl size&#x3D;94330 sha256&#x3D;a7e904c263450da07cbc3a73891e049bab3035c37841778963599e544d3df91c<br>  Stored in directory: &#x2F;root&#x2F;.cache&#x2F;pip&#x2F;wheels&#x2F;bd&#x2F;00&#x2F;bf&#x2F;afb81816e42f4cd82890c552262451d2683fce154d72a2a7f2<br>  Building wheel for pyrsistent (PEP 517): started<br>  Building wheel for pyrsistent (PEP 517): finished with status ‘done’<br>  Created wheel for pyrsistent: filename&#x3D;pyrsistent-0.18.0-cp37-cp37m-linux_aarch64.whl size&#x3D;124391 sha256&#x3D;4aa68debe7bd18cef92085f61bcff6ca4a308e7a0c3baa6d5e9b79d011a0860b<br>  Stored in directory: &#x2F;root&#x2F;.cache&#x2F;pip&#x2F;wheels&#x2F;41&#x2F;82&#x2F;79&#x2F;02feba19913ccf53c135a504fd28677aeecf1980d76c1bfad5<br>Successfully built argon2-cffi pyrsistent<br>Building wheels for collected packages: pandocfilters<br>  Building wheel for pandocfilters (setup.py): started<br>  Building wheel for pandocfilters (setup.py): finished with status ‘done’<br>  Created wheel for pandocfilters: filename&#x3D;pandocfilters-1.4.3-cp37-none-any.whl size&#x3D;7991 sha256&#x3D;74eac0d992a7841f6066709dcd1dcabfa4fa58eb171649fbaef06b141bcd033c<br>  Stored in directory: &#x2F;root&#x2F;.cache&#x2F;pip&#x2F;wheels&#x2F;f3&#x2F;b7&#x2F;38&#x2F;9a1fac073c6eb0cc2524036dfcef319b829ce237c80c31c044<br>Successfully built pandocfilters<br>Installing collected packages: ipython-genutils, traitlets, jupyter-core, pyrsistent, six, attrs, zipp, typing-extensions, importlib-metadata, jsonschema, nbformat, testpath, mistune, defusedxml, webencodings, pyparsing, packaging, bleach, pandocfilters, entrypoints, pygments, jupyterlab-pygments, nest-asyncio, pyzmq, python-dateutil, tornado, jupyter-client, nbclient, MarkupSafe, jinja2, nbconvert, backcall, ptyprocess, pexpect, parso, jedi, matplotlib-inline, pickleshare, decorator, wcwidth, prompt-toolkit, ipython, argcomplete, debugpy, ipykernel, qtpy, qtconsole, jupyterlab-widgets, pycparser, cffi, argon2-cffi, terminado, Send2Trash, prometheus-client, notebook, widgetsnbextension, ipywidgets, jupyter-console, jupyter<br>Successfully installed MarkupSafe-2.0.1 Send2Trash-1.8.0 argcomplete-1.12.3 argon2-cffi-20.1.0 attrs-21.2.0 backcall-0.2.0 bleach-4.0.0 cffi-1.14.6 debugpy-1.4.1 decorator-5.0.9 defusedxml-0.7.1 entrypoints-0.3 importlib-metadata-4.6.4 ipykernel-6.2.0 ipython-7.26.0 ipython-genutils-0.2.0 ipywidgets-7.6.3 jedi-0.18.0 jinja2-3.0.1 jsonschema-3.2.0 jupyter-1.0.0 jupyter-client-7.0.1 jupyter-console-6.4.0 jupyter-core-4.7.1 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.0.0 matplotlib-inline-0.1.2 mistune-0.8.4 nbclient-0.5.4 nbconvert-6.1.0 nbformat-5.1.3 nest-asyncio-1.5.1 notebook-6.4.3 packaging-21.0 pandocfilters-1.4.3 parso-0.8.2 pexpect-4.8.0 pickleshare-0.7.5 prometheus-client-0.11.0 prompt-toolkit-3.0.20 ptyprocess-0.7.0 pycparser-2.20 pygments-2.10.0 pyparsing-2.4.7 pyrsistent-0.18.0 python-dateutil-2.8.2 pyzmq-22.2.1 qtconsole-5.1.1 qtpy-1.10.0 six-1.16.0 terminado-0.11.1 testpath-0.5.0 tornado-6.1 traitlets-5.0.5 typing-extensions-3.10.0.0 wcwidth-0.2.5 webencodings-0.5.1 widgetsnbextension-3.5.1 zipp-3.5.0<br>WARNING: You are using pip version 19.3.1; however, version 21.2.4 is available.<br>You should consider upgrading via the ‘pip install –upgrade pip’ command.<br>Writing default config to: &#x2F;root&#x2F;.jupyter&#x2F;jupyter_notebook_config.py<br>Removing intermediate container e8a384542bf2<br> —&gt; cc59b531125b<br>Step 4&#x2F;12 : RUN apt-get update &amp;&amp; apt-get install -y openssh-server<br> —&gt; Running in 2e945ea6c6c8<br>Get:1 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster InRelease [122 kB]<br>Get:2 <a href="http://security.debian.org/debian-security">http://security.debian.org/debian-security</a> buster&#x2F;updates InRelease [65.4 kB]<br>Get:3 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster-updates InRelease [51.9 kB]<br>Get:4 <a href="http://security.debian.org/debian-security">http://security.debian.org/debian-security</a> buster&#x2F;updates&#x2F;main arm64 Packages [296 kB]<br>Get:5 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 Packages [7735 kB]<br>Get:6 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster-updates&#x2F;main arm64 Packages [14.5 kB]<br>Fetched 8285 kB in 3s (2598 kB&#x2F;s)<br>Reading package lists…<br>Reading package lists…<br>Building dependency tree…<br>Reading state information…<br>The following additional packages will be installed:<br>  dbus dmsetup libapparmor1 libargon2-1 libcryptsetup12 libdbus-1-3<br>  libdevmapper1.02.1 libidn11 libip4tc0 libjson-c3 libkmod2 libnss-systemd<br>  libpam-systemd libsystemd0 libwrap0 libxmuu1 ncurses-term openssh-client<br>  openssh-sftp-server systemd systemd-sysv xauth<br>Suggested packages:<br>  default-dbus-session-bus | dbus-session-bus keychain libpam-ssh monkeysphere<br>  ssh-askpass molly-guard rssh ufw systemd-container policykit-1<br>The following NEW packages will be installed:<br>  dbus dmsetup libapparmor1 libargon2-1 libcryptsetup12 libdbus-1-3<br>  libdevmapper1.02.1 libidn11 libip4tc0 libjson-c3 libkmod2 libnss-systemd<br>  libpam-systemd libwrap0 libxmuu1 ncurses-term openssh-server<br>  openssh-sftp-server systemd systemd-sysv xauth<br>The following packages will be upgraded:<br>  libsystemd0 openssh-client<br>2 upgraded, 21 newly installed, 0 to remove and 130 not upgraded.<br>Need to get 7006 kB of archives.<br>After this operation, 23.5 MB of additional disk space will be used.<br>Get:1 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libapparmor1 arm64 2.13.2-10 [93.8 kB]<br>Get:2 <a href="http://security.debian.org/debian-security">http://security.debian.org/debian-security</a> buster&#x2F;updates&#x2F;main arm64 libsystemd0 arm64 241-7<del>deb10u8 [314 kB]<br>Get:3 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libargon2-1 arm64 0</del>20171227-0.2 [18.9 kB]<br>Get:4 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 dmsetup arm64 2:1.02.155-3 [83.9 kB]<br>Get:5 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libdevmapper1.02.1 arm64 2:1.02.155-3 [124 kB]<br>Get:6 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libjson-c3 arm64 0.12.1+ds-2+deb10u1 [26.8 kB]<br>Get:7 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libcryptsetup12 arm64 2:2.1.0-5+deb10u2 [181 kB]<br>Get:8 <a href="http://security.debian.org/debian-security">http://security.debian.org/debian-security</a> buster&#x2F;updates&#x2F;main arm64 systemd arm64 241-7<del>deb10u8 [3256 kB]<br>Get:9 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libidn11 arm64 1.33-2.2 [113 kB]<br>Get:10 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libip4tc0 arm64 1.8.2-4 [69.6 kB]<br>Get:11 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libkmod2 arm64 26-1 [49.4 kB]<br>Get:12 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libdbus-1-3 arm64 1.12.20-0+deb10u1 [206 kB]<br>Get:13 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 dbus arm64 1.12.20-0+deb10u1 [227 kB]<br>Get:14 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 ncurses-term all 6.1+20181013-2+deb10u2 [490 kB]<br>Get:15 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 openssh-client arm64 1:7.9p1-10+deb10u2 [757 kB]<br>Get:16 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libwrap0 arm64 7.6.q-28 [58.4 kB]<br>Get:17 <a href="http://security.debian.org/debian-security">http://security.debian.org/debian-security</a> buster&#x2F;updates&#x2F;main arm64 systemd-sysv arm64 241-7</del>deb10u8 [100 kB]<br>Get:18 <a href="http://security.debian.org/debian-security">http://security.debian.org/debian-security</a> buster&#x2F;updates&#x2F;main arm64 libpam-systemd arm64 241-7<del>deb10u8 [201 kB]<br>Get:19 <a href="http://security.debian.org/debian-security">http://security.debian.org/debian-security</a> buster&#x2F;updates&#x2F;main arm64 libnss-systemd arm64 241-7</del>deb10u8 [197 kB]<br>Get:20 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 libxmuu1 arm64 2:1.1.2-2+b3 [24.1 kB]<br>Get:21 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 openssh-sftp-server arm64 1:7.9p1-10+deb10u2 [42.8 kB]<br>Get:22 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 openssh-server arm64 1:7.9p1-10+deb10u2 [334 kB]<br>Get:23 <a href="http://deb.debian.org/debian">http://deb.debian.org/debian</a> buster&#x2F;main arm64 xauth arm64 1:1.0.10-1 [38.2 kB]<br>debconf: delaying package configuration, since apt-utils is not installed<br>Fetched 7006 kB in 1s (6820 kB&#x2F;s)<br>(Reading database … 24499 files and directories currently installed.)<br>Preparing to unpack …&#x2F;libsystemd0_241-7<del>deb10u8_arm64.deb …<br>Unpacking libsystemd0:arm64 (241-7</del>deb10u8) over (241-7<del>deb10u2) …<br>Setting up libsystemd0:arm64 (241-7</del>deb10u8) …<br>Selecting previously unselected package libapparmor1:arm64.<br>(Reading database … 24499 files and directories currently installed.)<br>Preparing to unpack …&#x2F;0-libapparmor1_2.13.2-10_arm64.deb …<br>Unpacking libapparmor1:arm64 (2.13.2-10) …<br>Selecting previously unselected package libargon2-1:arm64.<br>Preparing to unpack …&#x2F;1-libargon2-1_0<del>20171227-0.2_arm64.deb …<br>Unpacking libargon2-1:arm64 (0</del>20171227-0.2) …<br>Selecting previously unselected package dmsetup.<br>Preparing to unpack …&#x2F;2-dmsetup_2%3a1.02.155-3_arm64.deb …<br>Unpacking dmsetup (2:1.02.155-3) …<br>Selecting previously unselected package libdevmapper1.02.1:arm64.<br>Preparing to unpack …&#x2F;3-libdevmapper1.02.1_2%3a1.02.155-3_arm64.deb …<br>Unpacking libdevmapper1.02.1:arm64 (2:1.02.155-3) …<br>Selecting previously unselected package libjson-c3:arm64.<br>Preparing to unpack …&#x2F;4-libjson-c3_0.12.1+ds-2+deb10u1_arm64.deb …<br>Unpacking libjson-c3:arm64 (0.12.1+ds-2+deb10u1) …<br>Selecting previously unselected package libcryptsetup12:arm64.<br>Preparing to unpack …&#x2F;5-libcryptsetup12_2%3a2.1.0-5+deb10u2_arm64.deb …<br>Unpacking libcryptsetup12:arm64 (2:2.1.0-5+deb10u2) …<br>Selecting previously unselected package libidn11:arm64.<br>Preparing to unpack …&#x2F;6-libidn11_1.33-2.2_arm64.deb …<br>Unpacking libidn11:arm64 (1.33-2.2) …<br>Selecting previously unselected package libip4tc0:arm64.<br>Preparing to unpack …&#x2F;7-libip4tc0_1.8.2-4_arm64.deb …<br>Unpacking libip4tc0:arm64 (1.8.2-4) …<br>Selecting previously unselected package libkmod2:arm64.<br>Preparing to unpack …&#x2F;8-libkmod2_26-1_arm64.deb …<br>Unpacking libkmod2:arm64 (26-1) …<br>Selecting previously unselected package systemd.<br>Preparing to unpack …&#x2F;9-systemd_241-7<del>deb10u8_arm64.deb …<br>Unpacking systemd (241-7</del>deb10u8) …<br>Setting up libapparmor1:arm64 (2.13.2-10) …<br>Setting up libargon2-1:arm64 (0<del>20171227-0.2) …<br>Setting up libjson-c3:arm64 (0.12.1+ds-2+deb10u1) …<br>Setting up libidn11:arm64 (1.33-2.2) …<br>Setting up libip4tc0:arm64 (1.8.2-4) …<br>Setting up libkmod2:arm64 (26-1) …<br>Setting up libdevmapper1.02.1:arm64 (2:1.02.155-3) …<br>Setting up libcryptsetup12:arm64 (2:2.1.0-5+deb10u2) …<br>Setting up systemd (241-7</del>deb10u8) …<br>Created symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;getty.target.wants&#x2F;<a href="mailto:&#x67;&#x65;&#116;&#x74;&#121;&#x40;&#x74;&#116;&#x79;&#49;&#x2e;&#115;&#x65;&#x72;&#118;&#105;&#x63;&#101;">&#x67;&#x65;&#116;&#x74;&#121;&#x40;&#x74;&#116;&#x79;&#49;&#x2e;&#115;&#x65;&#x72;&#118;&#105;&#x63;&#101;</a> → &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;getty@.service.<br>Created symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;remote-fs.target → &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;remote-fs.target.<br>Created symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;dbus-org.freedesktop.timesync1.service → &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;systemd-timesyncd.service.<br>Created symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;sysinit.target.wants&#x2F;systemd-timesyncd.service → &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;systemd-timesyncd.service.<br>Setting up dmsetup (2:1.02.155-3) …<br>Selecting previously unselected package systemd-sysv.<br>(Reading database … 25328 files and directories currently installed.)<br>Preparing to unpack …&#x2F;00-systemd-sysv_241-7<del>deb10u8_arm64.deb …<br>Unpacking systemd-sysv (241-7</del>deb10u8) …<br>Selecting previously unselected package libdbus-1-3:arm64.<br>Preparing to unpack …&#x2F;01-libdbus-1-3_1.12.20-0+deb10u1_arm64.deb …<br>Unpacking libdbus-1-3:arm64 (1.12.20-0+deb10u1) …<br>Selecting previously unselected package dbus.<br>Preparing to unpack …&#x2F;02-dbus_1.12.20-0+deb10u1_arm64.deb …<br>Unpacking dbus (1.12.20-0+deb10u1) …<br>Selecting previously unselected package libpam-systemd:arm64.<br>Preparing to unpack …&#x2F;03-libpam-systemd_241-7<del>deb10u8_arm64.deb …<br>Unpacking libpam-systemd:arm64 (241-7</del>deb10u8) …<br>Selecting previously unselected package ncurses-term.<br>Preparing to unpack …&#x2F;04-ncurses-term_6.1+20181013-2+deb10u2_all.deb …<br>Unpacking ncurses-term (6.1+20181013-2+deb10u2) …<br>Preparing to unpack …&#x2F;05-openssh-client_1%3a7.9p1-10+deb10u2_arm64.deb …<br>Unpacking openssh-client (1:7.9p1-10+deb10u2) over (1:7.9p1-10+deb10u1) …<br>Selecting previously unselected package libwrap0:arm64.<br>Preparing to unpack …&#x2F;06-libwrap0_7.6.q-28_arm64.deb …<br>Unpacking libwrap0:arm64 (7.6.q-28) …<br>Selecting previously unselected package libxmuu1:arm64.<br>Preparing to unpack …&#x2F;07-libxmuu1_2%3a1.1.2-2+b3_arm64.deb …<br>Unpacking libxmuu1:arm64 (2:1.1.2-2+b3) …<br>Selecting previously unselected package openssh-sftp-server.<br>Preparing to unpack …&#x2F;08-openssh-sftp-server_1%3a7.9p1-10+deb10u2_arm64.deb …<br>Unpacking openssh-sftp-server (1:7.9p1-10+deb10u2) …<br>Selecting previously unselected package openssh-server.<br>Preparing to unpack …&#x2F;09-openssh-server_1%3a7.9p1-10+deb10u2_arm64.deb …<br>Unpacking openssh-server (1:7.9p1-10+deb10u2) …<br>Selecting previously unselected package xauth.<br>Preparing to unpack …&#x2F;10-xauth_1%3a1.0.10-1_arm64.deb …<br>Unpacking xauth (1:1.0.10-1) …<br>Selecting previously unselected package libnss-systemd:arm64.<br>Preparing to unpack …&#x2F;11-libnss-systemd_241-7<del>deb10u8_arm64.deb …<br>Unpacking libnss-systemd:arm64 (241-7</del>deb10u8) …<br>Setting up systemd-sysv (241-7<del>deb10u8) …<br>Setting up openssh-client (1:7.9p1-10+deb10u2) …<br>Setting up libnss-systemd:arm64 (241-7</del>deb10u8) …<br>First installation detected…<br>Checking NSS setup…<br>Setting up libwrap0:arm64 (7.6.q-28) …<br>Setting up libdbus-1-3:arm64 (1.12.20-0+deb10u1) …<br>Setting up dbus (1.12.20-0+deb10u1) …<br>invoke-rc.d: could not determine current runlevel<br>invoke-rc.d: policy-rc.d denied execution of start.<br>Setting up libpam-systemd:arm64 (241-7~deb10u8) …<br>debconf: unable to initialize frontend: Dialog<br>debconf: (TERM is not set, so the dialog frontend is not usable.)<br>debconf: falling back to frontend: Readline<br>Setting up libxmuu1:arm64 (2:1.1.2-2+b3) …<br>Setting up ncurses-term (6.1+20181013-2+deb10u2) …<br>Setting up openssh-sftp-server (1:7.9p1-10+deb10u2) …<br>Setting up openssh-server (1:7.9p1-10+deb10u2) …<br>debconf: unable to initialize frontend: Dialog<br>debconf: (TERM is not set, so the dialog frontend is not usable.)<br>debconf: falling back to frontend: Readline</p>
<p>Creating config file &#x2F;etc&#x2F;ssh&#x2F;sshd_config with new version<br>Creating SSH2 RSA key; this may take some time …<br>2048 SHA256:cEaUdyT6Hx04XRMm9rM&#x2F;3XwpPfYW1pk8aLuPj+H&#x2F;H74 root@2e945ea6c6c8 (RSA)<br>Creating SSH2 ECDSA key; this may take some time …<br>256 SHA256:SdNsg649xnvS1iDxsRnLZyYbAoBuVC0AAgBn2BrpBIA root@2e945ea6c6c8 (ECDSA)<br>Creating SSH2 ED25519 key; this may take some time …<br>256 SHA256:gp7YaazhqkMCaueTtGPhN4eqXQM7EY&#x2F;qo6CIMJKJUAM root@2e945ea6c6c8 (ED25519)<br>Created symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;sshd.service → &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ssh.service.<br>Created symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;ssh.service → &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ssh.service.<br>invoke-rc.d: could not determine current runlevel<br>invoke-rc.d: policy-rc.d denied execution of start.<br>Setting up xauth (1:1.0.10-1) …<br>Processing triggers for systemd (241-7<del>deb10u8) …<br>Processing triggers for libc-bin (2.28-10) …<br>Removing intermediate container 2e945ea6c6c8<br> —&gt; 2e0c25b239f8<br>Step 5&#x2F;12 : RUN sed -ri ‘s&#x2F;UsePAM yes&#x2F;#UsePAM yes&#x2F;g’ &#x2F;etc&#x2F;ssh&#x2F;sshd_config &amp;&amp; sed -ri ‘s&#x2F;^#?PermitRootLogin\s+.*&#x2F;PermitRootLogin yes&#x2F;‘ &#x2F;etc&#x2F;ssh&#x2F;sshd_config<br> —&gt; Running in feb082ef3d54<br>Removing intermediate container feb082ef3d54<br> —&gt; 04e7d111667f<br>Step 6&#x2F;12 : ENV http_proxy ‘’<br> —&gt; Running in d85cabc29931<br>Removing intermediate container d85cabc29931<br> —&gt; 7be3a0816c55<br>Step 7&#x2F;12 : ENV https_proxy ‘’<br> —&gt; Running in fde04a902add<br>Removing intermediate container fde04a902add<br> —&gt; ab4b80bbf41d<br>Step 8&#x2F;12 : ENV ftp_proxy ‘’<br> —&gt; Running in e69f82c2dbdb<br>Removing intermediate container e69f82c2dbdb<br> —&gt; b5e9f01546bd<br>Step 9&#x2F;12 : RUN useradd -d &#x2F;home&#x2F;hwMindX -u 9000 -m -s &#x2F;bin&#x2F;bash hwMindX &amp;&amp;     useradd -d &#x2F;home&#x2F;HwHiAiUser -u 1000 -m -s &#x2F;bin&#x2F;bash HwHiAiUser &amp;&amp;     usermod -a -G HwHiAiUser hwMindX<br> —&gt; Running in 4d1821f15a61<br>Removing intermediate container 4d1821f15a61<br> —&gt; 62891e7cf121<br>Step 10&#x2F;12 : RUN echo root:123123 | chpasswd<br> —&gt; Running in 6f31c83a1b24<br>Removing intermediate container 6f31c83a1b24<br> —&gt; 90fb27e9b246<br>Step 11&#x2F;12 : USER hwMindX<br> —&gt; Running in 3dca31695032<br>Removing intermediate container 3dca31695032<br> —&gt; 3c8e3d5fb2df<br>Step 12&#x2F;12 : ENTRYPOINT jupyter notebook –allow-root<br> —&gt; Running in 0af4a0c4ebf0<br>Removing intermediate container 0af4a0c4ebf0<br> —&gt; 36ec8fff3e06<br>Successfully built 36ec8fff3e06<br>Successfully tagged notebook:latest<br>root@ubuntu:</del>&#x2F;123&#x2F;jupyter-notebook#<br>root@ubuntu:<del>&#x2F;123&#x2F;jupyter-notebook# docker images | grep notebook<br>notebook                                                      latest              36ec8fff3e06        2 minutes ago       1.04GB<br>root@ubuntu:</del>&#x2F;123&#x2F;jupyter-notebook#</p>
<p>&#96;&#96;&#96;shell</p>
<p>十、构建tensorboard镜像</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:<del>&#x2F;123# mkdir tensorboard<br>root@ubuntu:</del>&#x2F;123# cd tensorboard<br>root@ubuntu:<del>&#x2F;123&#x2F;tensorboard# vi Dockerfile<br>root@ubuntu:</del>&#x2F;123&#x2F;tensorboard# cat Dockerfile<br>FROM python:3.7.5</p>
<h1 id="————————-Optional-Configure-the-pip-source-–-l-1-———————"><a href="#————————-Optional-Configure-the-pip-source-–-l-1-———————" class="headerlink" title="————————-(Optional) Configure the pip source.–[l(1] ———————"></a>————————-(Optional) Configure the pip source.–[l(1] ———————</h1><p>#ENV http_proxy http:&#x2F;&#x2F;<user>:<password>@ip:port<br>#ENV https_proxy http:&#x2F;&#x2F;<user>:<password>@ip:port<br>#ENV ftp_proxy ftp:&#x2F;&#x2F;<user>:<password>@ip:port</p>
<p>RUN mkdir -p ~&#x2F;.pip <br>&amp;&amp; echo ‘[global] \n\<br>index-url&#x3D;<a href="https://pypi.doubanio.com/simple//n/">https://pypi.doubanio.com/simple/\n\</a><br>trusted-host&#x3D;pypi.doubanio.com’ &gt;&gt; ~&#x2F;.pip&#x2F;pip.conf</p>
<p>RUN pip install –upgrade pip &amp;&amp; pip install tensorboard&#x3D;&#x3D;1.15.0</p>
<p>ENV http_proxy ‘’<br>ENV https_proxy ‘’<br>ENV ftp_proxy ‘’</p>
<p>RUN useradd -d &#x2F;home&#x2F;hwMindX -u 9000 -m -s &#x2F;bin&#x2F;bash hwMindX &amp;&amp; <br>    useradd -d &#x2F;home&#x2F;HwHiAiUser -u 1000 -m -s &#x2F;bin&#x2F;bash HwHiAiUser &amp;&amp; <br>    usermod -a -G HwHiAiUser hwMindX</p>
<p>USER hwMindX</p>
<p>root@ubuntu:<del>&#x2F;123&#x2F;tensorboard# docker build -t tensorboard:latest .<br>Sending build context to Docker daemon   2.56kB<br>Step 1&#x2F;8 : FROM python:3.7.5<br> —&gt; a4356c370cda<br>Step 2&#x2F;8 : RUN mkdir -p ~&#x2F;.pip &amp;&amp; echo ‘[global] \nindex-url&#x3D;<a href="https://pypi.doubanio.com/simple//ntrusted-host=pypi.doubanio.com&#39;">https://pypi.doubanio.com/simple/\ntrusted-host=pypi.doubanio.com&#39;</a> &gt;&gt; ~&#x2F;.pip&#x2F;pip.conf<br> —&gt; Using cache<br> —&gt; 2e9619b95f3c<br>Step 3&#x2F;8 : RUN pip install –upgrade pip &amp;&amp; pip install tensorboard&#x3D;&#x3D;1.15.0<br> —&gt; Running in 7d03c4546a34<br>Looking in indexes: <a href="https://pypi.doubanio.com/simple/">https://pypi.doubanio.com/simple/</a><br>Collecting pip<br>  Downloading <a href="https://pypi.doubanio.com/packages/ca/31/b88ef447d595963c01060998cb329251648acf4a067721b0452c45527eb8/pip-21.2.4-py3-none-any.whl">https://pypi.doubanio.com/packages/ca/31/b88ef447d595963c01060998cb329251648acf4a067721b0452c45527eb8/pip-21.2.4-py3-none-any.whl</a> (1.6MB)<br>Installing collected packages: pip<br>  Found existing installation: pip 19.3.1<br>    Uninstalling pip-19.3.1:<br>      Successfully uninstalled pip-19.3.1<br>Successfully installed pip-21.2.4<br>Looking in indexes: <a href="https://pypi.doubanio.com/simple/">https://pypi.doubanio.com/simple/</a><br>Collecting tensorboard&#x3D;&#x3D;1.15.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl">https://pypi.doubanio.com/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl</a> (3.8 MB)<br>Requirement already satisfied: setuptools&gt;&#x3D;41.0.0 in &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.7&#x2F;site-packages (from tensorboard&#x3D;&#x3D;1.15.0) (41.6.0)<br>Collecting markdown&gt;&#x3D;2.6.8<br>  Downloading <a href="https://pypi.doubanio.com/packages/6e/33/1ae0f71395e618d6140fbbc9587cc3156591f748226075e0f7d6f9176522/Markdown-3.3.4-py3-none-any.whl">https://pypi.doubanio.com/packages/6e/33/1ae0f71395e618d6140fbbc9587cc3156591f748226075e0f7d6f9176522/Markdown-3.3.4-py3-none-any.whl</a> (97 kB)<br>Collecting six&gt;&#x3D;1.10.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl</a> (11 kB)<br>Collecting numpy&gt;&#x3D;1.12.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/5c/61/b2f14fb5aa1198fa63c6c90205dc2557df5cacdeb0b16d66abc6af8724b8/numpy-1.21.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/5c/61/b2f14fb5aa1198fa63c6c90205dc2557df5cacdeb0b16d66abc6af8724b8/numpy-1.21.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl</a> (13.0 MB)<br>Collecting werkzeug&gt;&#x3D;0.11.15<br>  Downloading <a href="https://pypi.doubanio.com/packages/bd/24/11c3ea5a7e866bf2d97f0501d0b4b1c9bbeade102bb4b588f0d2919a5212/Werkzeug-2.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/bd/24/11c3ea5a7e866bf2d97f0501d0b4b1c9bbeade102bb4b588f0d2919a5212/Werkzeug-2.0.1-py3-none-any.whl</a> (288 kB)<br>Requirement already satisfied: wheel&gt;&#x3D;0.26 in &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.7&#x2F;site-packages (from tensorboard&#x3D;&#x3D;1.15.0) (0.33.6)<br>Collecting grpcio&gt;&#x3D;1.6.3<br>  Downloading <a href="https://pypi.doubanio.com/packages/8d/87/f66686884e21e4350746a18e664202ab9b39a3cd527df3ff54a022935ee5/grpcio-1.39.0-cp37-cp37m-manylinux_2_24_aarch64.whl">https://pypi.doubanio.com/packages/8d/87/f66686884e21e4350746a18e664202ab9b39a3cd527df3ff54a022935ee5/grpcio-1.39.0-cp37-cp37m-manylinux_2_24_aarch64.whl</a> (38.5 MB)<br>Collecting protobuf&gt;&#x3D;3.6.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/fd/5f/6d6f7a5859caf79894685ec543354edc05538a0a34d63a411a2a7cb4ecfd/protobuf-3.17.3-cp37-cp37m-manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/fd/5f/6d6f7a5859caf79894685ec543354edc05538a0a34d63a411a2a7cb4ecfd/protobuf-3.17.3-cp37-cp37m-manylinux2014_aarch64.whl</a> (922 kB)<br>Collecting absl-py&gt;&#x3D;0.4<br>  Downloading <a href="https://pypi.doubanio.com/packages/23/47/835652c7e19530973c73c65e652fc53bd05725d5a7cf9bb8706777869c1e/absl_py-0.13.0-py3-none-any.whl">https://pypi.doubanio.com/packages/23/47/835652c7e19530973c73c65e652fc53bd05725d5a7cf9bb8706777869c1e/absl_py-0.13.0-py3-none-any.whl</a> (132 kB)<br>Collecting importlib-metadata<br>  Downloading <a href="https://pypi.doubanio.com/packages/c0/72/4512a88e402d4dc3bab49a845130d95ac48936ef3a9469b55cc79a60d84d/importlib_metadata-4.6.4-py3-none-any.whl">https://pypi.doubanio.com/packages/c0/72/4512a88e402d4dc3bab49a845130d95ac48936ef3a9469b55cc79a60d84d/importlib_metadata-4.6.4-py3-none-any.whl</a> (17 kB)<br>Collecting zipp&gt;&#x3D;0.5<br>  Downloading <a href="https://pypi.doubanio.com/packages/92/d9/89f433969fb8dc5b9cbdd4b4deb587720ec1aeb59a020cf15002b9593eef/zipp-3.5.0-py3-none-any.whl">https://pypi.doubanio.com/packages/92/d9/89f433969fb8dc5b9cbdd4b4deb587720ec1aeb59a020cf15002b9593eef/zipp-3.5.0-py3-none-any.whl</a> (5.7 kB)<br>Collecting typing-extensions&gt;&#x3D;3.6.4<br>  Downloading <a href="https://pypi.doubanio.com/packages/2e/35/6c4fff5ab443b57116cb1aad46421fb719bed2825664e8fe77d66d99bcbc/typing_extensions-3.10.0.0-py3-none-any.whl">https://pypi.doubanio.com/packages/2e/35/6c4fff5ab443b57116cb1aad46421fb719bed2825664e8fe77d66d99bcbc/typing_extensions-3.10.0.0-py3-none-any.whl</a> (26 kB)<br>Installing collected packages: zipp, typing-extensions, six, importlib-metadata, werkzeug, protobuf, numpy, markdown, grpcio, absl-py, tensorboard<br>Successfully installed absl-py-0.13.0 grpcio-1.39.0 importlib-metadata-4.6.4 markdown-3.3.4 numpy-1.21.2 protobuf-3.17.3 six-1.16.0 tensorboard-1.15.0 typing-extensions-3.10.0.0 werkzeug-2.0.1 zipp-3.5.0<br>WARNING: Running pip as the ‘root’ user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: <a href="https://pip.pypa.io/warnings/venv">https://pip.pypa.io/warnings/venv</a><br>Removing intermediate container 7d03c4546a34<br> —&gt; 4dd40311445c<br>Step 4&#x2F;8 : ENV http_proxy ‘’<br> —&gt; Running in 51e014124cef<br>Removing intermediate container 51e014124cef<br> —&gt; 90694cc782ca<br>Step 5&#x2F;8 : ENV https_proxy ‘’<br> —&gt; Running in ddaaf7ceeded<br>Removing intermediate container ddaaf7ceeded<br> —&gt; 66a6f22d6688<br>Step 6&#x2F;8 : ENV ftp_proxy ‘’<br> —&gt; Running in d18d506c95bb<br>Removing intermediate container d18d506c95bb<br> —&gt; a6f8d3009ce3<br>Step 7&#x2F;8 : RUN useradd -d &#x2F;home&#x2F;hwMindX -u 9000 -m -s &#x2F;bin&#x2F;bash hwMindX &amp;&amp;     useradd -d &#x2F;home&#x2F;HwHiAiUser -u 1000 -m -s &#x2F;bin&#x2F;bash HwHiAiUser &amp;&amp;     usermod -a -G HwHiAiUser hwMindX<br> —&gt; Running in c29af506d5ed<br>Removing intermediate container c29af506d5ed<br> —&gt; 5faf1754daba<br>Step 8&#x2F;8 : USER hwMindX<br> —&gt; Running in d032b1b13d00<br>Removing intermediate container d032b1b13d00<br> —&gt; d00db512a587<br>Successfully built d00db512a587<br>Successfully tagged tensorboard:latest<br>root@ubuntu:</del>&#x2F;123&#x2F;tensorboard# docker images | grep tensorboard<br>tensorboard                                                   latest              d00db512a587        3 minutes ago       1.12GB<br>root@ubuntu:~&#x2F;123&#x2F;tensorboard#</p>
<p>&#96;&#96;&#96;shell</p>
<p>十一、构建mindinsight镜像</p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:<del>&#x2F;123# mkdir mindinsight<br>root@ubuntu:</del>&#x2F;123# cd mindinsight<br>root@ubuntu:~&#x2F;123&#x2F;mindinsight# wget <a href="https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.3.0/MindInsight/any/mindinsight-1.3.0-py3-none-any.whl">https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.3.0/MindInsight/any/mindinsight-1.3.0-py3-none-any.whl</a><br>–2021-08-21 11:29:24–  <a href="https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.3.0/MindInsight/any/mindinsight-1.3.0-py3-none-any.whl">https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.3.0/MindInsight/any/mindinsight-1.3.0-py3-none-any.whl</a><br>Resolving ms-release.obs.cn-north-4.myhuaweicloud.com (ms-release.obs.cn-north-4.myhuaweicloud.com)… 49.4.112.92, 49.4.112.3, 49.4.112.91<br>Connecting to ms-release.obs.cn-north-4.myhuaweicloud.com (ms-release.obs.cn-north-4.myhuaweicloud.com)|49.4.112.92|:443… connected.<br>HTTP request sent, awaiting response… 200 OK<br>Length: 5422450 (5.2M) [binary&#x2F;octet-stream]<br>Saving to: ‘mindinsight-1.3.0-py3-none-any.whl’</p>
<p>mindinsight-1.3.0-py3-none-any.whl                   100%[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;]   5.17M  24.3MB&#x2F;s    in 0.2s    </p>
<p>2021-08-21 11:29:25 (24.3 MB&#x2F;s) - ‘mindinsight-1.3.0-py3-none-any.whl’ saved [5422450&#x2F;5422450]</p>
<p>root@ubuntu:<del>&#x2F;123&#x2F;mindinsight# vi Dockerfile<br>root@ubuntu:</del>&#x2F;123&#x2F;mindinsight#<br>root@ubuntu:<del>&#x2F;123&#x2F;mindinsight#<br>root@ubuntu:</del>&#x2F;123&#x2F;mindinsight#<br>root@ubuntu:~&#x2F;123&#x2F;mindinsight# cat Dockerfile<br>FROM python:3.7.5</p>
<h1 id="————————-Optional-Configure-the-pip-source-–-l-1-———————-1"><a href="#————————-Optional-Configure-the-pip-source-–-l-1-———————-1" class="headerlink" title="————————-(Optional) Configure the pip source.–[l(1] ———————"></a>————————-(Optional) Configure the pip source.–[l(1] ———————</h1><p>#ENV http_proxy http:&#x2F;&#x2F;<user>:<password>@ip:port<br>#ENV https_proxy http:&#x2F;&#x2F;<user>:<password>@ip:port<br>#ENV ftp_proxy ftp:&#x2F;&#x2F;<user>:<password>@ip:port</p>
<p>WORKDIR &#x2F;tmp<br>COPY . .&#x2F;</p>
<p>RUN mkdir -p ~&#x2F;.pip <br>&amp;&amp; echo ‘[global] \n\<br>index-url&#x3D;<a href="https://pypi.doubanio.com/simple//n/">https://pypi.doubanio.com/simple/\n\</a><br>trusted-host&#x3D;pypi.doubanio.com’ &gt;&gt; ~&#x2F;.pip&#x2F;pip.conf</p>
<p>RUN pip install –upgrade pip &amp;&amp; pip3 install mindinsight-1.3.0-py3-none-any.whl &amp;&amp; <br>    rm mindinsight-1.3.0-py3-none-any.whl &amp;&amp; rm Dockerfile</p>
<p>RUN sed -i “&#x2F;^HOST&#x2F;cHOST &#x3D; ‘0.0.0.0’” &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;mindinsight&#x2F;conf&#x2F;constants.py</p>
<p>ENV http_proxy ‘’<br>ENV https_proxy ‘’<br>ENV ftp_proxy ‘’<br>RUN useradd -d &#x2F;home&#x2F;hwMindX -u 9000 -m -s &#x2F;bin&#x2F;bash hwMindX &amp;&amp; <br>    useradd -d &#x2F;home&#x2F;HwHiAiUser -u 1000 -m -s &#x2F;bin&#x2F;bash HwHiAiUser &amp;&amp; <br>    usermod -a -G HwHiAiUser hwMindX<br>root@ubuntu:<del>&#x2F;123&#x2F;mindinsight# vi start.sh<br>root@ubuntu:</del>&#x2F;123&#x2F;mindinsight#<br>root@ubuntu:<del>&#x2F;123&#x2F;mindinsight#<br>root@ubuntu:</del>&#x2F;123&#x2F;mindinsight# vi start.sh<br>root@ubuntu:<del>&#x2F;123&#x2F;mindinsight#<br>root@ubuntu:</del>&#x2F;123&#x2F;mindinsight#<br>root@ubuntu:<del>&#x2F;123&#x2F;mindinsight#<br>root@ubuntu:</del>&#x2F;123&#x2F;mindinsight# cat start.sh<br>#!&#x2F;bin&#x2F;bash</p>
<p>param&#x3D;$*</p>
<p>mindinsight start $param<br>while true<br>do<br>    sleep 30<br>    processnum&#x3D;<code>ps -ef | grep -w gunicorn | grep -v grep | wc -l</code><br>    if [ $processnum -le 0 ];then<br>      exit 1<br>    fi<br>done</p>
<p>root@ubuntu:<del>&#x2F;123&#x2F;mindinsight# docker build -t mindinsight:latest .<br>Sending build context to Docker daemon  5.427MB<br>Step 1&#x2F;10 : FROM python:3.7.5<br> —&gt; a4356c370cda<br>Step 2&#x2F;10 : WORKDIR &#x2F;tmp<br> —&gt; Using cache<br> —&gt; 6dca759650eb<br>Step 3&#x2F;10 : COPY . .&#x2F;<br> —&gt; 1c047c1f27a0<br>Step 4&#x2F;10 : RUN mkdir -p ~&#x2F;.pip &amp;&amp; echo ‘[global] \nindex-url&#x3D;<a href="https://pypi.doubanio.com/simple//ntrusted-host=pypi.doubanio.com&#39;">https://pypi.doubanio.com/simple/\ntrusted-host=pypi.doubanio.com&#39;</a> &gt;&gt; ~&#x2F;.pip&#x2F;pip.conf<br> —&gt; Running in 9ec07e2141f8<br>Removing intermediate container 9ec07e2141f8<br> —&gt; d2770d9bceb0<br>Step 5&#x2F;10 : RUN pip install –upgrade pip &amp;&amp; pip3 install mindinsight-1.3.0-py3-none-any.whl &amp;&amp;     rm mindinsight-1.3.0-py3-none-any.whl &amp;&amp; rm Dockerfile<br> —&gt; Running in 4f6b33bf9638<br>Looking in indexes: <a href="https://pypi.doubanio.com/simple/">https://pypi.doubanio.com/simple/</a><br>Collecting pip<br>  Downloading <a href="https://pypi.doubanio.com/packages/ca/31/b88ef447d595963c01060998cb329251648acf4a067721b0452c45527eb8/pip-21.2.4-py3-none-any.whl">https://pypi.doubanio.com/packages/ca/31/b88ef447d595963c01060998cb329251648acf4a067721b0452c45527eb8/pip-21.2.4-py3-none-any.whl</a> (1.6MB)<br>Installing collected packages: pip<br>  Found existing installation: pip 19.3.1<br>    Uninstalling pip-19.3.1:<br>      Successfully uninstalled pip-19.3.1<br>Successfully installed pip-21.2.4<br>Looking in indexes: <a href="https://pypi.doubanio.com/simple/">https://pypi.doubanio.com/simple/</a><br>Processing .&#x2F;mindinsight-1.3.0-py3-none-any.whl<br>Collecting treelib&gt;&#x3D;1.6.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/04/b0/2269c328abffbb63979f7143351a24a066776b87526d79956aea5018b80a/treelib-1.6.1.tar.gz">https://pypi.doubanio.com/packages/04/b0/2269c328abffbb63979f7143351a24a066776b87526d79956aea5018b80a/treelib-1.6.1.tar.gz</a> (24 kB)<br>Collecting XlsxWriter&gt;&#x3D;1.3.2<br>  Downloading <a href="https://pypi.doubanio.com/packages/68/51/f6f6aa86106712dad0db9663c7d24b6b32d2103b626d900fa68d48a9b262/XlsxWriter-3.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/68/51/f6f6aa86106712dad0db9663c7d24b6b32d2103b626d900fa68d48a9b262/XlsxWriter-3.0.1-py3-none-any.whl</a> (148 kB)<br>Collecting pandas&gt;&#x3D;1.0.4<br>  Downloading <a href="https://pypi.doubanio.com/packages/08/dc/d3513ec40c7df37a0e55b749a9b3a715f0d8b992c34c6ec6050bfd4a1703/pandas-1.3.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/08/dc/d3513ec40c7df37a0e55b749a9b3a715f0d8b992c34c6ec6050bfd4a1703/pandas-1.3.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl</a> (10.7 MB)<br>Collecting MarkupSafe&gt;&#x3D;1.1.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/70/fc/5a7253a9c1c4e2a3feadb80a5def4563500daa4b2d4a39cae39483afa1b0/MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/70/fc/5a7253a9c1c4e2a3feadb80a5def4563500daa4b2d4a39cae39483afa1b0/MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl</a> (26 kB)<br>Collecting scikit-learn&gt;&#x3D;0.23.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/f3/78/b4aa1db778c2eb4a2e7ee0df84461ecb1bb2019031fd08723bd4c923452f/scikit_learn-0.24.2-cp37-cp37m-manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/f3/78/b4aa1db778c2eb4a2e7ee0df84461ecb1bb2019031fd08723bd4c923452f/scikit_learn-0.24.2-cp37-cp37m-manylinux2014_aarch64.whl</a> (24.0 MB)<br>Collecting psutil&gt;&#x3D;5.7.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/e1/b0/7276de53321c12981717490516b7e612364f2cb372ee8901bd4a66a000d7/psutil-5.8.0.tar.gz">https://pypi.doubanio.com/packages/e1/b0/7276de53321c12981717490516b7e612364f2cb372ee8901bd4a66a000d7/psutil-5.8.0.tar.gz</a> (470 kB)<br>Collecting marshmallow&gt;&#x3D;3.10.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/2b/fb/d42cbb318e07c4d709a3cb8d85a2ca75fbb373fc536cb0afd36039233f32/marshmallow-3.13.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/2b/fb/d42cbb318e07c4d709a3cb8d85a2ca75fbb373fc536cb0afd36039233f32/marshmallow-3.13.0-py2.py3-none-any.whl</a> (47 kB)<br>Collecting yapf&gt;&#x3D;0.30.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/5f/0d/8814e79eb865eab42d95023b58b650d01dec6f8ea87fc9260978b1bf2167/yapf-0.31.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/5f/0d/8814e79eb865eab42d95023b58b650d01dec6f8ea87fc9260978b1bf2167/yapf-0.31.0-py2.py3-none-any.whl</a> (185 kB)<br>Collecting Jinja2&gt;&#x3D;2.10.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/80/21/ae597efc7ed8caaa43fb35062288baaf99a7d43ff0cf66452ddf47604ee6/Jinja2-3.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/80/21/ae597efc7ed8caaa43fb35062288baaf99a7d43ff0cf66452ddf47604ee6/Jinja2-3.0.1-py3-none-any.whl</a> (133 kB)<br>Collecting Flask&gt;&#x3D;1.1.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/54/4f/1b294c1a4ab7b2ad5ca5fc4a9a65a22ef1ac48be126289d97668852d4ab3/Flask-2.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/54/4f/1b294c1a4ab7b2ad5ca5fc4a9a65a22ef1ac48be126289d97668852d4ab3/Flask-2.0.1-py3-none-any.whl</a> (94 kB)<br>Collecting protobuf&gt;&#x3D;3.8.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/fd/5f/6d6f7a5859caf79894685ec543354edc05538a0a34d63a411a2a7cb4ecfd/protobuf-3.17.3-cp37-cp37m-manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/fd/5f/6d6f7a5859caf79894685ec543354edc05538a0a34d63a411a2a7cb4ecfd/protobuf-3.17.3-cp37-cp37m-manylinux2014_aarch64.whl</a> (922 kB)<br>Collecting google-pasta&gt;&#x3D;0.1.8<br>  Downloading <a href="https://pypi.doubanio.com/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl">https://pypi.doubanio.com/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl</a> (57 kB)<br>Collecting pyyaml&gt;&#x3D;5.3.1<br>  Downloading <a href="https://pypi.doubanio.com/packages/32/ac/a9383af90be713b0cb2ee7c7eb4317ab76957ed0a7e4aa9b9c170a992565/PyYAML-5.4.1-cp37-cp37m-manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/32/ac/a9383af90be713b0cb2ee7c7eb4317ab76957ed0a7e4aa9b9c170a992565/PyYAML-5.4.1-cp37-cp37m-manylinux2014_aarch64.whl</a> (716 kB)<br>Collecting gunicorn&gt;&#x3D;20.0.4<br>  Downloading <a href="https://pypi.doubanio.com/packages/e4/dd/5b190393e6066286773a67dfcc2f9492058e9b57c4867a95f1ba5caf0a83/gunicorn-20.1.0-py3-none-any.whl">https://pypi.doubanio.com/packages/e4/dd/5b190393e6066286773a67dfcc2f9492058e9b57c4867a95f1ba5caf0a83/gunicorn-20.1.0-py3-none-any.whl</a> (79 kB)<br>Collecting pillow&gt;&#x3D;6.2.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/df/97/e6e1aae9d75a7ac638cd7e5c5ddd1cf0ed3813275c07a43b68d081e1d479/Pillow-8.3.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/df/97/e6e1aae9d75a7ac638cd7e5c5ddd1cf0ed3813275c07a43b68d081e1d479/Pillow-8.3.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl</a> (2.9 MB)<br>Collecting Click&gt;&#x3D;7.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/76/0a/b6c5f311e32aeb3b406e03c079ade51e905ea630fc19d1262a46249c1c86/click-8.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/76/0a/b6c5f311e32aeb3b406e03c079ade51e905ea630fc19d1262a46249c1c86/click-8.0.1-py3-none-any.whl</a> (97 kB)<br>Collecting scipy&gt;&#x3D;1.5.2<br>  Downloading <a href="https://pypi.doubanio.com/packages/01/0b/279f3a059ee7e59aa087ccfe0c81e69fc286b869a9052f8c119ba1138a7b/scipy-1.7.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/01/0b/279f3a059ee7e59aa087ccfe0c81e69fc286b869a9052f8c119ba1138a7b/scipy-1.7.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl</a> (27.3 MB)<br>Collecting grpcio&lt;&#x3D;1.36.0,&gt;&#x3D;1.35.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/9d/9e/18e92a4042fdee8613f5613a37cf7162d32b5674f1b12d0f7b042e7e710b/grpcio-1.36.0.tar.gz">https://pypi.doubanio.com/packages/9d/9e/18e92a4042fdee8613f5613a37cf7162d32b5674f1b12d0f7b042e7e710b/grpcio-1.36.0.tar.gz</a> (21.5 MB)<br>Collecting Flask-Cors&gt;&#x3D;3.0.8<br>  Downloading <a href="https://pypi.doubanio.com/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl</a> (14 kB)<br>Collecting numpy&gt;&#x3D;1.17.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/5c/61/b2f14fb5aa1198fa63c6c90205dc2557df5cacdeb0b16d66abc6af8724b8/numpy-1.21.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl">https://pypi.doubanio.com/packages/5c/61/b2f14fb5aa1198fa63c6c90205dc2557df5cacdeb0b16d66abc6af8724b8/numpy-1.21.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl</a> (13.0 MB)<br>Collecting six&gt;&#x3D;1.12.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl</a> (11 kB)<br>Collecting itsdangerous&gt;&#x3D;1.1.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/9c/96/26f935afba9cd6140216da5add223a0c465b99d0f112b68a4ca426441019/itsdangerous-2.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/9c/96/26f935afba9cd6140216da5add223a0c465b99d0f112b68a4ca426441019/itsdangerous-2.0.1-py3-none-any.whl</a> (18 kB)<br>Collecting Werkzeug&gt;&#x3D;1.0.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/bd/24/11c3ea5a7e866bf2d97f0501d0b4b1c9bbeade102bb4b588f0d2919a5212/Werkzeug-2.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/bd/24/11c3ea5a7e866bf2d97f0501d0b4b1c9bbeade102bb4b588f0d2919a5212/Werkzeug-2.0.1-py3-none-any.whl</a> (288 kB)<br>Collecting importlib-metadata<br>  Downloading <a href="https://pypi.doubanio.com/packages/c0/72/4512a88e402d4dc3bab49a845130d95ac48936ef3a9469b55cc79a60d84d/importlib_metadata-4.6.4-py3-none-any.whl">https://pypi.doubanio.com/packages/c0/72/4512a88e402d4dc3bab49a845130d95ac48936ef3a9469b55cc79a60d84d/importlib_metadata-4.6.4-py3-none-any.whl</a> (17 kB)<br>Requirement already satisfied: setuptools&gt;&#x3D;3.0 in &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.7&#x2F;site-packages (from gunicorn&gt;&#x3D;20.0.4-&gt;mindinsight&#x3D;&#x3D;1.3.0) (41.6.0)<br>Collecting pytz&gt;&#x3D;2017.3<br>  Downloading <a href="https://pypi.doubanio.com/packages/70/94/784178ca5dd892a98f113cdd923372024dc04b8d40abe77ca76b5fb90ca6/pytz-2021.1-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/70/94/784178ca5dd892a98f113cdd923372024dc04b8d40abe77ca76b5fb90ca6/pytz-2021.1-py2.py3-none-any.whl</a> (510 kB)<br>Collecting python-dateutil&gt;&#x3D;2.7.3<br>  Downloading <a href="https://pypi.doubanio.com/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl">https://pypi.doubanio.com/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl</a> (247 kB)<br>Collecting threadpoolctl&gt;&#x3D;2.0.0<br>  Downloading <a href="https://pypi.doubanio.com/packages/c6/e8/c216b9b60cbba4642d3ca1bae7a53daa0c24426f662e0e3ce3dc7f6caeaa/threadpoolctl-2.2.0-py3-none-any.whl">https://pypi.doubanio.com/packages/c6/e8/c216b9b60cbba4642d3ca1bae7a53daa0c24426f662e0e3ce3dc7f6caeaa/threadpoolctl-2.2.0-py3-none-any.whl</a> (12 kB)<br>Collecting joblib&gt;&#x3D;0.11<br>  Downloading <a href="https://pypi.doubanio.com/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl">https://pypi.doubanio.com/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl</a> (303 kB)<br>Collecting future<br>  Downloading <a href="https://pypi.doubanio.com/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz">https://pypi.doubanio.com/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz</a> (829 kB)<br>Collecting typing-extensions&gt;&#x3D;3.6.4<br>  Downloading <a href="https://pypi.doubanio.com/packages/2e/35/6c4fff5ab443b57116cb1aad46421fb719bed2825664e8fe77d66d99bcbc/typing_extensions-3.10.0.0-py3-none-any.whl">https://pypi.doubanio.com/packages/2e/35/6c4fff5ab443b57116cb1aad46421fb719bed2825664e8fe77d66d99bcbc/typing_extensions-3.10.0.0-py3-none-any.whl</a> (26 kB)<br>Collecting zipp&gt;&#x3D;0.5<br>  Downloading <a href="https://pypi.doubanio.com/packages/92/d9/89f433969fb8dc5b9cbdd4b4deb587720ec1aeb59a020cf15002b9593eef/zipp-3.5.0-py3-none-any.whl">https://pypi.doubanio.com/packages/92/d9/89f433969fb8dc5b9cbdd4b4deb587720ec1aeb59a020cf15002b9593eef/zipp-3.5.0-py3-none-any.whl</a> (5.7 kB)<br>Building wheels for collected packages: grpcio, psutil, treelib, future<br>  Building wheel for grpcio (setup.py): started<br>  Building wheel for grpcio (setup.py): still running…<br>  Building wheel for grpcio (setup.py): finished with status ‘done’<br>  Created wheel for grpcio: filename&#x3D;grpcio-1.36.0-cp37-cp37m-linux_aarch64.whl size&#x3D;43277028 sha256&#x3D;0f9c41905a2331f6405bee3d2e7dcf083ea1aa6e39f85ae1190ff3a2ce98069a<br>  Stored in directory: &#x2F;root&#x2F;.cache&#x2F;pip&#x2F;wheels&#x2F;dd&#x2F;72&#x2F;74&#x2F;30b696f7d2a6abedf42d201eccd5f7a03f84931dfaa4b147db<br>  Building wheel for psutil (setup.py): started<br>  Building wheel for psutil (setup.py): finished with status ‘done’<br>  Created wheel for psutil: filename&#x3D;psutil-5.8.0-cp37-cp37m-linux_aarch64.whl size&#x3D;295178 sha256&#x3D;34f88db3e2056672357f438d0d338027bb65594437eafb4ae7c391ad0380d8bb<br>  Stored in directory: &#x2F;root&#x2F;.cache&#x2F;pip&#x2F;wheels&#x2F;2f&#x2F;c7&#x2F;77&#x2F;86efc5d98b9a79575ab1aaa9c24651f8841e57d46862979efd<br>  Building wheel for treelib (setup.py): started<br>  Building wheel for treelib (setup.py): finished with status ‘done’<br>  Created wheel for treelib: filename&#x3D;treelib-1.6.1-py3-none-any.whl size&#x3D;18370 sha256&#x3D;437a681028a4c479a0cc23c87a01a2cc51be82dc9fd355f3baa9e1363fe7fa5b<br>  Stored in directory: &#x2F;root&#x2F;.cache&#x2F;pip&#x2F;wheels&#x2F;44&#x2F;dd&#x2F;b6&#x2F;a9967a60d3575162a2e29846347f826dcb20466b0a1b67198e<br>  Building wheel for future (setup.py): started<br>  Building wheel for future (setup.py): finished with status ‘done’<br>  Created wheel for future: filename&#x3D;future-0.18.2-py3-none-any.whl size&#x3D;491056 sha256&#x3D;5b3be1990014b279b2ec75bfb2ba81737b5f2eee949d6573c7924391bdd19ed7<br>  Stored in directory: &#x2F;root&#x2F;.cache&#x2F;pip&#x2F;wheels&#x2F;97&#x2F;83&#x2F;dc&#x2F;8e47b8e3874918101250790fbce5d89fef8d0c33eb8097ad07<br>Successfully built grpcio psutil treelib future<br>Installing collected packages: zipp, typing-extensions, MarkupSafe, importlib-metadata, Werkzeug, six, numpy, Jinja2, itsdangerous, Click, threadpoolctl, scipy, pytz, python-dateutil, joblib, future, Flask, yapf, XlsxWriter, treelib, scikit-learn, pyyaml, psutil, protobuf, pillow, pandas, marshmallow, gunicorn, grpcio, google-pasta, Flask-Cors, mindinsight<br>Successfully installed Click-8.0.1 Flask-2.0.1 Flask-Cors-3.0.10 Jinja2-3.0.1 MarkupSafe-2.0.1 Werkzeug-2.0.1 XlsxWriter-3.0.1 future-0.18.2 google-pasta-0.2.0 grpcio-1.36.0 gunicorn-20.1.0 importlib-metadata-4.6.4 itsdangerous-2.0.1 joblib-1.0.1 marshmallow-3.13.0 mindinsight-1.3.0 numpy-1.21.2 pandas-1.3.2 pillow-8.3.1 protobuf-3.17.3 psutil-5.8.0 python-dateutil-2.8.2 pytz-2021.1 pyyaml-5.4.1 scikit-learn-0.24.2 scipy-1.7.1 six-1.16.0 threadpoolctl-2.2.0 treelib-1.6.1 typing-extensions-3.10.0.0 yapf-0.31.0 zipp-3.5.0<br>WARNING: Running pip as the ‘root’ user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: <a href="https://pip.pypa.io/warnings/venv">https://pip.pypa.io/warnings/venv</a><br>Removing intermediate container 4f6b33bf9638<br> —&gt; 2ef8fa6e4a74<br>Step 6&#x2F;10 : RUN sed -i “&#x2F;^HOST&#x2F;cHOST &#x3D; ‘0.0.0.0’” &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;mindinsight&#x2F;conf&#x2F;constants.py<br> —&gt; Running in 1da0a898001b<br>Removing intermediate container 1da0a898001b<br> —&gt; 08940216b1cc<br>Step 7&#x2F;10 : ENV http_proxy ‘’<br> —&gt; Running in 34dee7b0cd32<br>Removing intermediate container 34dee7b0cd32<br> —&gt; 7b7d62b31d09<br>Step 8&#x2F;10 : ENV https_proxy ‘’<br> —&gt; Running in ccc705d304f8<br>Removing intermediate container ccc705d304f8<br> —&gt; a533d73340db<br>Step 9&#x2F;10 : ENV ftp_proxy ‘’<br> —&gt; Running in 583ab62da6b4<br>Removing intermediate container 583ab62da6b4<br> —&gt; e9377900aedc<br>Step 10&#x2F;10 : RUN useradd -d &#x2F;home&#x2F;hwMindX -u 9000 -m -s &#x2F;bin&#x2F;bash hwMindX &amp;&amp;     useradd -d &#x2F;home&#x2F;HwHiAiUser -u 1000 -m -s &#x2F;bin&#x2F;bash HwHiAiUser &amp;&amp;     usermod -a -G HwHiAiUser hwMindX<br> —&gt; Running in c111b84f6220<br>Removing intermediate container c111b84f6220<br> —&gt; 7c11b719966b<br>Successfully built 7c11b719966b<br>Successfully tagged mindinsight:latest<br>root@ubuntu:</del>&#x2F;123&#x2F;mindinsight# docker images | grep mindinsight<br>mindinsight                                                   latest              7c11b719966b        17 seconds ago      1.52GB<br>root@ubuntu:~&#x2F;123&#x2F;mindinsight#</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e1a58c86830a4135999669e6d94a091a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>十二、配置Grafana</p>
<p>    打开Prometheus地址 》 选择“Status &gt; Targets” 》 当kubenetes-cadvisor下的“Endpoint”状态为“UP”时，记录“Labels”下的job值，该值为cadvisor所在节点的nodeName，下方文件中的“nodeName”批量替换成此名称。</p>
<p>&#96;&#96;&#96;shell<br>{<br>  “annotations”: {<br>    “list”: [<br>      {<br>        “builtIn”: 1,<br>        “datasource”: “– Grafana –”,<br>        “enable”: true,<br>        “hide”: true,<br>        “iconColor”: “rgba(0, 211, 255, 1)”,<br>        “name”: “Annotations &amp; Alerts”,<br>        “type”: “dashboard”<br>      }<br>    ]<br>  },<br>  “editable”: true,<br>  “gnetId”: null,<br>  “graphTooltip”: 0,<br>  “id”: 2,<br>  “links”: [],<br>  “panels”: [<br>    {<br>      “datasource”: null,<br>      “fieldConfig”: {<br>        “defaults”: {<br>          “custom”: {},<br>          “mappings”: [],<br>          “thresholds”: {<br>            “mode”: “absolute”,<br>            “steps”: [<br>              {<br>                “color”: “green”,<br>                “value”: null<br>              },<br>              {<br>                “color”: “red”,<br>                “value”: 80<br>              }<br>            ]<br>          }<br>        },<br>        “overrides”: []<br>      },<br>      “gridPos”: {<br>        “h”: 8,<br>        “w”: 7,<br>        “x”: 0,<br>        “y”: 0<br>      },<br>      “id”: 2,<br>      “options”: {<br>        “orientation”: “auto”,<br>        “reduceOptions”: {<br>          “calcs”: [<br>            “mean”<br>          ],<br>          “fields”: “”,<br>          “values”: false<br>        },<br>        “showThresholdLabels”: false,<br>        “showThresholdMarkers”: true<br>      },<br>      “pluginVersion”: “7.0.2”,<br>      “targets”: [<br>        {<br>          “expr”: “npu_chip_info_health_status{id&#x3D;&quot;0&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片0”,<br>          “refId”: “A”<br>        },<br>        {<br>          “expr”: “npu_chip_info_health_status{id&#x3D;&quot;1&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片1”,<br>          “refId”: “B”<br>        },<br>        {<br>          “expr”: “npu_chip_info_health_status{id&#x3D;&quot;2&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片2”,<br>          “refId”: “C”<br>        },<br>        {<br>          “expr”: “npu_chip_info_health_status{id&#x3D;&quot;3&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片3”,<br>          “refId”: “D”<br>        },<br>        {<br>          “expr”: “npu_chip_info_health_status{id&#x3D;&quot;4&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片4”,<br>          “refId”: “E”<br>        },<br>        {<br>          “expr”: “npu_chip_info_health_status{id&#x3D;&quot;5&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片5”,<br>          “refId”: “F”<br>        },<br>        {<br>          “expr”: “npu_chip_info_health_status{id&#x3D;&quot;6&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片6”,<br>          “refId”: “G”<br>        },<br>        {<br>          “expr”: “npu_chip_info_health_status{id&#x3D;&quot;7&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片7”,<br>          “refId”: “H”<br>        }<br>      ],<br>      “timeFrom”: null,<br>      “timeShift”: null,<br>      “title”: “npu健康状态(nodeName)”,<br>      “type”: “gauge”<br>    },<br>    {<br>      “aliasColors”: {},<br>      “bars”: false,<br>      “dashLength”: 10,<br>      “dashes”: false,<br>      “datasource”: “Prometheus”,<br>      “fieldConfig”: {<br>        “defaults”: {<br>          “custom”: {},<br>          “mappings”: [],<br>          “thresholds”: {<br>            “mode”: “absolute”,<br>            “steps”: [<br>              {<br>                “color”: “green”,<br>                “value”: null<br>              },<br>              {<br>                “color”: “red”,<br>                “value”: 80<br>              }<br>            ]<br>          }<br>        },<br>        “overrides”: []<br>      },<br>      “fill”: 1,<br>      “fillGradient”: 0,<br>      “gridPos”: {<br>        “h”: 8,<br>        “w”: 8,<br>        “x”: 7,<br>        “y”: 0<br>      },<br>      “hiddenSeries”: false,<br>      “id”: 6,<br>      “legend”: {<br>        “avg”: false,<br>        “current”: false,<br>        “max”: false,<br>        “min”: false,<br>        “show”: true,<br>        “total”: false,<br>        “values”: false<br>      },<br>      “lines”: true,<br>      “linewidth”: 1,<br>      “nullPointMode”: “null”,<br>      “options”: {<br>        “dataLinks”: []<br>      },<br>      “percentage”: false,<br>      “pluginVersion”: “7.0.3”,<br>      “pointradius”: 2,<br>      “points”: false,<br>      “renderer”: “flot”,<br>      “seriesOverrides”: [],<br>      “spaceLength”: 10,<br>      “stack”: false,<br>      “steppedLine”: false,<br>      “targets”: [<br>        {<br>          “expr”: “npu_chip_info_temperature{id&#x3D;&quot;0&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片0”,<br>          “refId”: “A”<br>        },<br>        {<br>          “expr”: “npu_chip_info_temperature{id&#x3D;&quot;1&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片1”,<br>          “refId”: “B”<br>        },<br>        {<br>          “expr”: “npu_chip_info_temperature{id&#x3D;&quot;2&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片2”,<br>          “refId”: “C”<br>        },<br>        {<br>          “expr”: “npu_chip_info_temperature{id&#x3D;&quot;3&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片3”,<br>          “refId”: “D”<br>        },<br>        {<br>          “expr”: “npu_chip_info_temperature{id&#x3D;&quot;4&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片4”,<br>          “refId”: “E”<br>        },<br>        {<br>          “expr”: “npu_chip_info_temperature{id&#x3D;&quot;5&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片5”,<br>          “refId”: “F”<br>        },<br>        {<br>          “expr”: “npu_chip_info_temperature{id&#x3D;&quot;6&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片6”,<br>          “refId”: “G”<br>        },<br>        {<br>          “expr”: “npu_chip_info_temperature{id&#x3D;&quot;7&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片7”,<br>          “refId”: “H”<br>        }<br>      ],<br>      “thresholds”: [],<br>      “timeFrom”: null,<br>      “timeRegions”: [],<br>      “timeShift”: null,<br>      “title”: “npu温度(nodeName)”,<br>      “tooltip”: {<br>        “shared”: true,<br>        “sort”: 0,<br>        “value_type”: “individual”<br>      },<br>      “type”: “graph”,<br>      “xaxis”: {<br>        “buckets”: null,<br>        “mode”: “time”,<br>        “name”: null,<br>        “show”: true,<br>        “values”: []<br>      },<br>      “yaxes”: [<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        },<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        }<br>      ],<br>      “yaxis”: {<br>        “align”: false,<br>        “alignLevel”: null<br>      }<br>    },<br>    {<br>      “datasource”: null,<br>      “fieldConfig”: {<br>        “defaults”: {<br>          “custom”: {},<br>          “mappings”: [],<br>          “thresholds”: {<br>            “mode”: “absolute”,<br>            “steps”: [<br>              {<br>                “color”: “green”,<br>                “value”: null<br>              },<br>              {<br>                “color”: “red”,<br>                “value”: 80<br>              }<br>            ]<br>          }<br>        },<br>        “overrides”: []<br>      },<br>      “gridPos”: {<br>        “h”: 8,<br>        “w”: 8,<br>        “x”: 15,<br>        “y”: 0<br>      },<br>      “id”: 12,<br>      “options”: {<br>        “colorMode”: “value”,<br>        “graphMode”: “area”,<br>        “justifyMode”: “auto”,<br>        “orientation”: “auto”,<br>        “reduceOptions”: {<br>          “calcs”: [<br>            “mean”<br>          ],<br>          “fields”: “”,<br>          “values”: false<br>        }<br>      },<br>      “pluginVersion”: “7.0.2”,<br>      “targets”: [<br>        {<br>          “expr”: “npu_chip_info_voltage{id&#x3D;&quot;0&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片0”,<br>          “refId”: “A”<br>        },<br>        {<br>          “expr”: “npu_chip_info_voltage{id&#x3D;&quot;1&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片1”,<br>          “refId”: “B”<br>        },<br>        {<br>          “expr”: “npu_chip_info_voltage{id&#x3D;&quot;2&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片2”,<br>          “refId”: “C”<br>        },<br>        {<br>          “expr”: “npu_chip_info_voltage{id&#x3D;&quot;3&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片3”,<br>          “refId”: “D”<br>        },<br>        {<br>          “expr”: “npu_chip_info_voltage{id&#x3D;&quot;4&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片4”,<br>          “refId”: “E”<br>        },<br>        {<br>          “expr”: “npu_chip_info_voltage{id&#x3D;&quot;5&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片5”,<br>          “refId”: “F”<br>        },<br>        {<br>          “expr”: “npu_chip_info_voltage{id&#x3D;&quot;6&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片6”,<br>          “refId”: “G”<br>        },<br>        {<br>          “expr”: “npu_chip_info_voltage{id&#x3D;&quot;7&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片7”,<br>          “refId”: “H”<br>        }<br>      ],<br>      “timeFrom”: null,<br>      “timeShift”: null,<br>      “title”: “npu电压(nodeName)”,<br>      “type”: “stat”<br>    },<br>    {<br>      “aliasColors”: {},<br>      “bars”: false,<br>      “dashLength”: 10,<br>      “dashes”: false,<br>      “datasource”: null,<br>      “fieldConfig”: {<br>        “defaults”: {<br>          “custom”: {<br>            “align”: null<br>          },<br>          “mappings”: [],<br>          “thresholds”: {<br>            “mode”: “absolute”,<br>            “steps”: [<br>              {<br>                “color”: “green”,<br>                “value”: null<br>              },<br>              {<br>                “color”: “red”,<br>                “value”: 80<br>              }<br>            ]<br>          }<br>        },<br>        “overrides”: []<br>      },<br>      “fill”: 1,<br>      “fillGradient”: 0,<br>      “gridPos”: {<br>        “h”: 8,<br>        “w”: 7,<br>        “x”: 0,<br>        “y”: 8<br>      },<br>      “hiddenSeries”: false,<br>      “id”: 8,<br>      “legend”: {<br>        “avg”: false,<br>        “current”: false,<br>        “max”: false,<br>        “min”: false,<br>        “show”: true,<br>        “total”: false,<br>        “values”: false<br>      },<br>      “lines”: true,<br>      “linewidth”: 1,<br>      “nullPointMode”: “null”,<br>      “options”: {<br>        “dataLinks”: []<br>      },<br>      “percentage”: false,<br>      “pluginVersion”: “7.0.3”,<br>      “pointradius”: 2,<br>      “points”: false,<br>      “renderer”: “flot”,<br>      “seriesOverrides”: [],<br>      “spaceLength”: 10,<br>      “stack”: false,<br>      “steppedLine”: false,<br>      “targets”: [<br>        {<br>          “expr”: “npu_chip_info_used_memory{id&#x3D;&quot;0&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片0”,<br>          “refId”: “A”<br>        },<br>        {<br>          “expr”: “npu_chip_info_used_memory{id&#x3D;&quot;1&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片1”,<br>          “refId”: “B”<br>        },<br>        {<br>          “expr”: “npu_chip_info_used_memory{id&#x3D;&quot;2&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片2”,<br>          “refId”: “C”<br>        },<br>        {<br>          “expr”: “npu_chip_info_used_memory{id&#x3D;&quot;3&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片3”,<br>          “refId”: “D”<br>        },<br>        {<br>          “expr”: “npu_chip_info_used_memory{id&#x3D;&quot;4&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片4”,<br>          “refId”: “E”<br>        },<br>        {<br>          “expr”: “npu_chip_info_used_memory{id&#x3D;&quot;5&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片5”,<br>          “refId”: “F”<br>        },<br>        {<br>          “expr”: “npu_chip_info_used_memory{id&#x3D;&quot;6&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片6”,<br>          “refId”: “G”<br>        },<br>        {<br>          “expr”: “npu_chip_info_used_memory{id&#x3D;&quot;7&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片7”,<br>          “refId”: “H”<br>        }<br>      ],<br>      “thresholds”: [],<br>      “timeFrom”: null,<br>      “timeRegions”: [],<br>      “timeShift”: null,<br>      “title”: “npu内存使用(nodeName)”,<br>      “tooltip”: {<br>        “shared”: true,<br>        “sort”: 0,<br>        “value_type”: “individual”<br>      },<br>      “type”: “graph”,<br>      “xaxis”: {<br>        “buckets”: null,<br>        “mode”: “time”,<br>        “name”: null,<br>        “show”: true,<br>        “values”: []<br>      },<br>      “yaxes”: [<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        },<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        }<br>      ],<br>      “yaxis”: {<br>        “align”: false,<br>        “alignLevel”: null<br>      }<br>    },<br>    {<br>      “aliasColors”: {},<br>      “bars”: false,<br>      “dashLength”: 10,<br>      “dashes”: false,<br>      “datasource”: null,<br>      “description”: “”,<br>      “fieldConfig”: {<br>        “defaults”: {<br>          “custom”: {<br>            “align”: null<br>          },<br>          “mappings”: [],<br>          “thresholds”: {<br>            “mode”: “absolute”,<br>            “steps”: [<br>              {<br>                “color”: “green”,<br>                “value”: null<br>              },<br>              {<br>                “color”: “red”,<br>                “value”: 80<br>              }<br>            ]<br>          }<br>        },<br>        “overrides”: []<br>      },<br>      “fill”: 1,<br>      “fillGradient”: 0,<br>      “gridPos”: {<br>        “h”: 8,<br>        “w”: 8,<br>        “x”: 7,<br>        “y”: 8<br>      },<br>      “hiddenSeries”: false,<br>      “id”: 10,<br>      “legend”: {<br>        “avg”: false,<br>        “current”: false,<br>        “max”: false,<br>        “min”: false,<br>        “show”: true,<br>        “total”: false,<br>        “values”: false<br>      },<br>      “lines”: true,<br>      “linewidth”: 1,<br>      “nullPointMode”: “null”,<br>      “options”: {<br>        “dataLinks”: []<br>      },<br>      “percentage”: false,<br>      “pluginVersion”: “7.0.3”,<br>      “pointradius”: 2,<br>      “points”: false,<br>      “renderer”: “flot”,<br>      “seriesOverrides”: [],<br>      “spaceLength”: 10,<br>      “stack”: false,<br>      “steppedLine”: false,<br>      “targets”: [<br>        {<br>          “expr”: “npu_chip_info_utilization{id&#x3D;&quot;0&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片0”,<br>          “refId”: “A”<br>        },<br>        {<br>          “expr”: “npu_chip_info_utilization{id&#x3D;&quot;1&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片1”,<br>          “refId”: “B”<br>        },<br>        {<br>          “expr”: “npu_chip_info_utilization{id&#x3D;&quot;2&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片2”,<br>          “refId”: “C”<br>        },<br>        {<br>          “expr”: “npu_chip_info_utilization{id&#x3D;&quot;3&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片3”,<br>          “refId”: “D”<br>        },<br>        {<br>          “expr”: “npu_chip_info_utilization{id&#x3D;&quot;4&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片4”,<br>          “refId”: “E”<br>        },<br>        {<br>          “expr”: “npu_chip_info_utilization{id&#x3D;&quot;5&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片5”,<br>          “refId”: “F”<br>        },<br>        {<br>          “expr”: “npu_chip_info_utilization{id&#x3D;&quot;6&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片6”,<br>          “refId”: “G”<br>        },<br>        {<br>          “expr”: “npu_chip_info_utilization{id&#x3D;&quot;7&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片7”,<br>          “refId”: “H”<br>        }<br>      ],<br>      “thresholds”: [],<br>      “timeFrom”: null,<br>      “timeRegions”: [],<br>      “timeShift”: null,<br>      “title”: “npu_AI_Core使用率(nodeName)”,<br>      “tooltip”: {<br>        “shared”: true,<br>        “sort”: 0,<br>        “value_type”: “individual”<br>      },<br>      “type”: “graph”,<br>      “xaxis”: {<br>        “buckets”: null,<br>        “mode”: “time”,<br>        “name”: null,<br>        “show”: true,<br>        “values”: []<br>      },<br>      “yaxes”: [<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        },<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        }<br>      ],<br>      “yaxis”: {<br>        “align”: false,<br>        “alignLevel”: null<br>      }<br>    },<br>    {<br>      “aliasColors”: {},<br>      “bars”: false,<br>      “dashLength”: 10,<br>      “dashes”: false,<br>      “datasource”: null,<br>      “fieldConfig”: {<br>        “defaults”: {<br>          “custom”: {<br>            “align”: null<br>          },<br>          “mappings”: [],<br>          “thresholds”: {<br>            “mode”: “absolute”,<br>            “steps”: [<br>              {<br>                “color”: “green”,<br>                “value”: null<br>              },<br>              {<br>                “color”: “red”,<br>                “value”: 80<br>              }<br>            ]<br>          }<br>        },<br>        “overrides”: []<br>      },<br>      “fill”: 1,<br>      “fillGradient”: 0,<br>      “gridPos”: {<br>        “h”: 8,<br>        “w”: 8,<br>        “x”: 15,<br>        “y”: 8<br>      },<br>      “hiddenSeries”: false,<br>      “id”: 4,<br>      “legend”: {<br>        “avg”: false,<br>        “current”: false,<br>        “max”: false,<br>        “min”: false,<br>        “show”: true,<br>        “total”: false,<br>        “values”: false<br>      },<br>      “lines”: true,<br>      “linewidth”: 1,<br>      “nullPointMode”: “null”,<br>      “options”: {<br>        “dataLinks”: []<br>      },<br>      “percentage”: false,<br>      “pluginVersion”: “7.0.3”,<br>      “pointradius”: 2,<br>      “points”: false,<br>      “renderer”: “flot”,<br>      “seriesOverrides”: [],<br>      “spaceLength”: 10,<br>      “stack”: false,<br>      “steppedLine”: false,<br>      “targets”: [<br>        {<br>          “expr”: “npu_chip_info_power{id&#x3D;&quot;0&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片0”,<br>          “refId”: “A”<br>        },<br>        {<br>          “expr”: “npu_chip_info_power{id&#x3D;&quot;1&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片1”,<br>          “refId”: “B”<br>        },<br>        {<br>          “expr”: “npu_chip_info_power{id&#x3D;&quot;2&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片2”,<br>          “refId”: “C”<br>        },<br>        {<br>          “expr”: “npu_chip_info_power{id&#x3D;&quot;3&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片3”,<br>          “refId”: “D”<br>        },<br>        {<br>          “expr”: “npu_chip_info_power{id&#x3D;&quot;4&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片4”,<br>          “refId”: “E”<br>        },<br>        {<br>          “expr”: “npu_chip_info_power{id&#x3D;&quot;5&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片5”,<br>          “refId”: “F”<br>        },<br>        {<br>          “expr”: “npu_chip_info_power{id&#x3D;&quot;6&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片6”,<br>          “refId”: “G”<br>        },<br>        {<br>          “expr”: “npu_chip_info_power{id&#x3D;&quot;7&quot;,job&#x3D;&quot;nodeName&quot;}”,<br>          “interval”: “”,<br>          “legendFormat”: “芯片7”,<br>          “refId”: “H”<br>        }<br>      ],<br>      “thresholds”: [],<br>      “timeFrom”: null,<br>      “timeRegions”: [],<br>      “timeShift”: null,<br>      “title”: “npu使用功耗(nodeName)”,<br>      “tooltip”: {<br>        “shared”: true,<br>        “sort”: 0,<br>        “value_type”: “individual”<br>      },<br>      “type”: “graph”,<br>      “xaxis”: {<br>        “buckets”: null,<br>        “mode”: “time”,<br>        “name”: null,<br>        “show”: true,<br>        “values”: []<br>      },<br>      “yaxes”: [<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        },<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        }<br>      ],<br>      “yaxis”: {<br>        “align”: false,<br>        “alignLevel”: null<br>      }<br>    },<br>    {<br>      “aliasColors”: {},<br>      “bars”: false,<br>      “dashLength”: 10,<br>      “dashes”: false,<br>      “datasource”: null,<br>      “fieldConfig”: {<br>        “defaults”: {<br>          “custom”: {}<br>        },<br>        “overrides”: []<br>      },<br>      “fill”: 1,<br>      “fillGradient”: 0,<br>      “gridPos”: {<br>        “h”: 10,<br>        “w”: 7,<br>        “x”: 0,<br>        “y”: 16<br>      },<br>      “hiddenSeries”: false,<br>      “id”: 20,<br>      “legend”: {<br>        “avg”: false,<br>        “current”: false,<br>        “max”: false,<br>        “min”: false,<br>        “show”: true,<br>        “total”: false,<br>        “values”: false<br>      },<br>      “lines”: true,<br>      “linewidth”: 1,<br>      “nullPointMode”: “null”,<br>      “options”: {<br>        “dataLinks”: []<br>      },<br>      “percentage”: false,<br>      “pointradius”: 2,<br>      “points”: false,<br>      “renderer”: “flot”,<br>      “seriesOverrides”: [],<br>      “spaceLength”: 10,<br>      “stack”: false,<br>      “steppedLine”: false,<br>      “targets”: [<br>        {<br>          “expr”: “container_memory_usage_bytes”,<br>          “interval”: “”,<br>          “legendFormat”: “”,<br>          “refId”: “A”<br>        }<br>      ],<br>      “thresholds”: [],<br>      “timeFrom”: null,<br>      “timeRegions”: [],<br>      “timeShift”: null,<br>      “title”: “容器内存使用量”,<br>      “tooltip”: {<br>        “shared”: true,<br>        “sort”: 0,<br>        “value_type”: “individual”<br>      },<br>      “type”: “graph”,<br>      “xaxis”: {<br>        “buckets”: null,<br>        “mode”: “time”,<br>        “name”: null,<br>        “show”: true,<br>        “values”: []<br>      },<br>      “yaxes”: [<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        },<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        }<br>      ],<br>      “yaxis”: {<br>        “align”: false,<br>        “alignLevel”: null<br>      }<br>    },<br>    {<br>      “aliasColors”: {},<br>      “bars”: false,<br>      “dashLength”: 10,<br>      “dashes”: false,<br>      “datasource”: null,<br>      “fieldConfig”: {<br>        “defaults”: {<br>          “custom”: {}<br>        },<br>        “overrides”: []<br>      },<br>      “fill”: 1,<br>      “fillGradient”: 0,<br>      “gridPos”: {<br>        “h”: 10,<br>        “w”: 7,<br>        “x”: 7,<br>        “y”: 16<br>      },<br>      “hiddenSeries”: false,<br>      “id”: 18,<br>      “legend”: {<br>        “avg”: false,<br>        “current”: false,<br>        “max”: false,<br>        “min”: false,<br>        “show”: true,<br>        “total”: false,<br>        “values”: false<br>      },<br>      “lines”: true,<br>      “linewidth”: 1,<br>      “nullPointMode”: “null”,<br>      “options”: {<br>        “dataLinks”: []<br>      },<br>      “percentage”: false,<br>      “pointradius”: 2,<br>      “points”: false,<br>      “renderer”: “flot”,<br>      “seriesOverrides”: [],<br>      “spaceLength”: 10,<br>      “stack”: false,<br>      “steppedLine”: false,<br>      “targets”: [<br>        {<br>          “expr”: “sum(rate(container_network_receive_bytes_total{image!&#x3D;&quot;&quot;}[1m])) without (interface)”,<br>          “interval”: “”,<br>          “legendFormat”: “”,<br>          “refId”: “A”<br>        }<br>      ],<br>      “thresholds”: [],<br>      “timeFrom”: null,<br>      “timeRegions”: [],<br>      “timeShift”: null,<br>      “title”: “容器网络接收量速率”,<br>      “tooltip”: {<br>        “shared”: true,<br>        “sort”: 0,<br>        “value_type”: “individual”<br>      },<br>      “type”: “graph”,<br>      “xaxis”: {<br>        “buckets”: null,<br>        “mode”: “time”,<br>        “name”: null,<br>        “show”: true,<br>        “values”: []<br>      },<br>      “yaxes”: [<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        },<br>        {<br>          “format”: “short”,<br>          “label”: null,<br>          “logBase”: 1,<br>          “max”: null,<br>          “min”: null,<br>          “show”: true<br>        }<br>      ],<br>      “yaxis”: {<br>        “align”: false,<br>        “alignLevel”: null<br>      }<br>    }<br>  ],<br>  “refresh”: “5s”,<br>  “schemaVersion”: 25,<br>  “style”: “dark”,<br>  “tags”: [],<br>  “templating”: {<br>    “list”: []<br>  },<br>  “time”: {<br>    “from”: “now-15m”,<br>    “to”: “now”<br>  },<br>  “timepicker”: {<br>    “refresh_intervals”: [<br>      “10s”,<br>      “30s”,<br>      “1m”,<br>      “5m”,<br>      “15m”,<br>      “30m”,<br>      “1h”,<br>      “2h”,<br>      “1d”<br>    ]<br>  },<br>  “timezone”: “”,<br>  “title”: “nodeName”,<br>  “uid”: “2kWOIniGz”,<br>  “version”: 7<br>}</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f035f0db96145b89d31fca711d3b0c2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>查看pod：  </p>
<p>&#96;&#96;&#96;shell<br>root@ubuntu:<del># kubectl get pod -A<br>NAMESPACE        NAME                                       READY   STATUS      RESTARTS   AGE<br>cadvisor         cadvisor-phj6x                             1&#x2F;1     Running     1          17h<br>default          dls-cec-deploy-686bd4d6cd-gtrqb            1&#x2F;1     Running     2          15h<br>default          dls-mms-deploy-6fd697754f-8xkkv            1&#x2F;1     Running     2          15h<br>default          hccl-controller-645bb466f-lw9b4            1&#x2F;1     Running     1          17h<br>default          tjm-77f784dcf-6s2f4                        1&#x2F;1     Running     2          15h<br>kube-system      ascend-device-plugin-daemonset-qrfbx       1&#x2F;1     Running     1          17h<br>kube-system      calico-kube-controllers-8464785d6b-tl44n   1&#x2F;1     Running     1          17h<br>kube-system      calico-node-lm7x5                          1&#x2F;1     Running     1          17h<br>kube-system      coredns-6955765f44-czzws                   1&#x2F;1     Running     1          17h<br>kube-system      coredns-6955765f44-t2n4z                   1&#x2F;1     Running     1          17h<br>kube-system      dls-apigw-deploy-9f58f549-sklgc            1&#x2F;1     Running     2          15h<br>kube-system      dls-dms-deploy-76b79854cc-6m54s            1&#x2F;1     Running     2          15h<br>kube-system      dls-ims-deploy-5445d6cc9d-96chh            1&#x2F;1     Running     2          15h<br>kube-system      dls-nginx-deploy-7c9d889998-84956          1&#x2F;1     Running     0          15h<br>kube-system      etcd-ubuntu                                1&#x2F;1     Running     1          17h<br>kube-system      grafana-core-f97475d78-b74ww               1&#x2F;1     Running     0          15h<br>kube-system      kube-apiserver-ubuntu                      1&#x2F;1     Running     1          17h<br>kube-system      kube-controller-manager-ubuntu             1&#x2F;1     Running     1          17h<br>kube-system      kube-proxy-rljv7                           1&#x2F;1     Running     1          17h<br>kube-system      kube-scheduler-ubuntu                      1&#x2F;1     Running     1          17h<br>kube-system      mysql-5cccdd88bd-mqv27                     1&#x2F;1     Running     0          15h<br>kube-system      prometheus-58c69548b4-bgw4h                1&#x2F;1     Running     0          15h<br>kube-system      redis-deploy-7fbc4fb97d-bkkmb              1&#x2F;1     Running     0          15h<br>volcano-system   volcano-admission-74776688c8-45mr8         1&#x2F;1     Running     1          17h<br>volcano-system   volcano-admission-init-zgr5t               0&#x2F;1     Completed   0          17h<br>volcano-system   volcano-controllers-6786db54f-nwnfw        1&#x2F;1     Running     1          17h<br>volcano-system   volcano-scheduler-844f9b547b-qkxgt         1&#x2F;1     Running     1          17h<br>root@ubuntu:</del>#</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d199d3e1d1394b5dbd58a122f0fe2e7d~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>33篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4594e4602896453c8f70b562634a32ec~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>搭建Hadoop2.7.2和Hive2.3.3以及Spark3.1.2</title>
    <url>/2021/12/30/2021-12-30-%E6%90%AD%E5%BB%BAHadoop2.7.2%E5%92%8CHive2.3.3%E4%BB%A5%E5%8F%8ASpark3.1.2/</url>
    <content><![CDATA[<p><strong>Hadoop 简介</strong></p>
<p>Hadoop是一个用Java编写的Apache开源框架，允许使用简单的编程模型跨计算机集群分布式处理大型数据集。Hadoop框架工作的应用程序在跨计算机集群提供分布式存储和计算的环境中工作。Hadoop旨在从单个服务器扩展到数千个机器，每个都提供本地计算和存储。</p>
<p><strong>Hive简介</strong></p>
<p>Apache Hive是一个构建于Hadoop顶层的数据仓库，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。需要注意的是，Hive它并不是数据库。</p>
<p>Hive依赖于HDFS和MapReduce，其对HDFS的操作类似于SQL，我们称之为HQL，它提供了丰富的SQL查询方式来分析存储在HDFS中的数据。HQL可以编译转为MapReduce作业，完成查询、汇总、分析数据等工作。这样一来，即使不熟悉MapReduce 的用户也可以很方便地利用SQL 语言查询、汇总、分析数据。而MapReduce开发人员可以把己写的mapper 和reducer 作为插件来支持Hive 做更复杂的数据分析。</p>
<p><strong>Apache Spark 简介</strong></p>
<p>用于大数据工作负载的分布式开源处理系统</p>
<p>Apache Spark 是一种用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。它提供使用 Java、Scala、Python 和 R 语言的开发 API，支持跨多个工作负载重用代码—批处理、交互式查询、实时分析、机器学习和图形处理等。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6afdfd92a4324cb1bfe1d8f726d59201~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>本文将先搭建 jdk1.8 + MySQL5.7基础环境</strong></p>
<p><strong>之后搭建Hadoop2.7.2和Hive2.3.3以及Spark3.1.2</strong></p>
<p><strong>此文章搭建为单机版</strong>  </p>
<p><strong>1.创建目录并解压jdk安装包</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# mkdir  jdk<br>[root@localhost ~]# cd jdk&#x2F;<br>[root@localhost jdk]# ls<br>jdk-8u202-linux-x64.tar.gz<br>[root@localhost jdk]# ll<br>total 189496<br>-rw-r–r–. 1 root root 194042837 Oct 18 12:05 jdk-8u202-linux-x64.tar.gz<br>[root@localhost jdk]#<br>[root@localhost jdk]# tar xvf jdk-8u202-linux-x64.tar.gz</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>2.配置环境变量</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# vim &#x2F;etc&#x2F;profile<br>[root@localhost ~]# tail -n 3 &#x2F;etc&#x2F;profile<br>export JAVA_HOME&#x3D;&#x2F;root&#x2F;jdk&#x2F;jdk1.8.0_202&#x2F;<br>export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH<br>export CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar<br>[root@localhost ~]#<br>[root@localhost ~]# source &#x2F;etc&#x2F;profile</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>3.下载安装MySQL并设置为开机自启</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# mkdir mysql<br>[root@localhost ~]# cd mysql<br>[root@localhost mysql]# wget <a href="https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.35-1.el7.x86_64.rpm-bundle.tar">https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.35-1.el7.x86_64.rpm-bundle.tar</a><br>[root@localhost mysql]# tar xvf mysql-5.7.35-1.el7.x86_64.rpm-bundle.tar<br>[root@localhost mysql]# yum install .&#x2F;*.rpm<br>[root@localhost mysql]# systemctl start mysqld.service<br>[root@localhost mysql]#<br>[root@localhost mysql]# systemctl enable mysqld.service<br>[root@localhost mysql]#<br>[root@localhost mysql]#</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>4.查看MySQL默认密码，并修改默认密码，同时创建新的用户，将其设置为可以远程登录</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost mysql]# sudo grep ‘temporary password’ &#x2F;var&#x2F;log&#x2F;mysqld.log<br>2021-10-18T06:12:35.519726Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: eNHu&lt;sXHt3rq<br>[root@localhost mysql]#<br>[root@localhost mysql]#<br>[root@localhost mysql]# mysql -u root -p<br>Enter password:<br>Welcome to the MySQL monitor.  Commands end with ; or \g.<br>Your MySQL connection id is 9<br>Server version: 8.0.25</p>
<p>Copyright (c) 2000, 2021, Oracle and&#x2F;or its affiliates.</p>
<p>Oracle is a registered trademark of Oracle Corporation and&#x2F;or its<br>affiliates. Other names may be trademarks of their respective<br>owners.</p>
<p>Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement.</p>
<p>mysql&gt;<br>mysql&gt; ALTER USER ‘root‘@’localhost’ IDENTIFIED WITH mysql_native_password BY ‘Cby123..’;<br>Query OK, 0 rows affected (0.02 sec)</p>
<p>mysql&gt;<br>mysql&gt;<br>mysql&gt; use mysql;<br>Database changed<br>mysql&gt;<br>mysql&gt; update user set host&#x3D;’%’ where user &#x3D;’root’;<br>Query OK, 1 row affected (0.01 sec)<br>Rows matched: 1  Changed: 1  Warnings: 0</p>
<p>mysql&gt; set global validate_password_policy&#x3D;0;<br>Query OK, 0 rows affected (0.01 sec)</p>
<p>mysql&gt; set global validate_password_mixed_case_count&#x3D;0;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt;  set global validate_password_number_count&#x3D;3;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; set global validate_password_special_char_count&#x3D;0;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; set global validate_password_length&#x3D;3;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; SHOW VARIABLES LIKE ‘validate_password%’;<br>+————————————–+——-+<br>| Variable_name                        | Value |<br>+————————————–+——-+<br>| validate_password_check_user_name    | OFF   |<br>| validate_password_dictionary_file    |       |<br>| validate_password_length             | 3     |<br>| validate_password_mixed_case_count   | 0     |<br>| validate_password_number_count       | 3     |<br>| validate_password_policy             | LOW   |<br>| validate_password_special_char_count | 0     |<br>+————————————–+——-+<br>7 rows in set (0.00 sec)</p>
<p>mysql&gt; create user ‘cby‘@’%’ identified by ‘cby’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; grant all on <em>.</em> to ‘cby‘@’%’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; FLUSH PRIVILEGES;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; GRANT ALL PRIVILEGES ON <em>.</em> TO ‘root‘@’%’WITH GRANT OPTION;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; CREATE DATABASE dss_dev;<br>Query OK, 1 row affected (0.00 sec)</p>
<p>mysql&gt;<br>mysql&gt; select host,user,plugin from user;<br>+———–+—————+———————–+<br>| host      | user          | plugin                |<br>+———–+—————+———————–+<br>| %         | root          | mysql_native_password |<br>| localhost | mysql.session | mysql_native_password |<br>| localhost | mysql.sys     | mysql_native_password |<br>+———–+—————+———————–+<br>3 rows in set (0.01 sec)</p>
<p>mysql&gt;</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>注：若上面root不是mysql_native_password使用以下命令将其改掉</strong></p>
<p>&#96;&#96;&#96;shell<br>update user set plugin&#x3D;’mysql_native_password’ where user&#x3D;’root’;</p>
<p>&#96;&#96;&#96;shell</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/732afa3a5c5a4b23bc1fdfba94105597~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>5.添加hosts解析，同时设置免密登录</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# mkdir Hadoop<br>[root@localhost ~]#<br>[root@localhost ~]# vim &#x2F;etc&#x2F;hosts<br>[root@localhost ~]#<br>[root@localhost ~]#<br>[root@localhost ~]# cat &#x2F;etc&#x2F;hosts<br>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4<br>::1         localhost localhost.localdomain localhost6 localhost6.localdomain6<br>127.0.0.1 namenode<br>[root@localhost ~]# ssh-keygen<br>[root@localhost ~]# ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_rsa.pub <a href="mailto:&#114;&#111;&#x6f;&#116;&#x40;&#x31;&#x32;&#x37;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#x31;">&#114;&#111;&#x6f;&#116;&#x40;&#x31;&#x32;&#x37;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#x31;</a><br>[root@localhost ~]#</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>6.下载Hadoop，解压后创建所需目录</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# cd Hadoop&#x2F;<br>[root@localhost Hadoop]# ls<br>[root@localhost Hadoop]# wget <a href="https://archive.apache.org/dist/hadoop/core/hadoop-2.7.2/hadoop-2.7.2.tar.gz">https://archive.apache.org/dist/hadoop/core/hadoop-2.7.2/hadoop-2.7.2.tar.gz</a><br>[root@localhost Hadoop]# tar xvf hadoop-2.7.2.tar.gz<br>[root@localhost Hadoop]#<br>[root@localhost Hadoop]# mkdir  -p &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;hadoopinfra&#x2F;hdfs&#x2F;namenode<br>[root@localhost Hadoop]#<br>[root@localhost Hadoop]#<br>[root@localhost Hadoop]# mkdir  -p &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;hadoopinfra&#x2F;hdfs&#x2F;datanode</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>7.添加Hadoop环境变量</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# vim &#x2F;etc&#x2F;profile<br>[root@localhost ~]# tail -n 8 &#x2F;etc&#x2F;profile<br>export HADOOP_HOME&#x3D;&#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;<br>export HADOOP_INSTALL&#x3D;$HADOOP_HOME<br>export HADOOP_MAPRED_HOME&#x3D;$HADOOP_HOME<br>export HADOOP_COMMON_HOME&#x3D;$HADOOP_HOME<br>export HADOOP_HDFS_HOME&#x3D;$HADOOP_HOME<br>export YARN_HOME&#x3D;$HADOOP_HOME<br>export HADOOP_COMMON_LIB_NATIVE_DIR&#x3D;$HADOOP_HOME&#x2F;lib&#x2F;native<br>export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;sbin:$HADOOP_HOME&#x2F;bin<br>[root@localhost ~]#<br>[root@localhost ~]# source &#x2F;etc&#x2F;profile</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>8.修改Hadoop配置</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# cd Hadoop&#x2F;hadoop-2.7.2&#x2F;<br>[root@localhost hadoop]# vim &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml<br>[root@localhost hadoop]#<br>[root@localhost hadoop]#<br>[root@localhost hadoop]# tail &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml</p>
<!-- Put site-specific property overrides in this file. -->


<configuration>
    <!-- 指定HDFS中NameNode的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://127.0.0.1:9000</value>
    </property>


<pre><code>&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/home/hadoop/hadoop-2.7.2/data/tmp&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</configuration>
```shell

  

<p><strong>9.修改Hadoop的hdfs目录配置</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost hadoop]# vim &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml<br>[root@localhost hadoop]#<br>[root@localhost hadoop]#<br>[root@localhost hadoop]#<br>[root@localhost hadoop]# tail -n 15  &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml<br><configuration><br>   <property><br>      <name>dfs.replication</name><br>      <value>1</value><br>   </property><br>   <property><br>      <name>dfs.name.dir</name><br>      <value>&#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;hadoopinfra&#x2F;hdfs&#x2F;namenode</value><br>   </property><br>   <property><br>      <name>dfs.data.dir</name><br>      <value>&#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;hadoopinfra&#x2F;hdfs&#x2F;datanode</value><br>   </property><br></configuration></p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>10.修改Hadoop的yarn配置</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost hadoop]#<br>[root@localhost hadoop]# vim  &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;yarn-site.xml<br>[root@localhost hadoop]#<br>[root@localhost hadoop]#<br>[root@localhost hadoop]# tail -n 6 &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;yarn-site.xml<br><configuration></p>
   <property> 
      <name>yarn.nodemanager.aux-services</name> 
      <value>mapreduce_shuffle</value> 
   </property>


</configuration>
```shell

  

<p>&#96;&#96;&#96;shell<br>[root@localhost hadoop]#<br>[root@localhost hadoop]# cp &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;mapred-site.xml.template &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;mapred-site.xml<br>[root@localhost hadoop]# vim &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;mapred-site.xml<br>[root@localhost hadoop]#<br>[root@localhost hadoop]#<br>[root@localhost hadoop]# tail &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;mapred-site.xml<br><configuration><br>   <property><br>      <name>mapreduce.framework.name</name><br>      <value>yarn</value><br>   </property><br></configuration><br>[root@localhost hadoop]#</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>11.修改Hadoop环境配置文件</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost hadoop]# vim &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;hadoop-env.sh</p>
<p>修改JAVA_HOME<br>export JAVA_HOME&#x3D;&#x2F;root&#x2F;jdk&#x2F;jdk1.8.0_202&#x2F;</p>
<p>[root@localhost ~]# hdfs namenode -format<br>[root@localhost ~]# start-dfs.sh<br>[root@localhost ~]# start-yarn.sh</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>若重置太多次会导致clusterID不匹配，datanode起不来，删除版本后在初始化启动</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# rm -rf &#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;hadoopinfra&#x2F;hdfs&#x2F;datanode&#x2F;current&#x2F;VERSION<br>[root@localhost ~]# hadoop namenode -format<br>[root@localhost ~]# hdfs namenode -format<br>[root@localhost ~]# start-dfs.sh<br>[root@localhost ~]# start-yarn.sh</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>在浏览器访问Hadoop</strong></p>
<p>访问Hadoop的默认端口号为50070.使用以下网址，以获取浏览器Hadoop服务。</p>
<p><strong><a href="http://localhost:50070/">http://localhost:50070/</a></strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e6e5d35c40ba4ab1824e48f88a081536~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p> <strong>验证集群的所有应用程序</strong></p>
<p>访问集群中的所有应用程序的默认端口号为8088。使用以下URL访问该服务。</p>
<p><strong><a href="http://localhost:8088/">http://localhost:8088/</a></strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a8ef9393ee3c422c8c1a3e1df487ef62~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>12.创建hive目录并解压</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# mkdir hive<br>[root@localhost ~]# cd hive<br>[root@localhost hive]# wget <a href="https://archive.apache.org/dist/hive/hive-2.3.3/apache-hive-2.3.3-bin.tar.gz">https://archive.apache.org/dist/hive/hive-2.3.3/apache-hive-2.3.3-bin.tar.gz</a><br>[root@localhost hive]# tar xvf apache-hive-2.3.3-bin.tar.gz<br>[root@localhost hive]#</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>13.备份hive配置文件</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost hive]# cd &#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;conf&#x2F;<br>[root@localhost conf]# cp hive-env.sh.template hive-env.sh<br>[root@localhost conf]# cp hive-default.xml.template hive-site.xml<br>[root@localhost conf]# cp hive-log4j2.properties.template hive-log4j2.properties<br>[root@localhost conf]# cp hive-exec-log4j2.properties.template hive-exec-log4j2.properties</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>14.在Hadoop中创建文件夹并设置权限</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost conf]# hadoop fs -mkdir -p &#x2F;data&#x2F;hive&#x2F;warehouse<br>21&#x2F;10&#x2F;18 14:27:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>[root@localhost conf]#<br>[root@localhost conf]# hadoop fs -mkdir &#x2F;data&#x2F;hive&#x2F;tmp<br>21&#x2F;10&#x2F;18 14:27:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>[root@localhost conf]#<br>[root@localhost conf]# hadoop fs -mkdir &#x2F;data&#x2F;hive&#x2F;log<br>21&#x2F;10&#x2F;18 14:27:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>[root@localhost conf]#<br>[root@localhost conf]# hadoop fs -chmod -R 777 &#x2F;data&#x2F;hive&#x2F;warehouse<br>21&#x2F;10&#x2F;18 14:27:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>[root@localhost conf]# hadoop fs -chmod -R 777 &#x2F;data&#x2F;hive&#x2F;tmp<br>21&#x2F;10&#x2F;18 14:27:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>[root@localhost conf]# hadoop fs -chmod -R 777 &#x2F;data&#x2F;hive&#x2F;log<br>21&#x2F;10&#x2F;18 14:27:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>[root@localhost conf]#</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>15.修改hive配置文件</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost conf]# vim hive-site.xml</p>
<p>hive 配置入下：<br><property><br>  <name>hive.exec.scratchdir</name><br>  <value>hdfs:&#x2F;&#x2F;127.0.0.1:9000&#x2F;data&#x2F;hive&#x2F;tmp</value><br></property><br><property><br>   <name>hive.metastore.warehouse.dir</name><br>  <value>hdfs:&#x2F;&#x2F;127.0.0.1:9000&#x2F;data&#x2F;hive&#x2F;warehouse</value><br></property><br><property><br>  <name>hive.querylog.location</name><br>  <value>hdfs:&#x2F;&#x2F;127.0.0.1:9000&#x2F;data&#x2F;hive&#x2F;log</value><br></property></p>
<p>&lt;!—该配置是关闭hive元数据版本认证，否则会在启动spark程序时报错–&gt;<br><property><br>  <name>hive.metastore.schema.verification</name><br>  <value>false</value><br></property></p>
<p>配置mysql IP 端口以及放元数据的库名称</p>
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://127.0.0.1:3306/hive?createDatabaseIfNotExist=true</value>
</property>
<!—配置mysql启动器名称 -->
<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
   <value>com.mysql.jdbc.Driver</value>
</property>
<!—配置连接mysql用户名 -->
<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>root</value>
</property>
<!—配置连接mysql用户名登录密码-->
<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>Cby123..</value>
</property>
```shell

  

  

  

<p><strong>修改配置文件中 system:java.io.tmpdir 和 system:user.name 相关信息，改为实际目录和用户名，或者加入如下配置</strong></p>
<p>&#96;&#96;&#96;shell<br>  <property><br>    <name>system:java.io.tmpdir</name><br>    <value>&#x2F;tmp&#x2F;hive&#x2F;java</value><br>  </property><br>  <property><br>    <name>system:user.name</name><br>    <value>${user.name}</value><br>  </property></p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>并修改临时路径 ：</strong></p>
<p>&#96;&#96;&#96;shell<br> <property><br>    <name>hive.exec.local.scratchdir</name><br>    <value>&#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;tmp&#x2F;${system:user.name}</value><br>    <description>Local scratch space for Hive jobs</description><br>  </property><br>  <property><br>    <name>hive.downloaded.resources.dir</name><br>    <value>&#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;tmp&#x2F;${hive.session.id}_resources</value><br>    <description>Temporary local directory for added resources in the remote file system.</description><br>  </property></p>
<property>
    <name>hive.server2.logging.operation.log.location</name>
    <value>/root/hive/apache-hive-2.3.3-bin/tmp/root/operation_logs</value>
    <description>Top level directory where operation logs are stored if logging functionality is enabled</description>
  </property>
```shell

  

<p><strong>16.配置hive中jdbc的MySQL驱动</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost lib]# cd &#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;lib&#x2F;<br>[root@localhost lib]# wget <a href="https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-java-5.1.49.tar.gz">https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-java-5.1.49.tar.gz</a><br>[root@localhost lib]# tar xvf mysql-connector-java-5.1.49.tar.gz<br>[root@localhost lib]# cp mysql-connector-java-5.1.49&#x2F;mysql-connector-java-5.1.49.jar .<br>[root@localhost bin]#<br>[root@localhost bin]# vim &#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;conf&#x2F;hive-env.sh<br>[root@localhost bin]# tail -n 3 &#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;conf&#x2F;hive-env.sh<br>export HADOOP_HOME&#x3D;&#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;<br>export HIVE_CONF_DIR&#x3D;&#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;conf<br>export HIVE_AUX_JARS_PATH&#x3D;&#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;lib<br>[root@localhost bin]#</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>17.配置hive环境变量</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# vim &#x2F;etc&#x2F;profile<br>[root@localhost ~]# tail -n 6 &#x2F;etc&#x2F;profile<br>export HADOOP_HOME&#x3D;&#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;<br>export HIVE_CONF_DIR&#x3D;&#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;conf<br>export HIVE_AUX_JARS_PATH&#x3D;&#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;lib<br>export HIVE_PATH&#x3D;&#x2F;root&#x2F;hive&#x2F;apache-hive-2.3.3-bin&#x2F;<br>export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;sbin:$HADOOP_HOME&#x2F;bin:$HIVE_PATH&#x2F;bin</p>
<p>[root@localhost bin]# .&#x2F;schematool -dbType mysql -initSchema</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>初始化完成后修改MySQL链接信息，之后配置mysql IP 端口以及放元数据的库名称</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost conf]# vim hive-site.xml</p>
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://127.0.0.1:3306/hive?characterEncoding=utf8&amp;useSSL=false</value>
</property>

<p>[root@localhost bin]# nohup hive –service metastore &amp;<br>[root@localhost bin]# nohup hive –service hiveserver2 &amp;</p>
<p>&#96;&#96;&#96;shell</p>
<p>**18.创建spark目录并下载所需文件<br>**</p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# mkdir  spark<br>[root@localhost ~]#<br>[root@localhost ~]# cd spark<br>[root@localhost spark]#<br>[root@localhost spark]# wget <a href="https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-without-hadoop.tgz">https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-without-hadoop.tgz</a> –no-check-certificate<br>[root@localhost spark]# tar xvf  spark-3.1.2-bin-without-hadoop.tgz</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>19.配置spark环境变量以及备份配置文件</strong></p>
<p>&#96;&#96;&#96;shell<br>[root@localhost ~]# vim &#x2F;etc&#x2F;profile<br>[root@localhost ~]#<br>[root@localhost ~]# tail -n 3 &#x2F;etc&#x2F;profile<br>export SPARK_HOME&#x3D;&#x2F;root&#x2F;spark&#x2F;spark-3.1.2-bin-without-hadoop&#x2F;<br>export PATH&#x3D;$PATH:$SPARK_HOME&#x2F;bin</p>
<p>[root@localhost spark]# cd &#x2F;root&#x2F;spark&#x2F;spark-3.1.2-bin-without-hadoop&#x2F;conf&#x2F;<br>[root@localhost conf]# cp spark-env.sh.template spark-env.sh<br>[root@localhost conf]# cp spark-defaults.conf.template spark-defaults.conf<br>[root@localhost conf]# cp metrics.properties.template metrics.properties</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>20.配置程序的环境变量</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost conf]# cp workers.template workers<br>[root@localhost conf]# vim spark-env.sh</p>
<p>export JAVA_HOME&#x3D;&#x2F;root&#x2F;jdk&#x2F;jdk1.8.0_202<br>export HADOOP_HOME&#x3D;&#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2<br>export HADOOP_CONF_DIR&#x3D;&#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop<br>export SPARK_DIST_CLASSPATH&#x3D;$(&#x2F;root&#x2F;Hadoop&#x2F;hadoop-2.7.2&#x2F;bin&#x2F;hadoop classpath)<br>export SPARK_MASTER_HOST&#x3D;127.0.0.1<br>export SPARK_MASTER_PORT&#x3D;7077<br>export SPARK_HISTORY_OPTS&#x3D;”-Dspark.history.ui.port&#x3D;18080 -<br>Dspark.history.retainedApplications&#x3D;50 -<br>Dspark.history.fs.logDirectory&#x3D;hdfs:&#x2F;&#x2F;127.0.0.1:9000&#x2F;spark-eventlog”</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>21.修改默认的配置文件</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost conf]# vim spark-defaults.conf</p>
<p>spark.master                     spark:&#x2F;&#x2F;127.0.0.1:7077<br>spark.eventLog.enabled           true<br>spark.eventLog.dir               hdfs:&#x2F;&#x2F;127.0.0.1:9000&#x2F;spark-eventlog<br>spark.serializer                 org.apache.spark.serializer.KryoSerializer<br>spark.driver.memory              3g<br>spark.eventLog.enabled           true<br>spark.eventLog.dir               hdfs:&#x2F;&#x2F;127.0.0.1:9000&#x2F;spark-eventlog<br>spark.eventLog.compress          true</p>
<p>&#96;&#96;&#96;shell</p>
<p><strong>22.配置工作节点</strong>  </p>
<p>&#96;&#96;&#96;shell<br>[root@localhost conf]# vim workers</p>
<p>[root@localhost conf]# cat workers<br>127.0.0.1</p>
<p>[root@localhost conf]# </p>
<p>[root@localhost sbin]# &#x2F;root&#x2F;spark&#x2F;spark-3.1.2-bin-without-hadoop&#x2F;sbin&#x2F;start-all.sh</p>
<p>&#96;&#96;&#96;shell</p>
<p> <strong>验证应用程序</strong></p>
<p>访问集群中的所有应用程序的默认端口号为8080。使用以下URL访问该服务。</p>
<p><strong><a href="http://localhost:8080/">http://localhost:8080/</a></strong></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/35679b2bcb784216a1ec18a153319e61~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3fa0c9539aeb49eca25a60861911abd7~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>41篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c010a1ccc0094b208340e06f26566146~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>搭建一个自己专属的个人网盘</title>
    <url>/2021/12/30/2021-12-30-%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%87%AA%E5%B7%B1%E4%B8%93%E5%B1%9E%E7%9A%84%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%9B%98/</url>
    <content><![CDATA[<p>我们可以搭建一个自己的个人网盘（私有云盘），常用的开源框架包括ownCloud，Seafile，Nextcloud，本文介绍的是在CentOS 7下基于Nextcloud教你如何搭建一个私有云。</p>
<p>安装MySQL</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">安装mysql源信息</span><br><span class="line">\[root@xxx ~\]# yum install https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm</span><br><span class="line"></span><br><span class="line">安装mysql</span><br><span class="line">\[root@xxx ~\]# yum install mysql-community-server</span><br><span class="line"></span><br><span class="line">启动mysql</span><br><span class="line">\[root@xxx ~\]# systemctl start mysqld</span><br><span class="line"></span><br><span class="line">查看密码</span><br><span class="line">\[root@xxx ~\]# grep &#x27;temporary password&#x27; /var/log/mysqld.log</span><br><span class="line"></span><br><span class="line">修改密码</span><br><span class="line">mysql&gt; ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;Cby123..&#x27;</span><br><span class="line"></span><br><span class="line">设置开机自启</span><br><span class="line">\[root@xxx ~\]# systemctl enable mysqld</span><br></pre></td></tr></table></figure>

<p>安装PHP并配置  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">安装epel</span><br><span class="line">\[root@xxx ~\]# yum install epel\*</span><br><span class="line"></span><br><span class="line">安装remi</span><br><span class="line">\[root@xxx ~\]# yum install http://rpms.remirepo.net/enterprise/remi-release-7.rpm  </span><br><span class="line"></span><br><span class="line">安装php以及php-fpm</span><br><span class="line">\[root@xxx ~\]# yum install -y php74-php-fpm php74-php-cli php74-php-bcmath php74-php-gd php74-php-json php74-php-mbstring php74-php-mcrypt php74-php-mysqlnd php74-php-opcache php74-php-pdo php74-php-pecl-crypto php74-php-pecl-mcrypt php74-php-pecl-geoip php74-php-recode php74-php-snmp php74-php-soap php74-php-xmll</span><br><span class="line"></span><br><span class="line"># 编辑配置文件</span><br><span class="line">\[root@xxx ~\]# vim /etc/php.ini</span><br><span class="line"></span><br><span class="line"># 找到</span><br><span class="line">;cgi.fix\_pathinfo=1</span><br><span class="line"># 去掉注释，并将1改成0</span><br><span class="line">cgi.fix\_pathinfo=0</span><br><span class="line"></span><br><span class="line">添加开机自启</span><br><span class="line">\[root@xxx ~\]# systemctl enable php74-php-fpm</span><br><span class="line"></span><br><span class="line">\[root@xxx ~\]# systemctl restart php74-php-fpm</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>安装Nginx并设置开启启动</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">安装Nginx</span><br><span class="line">\[root@xxx ~\]# yum install nginx</span><br><span class="line"></span><br><span class="line">启动Nginx</span><br><span class="line">\[root@xxx ~\]# systemctl start nginx</span><br><span class="line"></span><br><span class="line">设置开机自启</span><br><span class="line">\[root@xxx ~\]# systemctl enable nginx</span><br></pre></td></tr></table></figure>

<p>安装nextcloud  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">下载软件包</span><br><span class="line">\[root@xxx ~\]# wget https://download.nextcloud.com/server/releases/nextcloud-18.0.2.tar.bz2</span><br><span class="line"></span><br><span class="line">安装解压依赖</span><br><span class="line">\[root@xxx ~\]# yum install lbzip2</span><br><span class="line"></span><br><span class="line">进行解压</span><br><span class="line">\[root@xxx ~\]# tar xvf nextcloud-18.0.2.tar.bz2 </span><br><span class="line"></span><br><span class="line">挪动文件夹</span><br><span class="line">\[root@xxx ~\]# mv nextcloud /var/www/</span><br><span class="line"></span><br><span class="line">给文件权限</span><br><span class="line">\[root@xxx ~\]# chmod 777 /var/www/nextcloud -Rf</span><br></pre></td></tr></table></figure>

<p>创建数据库  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\# 进入MySQL</span><br><span class="line">mysql -u root -p</span><br><span class="line"></span><br><span class="line"># 创建一个名为nextclud\_db的数据库</span><br><span class="line">CREATE DATABASE nextcloud\_db;</span><br><span class="line"></span><br><span class="line"># 创建一个名为nextcloud、密码也为nextcloud的用户</span><br><span class="line">CREATE USER &#x27;nextcloud&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;Cby123..&#x27;;</span><br><span class="line"></span><br><span class="line"># 赋予用户nextcloud对数据库nextcloud\_db的所有操作权限</span><br><span class="line">GRANT ALL PRIVILEGES ON nextcloud\_db.\* TO &#x27;nextcloud&#x27;@&#x27;localhost&#x27;;</span><br><span class="line"></span><br><span class="line"># 刷新数据库权限</span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"></span><br><span class="line"># 退出</span><br><span class="line">exit</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/33e805c7d85044d8b3d366dd4d5f9251~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/513c8a2b73dd4dddae09ec3187435c47~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>腾讯蓝鲸集群式部署</title>
    <url>/2021/12/30/2021-12-30-%E8%85%BE%E8%AE%AF%E8%93%9D%E9%B2%B8%E9%9B%86%E7%BE%A4%E5%BC%8F%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p> 腾讯蓝鲸智云，简称蓝鲸，是腾讯互动娱乐事业群（Interactive Entertainment Group，简称 IEG）自研自用的一套用于构建企业研发运营一体化体系的 PaaS 开发框架，提供了 aPaaS（DevOps 流水线、运行环境托管、前后台框架）和 iPaaS（持续集成、CMDB、作业平台、容器管理、计算平台、AI 等原子平台）等模块，帮助企业技术人员快速构建基础运营 PaaS。</p>
<p>关闭防火墙</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# sed -i &#x27;s/^SELINUX=enforcing/SELINUX=disabled/g&#x27; /etc/selinux/config</span><br><span class="line">[root@localhost ~]# setenforce 0</span><br><span class="line">[root@localhost ~]# systemctl stop firewalld</span><br><span class="line">[root@localhost ~]# systemctl disable firewalld</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.</span><br><span class="line">Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</span><br></pre></td></tr></table></figure>

<p>关闭网络管理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# systemctl status NetworkManager</span><br><span class="line">● NetworkManager.service - Network Manager</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: active (running) since Thu 2021-07-29 15:49:45 CST; 1h 10min ago</span><br><span class="line">     Docs: man:NetworkManager(8)</span><br><span class="line"> Main PID: 1086 (NetworkManager)</span><br><span class="line">   CGroup: /system.slice/NetworkManager.service</span><br><span class="line">           ├─1086 /usr/sbin/NetworkManager --no-daemon</span><br><span class="line">           └─1197 /sbin/dhclient -d -q -sf /usr/libexec/nm-dhcp-helper -pf /var/run/dhclient-ens33.pid -lf /var/lib/NetworkManager/dhclient-54043ffa-9f33-49a0-b4d5-4b191...</span><br><span class="line"></span><br><span class="line">Jul 29 15:49:58 localhost.localdomain NetworkManager[1086]: &lt;info&gt;  [1627544998.6410] device (ens33): state change: secondaries -&gt; activated (reason &#x27;none&#x27;, sys...managed&#x27;)</span><br><span class="line">Jul 29 15:49:58 localhost.localdomain NetworkManager[1086]: &lt;info&gt;  [1627544998.6420] manager: NetworkManager state is now CONNECTED_LOCAL</span><br><span class="line">Jul 29 15:49:58 localhost.localdomain NetworkManager[1086]: &lt;info&gt;  [1627544998.6445] manager: NetworkManager state is now CONNECTED_SITE</span><br><span class="line">Jul 29 15:49:58 localhost.localdomain NetworkManager[1086]: &lt;info&gt;  [1627544998.6447] policy: set &#x27;ens33&#x27; (ens33) as default for IPv4 routing and DNS</span><br><span class="line">Jul 29 15:49:58 localhost.localdomain dhclient[1197]: bound to 192.168.1.74 -- renewal in 39901 seconds.</span><br><span class="line">Jul 29 15:49:58 localhost.localdomain NetworkManager[1086]: &lt;info&gt;  [1627544998.6550] device (ens33): Activation: successful, device activated.</span><br><span class="line">Jul 29 15:49:58 localhost.localdomain NetworkManager[1086]: &lt;info&gt;  [1627544998.6559] manager: NetworkManager state is now CONNECTED_GLOBAL</span><br><span class="line">Jul 29 15:49:58 localhost.localdomain NetworkManager[1086]: &lt;info&gt;  [1627544998.6567] manager: startup complete</span><br><span class="line">Jul 29 16:53:57 tencen-3 NetworkManager[1086]: &lt;info&gt;  [1627548837.1248] hostname: hostname changed from &quot;localhost.localdomain&quot; to &quot;tencen-3&quot;</span><br><span class="line">Jul 29 16:53:57 tencen-3 NetworkManager[1086]: &lt;info&gt;  [1627548837.1252] policy: set-hostname: set hostname to &#x27;tencen-3&#x27; (from system configuration)</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@localhost ~]# systemctl stop NetworkManager</span><br><span class="line">[root@localhost ~]# systemctl disable NetworkManager</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/NetworkManager.service.</span><br><span class="line">Removed symlink /etc/systemd/system/dbus-org.freedesktop.nm-dispatcher.service.</span><br><span class="line">Removed symlink /etc/systemd/system/network-online.target.wants/NetworkManager-wait-online.service.</span><br></pre></td></tr></table></figure>

<p>设置最大连接数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# ulimit -n</span><br><span class="line">1024</span><br><span class="line">[root@localhost ~]# cp /etc/security/limits.conf /etc/security/limits.conf.bak</span><br><span class="line">[root@localhost ~]# cat &lt;&lt; EOF &gt;&gt; /etc/security/limits.conf</span><br><span class="line">&gt; root soft nofile 102400</span><br><span class="line">&gt; root hard nofile 102400</span><br><span class="line">&gt; EOF</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>

<p>准备所需软件包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# mkdir  /data</span><br><span class="line">[root@localhost ~]# mv bkce_basic_suite-6.0.3.tgz /data</span><br><span class="line">[root@localhost ~]# cd /data</span><br><span class="line">[root@localhost data]# ls</span><br><span class="line">bkce_basic_suite-6.0.3.tgz</span><br><span class="line">[root@localhost data]# </span><br><span class="line">[root@localhost data]# </span><br><span class="line">[root@localhost data]#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dc57f354d6094d55942f21373bcd7a11~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>解压套餐包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost data]# tar xf bkce_basic_suite-6.0.3.tgz</span><br><span class="line">[root@localhost data]#</span><br></pre></td></tr></table></figure>

<p>解压各个产品软件包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost data]# cd /data/src/; for f in *gz;do tar xf $f; done</span><br></pre></td></tr></table></figure>

<p>解压证书包</p>
<p>    在网站 <a href="https://bk.tencent.com/download/_ssl/">https://bk.tencent.com/download\_ssl/</a> 中使用Mac地址进行注册</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost src]# install -d -m 755 /data/src/cert</span><br><span class="line">[root@localhost src]# tar xf /data/ssl_certificates.tar.gz -C /data/src/cert/</span><br><span class="line">[root@localhost src]# chmod 644 /data/src/cert/*</span><br></pre></td></tr></table></figure>

<p>拷贝 rpm 包文件夹到&#x2F;opt&#x2F;目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost src]# cp -a /data/src/yum /opt</span><br><span class="line">[root@localhost src]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>生成并配置 install.config</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost src]# cat &lt;&lt; EOF &gt;/data/install/install.config</span><br><span class="line">&gt; 192.168.1.75 iam,ssm,usermgr,gse,license,redis,consul,mysql</span><br><span class="line">&gt; 192.168.1.50 nginx,consul,mongodb,rabbitmq,appo</span><br><span class="line">&gt; 192.168.1.74 paas,cmdb,job,zk(config),appt,consul,nodeman(nodeman)</span><br><span class="line">&gt; </span><br><span class="line">&gt; EOF</span><br></pre></td></tr></table></figure>

<p>执行免密</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost src]# cd /data/install</span><br><span class="line">[root@localhost install]# yum install rsync -y</span><br><span class="line">[root@localhost install]# bash /data/install/configure_ssh_without_pass</span><br></pre></td></tr></table></figure>

<p>初始化并检查环境</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install common</span><br><span class="line"></span><br><span class="line">[root@localhost install]# ./health_check/check_bk_controller.sh</span><br></pre></td></tr></table></figure>

<p>部署 PaaS 平台</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install paas</span><br><span class="line"></span><br><span class="line">如果以上步骤没有报错, 你现在可以通过 http://paas.bktencent.com:80 访问 paas 平台,</span><br><span class="line">登陆用户名(login user): admin</span><br><span class="line">登陆密码(login password): fKJbtZ54KDA_</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c10e4f44c1c84419be9c13cd9aab6c5d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>部署 app_mgr</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install app_mgr</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/86e2b68f6ff544a0929c4905a7dec5cb~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>部署权限中心与用户管理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install saas-o bk_iam</span><br><span class="line">[root@localhost install]# ./bk_install saas-o bk_user_manage</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0487790bf664ca68e7f153f5da3ee29~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/acf1458099c14e05bbbdb39395d4da44~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>部署 CMDB</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install cmdb</span><br></pre></td></tr></table></figure>

<p>部署 JOB</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install job</span><br></pre></td></tr></table></figure>

<p>部署 bknodeman</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install bknodeman</span><br></pre></td></tr></table></figure>

<p># 标准运维</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install saas-o bk_sops</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5b093f8b47e74210937e609a77ceac66~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p># 流程管理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bk_install saas-o bk_itsm</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b508727c928a4bf6ac4e3369dbebb28a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>加载蓝鲸相关维护命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# source ~/.bashrc</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2bfd5fb61a184ff0b3f973ba3d0be906~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>初始化蓝鲸业务拓扑</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# ./bkcli initdata topo</span><br></pre></td></tr></table></figure>

<p>检测相关服务状态</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost install]# cd /data/install/</span><br><span class="line">[root@localhost install]# echo bkssm bkiam usermgr paas cmdb gse job consul | xargs -n 1 ./bkcli check</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9e944b2f2b424c7cbf2d9eb6568afe13~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>Windows 配置</p>
<p>用文本编辑器（如 Notepad++）打开文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\Windows\System32\drivers\etc\hosts</span><br></pre></td></tr></table></figure>

<p>将以下内容复制到上述文件内，并将以下 IP 需更换为本机浏览器可以访问的 IP，然后保存。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10.0.0.2 paas.bktencent.com cmdb.bktencent.com job.bktencent.com jobapi.bktencent.com</span><br><span class="line">10.0.0.3 nodeman.bktencent.com</span><br></pre></td></tr></table></figure>

<p>注意：10.0.0.2 为 nginx 模块所在的机器，10.0.0.3 为 nodeman 模块所在的机器。IP 需更换为本机浏览器可以访问的 IP。</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>部署lnmp环境，安装typecho博客</title>
    <url>/2022/01/03/2022-01-03-%E9%83%A8%E7%BD%B2lnmp%E7%8E%AF%E5%A2%83%EF%BC%8C%E5%AE%89%E8%A3%85typecho%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h1 id="安装nginx和PHP环境"><a href="#安装nginx和PHP环境" class="headerlink" title="安装nginx和PHP环境"></a>安装nginx和PHP环境</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# apt install nginx php7.4 php7.4-mysql php7.4-fpm</span><br></pre></td></tr></table></figure>

<h1 id="修改nginx配置文件"><a href="#修改nginx配置文件" class="headerlink" title="修改nginx配置文件"></a>修改nginx配置文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# vim /etc/nginx/sites-available/default</span><br><span class="line">root@cby:~# cat /etc/nginx/sites-available/default</span><br><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        listen [::]:80;</span><br><span class="line">        </span><br><span class="line">        #填写域名或者IP</span><br><span class="line">        server_name www.oiox.cn; </span><br><span class="line"></span><br><span class="line">        # SSL configuration</span><br><span class="line">        #</span><br><span class="line">        </span><br><span class="line">        #开启ssl证书监听端口</span><br><span class="line">        listen 443 ssl; </span><br><span class="line">        listen [::]:443;</span><br><span class="line">        </span><br><span class="line">        #配置证书</span><br><span class="line">        ssl_certificate /var/www/ssl/www.oiox.cn_nginx/www.oiox.cn_bundle.pem; </span><br><span class="line">        ssl_certificate_key /var/www/ssl/www.oiox.cn_nginx/www.oiox.cn.key;</span><br><span class="line">        ssl_session_timeout  5m;</span><br><span class="line">        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;</span><br><span class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">        ssl_prefer_server_ciphers on;</span><br><span class="line"></span><br><span class="line">        root /var/www/html;</span><br><span class="line"></span><br><span class="line">        # 配置默认访问页面</span><br><span class="line">        index index.php index.html index.htm index.nginx-debian.html;</span><br><span class="line"></span><br><span class="line">        #配置访问路径</span><br><span class="line">        location / &#123;</span><br><span class="line">                # First attempt to serve request as file, then</span><br><span class="line">                # as directory, then fall back to displaying a 404.</span><br><span class="line">                try_files $uri $uri/ =404;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        # 配置跳转路由</span><br><span class="line">        if (-f $request_filename/index.html) &#123;</span><br><span class="line">        rewrite (.*) $1/index.html break;</span><br><span class="line">        &#125;</span><br><span class="line">        if (-f $request_filename/index.php) &#123;</span><br><span class="line">        rewrite (.*) $1/index.php;</span><br><span class="line">        &#125;</span><br><span class="line">        if (!-f $request_filename) &#123;</span><br><span class="line">        rewrite (.*) /index.php;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #配置PHP访问路由</span><br><span class="line">        location ~ \.php$ &#123;</span><br><span class="line">                include snippets/fastcgi-php.conf;</span><br><span class="line"></span><br><span class="line">                # With php-fpm (or other unix sockets):</span><br><span class="line">                fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;</span><br><span class="line">                # With php-cgi (or other tcp sockets):</span><br><span class="line">                #fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">                fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;</span><br><span class="line">                include        fastcgi_params;</span><br><span class="line">                fastcgi_intercept_errors  on;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置其他的域名访问</span></span><br><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        listen [::]:80;</span><br><span class="line"></span><br><span class="line">        server_name aliyun.chenby.cn;</span><br><span class="line"></span><br><span class="line">        root /var/www/cby;</span><br><span class="line">        index index.html;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">                try_files $uri $uri/ =404;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">root@cby:~#</span><br></pre></td></tr></table></figure>

<h1 id="启动服务并设置开机自启"><a href="#启动服务并设置开机自启" class="headerlink" title="启动服务并设置开机自启"></a>启动服务并设置开机自启</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# nginx -t </span><br><span class="line">root@cby:~# systemctl restart nginx </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~# systemctl  enable php7.4-fpm</span><br><span class="line">Synchronizing state of php7.4-fpm.service with SysV service script with /lib/systemd/systemd-sysv-install.</span><br><span class="line">Executing: /lib/systemd/systemd-sysv-install enable php7.4-fpm</span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# systemctl  enable nginx</span><br><span class="line">Synchronizing state of nginx.service with SysV service script with /lib/systemd/systemd-sysv-install.</span><br><span class="line">Executing: /lib/systemd/systemd-sysv-install enable nginx</span><br><span class="line">root@cby:~#</span><br></pre></td></tr></table></figure>

<h1 id="安装docker，并使用docker启动MySQL服务"><a href="#安装docker，并使用docker启动MySQL服务" class="headerlink" title="安装docker，并使用docker启动MySQL服务"></a>安装docker，并使用docker启动MySQL服务</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br><span class="line"></span><br><span class="line">root@cby:~# mkdir /mysql </span><br><span class="line">root@cby:~# cd /mysql</span><br><span class="line">root@cby:/mysql# docker run -p 3306:3306 --name mymysql --restart=always -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL\_ROOT\_PASSWORD=Cby123.. -d mysql:5.7</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">登录MySQL数据库执行创建数据库</span></span><br><span class="line">create database typecho;</span><br></pre></td></tr></table></figure>

<h1 id="部署typecho"><a href="#部署typecho" class="headerlink" title="部署typecho"></a>部署typecho</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# cd /var/www/html/</span><br><span class="line">root@cby:/var/www/html# wget https://typecho.org/downloads/1.1-17.10.30-release.tar.gz</span><br><span class="line">root@cby:/var/www/html# tar xvf 1.1-17.10.30-release.tar.gz </span><br><span class="line">root@cby:/var/www/html# mv build/* .</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d61153e4ca254d199ab8e02500dc72f0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a50202daf35946b59bc80bb68ff529ce~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>75篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5db00d8e006042df802e5869f591e152~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云、简书、今日头条</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>GitLab 安装部署使用</title>
    <url>/2022/01/04/2022-01-04-GitLab_%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>GitLab介绍</p>
<p>GitLab：是一个基于Git实现的在线代码仓库托管软件，你可以用gitlab自己搭建一个类似于Github一样的系统，一般用于在企业、学校等内部网络搭建git私服。</p>
<p>功能：Gitlab 是一个提供代码托管、提交审核和问题跟踪的代码管理平台。对于软件工程质量管理非常重要。</p>
<p>版本：GitLab 分为社区版（CE） 和企业版（EE）。</p>
<p>Gitlab的服务构成</p>
<p>Nginx：静态web服务器。</p>
<p>gitlab-shell：用于处理Git命令和修改authorized keys列表。（Ruby）</p>
<p>gitlab-workhorse: 轻量级的反向代理服务器。（go）</p>
<p>logrotate：日志文件管理工具。</p>
<p>postgresql：数据库。</p>
<p>redis：缓存数据库。</p>
<p>sidekiq：用于在后台执行队列任务（异步执行）。（Ruby）</p>
<p>unicorn：An HTTP server for Rack applications，GitLab Rails应用是托管在这个服务器上面的。（Ruby Web Server,主要使用Ruby编写）</p>
<p>* GitLab Workhorse是一个敏捷的反向代理。它会处理一些大的HTTP请求，比如文件上传、文件下载、Git push&#x2F;pull和Git包下载。其它请求会反向代理到GitLab Rails应用，即反向代理给后端的unicorn。  </p>
<p>01</p>
<p>—</p>
<h1 id="安装Gitlab主程序"><a href="#安装Gitlab主程序" class="headerlink" title="安装Gitlab主程序"></a>安装Gitlab主程序</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# apt update &amp;&amp; apt upgrade</span><br><span class="line">root@hello:~# apt install -y curl openssh-server ca-certificates tzdata perl</span><br><span class="line"></span><br><span class="line">root@hello:~# apt install -y postfix</span><br><span class="line">root@hello:~# curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.deb.sh | sudo bash</span><br><span class="line"></span><br><span class="line">root@hello:~# apt install gitlab-ee</span><br></pre></td></tr></table></figure>

<p>02</p>
<p>—</p>
<h1 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# vim /etc/gitlab/gitlab.rb</span><br><span class="line"></span><br><span class="line">external_url &#x27;http://192.168.1.88&#x27;</span><br><span class="line"></span><br><span class="line">gitlab_rails[&#x27;smtp_enable&#x27;] = true</span><br><span class="line">gitlab_rails[&#x27;smtp_address&#x27;] = &quot;smtp.qiye.aliyun.com&quot;</span><br><span class="line">gitlab_rails[&#x27;smtp_port&#x27;] = 465</span><br><span class="line">gitlab_rails[&#x27;smtp_user_name&#x27;] = &quot;cby&quot;</span><br><span class="line">gitlab_rails[&#x27;smtp_password&#x27;] = &quot;Cby123..&quot;</span><br><span class="line">gitlab_rails[&#x27;smtp_domain&#x27;] = &quot;chenby.cn&quot;</span><br><span class="line">gitlab_rails[&#x27;smtp_authentication&#x27;] = &quot;plain&quot;</span><br><span class="line">gitlab_rails[&#x27;smtp_enable_starttls_auto&#x27;] = true</span><br><span class="line">gitlab_rails[&#x27;smtp_tls&#x27;] = false</span><br><span class="line">gitlab_rails[&#x27;smtp_pool&#x27;] = false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# gitlab-ctl reconfigure</span><br><span class="line"></span><br><span class="line">root@hello:~#  gitlab-ctl restart</span><br><span class="line">ok: run: alertmanager: (pid 63590) 1s</span><br><span class="line">ok: run: gitaly: (pid 63610) 1s</span><br><span class="line">ok: run: gitlab-exporter: (pid 63641) 0s</span><br><span class="line">ok: run: gitlab-workhorse: (pid 63643) 1s</span><br><span class="line">ok: run: grafana: (pid 63659) 0s</span><br><span class="line">ok: run: logrotate: (pid 63676) 1s</span><br><span class="line">ok: run: nginx: (pid 63682) 0s</span><br><span class="line">ok: run: node-exporter: (pid 63718) 1s</span><br><span class="line">ok: run: postgres-exporter: (pid 63728) 0s</span><br><span class="line">ok: run: postgresql: (pid 63737) 0s</span><br><span class="line">ok: run: prometheus: (pid 63746) 1s</span><br><span class="line">ok: run: puma: (pid 63777) 1s</span><br><span class="line">ok: run: redis: (pid 63782) 0s</span><br><span class="line">ok: run: redis-exporter: (pid 63788) 1s</span><br><span class="line">ok: run: sidekiq: (pid 63887) 1s</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>03</p>
<p>—</p>
<h1 id="查看root密码"><a href="#查看root密码" class="headerlink" title="查看root密码"></a>查看root密码</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# cat /etc/gitlab/initial_root_password</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">WARNING: This value is valid only <span class="keyword">in</span> the following conditions</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">         1. If provided manually (either via `GITLAB_ROOT_PASSWORD` environment variable or via `gitlab_rails[<span class="string">&#x27;initial_root_password&#x27;</span>]` setting <span class="keyword">in</span> `gitlab.rb`, it was provided before database was seeded <span class="keyword">for</span> the first time (usually, the first reconfigure run).</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">         2. Password hasn<span class="string">&#x27;t been changed manually, either via UI or via command line.</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"></span></span></span><br><span class="line"><span class="string"><span class="language-bash">#          If the password shown here doesn&#x27;</span>t work, you must reset the admin password following https://docs.gitlab.com/ee/security/reset_user_password.html<span class="comment">#reset-your-root-password.</span></span></span><br><span class="line"></span><br><span class="line">Password: HUd9b632LHN89WXYEVYPssWGpyJrgK7BJLbVLC4VCas=</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">NOTE: This file will be automatically deleted <span class="keyword">in</span> the first reconfigure run after 24 hours.</span></span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>04</p>
<p>—</p>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gitlab-ctl start    # 启动所有 gitlab 组件；</span><br><span class="line">gitlab-ctl stop        # 停止所有 gitlab 组件；</span><br><span class="line">gitlab-ctl restart        # 重启所有 gitlab 组件；</span><br><span class="line">gitlab-ctl status        # 查看服务状态；</span><br><span class="line">vim /etc/gitlab/gitlab.rb        # 修改gitlab配置文件；</span><br><span class="line">gitlab-ctl reconfigure        # 重新编译gitlab的配置；</span><br><span class="line">gitlab-rake gitlab:check SANITIZE=true --trace    # 检查gitlab；</span><br><span class="line">gitlab-ctl tail        # 查看日志；</span><br><span class="line">gitlab-ctl tail nginx/gitlab_access.log</span><br><span class="line"></span><br><span class="line">日志地址：/var/log/gitlab/   # 对应各服务的打印日志 </span><br><span class="line">服务地址：/var/opt/gitlab/   # 对应各服务的主目录</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/22cd5b80fca44d1691c263ce61aeb410~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1b83e9d2c61a4cfcbaf47cf89ca49ebf~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>75篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/74308c9be0514429814b8aa08d01763a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云、简书、今日头条</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>最新版 Harbor 在ubuntu系统上安装</title>
    <url>/2021/12/30/2021-12-30-%E6%9C%80%E6%96%B0%E7%89%88_Harbor_%E5%9C%A8ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%8A%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p><strong>最新版 Harbor 在ubuntu系统上安装</strong></p>
<p>The latest version of Harbor is installed on the ubuntu system</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bc0278692b6d4489aee626bf3543869c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>安装docker</strong>  </p>
<p>Install docker</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><strong>配置Docker Compose</strong></p>
<p>Configure Docker Compose</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100   633  100   633    0     0   2444      0 --:--:-- --:--:-- --:--:--  2444</span><br><span class="line">100 12.1M  100 12.1M    0     0  10.2M      0  0:00:01  0:00:01 --:--:-- 26.2M</span><br><span class="line">root@hello:~#  sudo chmod +x /usr/local/bin/docker-compose</span><br><span class="line">root@hello:~# sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose</span><br><span class="line">root@hello:~# docker-compose --version</span><br><span class="line">docker-compose version 1.29.2, build 5becea4c</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><strong>下载Docker Harbor安装包</strong></p>
<p>Download the Docker Harbor installation package</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# wget https://github.com/goharbor/harbor/releases/download/v2.3.2/harbor-offline-installer-v2.3.2.tgz</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><strong>解压安装包</strong></p>
<p>Unzip the installation package</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# tar xvf harbor-offline-installer-v2.3.2.tgz  -C /usr/local/ </span><br><span class="line">harbor/harbor.v2.3.2.tar.gz</span><br><span class="line">harbor/prepare</span><br><span class="line">harbor/LICENSE</span><br><span class="line">harbor/install.sh</span><br><span class="line">harbor/common.sh</span><br><span class="line">harbor/harbor.yml.tmpl</span><br><span class="line">root@hello:~# cd /usr/local/harbor/</span><br></pre></td></tr></table></figure>

<p><strong>配置证书</strong></p>
<p>Configure Certificate</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:/usr/local/harbor# mkdir ca</span><br><span class="line">root@hello:/usr/local/harbor# cd ca/</span><br><span class="line">root@hello:/usr/local/harbor/ca# pwd</span><br><span class="line">/usr/local/harbor/ca</span><br><span class="line">root@hello:/usr/local/harbor/ca# openssl genrsa -des3 -out server.key 2048</span><br><span class="line">Generating RSA private key, 2048 bit long modulus (2 primes)</span><br><span class="line">......................................+++++</span><br><span class="line">...................................................................................................................................................+++++</span><br><span class="line">e is 65537 (0x010001)</span><br><span class="line">Enter pass phrase for server.key:</span><br><span class="line">Verifying - Enter pass phrase for server.key:</span><br><span class="line">root@hello:/usr/local/harbor/ca# </span><br><span class="line">root@hello:/usr/local/harbor/ca# </span><br><span class="line">root@hello:/usr/local/harbor/ca# openssl req -new -key server.key -out server.csr</span><br><span class="line">Enter pass phrase for server.key:</span><br><span class="line">You are about to be asked to enter information that will be incorporated</span><br><span class="line">into your certificate request.</span><br><span class="line">What you are about to enter is what is called a Distinguished Name or a DN.</span><br><span class="line">There are quite a few fields but you can leave some blank</span><br><span class="line">For some fields there will be a default value,</span><br><span class="line">If you enter &#x27;.&#x27;, the field will be left blank.</span><br><span class="line">-----</span><br><span class="line">Country Name (2 letter code) [AU]:</span><br><span class="line">State or Province Name (full name) [Some-State]:</span><br><span class="line">Locality Name (eg, city) []:</span><br><span class="line">Organization Name (eg, company) [Internet Widgits Pty Ltd]:</span><br><span class="line">Organizational Unit Name (eg, section) []:</span><br><span class="line">Common Name (e.g. server FQDN or YOUR name) []:</span><br><span class="line">Email Address []:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please enter the following &#x27;extra&#x27; attributes</span><br><span class="line">to be sent with your certificate request</span><br><span class="line">A challenge password []:</span><br><span class="line">An optional company name []:</span><br><span class="line">root@hello:/usr/local/harbor/ca# </span><br><span class="line">root@hello:/usr/local/harbor/ca# cp server.key server.key.org</span><br><span class="line">root@hello:/usr/local/harbor/ca# openssl rsa -in server.key.org -out server.key</span><br><span class="line">Enter pass phrase for server.key.org:</span><br><span class="line">writing RSA key</span><br><span class="line">root@hello:/usr/local/harbor/ca# openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt</span><br><span class="line">Signature ok</span><br><span class="line">subject=C = AU, ST = Some-State, O = Internet Widgits Pty Ltd</span><br><span class="line">Getting Private key</span><br><span class="line">root@hello:/usr/local/harbor/ca#</span><br></pre></td></tr></table></figure>

<p><strong>修改配置文件，修改 hostname 和证书路径 即可</strong> </p>
<p>Modify the configuration file, modify the hostname and certification path</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:/usr/local/harbor# cp harbor.yml.tmpl harbor.yml</span><br><span class="line">root@hello:/usr/local/harbor# </span><br><span class="line">root@hello:/usr/local/harbor# vim harbor.yml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:/usr/local/harbor# cat harbor.yml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Configuration file of Harbor</span></span><br><span class="line"></span><br><span class="line">hostname: harbor.chenby.cn</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">http related config</span></span><br><span class="line">http:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">port <span class="keyword">for</span> http, default is 80. If https enabled, this port will redirect to https port</span></span><br><span class="line">  port: 80</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">https related config</span></span><br><span class="line">https:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">https port <span class="keyword">for</span> harbor, default is 443</span></span><br><span class="line">  port: 443</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">The path of cert and key files <span class="keyword">for</span> nginx</span></span><br><span class="line">  certificate: /usr/local/harbor/ca/server.crt</span><br><span class="line">  private_key: /usr/local/harbor/ca/server.key</span><br><span class="line"></span><br><span class="line">harbor_admin_password: Harbor12345</span><br><span class="line"></span><br><span class="line">----略----</span><br><span class="line"></span><br><span class="line">root@hello:/usr/local/harbor#</span><br></pre></td></tr></table></figure>

<p><strong>安装</strong></p>
<p>Install</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:/usr/local/harbor# ./install.sh</span><br><span class="line"></span><br><span class="line">[Step 0]: checking if docker is installed ...</span><br><span class="line"></span><br><span class="line">Note: docker version: 20.10.8</span><br><span class="line"></span><br><span class="line">[Step 1]: checking docker-compose is installed ...</span><br><span class="line"></span><br><span class="line">Note: docker-compose version: 1.29.2</span><br><span class="line"></span><br><span class="line">[Step 2]: loading Harbor images ...</span><br><span class="line">Loaded image: goharbor/redis-photon:v2.3.2</span><br><span class="line">Loaded image: goharbor/nginx-photon:v2.3.2</span><br><span class="line">Loaded image: goharbor/harbor-portal:v2.3.2</span><br><span class="line">Loaded image: goharbor/trivy-adapter-photon:v2.3.2</span><br><span class="line">Loaded image: goharbor/chartmuseum-photon:v2.3.2</span><br><span class="line">Loaded image: goharbor/notary-signer-photon:v2.3.2</span><br><span class="line">Loaded image: goharbor/harbor-core:v2.3.2</span><br><span class="line">Loaded image: goharbor/harbor-log:v2.3.2</span><br><span class="line">Loaded image: goharbor/harbor-registryctl:v2.3.2</span><br><span class="line">Loaded image: goharbor/harbor-exporter:v2.3.2</span><br><span class="line">Loaded image: goharbor/notary-server-photon:v2.3.2</span><br><span class="line">Loaded image: goharbor/prepare:v2.3.2</span><br><span class="line">Loaded image: goharbor/harbor-db:v2.3.2</span><br><span class="line">Loaded image: goharbor/harbor-jobservice:v2.3.2</span><br><span class="line">Loaded image: goharbor/registry-photon:v2.3.2</span><br><span class="line"></span><br><span class="line">[Step 3]: preparing environment ...</span><br><span class="line"></span><br><span class="line">[Step 4]: preparing harbor configs ...</span><br><span class="line">prepare base dir is set to /usr/local/harbor</span><br><span class="line">Clearing the configuration file: /config/portal/nginx.conf</span><br><span class="line">Clearing the configuration file: /config/log/rsyslog_docker.conf</span><br><span class="line">Clearing the configuration file: /config/log/logrotate.conf</span><br><span class="line">Generated configuration file: /config/portal/nginx.conf</span><br><span class="line">Generated configuration file: /config/log/logrotate.conf</span><br><span class="line">Generated configuration file: /config/log/rsyslog_docker.conf</span><br><span class="line">Generated configuration file: /config/nginx/nginx.conf</span><br><span class="line">Generated configuration file: /config/core/env</span><br><span class="line">Generated configuration file: /config/core/app.conf</span><br><span class="line">Generated configuration file: /config/registry/config.yml</span><br><span class="line">Generated configuration file: /config/registryctl/env</span><br><span class="line">Generated configuration file: /config/registryctl/config.yml</span><br><span class="line">Generated configuration file: /config/db/env</span><br><span class="line">Generated configuration file: /config/jobservice/env</span><br><span class="line">Generated configuration file: /config/jobservice/config.yml</span><br><span class="line">Generated and saved secret to file: /data/secret/keys/secretkey</span><br><span class="line">Successfully called func: create_root_cert</span><br><span class="line">Generated configuration file: /compose_location/docker-compose.yml</span><br><span class="line">Clean up the input dir</span><br><span class="line"></span><br><span class="line">[Step 5]: starting Harbor ...</span><br><span class="line">Creating network &quot;harbor_harbor&quot; with the default driver</span><br><span class="line">Creating harbor-log ... done</span><br><span class="line">Creating harbor-portal ... done</span><br><span class="line">Creating harbor-db     ... done</span><br><span class="line">Creating registryctl   ... done</span><br><span class="line">Creating redis         ... done</span><br><span class="line">Creating registry      ... done</span><br><span class="line">Creating harbor-core   ... done</span><br><span class="line">Creating harbor-jobservice ... done</span><br><span class="line">Creating nginx             ... done</span><br><span class="line">? ----Harbor has been installed and started successfully.----</span><br><span class="line">root@hello:/usr/local/harbor#</span><br></pre></td></tr></table></figure>

<p><strong>配置dns解析，或者在本地host中配置，具体配置略</strong></p>
<p>Configure dns resolution, or configure in the local host, the specific configuration is omitted</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9b75f4e007c147fa835abe195dfdf269~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>登陆</strong></p>
<p>Sign in</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f375b72dae584633b3235b55bfec303d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>默认账号：admin</strong></p>
<p><strong>默认密码：Harbor12345</strong></p>
<p>Default account: admin</p>
<p>Default password: Harbor12345</p>
<p><strong>客户端使用</strong></p>
<p>Client use</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# vim /etc/docker/daemon.json</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;insecure-registries&quot;: [&quot;https://harbor.chenby.cn&quot;]</span><br><span class="line">&#125;</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# systemctl daemon-reload</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# sudo systemctl restart docker</span><br><span class="line">root@hello:~# docker login https://harbor.chenby.cn/</span><br><span class="line">Username: admin</span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Login Succeeded</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8ee96c032f6e408db06f8aff8ac6eca0~tplv-k3u1fbpfcp-zoom-1.image" alt="Linux运维交流社区"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>38篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ef5550e4364b45c990cbfb17843b0288~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>搭建DHCP服务，实现自动分配地址</title>
    <url>/2021/12/30/2021-12-30-%E6%90%AD%E5%BB%BADHCP%E6%9C%8D%E5%8A%A1%EF%BC%8C%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%88%86%E9%85%8D%E5%9C%B0%E5%9D%80/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">erDiagram</span><br><span class="line">CUSTOMER ||--o&#123; ORDER : places</span><br><span class="line">ORDER ||--|&#123; LINE-ITEM : contains</span><br><span class="line">CUSTOMER &#125;|..|&#123; DELIVERY-ADDRESS : uses</span><br></pre></td></tr></table></figure>

<h1 id="DHCP实现原理"><a href="#DHCP实现原理" class="headerlink" title="DHCP实现原理"></a><strong>DHCP实现原理</strong></h1><h1 id="DHCP定义"><a href="#DHCP定义" class="headerlink" title="DHCP定义"></a><strong>DHCP定义</strong></h1><p><strong>DHCP</strong>（Dynamic Host Configuration Protocol，动态主机配置协议）是一个局域网的网络协议，使用UDP协议工作。它是一种流行的Client&#x2F;Server协议，一般用于为主机或者为路由器等指定相关的配置信息。DHCP服务在企业和家庭中得到了大量的应用，它能够自动分配ip地址以及一些其他的相关信息，整个过程对客户透明。</p>
<h1 id="DHCP分配方式"><a href="#DHCP分配方式" class="headerlink" title="DHCP分配方式"></a><strong>DHCP分配方式</strong></h1><p><strong>自动分配方式</strong>（Automatic Allocation），DHCP服务器为主机指定一个永久性的IP地址，一旦DHCP客户端第一次成功从DHCP服务器端租用到IP地址后，就可以永久性的使用该地址。</p>
<p><strong>动态分配方式</strong>（Dynamic Allocation），DHCP服务器给主机指定一个具有时间限制的IP地址，时间到期或主机明确表示放弃该地址时，该地址可以被其他主机使用。</p>
<p><strong>手工分配方式</strong>（Manual Allocation），客户端的IP地址是由网络管理员指定的，DHCP服务器只是将指定的IP地址告诉客户端主机。</p>
<h1 id="DHCP工作过程"><a href="#DHCP工作过程" class="headerlink" title="DHCP工作过程"></a><strong>DHCP工作过程</strong></h1><p>DHCP客户机在启动时，会搜寻网络中是否存在DHCP服务器。如果找到，则给DHCP服务器发送一个请求。DHCP服务器接到请求后，为DHCP客户机选择TCP&#x2F;IP配置的参数，并把这些参数发送给客户端。如果已配置冲突检测设置，则DHCP服务器在将租约中的地址提供给客户机之前会使用Ping测试作用域中每个可用地址的连通性。这可确保提供给客户的每个IP地址都没有被使用手动TCP&#x2F;IP配置的另一台非DHCP计算机使用。</p>
<p>根据客户端是否第一次登录网络，DHCP的工作形式会有所不同。</p>
<h1 id="初次登录"><a href="#初次登录" class="headerlink" title="初次登录"></a><strong>初次登录</strong></h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e957bbe8fd214c96957d0a2ce81d5e6a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>初次登录时DHCP工作包括四个步骤</p>
<h2 id="1、寻找DHCP服务器"><a href="#1、寻找DHCP服务器" class="headerlink" title="1、寻找DHCP服务器"></a><strong>1、寻找DHCP服务器</strong></h2><p>当DHCP客户端第一次登录网络的时候，计算机发现本机上没有任何IP地址设定，将以广播方式发送DHCP discover发现信息来寻找DHCP服务器，即向255.255.255.255发送特定的广播信息。网络上每一台安装了TCP&#x2F;IP协议的主机都会接收这个广播信息，但只有DHCP服务器才会做出响应。</p>
<h2 id="2、分配IP地址"><a href="#2、分配IP地址" class="headerlink" title="2、分配IP地址"></a><strong>2、分配IP地址</strong></h2><p>在网络中接收到DHCP discover发现信息的DHCP服务器就会做出响应，它从尚未分配的IP地址池中挑选一个分配给DHCP客户机，并向DHCP客户机发送一个包含分配的IP地址和其他设置的DHCP offer提供信息。</p>
<h2 id="3、接受IP地址"><a href="#3、接受IP地址" class="headerlink" title="3、接受IP地址"></a><strong>3、接受IP地址</strong></h2><p>DHCP客户端接受到DHCP offer提供信息之后，选择第一个接收到的提供信息，然后以广播的方式回答一个DHCP request请求信息，该信息包含向它所选定的DHCP服务器请求IP地址的内容。</p>
<h2 id="4、IP地址分配确认"><a href="#4、IP地址分配确认" class="headerlink" title="4、IP地址分配确认"></a><strong>4、IP地址分配确认</strong></h2><p>当DHCP服务器收到DHCP客户端回答的DHCP request请求信息之后，便向DHCP客户端发送一个包含它所提供的IP地址和其他设置的DHCP ack确认信息，告诉DHCP客户端可以使用它提供的IP地址。然后，DHCP客户机便将其TCP&#x2F;IP协议与网卡绑定，另外，除了DHCP客户机选中的DHCP服务器外，其他的DHCP服务器将收回曾经提供的IP地址。</p>
<h1 id="重新登录"><a href="#重新登录" class="headerlink" title="重新登录"></a><strong>重新登录</strong></h1><p>以后DHCP客户端每次重新登录网络时，就不需要再发送DHCP discover发现信息了，而是直接发送包含前一次所分配的IP地址的DHCP request请求信息。当DHCP服务器收到这一信息后，它会尝试让DHCP客户机继续使用原来的IP地址，并回答一个DHCP ack确认信息。如果此IP地址已无法再分配给原来的DHCP客户机使用时，则DHCP服务器给DHCP客户机回答一个DHCP nack否认信息。当原来的DHCP客户机收到此DHCP nack否认信息后，它就必须重新发送DHCP discover发现信息来请求新的IP地址。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2ae30085d9dc4962a1c4534f7f6f9d81~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>1、如果客户端DHCP request 内的IP地址在服务器端没有被使用，DHCP服务器回复DHCP ACK继续使用IP。</p>
<p>2、如果客户端DHCP request 内的IP地址在服务器端已被使用，DHCP服务器回复DHCP NACK告诉客户端IP已被使用。</p>
<p>3、回复NACK后，重新开始DHCP初次登录时的流程</p>
<h1 id="更新租约"><a href="#更新租约" class="headerlink" title="更新租约"></a><strong>更新租约</strong></h1><p>DHCP服务器向DHCP客户机出租的IP地址一般都有一个租借期限，期满后DHCP服务器便会收回出租的IP地址。如果DHCP客户机要延长其IP租约，则必须更新其IP租约。DHCP客户机启动时和IP租约期限到达租约的50%时，DHCP客户机都会自动向DHCP服务器发送更新其IP租约的信息。</p>
<h1 id="在CentOS7上安装DHCP软件包"><a href="#在CentOS7上安装DHCP软件包" class="headerlink" title="在CentOS7上安装DHCP软件包"></a><strong>在CentOS7上安装DHCP软件包</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@jhr-hub ~]# yum -y install dhcp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@jhr-hub ~]# cat /etc/dhcp/dhcpd</span><br><span class="line">dhcpd6.conf  dhcpd.conf   </span><br><span class="line">[root@jhr-hub ~]# cat /etc/dhcp/dhcpd.conf </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># DHCP Server Configuration file.</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  see /usr/share/doc/dhcp*/dhcpd.conf.example</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  see dhcpd.conf(5) man page</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">[root@jhr-hub ~]<span class="comment">#</span></span> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@jhr-hub ~]# cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcp/dhcpd.conf</span><br><span class="line">cp: overwrite ‘/etc/dhcp/dhcpd.conf’? y</span><br><span class="line">[root@jhr-hub ~]#</span><br></pre></td></tr></table></figure>

<h1 id="修改DHCP的配置文件"><a href="#修改DHCP的配置文件" class="headerlink" title="修改DHCP的配置文件"></a><strong>修改DHCP的配置文件</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@jhr-hub ~]# vim /etc/dhcp/dhcpd.conf</span><br><span class="line">[root@jhr-hub ~]# </span><br><span class="line">[root@jhr-hub ~]# </span><br><span class="line">[root@jhr-hub ~]# </span><br><span class="line">[root@jhr-hub ~]# cat /etc/dhcp/dhcpd.conf</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dhcpd.conf</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># Sample configuration file for ISC dhcpd</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"></span><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">option definitions common to all supported networks...</span></span><br><span class="line">option domain-name &quot;example.org&quot;;</span><br><span class="line">option domain-name-servers 3.7.191.1;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置当前的IP地址有效期，单位s</span></span><br><span class="line">default-lease-time 60; </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置申请最大有效期</span></span><br><span class="line">max-lease-time 60; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use this to enble / <span class="built_in">disable</span> dynamic dns updates globally.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">ddns-update-style none;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">If this DHCP server is the official DHCP server <span class="keyword">for</span> the <span class="built_in">local</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">network, the authoritative directive should be uncommented.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">authoritative;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use this to send dhcp <span class="built_in">log</span> messages to a different <span class="built_in">log</span> file (you also</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">have to hack syslog.conf to complete the redirection).</span></span><br><span class="line">log-facility local7;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">No service will be given on this subnet, but declaring it helps the</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">DHCP server to understand the network topology.</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">声明IP地址段和子网掩码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">subnet 192.168.1.0 netmask 255.255.255.0 &#123;</span><br><span class="line">    #地址池：设置一个地址段</span><br><span class="line">   range 192.168.1.100 192.168.1.200;</span><br><span class="line"><span class="meta prompt_">   #</span><span class="language-bash">指定网关</span></span><br><span class="line">   option routers 3.7.191.1;</span><br><span class="line"><span class="meta prompt_">   #</span><span class="language-bash">获取DNS</span>         </span><br><span class="line">   option domain-name-servers 192.168.1.1; </span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">This is a very basic subnet declaration.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">subnet 10.254.239.0 netmask 255.255.255.224 &#123;</span><br><span class="line">  range 10.254.239.10 10.254.239.20;</span><br><span class="line">  option routers rtr-239-0-1.example.org, rtr-239-0-2.example.org;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">This declaration allows BOOTP clients to get dynamic addresses,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">which</span> we don<span class="string">&#x27;t really recommend.</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">subnet 10.254.239.32 netmask 255.255.255.224 &#123;</span><br><span class="line">  range dynamic-bootp 10.254.239.40 10.254.239.60;</span><br><span class="line">  option broadcast-address 10.254.239.31;</span><br><span class="line">  option routers rtr-239-32-1.example.org;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">A slightly different configuration for an internal subnet.</span></span></span><br><span class="line">subnet 10.5.5.0 netmask 255.255.255.224 &#123;</span><br><span class="line">  range 10.5.5.26 10.5.5.30;</span><br><span class="line">  option domain-name-servers ns1.internal.example.org;</span><br><span class="line">  option domain-name &quot;internal.example.org&quot;;</span><br><span class="line">  option routers 10.5.5.1;</span><br><span class="line">  option broadcast-address 10.5.5.31;</span><br><span class="line">  default-lease-time 600;</span><br><span class="line">  max-lease-time 7200;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Hosts which require special configuration options can be listed in</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">host statements.   If no address is specified, the address will be</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">allocated dynamically (if possible), but the host-specific information</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">will still come from the host declaration.</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">host passacaglia &#123;</span><br><span class="line">  hardware ethernet 0:0:c0:5d:bd:95;</span><br><span class="line">  filename &quot;vmunix.passacaglia&quot;;</span><br><span class="line">  server-name &quot;toccata.fugue.com&quot;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Fixed IP addresses can also be specified for hosts.   These addresses</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">should not also be listed as being available for dynamic assignment.</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Hosts for which fixed IP addresses have been specified can boot using</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">BOOTP or DHCP.   Hosts for which no fixed address is specified can only</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">be booted with DHCP, unless there is an address range on the subnet</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">to which a BOOTP client is connected which has the dynamic-bootp flag</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">set.</span></span></span><br><span class="line">host fantasia &#123;</span><br><span class="line">  hardware ethernet 08:00:07:26:c0:a5;</span><br><span class="line">  fixed-address fantasia.fugue.com;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">You can declare a class of clients and then do address allocation</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">based on that.   The example below shows a case where all clients</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">in a certain class get addresses on the 10.17.224/24 subnet, and all</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">other clients get addresses on the 10.0.29/24 subnet.</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class &quot;foo&quot; &#123;</span><br><span class="line">  match if substring (option vendor-class-identifier, 0, 4) = &quot;SUNW&quot;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">shared-network 224-29 &#123;</span><br><span class="line">  subnet 10.17.224.0 netmask 255.255.255.0 &#123;</span><br><span class="line">    option routers rtr-224.example.org;</span><br><span class="line">  &#125;</span><br><span class="line">  subnet 10.0.29.0 netmask 255.255.255.0 &#123;</span><br><span class="line">    option routers rtr-29.example.org;</span><br><span class="line">  &#125;</span><br><span class="line">  pool &#123;</span><br><span class="line">    allow members of &quot;foo&quot;;</span><br><span class="line">    range 10.17.224.10 10.17.224.250;</span><br><span class="line">  &#125;</span><br><span class="line">  pool &#123;</span><br><span class="line">    deny members of &quot;foo&quot;;</span><br><span class="line">    range 10.0.29.10 10.0.29.230;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@jhr-hub ~]#</span><br></pre></td></tr></table></figure>

<h1 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a><strong>启动服务</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@jhr-hub ~]# systemctl start dhcpd</span><br><span class="line">[root@jhr-hub ~]# systemctl status dhcpd</span><br><span class="line">● dhcpd.service - DHCPv4 Server Daemon</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/dhcpd.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Thu 2021-12-09 11:25:37 CST; 2s ago</span><br><span class="line">     Docs: man:dhcpd(8)</span><br><span class="line">           man:dhcpd.conf(5)</span><br><span class="line"> Main PID: 142669 (dhcpd)</span><br><span class="line">   Status: &quot;Dispatching packets...&quot;</span><br><span class="line">   Memory: 5.0M</span><br><span class="line">   CGroup: /system.slice/dhcpd.service</span><br><span class="line">           └─142669 /usr/sbin/dhcpd -f -cf /etc/dhcp/dhcpd.conf -user dhcpd -group dhcpd --no-pid</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b2b9755a067f4111bd138e4b8d8ceb4e~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>71篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d6a9b318127f45f88658d1ef34ede4cf~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>为kubernetes（k8s）单独配置kubectl工具</title>
    <url>/2022/01/06/2022-01-06-%E4%B8%BAkubernetes%EF%BC%88k8s%EF%BC%89%E5%8D%95%E7%8B%AC%E9%85%8D%E7%BD%AEkubectl%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Kubernetes API 是一个 HTTP REST API。这个 API 是真正的 Kubernetes 用户界面，通过它可以完全控制它。这意味着每个 Kubernetes 操作都作为 API 端点公开，并且可以通过对该端点的 HTTP 请求进行。因此，kubectl 的主要目的是向 Kubernetes API 发出 HTTP 请求：<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3dd62e455489487985d282b6867f10c6~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="配置apt软件源"><a href="#配置apt软件源" class="headerlink" title="配置apt软件源"></a>配置apt软件源</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line">Hit:1 http://192.168.1.104:81/ubuntu focal InRelease</span><br><span class="line">Hit:2 http://192.168.1.104:81/ubuntu focal-security InRelease</span><br><span class="line">Hit:3 http://192.168.1.104:81/ubuntu focal-updates InRelease</span><br><span class="line">Hit:4 http://192.168.1.104:81/ubuntu focal-proposed InRelease</span><br><span class="line">Hit:5 https://mirrors.aliyun.com/docker-ce/linux/ubuntu focal InRelease</span><br><span class="line">Reading package lists... Done        </span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree       </span><br><span class="line">Reading state information... Done</span><br><span class="line">apt-transport-https is already the newest version (2.0.6).</span><br><span class="line">0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - </span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100  2537  100  2537    0     0  26989      0 --:--:-- --:--:-- --:--:-- 26989</span><br><span class="line">OK</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">EOF</span></span><br><span class="line">root@hello:~# apt-get update</span><br><span class="line">Hit:1 http://192.168.1.104:81/ubuntu focal InRelease</span><br><span class="line">Hit:2 http://192.168.1.104:81/ubuntu focal-security InRelease</span><br><span class="line">Hit:3 http://192.168.1.104:81/ubuntu focal-updates InRelease</span><br><span class="line">Hit:4 http://192.168.1.104:81/ubuntu focal-proposed InRelease</span><br><span class="line">Hit:5 https://mirrors.aliyun.com/docker-ce/linux/ubuntu focal InRelease</span><br><span class="line">Get:6 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial InRelease [9,383 B]</span><br><span class="line">Ign:7 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages</span><br><span class="line">Get:7 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages [52.6 kB]</span><br><span class="line">Fetched 62.0 kB in 1s (59.9 kB/s)   </span><br><span class="line">Reading package lists... Done</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<h1 id="使用apt安装kubectl工具"><a href="#使用apt安装kubectl工具" class="headerlink" title="使用apt安装kubectl工具"></a>使用apt安装kubectl工具</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# apt-get install -y kubectl</span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree       </span><br><span class="line">Reading state information... Done</span><br><span class="line">The following NEW packages will be installed:</span><br><span class="line">  kubectl</span><br><span class="line">0 upgraded, 1 newly installed, 0 to remove and 54 not upgraded.</span><br><span class="line">Need to get 8,928 kB of archives.</span><br><span class="line">After this operation, 46.6 MB of additional disk space will be used.</span><br><span class="line">Get:1 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubectl amd64 1.23.1-00 [8,928 kB]</span><br><span class="line">Fetched 8,928 kB in 2s (5,599 kB/s)   </span><br><span class="line">Selecting previously unselected package kubectl.</span><br><span class="line">(Reading database ... 129153 files and directories currently installed.)</span><br><span class="line">Preparing to unpack .../kubectl_1.23.1-00_amd64.deb ...</span><br><span class="line">Unpacking kubectl (1.23.1-00) ...</span><br><span class="line">Setting up kubectl (1.23.1-00) ...</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# mkdir /root/.kube/</span><br></pre></td></tr></table></figure>

<h1 id="配置kubectl配置文件"><a href="#配置kubectl配置文件" class="headerlink" title="配置kubectl配置文件"></a>配置kubectl配置文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# vim /root/.kube/config </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# cat /root/.kube/config</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUR1RENDQXFDZ0F3SUJBZ0lVSlF3R05rQS9BaGxLYVpEcS9oaVpQNStteVJ3d0RRWUpLb1pJaHZjTkFRRUwKQlFBd1lURUxNQWtHQTFVRUJoTUNRMDR4RVRBUEJnTlZCQWdUQ0VoaGJtZGFhRzkxTVFzd0NRWURWUVFIRXdKWQpVekVNTUFvR0ExVUVDaE1EYXpoek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweEV6QVJCZ05WQkFNVENtdDFZbVZ5CmJtVjBaWE13SUJjTk1qRXhNakF6TURJME1EQXdXaGdQTWpFeU1URXhNRGt3TWpRd01EQmFNR0V4Q3pBSkJnTlYKQkFZVEFrTk9NUkV3RHdZRFZRUUlFd2hJWVc1bldtaHZkVEVMTUFrR0ExVUVCeE1DV0ZNeEREQUtCZ05WQkFvVApBMnM0Y3pFUE1BMEdBMVVFQ3hNR1UzbHpkR1Z0TVJNd0VRWURWUVFERXdwcmRXSmxjbTVsZEdWek1JSUJJakFOCkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXRvcisyNkVLY2VRZGE5eDZodXRoL0h1S21ZRWIKVWhadWJSWVR0VW85WTBpaFc2ME1GK1RBTndNSURFdHo0MGhkSXhrTmtJaDhITEdUcjlwek9hWGNzSVg2NzJsZwpheTdQVGlVZ3I2cVRYcmEzcnpxMjJrdVJtU05yY29ZVmpRbDVXa2ZITWR6cS9GZFpRVDVsRytZZWlLS1Q0c2tzCmJUcmFwSGFUc0VYY0lMb2VBREdCUVJrSXhvTmswWGo3RzNXbEt4enFRRXJ3cVIvbkE3b0U2MStYbHJZaTJTYUkKVFFoaUpMV0lYRTluUkRRNG9hOVNDSXhKUFp5Ukl5UTJFSVc2TG1DRDVtazNtZ2lPNFlVK3ZiMXg3amppS3ZKcQo0MExaaklFQllxY1R4RVN3K2J6cnYrQ1JaMm9UUlRaVGxveGVtYzliOWdhM2pwSjZBbWdvYjRmQkVRSURBUUFCCm8yWXdaREFPQmdOVkhROEJBZjhFQkFNQ0FRWXdFZ1lEVlIwVEFRSC9CQWd3QmdFQi93SUJBakFkQmdOVkhRNEUKRmdRVThBWGxiWis4cnRySmxxYzhpUUxIVjVHUis3TXdId1lEVlIwakJCZ3dGb0FVOEFYbGJaKzhydHJKbHFjOAppUUxIVjVHUis3TXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBRkxFMGFGclQzTnptcWRRdCtPN1c1OW04WnJVCnNtbFFzNGt2cFhET0FwdUxaNzROVUY0K3F1aVVRaFB4VEZFVnA2azBqVjlwWVVzbURMKzZmR1BaQldwdVpscisKSjRYZlcwaENITjlnZ05JelcxWUNZNEVxWGp5ZmY1dTZZQ1MyNmU2ZVB3dFA2RGhObE0xNzRNOXpKbnhGbllZdApZYmFjdDhjOTlwRDZvYlI3VGhnd3BFdE9YbW11ajM5OU5ycjR5cXBaQk95dGxQR291N2JzcFl2dkFhMnJ3QnNJCkh4NTNUT1paMXFNRjBYemNWbVk2eHQ1MklkVUtSdDV1QWsxRGRsQ2RkMHplL2RsZmN4MVBxbnV6dDNndldpL3MKRERCYXg0SnB0cXloMjgwZkVlU1pEd0hpYnY4V3AwRi8ranI1N2Q1K0p0cXgrOTlBSXZiUlM5U1JLMmc9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K</span><br><span class="line">    server: https://192.168.1.11:6443</span><br><span class="line">  name: cluster1</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: cluster1</span><br><span class="line">    user: admin</span><br><span class="line">  name: context-cluster1</span><br><span class="line">current-context: context-cluster1</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: admin</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQxekNDQXIrZ0F3SUJBZ0lVVFprVnpuSFYxMStjdVRWSnNqWHpUVDVOZHQ4d0RRWUpLb1pJaHZjTkFRRUwKQlFBd1lURUxNQWtHQTFVRUJoTUNRMDR4RVRBUEJnTlZCQWdUQ0VoaGJtZGFhRzkxTVFzd0NRWURWUVFIRXdKWQpVekVNTUFvR0ExVUVDaE1EYXpoek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweEV6QVJCZ05WQkFNVENtdDFZbVZ5CmJtVjBaWE13SUJjTk1qRXhNakF6TURJME1EQXdXaGdQTWpBM01URXhNakV3TWpRd01EQmFNR2N4Q3pBSkJnTlYKQkFZVEFrTk9NUkV3RHdZRFZRUUlFd2hJWVc1bldtaHZkVEVMTUFrR0ExVUVCeE1DV0ZNeEZ6QVZCZ05WQkFvVApEbk41YzNSbGJUcHRZWE4wWlhKek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweERqQU1CZ05WQkFNVEJXRmtiV2x1Ck1JSUJJakFOQmdrcWhraUc5dzBCQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBbXNKUHBvdEcyNVE4bExyNC9NK3MKdVYzdWduQU14ZWRKYldFQmcxem81UGtyVW8wTUpDUEkyMTgrby9yTHh2eWJ1SlJKRm5qZlJMWlBZNmYrTGZTKwpJQmppbHJQN3J2OHdLMTh1V0EvNVdoWWNQeUZZYTZKeTVRM1RFdkZBYkdLVU5FUjBiWUhNOXdmTGJhVWNmdGkyCnI5dEd5TFVPYzBpemJ5QkFPZFU3Wkx0Z2d2OVdZb213aThLZG84bXVTTjdqSGlpd1BXTmIvQlBDUzE1WElvTXcKZDRzUW15MFFLVENTOHRuR2FzeFlPQ1pqMkhZMTV6dTdmbFJBeWZZcDNCM1pLZVZzQXdvUkhLQmVCa0NlMklwMQpYVnI3aEtkaEtkRWlaNGROcFVjd1V1U2xBRml3K1lPeUREbDZLdmVsSGVHVCs0N3E5SStjbXc0Rm1Ra1hhNGZFCkhRSURBUUFCbzM4d2ZUQU9CZ05WSFE4QkFmOEVCQU1DQmFBd0hRWURWUjBsQkJZd0ZBWUlLd1lCQlFVSEF3RUcKQ0NzR0FRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdIUVlEVlIwT0JCWUVGQTRwcGFzNUZzTGJuNVJIVGxwTQo5T1FlQTlZaE1COEdBMVVkSXdRWU1CYUFGUEFGNVcyZnZLN2F5WmFuUElrQ3gxZVJrZnV6TUEwR0NTcUdTSWIzCkRRRUJDd1VBQTRJQkFRQnRsQ21xN1pZQ2lRVVFHSGdSc2lDY2Q0UmVEZy8rcWVmbkJRT3h4SWN4TzU3UE1uNkwKWjVJNnJwUE9TSi9XaFlwUkNGUGVPTzZTUE5GS1RrUzNIQzlocytmY3dCaFBtV0gzNmJXQytDOXkrU1dXcXpkWQpWRzhpbDF1YW8wK04wWTZVdDdnZ0h5V1RscnByem43MmsrT1dKUlA4VWM5SVpBaWx5TUlHTmdZZENoMDVnbVBlCkd3Z0VyMHBLU3A5UE9SUDFZTGF5VVFsdUdCZkhtWERHM21kd3RYVmFFRmJNbEJsRU1CdCsvMW8xMWNVSFdNVWgKYXVBVWNPYy9RTGUvZUVZcFZTT25NRWpmalJZd1BwY1RybnNsYjNjblFnU2VrdE51QXJWZ1Y5UXg3WkhvZ1o3NApJZTJzSU9tRDRBUGEzNWJWb0c1SkMwYkc2NHVVM2hKOEIzNGgKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=</span><br><span class="line">    client-key-data: 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</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>*注意：配置文件中的server需要修改，并且该配置文件在原有的集权管理节点上。</p>
<h1 id="配置自动补全，并测试kubectl"><a href="#配置自动补全，并测试kubectl" class="headerlink" title="配置自动补全，并测试kubectl"></a>配置自动补全，并测试kubectl</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# apt install -y bash-completion</span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree       </span><br><span class="line">Reading state information... Done</span><br><span class="line">bash-completion is already the newest version (1:2.10-1ubuntu1).</span><br><span class="line">bash-completion set to manually installed.</span><br><span class="line">0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# source &lt;(kubectl completion bash)</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# kubectl get deployments.apps </span><br><span class="line">NAME                     READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">cby                      1/1     1            1           3h53m</span><br><span class="line">hello-server             2/2     2            2           30d</span><br><span class="line">ingress-demo-app         2/2     2            2           30d</span><br><span class="line">nfs-client-provisioner   1/1     1            1           34d</span><br><span class="line">nginx-demo               2/2     2            2           30d</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e5de0e0573dd401cb592f93d697971ed~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>76篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5ed5f95687254a299297f3e2bb64a65f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云、简书、今日头条</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>GitHub+Hexo 搭建博客网站</title>
    <url>/2022/01/08/2022-01-08-GitHub+Hexo_%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>    Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub和Heroku上，是搭建博客的首选框架。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aec1d93aba0a450cafcd07a65fae0d98~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="配置Github"><a href="#配置Github" class="headerlink" title="配置Github"></a>配置Github</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/cby# git config --global user.name &quot;cby-chen&quot;</span><br><span class="line">root@hello:~/cby# git config --global user.email &quot;cby@chenby.cn&quot;</span><br><span class="line">root@hello:~/cby# ssh-keygen -t rsa -C &quot;cby@chenby.cn&quot;</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/root/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /root/.ssh/id_rsa</span><br><span class="line">Your public key has been saved in /root/.ssh/id_rsa.pub</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:57aHSNuHDLRsy/UVOQKwrUmpKOqnkEbRuRc8jNrGVpU cby@chenby.cn</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+---[RSA 3072]----+</span><br><span class="line">|       .o.       |</span><br><span class="line">|  . = .E +.      |</span><br><span class="line">| . + *  + ..   . |</span><br><span class="line">|  = o.oo.o  . +  |</span><br><span class="line">| o.*...oS..  . o |</span><br><span class="line">|.oo..   *o.   .  |</span><br><span class="line">|+.     + Oo+ .   |</span><br><span class="line">|+  .    =.=.+    |</span><br><span class="line">| oo       .o     |</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line">root@hello:~/cby# cat /root/.ssh/</span><br><span class="line">authorized_keys  id_rsa           id_rsa.pub       known_hosts      </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">需要配置到github上</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">https://github.com/settings/ssh/new</span></span><br><span class="line"></span><br><span class="line">root@hello:~/cby# ssh git@github.com</span><br><span class="line">The authenticity of host &#x27;github.com (20.205.243.166)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:p2QAMXNIC1TJYWeIOttrVc98/R1BUFWu3/LiyKgUfQM.</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br><span class="line">Warning: Permanently added &#x27;github.com,20.205.243.166&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">PTY allocation request failed on channel 0</span><br><span class="line">Hi cby-chen! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br><span class="line">Connection to github.com closed.</span><br><span class="line">root@hello:~/cby#</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/437ef5592903459d906f754cc57feee1~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>*将id_rsa.pub文件中的内容粘贴进去</p>
<h1 id="安装nvm工具"><a href="#安装nvm工具" class="headerlink" title="安装nvm工具"></a>安装nvm工具</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/cby# curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash</span><br><span class="line">root@hello:~/cby# nvm install --lts</span><br><span class="line">Installing latest LTS version.</span><br><span class="line">Downloading and installing node v16.13.1...</span><br><span class="line">Downloading https://nodejs.org/dist/v16.13.1/node-v16.13.1-linux-x64.tar.xz...</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">############################################################################################################################################## 100.0%</span></span></span><br><span class="line">Computing checksum with sha256sum</span><br><span class="line">Checksums matched!</span><br><span class="line">Now using node v16.13.1 (npm v8.1.2)</span><br><span class="line">root@hello:~/cby# nvm use --lts</span><br><span class="line">Now using node v16.13.1 (npm v8.1.2)</span><br><span class="line">root@hello:~/cby# </span><br><span class="line">root@hello:~/cby# node -v</span><br><span class="line">v16.13.1</span><br><span class="line">root@hello:~/cby#</span><br></pre></td></tr></table></figure>

<h1 id="配置hexo环境，并修改主题"><a href="#配置hexo环境，并修改主题" class="headerlink" title="配置hexo环境，并修改主题"></a>配置hexo环境，并修改主题</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/cby# npm install -g hexo-cli </span><br><span class="line">root@hello:~/cby# npm install hexo -g</span><br><span class="line">root@hello:~/cby# npm update hexo -g </span><br><span class="line">root@hello:~/cby# hexo init</span><br><span class="line">INFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.git</span><br><span class="line">INFO  Install dependencies</span><br><span class="line">INFO  Start blogging with Hexo!</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">修改主题</span></span><br><span class="line">root@hello:~/cby# rm -rf scaffolds source themes _config.landscape.yml _config.yml package.json yarn.lock</span><br><span class="line">root@hello:~/cby# git clone https://github.com/V-Vincen/hexo-theme-livemylife.git</span><br><span class="line">root@hello:~/cby# mv hexo-theme-livemylife/* ./</span><br><span class="line">root@hello:~/cby# rm -rf hexo-theme-livemylife</span><br><span class="line">root@hello:~/cby# npm install</span><br></pre></td></tr></table></figure>

<h1 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/cby# vim _config.yml</span><br><span class="line">root@hello:~/cby# </span><br><span class="line">root@hello:~/cby# </span><br><span class="line">root@hello:~/cby# cat _config.yml</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">略</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Deployment</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Docs: https://hexo.io/docs/deployment.html</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#</span></span></span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: https://github.com/cby-chen/cby-chen.github.io.git # or https://gitee.com/&lt;yourAccount&gt;/&lt;repo&gt;</span><br><span class="line">  branch: master</span><br><span class="line">root@hello:~/cby# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~/cby# hexo clean </span><br><span class="line">root@hello:~/cby# hexo g </span><br><span class="line">root@hello:~/cby# hexo d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">注意，输入密码是需要输入token，创建时需要勾选所有权限</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">https://github.com/settings/tokens/new</span></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/06a7dd55b8a64f3e85fd15dfc517499c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/417c10a55d55470e9900764b3c0977ee~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>79篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9e65a2d4a4a34f4c93f488fd3a96709d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubectl管理多个集群配置</title>
    <url>/2022/01/07/2022-01-07-kubectl%E7%AE%A1%E7%90%86%E5%A4%9A%E4%B8%AA%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="需求描述："><a href="#需求描述：" class="headerlink" title="需求描述："></a><strong>需求描述：</strong></h1><p>在一台机器上通过kubectl管理多个Kubernetes集群。</p>
<p>操作过程：将各集群的kubectl config文件中的证书内容转换，通过命令创建config文件；通过上下文切换使用不同集群。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eb87c3ee85654b439b1bbeca5fb8de01~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/.kube# ll</span><br><span class="line">total 44</span><br><span class="line">drwxr-xr-x 3 root root 4096 Jan 6 16:23 ./</span><br><span class="line">drwx------ 21 root root 4096 Jan 6 16:22 ../</span><br><span class="line">drwxr-x--- 4 root root 4096 Jan 6 14:50 cache/</span><br><span class="line">-rw-r--r-- 1 root root 6252 Jan 6 16:21 config1</span><br><span class="line">-rw-r--r-- 1 root root 6254 Jan 6 16:22 config2</span><br><span class="line">root@hello:~/.kube#</span><br><span class="line">root@hello:~/.kube#</span><br></pre></td></tr></table></figure>

<h1 id="准备配置文件"><a href="#准备配置文件" class="headerlink" title="准备配置文件"></a><strong>准备配置文件</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/.kube# cat config1</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUR1RENDQXFDZ0F3SUJBZ0lVSlF3R05rQS9BaGxLYVpEcS9oaVpQNStteVJ3d0RRWUpLb1pJaHZjTkFRRUwKQlFBd1lURUxNQWtHQTFVRUJoTUNRMDR4RVRBUEJnTlZCQWdUQ0VoaGJtZGFhRzkxTVFzd0NRWURWUVFIRXdKWQpVekVNTUFvR0ExVUVDaE1EYXpoek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweEV6QVJCZ05WQkFNVENtdDFZbVZ5CmJtVjBaWE13SUJjTk1qRXhNakF6TURJME1EQXdXaGdQTWpFeU1URXhNRGt3TWpRd01EQmFNR0V4Q3pBSkJnTlYKQkFZVEFrTk9NUkV3RHdZRFZRUUlFd2hJWVc1bldtaHZkVEVMTUFrR0ExVUVCeE1DV0ZNeEREQUtCZ05WQkFvVApBMnM0Y3pFUE1BMEdBMVVFQ3hNR1UzbHpkR1Z0TVJNd0VRWURWUVFERXdwcmRXSmxjbTVsZEdWek1JSUJJakFOCkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXRvcisyNkVLY2VRZGE5eDZodXRoL0h1S21ZRWIKVWhadWJSWVR0VW85WTBpaFc2ME1GK1RBTndNSURFdHo0MGhkSXhrTmtJaDhITEdUcjlwek9hWGNzSVg2NzJsZwpheTdQVGlVZ3I2cVRYcmEzcnpxMjJrdVJtU05yY29ZVmpRbDVXa2ZITWR6cS9GZFpRVDVsRytZZWlLS1Q0c2tzCmJUcmFwSGFUc0VYY0lMb2VBREdCUVJrSXhvTmswWGo3RzNXbEt4enFRRXJ3cVIvbkE3b0U2MStYbHJZaTJTYUkKVFFoaUpMV0lYRTluUkRRNG9hOVNDSXhKUFp5Ukl5UTJFSVc2TG1DRDVtazNtZ2lPNFlVK3ZiMXg3amppS3ZKcQo0MExaaklFQllxY1R4RVN3K2J6cnYrQ1JaMm9UUlRaVGxveGVtYzliOWdhM2pwSjZBbWdvYjRmQkVRSURBUUFCCm8yWXdaREFPQmdOVkhROEJBZjhFQkFNQ0FRWXdFZ1lEVlIwVEFRSC9CQWd3QmdFQi93SUJBakFkQmdOVkhRNEUKRmdRVThBWGxiWis4cnRySmxxYzhpUUxIVjVHUis3TXdId1lEVlIwakJCZ3dGb0FVOEFYbGJaKzhydHJKbHFjOAppUUxIVjVHUis3TXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBRkxFMGFGclQzTnptcWRRdCtPN1c1OW04WnJVCnNtbFFzNGt2cFhET0FwdUxaNzROVUY0K3F1aVVRaFB4VEZFVnA2azBqVjlwWVVzbURMKzZmR1BaQldwdVpscisKSjRYZlcwaENITjlnZ05JelcxWUNZNEVxWGp5ZmY1dTZZQ1MyNmU2ZVB3dFA2RGhObE0xNzRNOXpKbnhGbllZdApZYmFjdDhjOTlwRDZvYlI3VGhnd3BFdE9YbW11ajM5OU5ycjR5cXBaQk95dGxQR291N2JzcFl2dkFhMnJ3QnNJCkh4NTNUT1paMXFNRjBYemNWbVk2eHQ1MklkVUtSdDV1QWsxRGRsQ2RkMHplL2RsZmN4MVBxbnV6dDNndldpL3MKRERCYXg0SnB0cXloMjgwZkVlU1pEd0hpYnY4V3AwRi8ranI1N2Q1K0p0cXgrOTlBSXZiUlM5U1JLMmc9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K</span><br><span class="line">    server: https://192.168.1.11:6443</span><br><span class="line">  name: cluster1</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: cluster1</span><br><span class="line">    user: dev-admin</span><br><span class="line">  name: context-cluster1</span><br><span class="line">current-context: context-cluster1</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: dev-admin</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQxekNDQXIrZ0F3SUJBZ0lVVFprVnpuSFYxMStjdVRWSnNqWHpUVDVOZHQ4d0RRWUpLb1pJaHZjTkFRRUwKQlFBd1lURUxNQWtHQTFVRUJoTUNRMDR4RVRBUEJnTlZCQWdUQ0VoaGJtZGFhRzkxTVFzd0NRWURWUVFIRXdKWQpVekVNTUFvR0ExVUVDaE1EYXpoek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweEV6QVJCZ05WQkFNVENtdDFZbVZ5CmJtVjBaWE13SUJjTk1qRXhNakF6TURJME1EQXdXaGdQTWpBM01URXhNakV3TWpRd01EQmFNR2N4Q3pBSkJnTlYKQkFZVEFrTk9NUkV3RHdZRFZRUUlFd2hJWVc1bldtaHZkVEVMTUFrR0ExVUVCeE1DV0ZNeEZ6QVZCZ05WQkFvVApEbk41YzNSbGJUcHRZWE4wWlhKek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweERqQU1CZ05WQkFNVEJXRmtiV2x1Ck1JSUJJakFOQmdrcWhraUc5dzBCQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBbXNKUHBvdEcyNVE4bExyNC9NK3MKdVYzdWduQU14ZWRKYldFQmcxem81UGtyVW8wTUpDUEkyMTgrby9yTHh2eWJ1SlJKRm5qZlJMWlBZNmYrTGZTKwpJQmppbHJQN3J2OHdLMTh1V0EvNVdoWWNQeUZZYTZKeTVRM1RFdkZBYkdLVU5FUjBiWUhNOXdmTGJhVWNmdGkyCnI5dEd5TFVPYzBpemJ5QkFPZFU3Wkx0Z2d2OVdZb213aThLZG84bXVTTjdqSGlpd1BXTmIvQlBDUzE1WElvTXcKZDRzUW15MFFLVENTOHRuR2FzeFlPQ1pqMkhZMTV6dTdmbFJBeWZZcDNCM1pLZVZzQXdvUkhLQmVCa0NlMklwMQpYVnI3aEtkaEtkRWlaNGROcFVjd1V1U2xBRml3K1lPeUREbDZLdmVsSGVHVCs0N3E5SStjbXc0Rm1Ra1hhNGZFCkhRSURBUUFCbzM4d2ZUQU9CZ05WSFE4QkFmOEVCQU1DQmFBd0hRWURWUjBsQkJZd0ZBWUlLd1lCQlFVSEF3RUcKQ0NzR0FRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdIUVlEVlIwT0JCWUVGQTRwcGFzNUZzTGJuNVJIVGxwTQo5T1FlQTlZaE1COEdBMVVkSXdRWU1CYUFGUEFGNVcyZnZLN2F5WmFuUElrQ3gxZVJrZnV6TUEwR0NTcUdTSWIzCkRRRUJDd1VBQTRJQkFRQnRsQ21xN1pZQ2lRVVFHSGdSc2lDY2Q0UmVEZy8rcWVmbkJRT3h4SWN4TzU3UE1uNkwKWjVJNnJwUE9TSi9XaFlwUkNGUGVPTzZTUE5GS1RrUzNIQzlocytmY3dCaFBtV0gzNmJXQytDOXkrU1dXcXpkWQpWRzhpbDF1YW8wK04wWTZVdDdnZ0h5V1RscnByem43MmsrT1dKUlA4VWM5SVpBaWx5TUlHTmdZZENoMDVnbVBlCkd3Z0VyMHBLU3A5UE9SUDFZTGF5VVFsdUdCZkhtWERHM21kd3RYVmFFRmJNbEJsRU1CdCsvMW8xMWNVSFdNVWgKYXVBVWNPYy9RTGUvZUVZcFZTT25NRWpmalJZd1BwY1RybnNsYjNjblFnU2VrdE51QXJWZ1Y5UXg3WkhvZ1o3NApJZTJzSU9tRDRBUGEzNWJWb0c1SkMwYkc2NHVVM2hKOEIzNGgKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=</span><br><span class="line">    client-key-data: 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</span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube# cat config2</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUR1RENDQXFDZ0F3SUJBZ0lVUzVMSE5FQ0lOMGxhVGRNK3pFZ0Y0SlZXNmp3d0RRWUpLb1pJaHZjTkFRRUwKQlFBd1lURUxNQWtHQTFVRUJoTUNRMDR4RVRBUEJnTlZCQWdUQ0VoaGJtZGFhRzkxTVFzd0NRWURWUVFIRXdKWQpVekVNTUFvR0ExVUVDaE1EYXpoek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweEV6QVJCZ05WQkFNVENtdDFZbVZ5CmJtVjBaWE13SUJjTk1qRXhNakF6TURJME1qQXdXaGdQTWpFeU1URXhNRGt3TWpReU1EQmFNR0V4Q3pBSkJnTlYKQkFZVEFrTk9NUkV3RHdZRFZRUUlFd2hJWVc1bldtaHZkVEVMTUFrR0ExVUVCeE1DV0ZNeEREQUtCZ05WQkFvVApBMnM0Y3pFUE1BMEdBMVVFQ3hNR1UzbHpkR1Z0TVJNd0VRWURWUVFERXdwcmRXSmxjbTVsZEdWek1JSUJJakFOCkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXZwdVJYVXd1TlQ5TGl4VDFCNHdEYTBZRHdKMFkKdWlaSGNsUk1rZjJTS3BWSHByazBNamx1R2g0WmR1ZEloUkk3YUpZbVZ3c3RQendpRlRPa2J0WEtzaVp5N0g4dApVVC9WRHQya0NnTDlvc0tKUE12OEI0aGp5R3h0bjFISk9aQ2NMSWEwTUFBaUtNVjhiRXFrT0hOK2tmVjhwR1lJCmZiVjRWYmlTUzRNMGlYdnhBT1hRSFFHU2lqV3c4d0h2aWNGWUxtME50bFlUM3pUZjVjVC9kRGJSdWhSRFF2clkKaVpnUHo0ZHg4YTZibFA3SkRmeTZMWTVXZmtBMFAxdWVtS05wR29pK1BHRDRFbGluRWd1aW9tbUtsWEowZ1pZTQpiNHNBbzJlWGY1ZGxQdkZxK0lJbzlYeWVzSGR1RDFWQ3dpRitudUZ4QmdlNnI2elQ4ZGFaL2NLMGZRSURBUUFCCm8yWXdaREFPQmdOVkhROEJBZjhFQkFNQ0FRWXdFZ1lEVlIwVEFRSC9CQWd3QmdFQi93SUJBakFkQmdOVkhRNEUKRmdRVTRhZlRpTE9MNVV1TUcrOS95ZXZGUVMxWkJEMHdId1lEVlIwakJCZ3dGb0FVNGFmVGlMT0w1VXVNRys5Lwp5ZXZGUVMxWkJEMHdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBRHQ1SlpqZjRoRS9VQVRCc3ZMUXphOFY5bkR4ClVZdStpaFVVTWRDenJQSkV0WXlMYWFQZXppenBicWFpU3YrblBoR2UxSndXMThIZmlsS0dsOTlCVENkc3VHSjUKVzhVTCtHbHdvVHZSRjNaK0F6M3NQL3dBelB1Vk5ORzZwVkJkanNSbDhhN29UMWV0RjM0UUovWWtOVFR4M1JrQQpRZjhqYXdZams3Wi9pL0VqM3hmd0FxRkhzT1Q2MjlXMnc0VU9SaVZBeHZuc2czWUozZ3RyVFRBK2hkVGhUWDViCkxpQjN5ZFFPUWNRTUE0SU9CeG0vdkRrR3lGMVBBL1BjMTFWTDBjZktrK25WY3J4RHAxS2JtVXhmNkhua3JqWlkKaGpNWEFqRDJIL0MzT2JjQUFMNXF6aUNKU1pDM0xDMVNwNEtKUGdMZVJPc1haZWpzUXRTRWN6YWhTRE09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K</span><br><span class="line">    server: https://192.168.1.12:6443</span><br><span class="line">  name: cluster2</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: cluster2</span><br><span class="line">    user: test-admin</span><br><span class="line">  name: context-cluster2</span><br><span class="line">current-context: context-cluster2</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: test-admin</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQxekNDQXIrZ0F3SUJBZ0lVRXF4OTlBOUFMem5GcTg5RDZLYzBjYk5GTGNVd0RRWUpLb1pJaHZjTkFRRUwKQlFBd1lURUxNQWtHQTFVRUJoTUNRMDR4RVRBUEJnTlZCQWdUQ0VoaGJtZGFhRzkxTVFzd0NRWURWUVFIRXdKWQpVekVNTUFvR0ExVUVDaE1EYXpoek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweEV6QVJCZ05WQkFNVENtdDFZbVZ5CmJtVjBaWE13SUJjTk1qRXhNakF6TURJMU1EQXdXaGdQTWpBM01URXhNakV3TWpVd01EQmFNR2N4Q3pBSkJnTlYKQkFZVEFrTk9NUkV3RHdZRFZRUUlFd2hJWVc1bldtaHZkVEVMTUFrR0ExVUVCeE1DV0ZNeEZ6QVZCZ05WQkFvVApEbk41YzNSbGJUcHRZWE4wWlhKek1ROHdEUVlEVlFRTEV3WlRlWE4wWlcweERqQU1CZ05WQkFNVEJXRmtiV2x1Ck1JSUJJakFOQmdrcWhraUc5dzBCQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBdkJ4aDlITEVNR3g0Y2VXWTNlYnAKbERseTcvQmo3aDF0Szlod21IV09iLy9sR0I2WjB0Sy93cDhUQUxwNThRV25mcE4xNkpWdFhsNXBXMDgwQVh0TgpyTkVpVnhsQXk0RUZSVVpNVFFtWTJZVDZlYVM1ZXFpQmZVR0dRRDM1OFdiOGtOS0R4a0REeEdHek1yYXRiZE5NCng0WTF6ZGNIUGh4Qy9jU3E1amNXN2RqTEp4ZnkzS29iZFIxTjNBSW5jSnZRYjNnZVdEN0FlNk9KZkJBTFJGY2sKOHVxS29MNFdVWGZuZVBqalN1ZzZLbytOL2IyS0hXU3gzaEdDbzJLLyszVkNvQXJETjdIeFJYSm4vakd6djRuQgo0aVlIYkZ4TU5MWDJ3TUk2NjJ0SEQ2TzBMbkdPUm5ETXFQTStLeFljbWZFc01jMWcyMGxsUWFUYXd3YXVUL1hPCk1RSURBUUFCbzM4d2ZUQU9CZ05WSFE4QkFmOEVCQU1DQmFBd0hRWURWUjBsQkJZd0ZBWUlLd1lCQlFVSEF3RUcKQ0NzR0FRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdIUVlEVlIwT0JCWUVGR3VJMEZodUJPY0xJTWM0WCtGTQpIMEJPdlhKME1COEdBMVVkSXdRWU1CYUFGT0duMDRpemkrVkxqQnZ2ZjhucnhVRXRXUVE5TUEwR0NTcUdTSWIzCkRRRUJDd1VBQTRJQkFRQnRzUXg5UGhXaXg4WVBMYU05OG14dGkxNHpZK3Q3bE0yWjJPSWE2L1NQZXZFd1plMGwKWngyWUdKQ3NnaDIvSGZwMGRHZG5MYXB1OVd5ODlxaVdQdnVxUm5PVVN4cmpnVEo4TmluYjBYUG4xNU96MGJ5MQpJemova3JjU09CTzVDSEFBTzBYeXVETThxblJqRCtXN3lPMDZhNG1XRUsyWWhqWE1wa1lORTZEeFZkZ0xEaUdBCnlDM3pQczVyd28yR2JkQnNPei9qYzcvazJBRjYrbnYzTnJCRnJMcjF0NmFHUE9zby96SlZLNHR5UHBkb3Zmc1cKQkgwS1lNbGdvK3h3dlRIZ0ZLNlcwQ2JZNlVzM3VSZERGUTZXSVpPaitCME9od0QvT3JONUxGZzdydDdQbHgxRwp1MjZBc3M0OE8wbjlIdDY5d2NnSTB4WGJPWGRUWXV4MFZVUUgKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=</span><br><span class="line">    client-key-data: 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</span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube#</span><br></pre></td></tr></table></figure>

<h1 id="修改配置中："><a href="#修改配置中：" class="headerlink" title="修改配置中："></a><strong>修改配置中：</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置1</span></span><br><span class="line">- cluster:</span><br><span class="line">    server: https://192.168.1.11:6443</span><br><span class="line">  name: cluster1</span><br><span class="line">  </span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: cluster1</span><br><span class="line">    user: dev-admin</span><br><span class="line">  name: context-cluster1</span><br><span class="line"></span><br><span class="line">users:</span><br><span class="line">- name: dev-admin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置2</span></span><br><span class="line">- cluster:</span><br><span class="line">    server: https://192.168.1.12:6443</span><br><span class="line">  name: cluster2</span><br><span class="line">  </span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: cluster2</span><br><span class="line">    user: test-admin</span><br><span class="line">  name: context-cluster2</span><br><span class="line"></span><br><span class="line">users:</span><br><span class="line">- name: test-admin</span><br></pre></td></tr></table></figure>

<h1 id="写入配置文件"><a href="#写入配置文件" class="headerlink" title="写入配置文件"></a><strong>写入配置文件</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/.kube# KUBECONFIG=config1:config2 kubectl config view --flatten &gt; $HOME/.kube/config</span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube#</span><br></pre></td></tr></table></figure>

<h1 id="测试配置"><a href="#测试配置" class="headerlink" title="测试配置"></a><strong>测试配置</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/.kube# kubectl config get-contexts</span><br><span class="line">CURRENT   NAME               CLUSTER    AUTHINFO     NAMESPACE</span><br><span class="line">*         context-cluster1   cluster1   dev-admin    </span><br><span class="line">          context-cluster2   cluster2   test-admin   </span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube# kubectl config current-context</span><br><span class="line">context-cluster1</span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube# kubectl get node</span><br><span class="line">NAME           STATUS   ROLES    AGE   VERSION</span><br><span class="line">192.168.1.11   Ready    master   34d   v1.22.2</span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube# kubectl config use-context context-cluster2</span><br><span class="line">Switched to context &quot;context-cluster2&quot;.</span><br><span class="line">root@hello:~/.kube# </span><br><span class="line">root@hello:~/.kube# kubectl get node</span><br><span class="line">NAME           STATUS                     ROLES    AGE   VERSION</span><br><span class="line">192.168.1.12   Ready,SchedulingDisabled   master   34d   v1.22.2</span><br><span class="line">192.168.1.13   Ready                      node     34d   v1.22.2</span><br><span class="line">192.168.1.14   Ready                      node     34d   v1.22.2</span><br><span class="line">root@hello:~/.kube#</span><br></pre></td></tr></table></figure>

<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a><strong>附录</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">current-context 显示 current_context</span><br><span class="line">delete-cluster  删除 kubeconfig 文件中指定的集群</span><br><span class="line">delete-context  删除 kubeconfig 文件中指定的 context</span><br><span class="line">get-clusters    显示 kubeconfig 文件中定义的集群</span><br><span class="line">get-contexts    描述一个或多个 contexts</span><br><span class="line">rename-context  Renames a context from the kubeconfig file.</span><br><span class="line">set             设置 kubeconfig 文件中的一个单个值</span><br><span class="line">set-cluster     设置 kubeconfig 文件中的一个集群条目</span><br><span class="line">set-context     设置 kubeconfig 文件中的一个 context 条目</span><br><span class="line">set-credentials 设置 kubeconfig 文件中的一个用户条目</span><br><span class="line">unset           取消设置 kubeconfig 文件中的一个单个值</span><br><span class="line">use-context     设置 kubeconfig 文件中的当前上下文</span><br><span class="line">view            显示合并的 kubeconfig 配置或一个指定的 kubeconfig 文件</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b1dbe669de694b7382bc287aca01323c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云、简书、今日头条</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>服务器被入侵，异常进程无法杀掉，随机进程名</title>
    <url>/2021/12/30/2021-12-30-%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E5%85%A5%E4%BE%B5%EF%BC%8C%E5%BC%82%E5%B8%B8%E8%BF%9B%E7%A8%8B%E6%97%A0%E6%B3%95%E6%9D%80%E6%8E%89%EF%BC%8C%E9%9A%8F%E6%9C%BA%E8%BF%9B%E7%A8%8B%E5%90%8D/</url>
    <content><![CDATA[<p>故事情节：</p>
<p>    有一天在聚餐中，我有一个朋友和我说他的服务器上有有个异常的进程他一直在占满CPU在运行，我在一顿谦虚之后答应了他，有空登录上他的服务器看一下具体情况。  </p>
<p>      </p>
<p>    这一天正是五月一日，一年一度的劳动节来了，我在家里闲着没事干在看某综艺，这时手机响了，来了一条微信消息，看到他给我发来了俩张图，突然勾起了我内心的好奇。  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aff292bb3ed545a5a71c52449f10bf55~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f9c20a96a67744f08ee41e26cbc60e4f~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f12ed157c81342df8fb2ac295150eeca~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    就是以上三张图，在proc目录中的exe指向的文件已被删除，我看到这里，我好奇这个进程肯定是被隐藏掉了。这时，我急中生智跟这位朋友要了root账号密码。登录服务器用top命令一看，发现一个奇怪的进程在运行，我使用kill命令将其杀后，等了十来分钟后，发现没有被启动，这时我和这位朋友说干掉了，他问我是不是kill掉了，我说嗯，他又补充到，这个进程杀掉过段时间会起来的，我问他大概多久就会启动，他说不清楚大概一天内肯定会启动。这时我慌了，如果是一天内才启动，我还得明天才能看见，那实在没办法了。我又开始看我的综艺了。</p>
<p>    没过多久，我又看了一下，发现这个进程换了个名字又启动了。还干满了CPU，就在这时，我在研究这个进程运行文件的时候发现：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2700693c2b3c42e29513095f1cd528e5~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ea178cf674ac4db681eae00e0e9e0758~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/af2b391ca2b840908272967f98548a6b~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    这个进程会连到一个韩国的服务器上，我访问这个IP发现是一个正常的网站，没有异常情况。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3589c932e46e414f98bb194a67917cda~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    同时在查看运行目录的时候，发现如下问题</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/be1b20c6036d4fab9d729c900a8d74f0~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/740298419f3542199bc5182f4990135d~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>   发现运行文件的命令也没有，同时运行目录也被删掉了。就在这时卡住了脖子，不知如何是好，这时突然想起来一个定时运行的脚本。打开脚本是这样的：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a6822603916648d4a8eb2dfa69d75f34~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>      </p>
<p>    发现这个脚本是base64编码加密的，在网上找了一个解密的工具，进解密后发现这个是脚本</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6c5fca27de9043a0b343049d8f2d90ac~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>完整脚本如图：  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3ce9e9469c964a1ba4a4ca8e5615e05a~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    在下大概看了一下脚本内容，如下是执行一个临时文件并赋予一个执行权限在执行完成后将其删除，所以刚刚在看得时候发现执行的目录下得文件报红出现丢失的情况  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1879ea2e824d405d9765cdb3d6ba65f5~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    最骚的是这里，关键东西在这里了。使用拼接组成一个URL进行下载病毒文件。通过一系列操作，先查看本地IP，又看了是我是谁，又看了机器的架构，还看了机器的主机名，同时还看了本地的网卡所有的IP。最关键的是把网络这一块搞成一个md5sum。在最后查看了定时任务并搞成了一个base64的字符串</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d8d44f7e54a94cbb8e70163d0df8deab~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>    再往下就是下载脚本执行并添加定时任务了，有意思的是这个脚本的2017年的，至今还再用。到最后我取消了他所有权限，并改了名字，同时把定时任务将其删除。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cd3cd4244ce74bb79e3ceade78022ffd~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>到此该病毒已被清理。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bb22ea56078b4509813142ecb7f5d026~tplv-k3u1fbpfcp-zoom-1.image"></p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>在 k8s（kubernetes）中使用 Loki 进行日志监控</title>
    <url>/2021/12/30/2021-12-30-%E5%9C%A8_k8s%EF%BC%88kubernetes%EF%BC%89%E4%B8%AD%E4%BD%BF%E7%94%A8_Loki_%E8%BF%9B%E8%A1%8C%E6%97%A5%E5%BF%97%E7%9B%91%E6%8E%A7/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3279789d71c64e61a0df1c24cb94b1dd~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="安装helm环境"><a href="#安装helm环境" class="headerlink" title="安装helm环境"></a>安装helm环境</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -</span><br><span class="line">[root@hello ~/yaml]# sudo apt-get install apt-transport-https --yes</span><br><span class="line">[root@hello ~/yaml]# echo &quot;deb https://baltocdn.com/helm/stable/debian/ all main&quot; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list</span><br><span class="line">deb https://baltocdn.com/helm/stable/debian/ all main</span><br><span class="line">[root@hello ~/yaml]# sudo apt-get update</span><br><span class="line">[root@hello ~/yaml]# sudo apt-get install helm</span><br><span class="line">[root@hello ~/yaml]#</span><br></pre></td></tr></table></figure>

<h1 id="添加安装下载源"><a href="#添加安装下载源" class="headerlink" title="添加安装下载源"></a>添加安装下载源</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# helm repo add loki https://grafana.github.io/loki/charts &amp;&amp; helm repo update</span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">&quot;loki&quot; has been added to your repositories</span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">Hang tight while we grab the latest from your chart repositories...</span><br><span class="line">...Successfully got an update from the &quot;loki&quot; chart repository</span><br><span class="line">Update Complete. ⎈Happy Helming!⎈</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@hello ~/yaml]# helm pull loki/loki-stack</span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">[root@hello ~/yaml]# ls</span><br><span class="line">loki-stack-2.1.2.tgz  nfs-storage.yaml  nginx-ingress.yaml</span><br><span class="line">[root@hello ~/yaml]# tar xf loki-stack-2.1.2.tgz</span><br><span class="line">[root@hello ~/yaml]# ls</span><br><span class="line">loki-stack  loki-stack-2.1.2.tgz  nfs-storage.yaml  nginx-ingress.yaml</span><br></pre></td></tr></table></figure>

<h1 id="安装loki日志系统"><a href="#安装loki日志系统" class="headerlink" title="安装loki日志系统"></a>安装loki日志系统</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# helm install loki loki-stack/</span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">WARNING: This chart is deprecated</span><br><span class="line">W1203 07:31:04.751065  212245 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+</span><br><span class="line">W1203 07:31:04.754254  212245 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+</span><br><span class="line">W1203 07:31:04.833003  212245 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+</span><br><span class="line">W1203 07:31:04.833003  212245 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+</span><br><span class="line">NAME: loki</span><br><span class="line">LAST DEPLOYED: Fri Dec  3 07:31:04 2021</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">NOTES:</span><br><span class="line">The Loki stack has been deployed to your cluster. Loki can now be added as a datasource in Grafana.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">See http://docs.grafana.org/features/datasources/loki/ for more detail.</span><br><span class="line">[root@hello ~/yaml]#</span><br></pre></td></tr></table></figure>

<h1 id="查看安装后是否完成"><a href="#查看安装后是否完成" class="headerlink" title="查看安装后是否完成"></a>查看安装后是否完成</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# helm list -A</span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">NAME    NAMESPACE   REVISION    UPDATED                                 STATUS      CHART               APP VERSION</span><br><span class="line">loki    default     1           2021-12-03 07:31:04.3324429 +0000 UTC   deployed    loki-stack-2.1.2    v2.0.0    </span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@hello ~/yaml]# kubectl  get pod</span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">loki-0                                   0/1     Running   0          68s</span><br><span class="line">loki-promtail-79tn8                      1/1     Running   0          68s</span><br><span class="line">loki-promtail-qzjjs                      1/1     Running   0          68s</span><br><span class="line">loki-promtail-zlt7p                      1/1     Running   0          68s</span><br><span class="line">nfs-client-provisioner-dc5789f74-jsrh7   1/1     Running   0          44m</span><br><span class="line">[root@hello ~/yaml]#</span><br></pre></td></tr></table></figure>

<h1 id="查看svc并修改类型"><a href="#查看svc并修改类型" class="headerlink" title="查看svc并修改类型"></a>查看svc并修改类型</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  get svc</span><br><span class="line">NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">kubernetes      ClusterIP   10.68.0.1       &lt;none&gt;        443/TCP    4h44m</span><br><span class="line">loki            ClusterIP   10.68.140.107   &lt;none&gt;        3100/TCP   2m58s</span><br><span class="line">loki-headless   ClusterIP   None            &lt;none&gt;        3100/TCP   2m58s</span><br><span class="line">[root@hello ~/yaml]#</span><br></pre></td></tr></table></figure>

<h1 id="将svc设置为-type-NodePort"><a href="#将svc设置为-type-NodePort" class="headerlink" title="将svc设置为 type: NodePort"></a>将svc设置为 type: NodePort</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  edit  svc loki</span><br><span class="line">service/loki edited</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# kubectl  get svc</span><br><span class="line">NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">kubernetes      ClusterIP   10.68.0.1       &lt;none&gt;        443/TCP          4h46m</span><br><span class="line">loki            NodePort    10.68.140.107   &lt;none&gt;        3100:31089/TCP   4m34s</span><br><span class="line">loki-headless   ClusterIP   None            &lt;none&gt;        3100/TCP         4m34s</span><br><span class="line">[root@hello ~/yaml]#</span><br></pre></td></tr></table></figure>

<h1 id="添加nginx应用"><a href="#添加nginx应用" class="headerlink" title="添加nginx应用"></a>添加nginx应用</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim nginx-app.yaml</span><br><span class="line">[root@hello ~/yaml]# cat nginx-app.yaml</span><br><span class="line">apiVersion: apps/v1 </span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  replicas: 1 </span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">    jobLabel: nginx</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: nginx</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  type: NodePort</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="查看nginx的pod"><a href="#查看nginx的pod" class="headerlink" title="查看nginx的pod"></a>查看nginx的pod</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl apply -f nginx-app.yaml </span><br><span class="line">deployment.apps/nginx created</span><br><span class="line">service/nginx created</span><br><span class="line"></span><br><span class="line">[root@hello ~/yaml]# kubectl get pod  | grep nginx</span><br><span class="line">nginx-5d59d67564-7fj4b                   1/1     Running   0          29s</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="测试访问"><a href="#测试访问" class="headerlink" title="测试访问"></a>测试访问</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  get svc</span><br><span class="line">NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">kubernetes      ClusterIP   10.68.0.1       &lt;none&gt;        443/TCP          4h57m</span><br><span class="line">loki            NodePort    10.68.140.107   &lt;none&gt;        3100:31089/TCP   15m</span><br><span class="line">loki-headless   ClusterIP   None            &lt;none&gt;        3100/TCP         15m</span><br><span class="line">nginx           NodePort    10.68.150.95    &lt;none&gt;        80:31317/TCP     105s</span><br><span class="line">[root@hello ~/yaml]# </span><br><span class="line">[root@hello ~/yaml]# while true; do curl --silent --output /dev/null --write-out &#x27;%&#123;http_code&#125;&#x27; http://192.168.1.12:31317; sleep 1; echo; done</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="在grafana中添加源"><a href="#在grafana中添加源" class="headerlink" title="在grafana中添加源"></a>在grafana中添加源</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bb42d16252a748ce90bb5fa77945c038~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed027a6ed9674ae98cedbc8f6a8249c5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="添加面板"><a href="#添加面板" class="headerlink" title="添加面板"></a>添加面板</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c23a4d8a5afd459b93280f2e02506a2d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eb98af4b99594a2cbf0448e8685715b5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/83d39f756f944709bc3cb9e205da3533~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>68篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6031aba6c4b847cd8a0ffbd534e049ed~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p>知乎、CSDN、开源中国、思否、掘金、哔哩哔哩、腾讯云</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>CentOS&amp;amp;RHEL内核升级</title>
    <url>/2022/02/08/2022-02-08-CentOS&amp;amp;RHEL%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7310a5b8c8584446892dd5da6467514f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>在安装部署一些环境的时候，会要求内核版本的要求，可以通过YUM工具进行安装配置更高版本的内核，当然更新内核有风险，在操作之前慎重，严谨在生产环境操作！</strong></p>
<p>安装源</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为 RHEL-8或 CentOS-8配置源</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为 RHEL-7 SL-7 或 CentOS-7 安装 ELRepo</span> </span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>

<p>启用内核源，并安装  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看可用安装包</span></span><br><span class="line">yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装最新的内核</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我这里选择的是稳定版kernel-ml   如需更新长期维护版本kernel-lt</span>  </span><br><span class="line">yum  --enablerepo=elrepo-kernel  install  kernel-ml</span><br></pre></td></tr></table></figure>

<p>查看已有内核  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 查看已安装哪些内核</span></span><br><span class="line">rpm -qa | grep kernel</span><br><span class="line">kernel-core-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-core-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-ml-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-modules-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-libs-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-modules-5.16.7-1.el8.elrepo.x86_64</span><br></pre></td></tr></table></figure>

<p>查看当前使用的并设置  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看默认内核</span></span><br><span class="line">grubby --default-kernel</span><br><span class="line">/boot/vmlinuz-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">若不是最新的使用命令设置</span></span><br><span class="line">grubby --set-default /boot/vmlinuz-「您的内核版本」.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启生效</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>

<p>整合一条命令为：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --default-kernel ; reboot</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/68cb551969c94cb992794e1b41abbebb~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>82篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/61d3f248847948b99d47f05b76cac10b~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>网络抓包 tcpdump 使用指南</title>
    <url>/2022/01/14/2022-01-14-%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85_tcpdump_%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<p> 在网络问题的调试中，tcpdump应该说是一个必不可少的工具，和大部分linux下优秀工具一样，它的特点就是简单而强大。它是基于Unix系统的命令行式的数据包嗅探工具，可以抓取流动在网卡上的数据包。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/15a327784e3f45e5b7a80681c9d2c310~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>监听所有网卡所有包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump</span><br></pre></td></tr></table></figure>

<p>监听指定网卡的包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -i ens18</span><br></pre></td></tr></table></figure>

<p>监听指定IP的包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump host 192.168.1.11</span><br></pre></td></tr></table></figure>

<p>监听指定来源IP</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump src host 192.168.1.11</span><br></pre></td></tr></table></figure>

<p>监听目标地址IP</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump dst host 192.168.1.11</span><br></pre></td></tr></table></figure>

<p>监听指定端口</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump port 80</span><br></pre></td></tr></table></figure>

<p>监听TCP</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump tcp</span><br></pre></td></tr></table></figure>

<p>监听UDP</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump udp</span><br></pre></td></tr></table></figure>

<p>监听192.168.1.11的tcp协议的80端口的数据包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump tcp port 80 and src host 192.168.1.11</span><br><span class="line"></span><br><span class="line">11:59:07.836563 IP 192.168.1.11.39680 &gt; hello.http: Flags [.], ack 867022485, win 502, length 0</span><br><span class="line">11:59:07.836711 IP 192.168.1.11.39680 &gt; hello.http: Flags [P.], seq 0:77, ack 1, win 502, length 77: HTTP: HEAD / HTTP/1.1</span><br><span class="line">11:59:07.838462 IP 192.168.1.11.39680 &gt; hello.http: Flags [.], ack 248, win 501, length 0</span><br><span class="line">11:59:07.838848 IP 192.168.1.11.39680 &gt; hello.http: Flags [F.], seq 77, ack 248, win 501, length 0</span><br><span class="line">11:59:07.839192 IP 192.168.1.11.39680 &gt; hello.http: Flags [.], ack 249, win 501, length 0</span><br></pre></td></tr></table></figure>

<p>监听IP之间的包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump ip host 192.168.1.11 and 192.168.1.60</span><br><span class="line"></span><br><span class="line">11:57:52.742468 IP 192.168.1.11.38978 &gt; hello.http: Flags [S], seq 3437424457, win 64240, options [mss 1460,sackOK,TS val 2166810854 ecr 0,nop,wscale 7], length 0</span><br><span class="line">11:57:52.742606 IP hello.http &gt; 192.168.1.11.38978: Flags [S.], seq 3541873211, ack 3437424458, win 64240, options [mss 1460,nop,nop,sackOK,nop,wscale 7], length 0</span><br><span class="line">11:57:52.742841 IP 192.168.1.11.38978 &gt; hello.http: Flags [.], ack 1, win 502, length 0</span><br><span class="line">11:57:52.742927 IP 192.168.1.11.38978 &gt; hello.http: Flags [P.], seq 1:78, ack 1, win 502, length 77: HTTP: HEAD / HTTP/1.1</span><br><span class="line">11:57:52.742943 IP hello.http &gt; 192.168.1.11.38978: Flags [.], ack 78, win 502, length 0</span><br><span class="line">11:57:52.744407 IP hello.http &gt; 192.168.1.11.38978: Flags [P.], seq 1:248, ack 78, win 502, length 247: HTTP: HTTP/1.1 200 OK</span><br><span class="line">11:57:52.744613 IP 192.168.1.11.38978 &gt; hello.http: Flags [.], ack 248, win 501, length 0</span><br><span class="line">11:57:52.744845 IP 192.168.1.11.38978 &gt; hello.http: Flags [F.], seq 78, ack 248, win 501, length 0</span><br><span class="line">11:57:52.745614 IP hello.http &gt; 192.168.1.11.38978: Flags [F.], seq 248, ack 79, win 502, length 0</span><br><span class="line">11:57:52.745772 IP 192.168.1.11.38978 &gt; hello.http: Flags [.], ack 249, win 501, length 0</span><br></pre></td></tr></table></figure>

<p>监听除了与192.168.1.4之外的数据包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump ip host 192.168.1.60 and ! 192.168.1.4</span><br><span class="line"></span><br><span class="line">11:57:20.862575 IP 192.168.1.9.47190 &gt; hello.9200: Flags [P.], seq 3233461117:3233461356, ack 1301434191, win 9399, length 239</span><br><span class="line">11:57:20.878165 IP hello.9200 &gt; 192.168.1.9.47190: Flags [P.], seq 1:4097, ack 239, win 3081, length 4096</span><br><span class="line">11:57:20.878340 IP hello.9200 &gt; 192.168.1.9.47190: Flags [P.], seq 4097:8193, ack 239, win 3081, length 4096</span><br><span class="line">11:57:20.878417 IP 192.168.1.9.47190 &gt; hello.9200: Flags [.], ack 4097, win 9384, length 0</span><br></pre></td></tr></table></figure>

<p>组合示例</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump tcp -i ens18 -v -nn -t -A -s 0 -c 50 and dst port ! 22 and src net 192.168.1.0/24 -w ./cby.cap</span><br><span class="line"></span><br><span class="line">(1)tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型</span><br><span class="line">(2)-i eth1 : 只抓经过接口eth1的包</span><br><span class="line">(3)-t : 不显示时间戳</span><br><span class="line">(4)-s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包</span><br><span class="line">(5)-c 50 : 只抓取50个数据包</span><br><span class="line">(6)dst port ! 22 : 不抓取目标端口是22的数据包</span><br><span class="line">(7)src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24</span><br><span class="line">(8)-w ./cby.cap : 保存成cap文件，方便用ethereal(即wireshark)分析</span><br><span class="line">(9)-v 使用 -v，-vv 和 -vvv 来显示更多的详细信息，通常会显示更多与特定协议相关的信息。</span><br><span class="line">(10)-nn 单个 n 表示不解析域名，直接显示 IP；两个 n 表示不解析域名和端口。</span><br><span class="line">(11)-A 表示使用 ASCII 字符串打印报文的全部数据</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">组合过滤器  《与/AND/&amp;&amp;》 《或/OR/||》 《非/not/!》</span><br><span class="line">and or &amp;&amp;</span><br><span class="line">or or ||</span><br><span class="line">not or !</span><br></pre></td></tr></table></figure>

<p>在HTTP中提取用户头</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -nn -A -s0 -l | grep &quot;User-Agent:&quot;</span><br><span class="line"></span><br><span class="line">User-Agent: Prometheus/2.30.0</span><br><span class="line">User-Agent: Microsoft-Delivery-Optimization/10.0</span><br></pre></td></tr></table></figure>

<p>在HTTP中同时提取用户头和主机信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -nn -A -s0 -l | egrep -i &#x27;User-Agent:|Host:&#x27;</span><br><span class="line"></span><br><span class="line">Host: 192.168.1.42:9200</span><br><span class="line">User-Agent: Prometheus/2.30.0</span><br><span class="line">HOST: 239.255.255.250:1900</span><br><span class="line">USER-AGENT: Microsoft Edge/97.0.1072.55 Windows</span><br></pre></td></tr></table></figure>

<p>抓取 HTTP GET 流量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -s 0 -A -vv &#x27;tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] = 0x47455420&#x27;</span><br><span class="line"></span><br><span class="line">11:55:13.704801 IP (tos 0x0, ttl 64, id 14605, offset 0, flags [DF], proto TCP (6), length 291)</span><br><span class="line">    localhost.35498 &gt; localhost.9200: Flags [P.], cksum 0x849a (incorrect -&gt; 0xd0b0), seq 3090925559:3090925798, ack 809492640, win 630, options [nop,nop,TS val 2076158003 ecr 842090965], length 239</span><br><span class="line">E..#9.@.@.&#125;C... ...+..#..;..0?.....v.......</span><br><span class="line">&#123;..321I.GET /metrics HTTP/1.1</span><br><span class="line">Host: 192.168.1.43:9200</span><br><span class="line">User-Agent: Prometheus/2.30.0</span><br><span class="line">Accept: application/openmetrics-text; version=0.0.1,text/plain;version=0.0.4;q=0.5,*/*;q=0.1</span><br><span class="line">Accept-Encoding: gzip</span><br><span class="line">X-Prometheus-Scrape-Timeout-Seconds: 10</span><br></pre></td></tr></table></figure>

<p>抓取 HTTP POST 请求流量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -s 0 -A -vv &#x27;tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] = 0x504f5354&#x27;</span><br><span class="line"></span><br><span class="line">11:53:10.831855 IP (tos 0x0, ttl 63, id 0, offset 0, flags [none], proto TCP (6), length 643)</span><br><span class="line">    localhost.47702 &gt; dns50.online.tj.cn.http-alt: Flags [P.], cksum 0x1a41 (correct), seq 3331055769:3331056372, ack 799860501, win 4096, length 603: HTTP, length: 603</span><br><span class="line">        POST /?tk=391f8956e632962ee9c1dc661a9b46779d86ca43fe252bddbfc09d2cc66bf875323f6e7f03b881db21133b1bf2ae5bc5 HTTP/1.1</span><br><span class="line">        Host: 220.194.116.50:8080</span><br><span class="line">        Accept: */*</span><br><span class="line">        Accept-Language: zh-CN,zh-Hans;q=0.9</span><br><span class="line">        Q-Guid: e54764008893a559b852b6e9f1c8ae268958471308f41a96fd42e477e26323b8</span><br><span class="line">        Q-UA: </span><br><span class="line">        Accept-Encoding: gzip,deflate</span><br><span class="line">        Q-UA2: QV=3&amp;PL=IOS&amp;RF=SDK&amp;PR=IBS&amp;PP=com.tencent.mqq&amp;PPVN=3.8.0.1824&amp;TBSVC=18500&amp;DE=PHONE&amp;VE=GA&amp;CO=IMTT&amp;RL=1170*2532&amp;MO=iPhone14,2&amp;CHID=50001&amp;LCID=9751&amp;OS=15.1.1</span><br><span class="line">        Content-Length: 144</span><br><span class="line">        User-Agent: </span><br><span class="line">        QQ-S-ZIP: gzip</span><br><span class="line">        Connection: keep-alive</span><br><span class="line">        Content-Type: application/multipart-formdata</span><br><span class="line">        Q-Auth: </span><br><span class="line"></span><br><span class="line">E.......?.f.......t2.V....../...P....A..POST /?tk=391f8956e632962ee9c1dc661a9b46779d86ca43fe252bddbfc09d2cc66bf875323f6e7f03b881db21133b1bf2ae5bc5 HTTP/1.1</span><br><span class="line">Host: 220.194.116.50:8080</span><br><span class="line">Accept: */*</span><br><span class="line">Accept-Language: zh-CN,zh-Hans;q=0.9</span><br><span class="line">Q-Guid: e54764008893a559b852b6e9f1c8ae268958471308f41a96fd42e477e26323b8</span><br><span class="line">Q-UA: </span><br><span class="line">Accept-Encoding: gzip,deflate</span><br><span class="line">Q-UA2: QV=3&amp;PL=IOS&amp;RF=SDK&amp;PR=IBS&amp;PP=com.tencent.mqq&amp;PPVN=3.8.0.1824&amp;TBSVC=18500&amp;DE=PHONE&amp;VE=GA&amp;CO=IMTT&amp;RL=1170*2532&amp;MO=iPhone14,2&amp;CHID=50001&amp;LCID=9751&amp;OS=15.1.1</span><br><span class="line">Content-Length: 144</span><br><span class="line">User-Agent: </span><br><span class="line">QQ-S-ZIP: gzip</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Content-Type: application/multipart-formdata</span><br><span class="line">Q-Auth:</span><br></pre></td></tr></table></figure>

<p>注意：一个 POST 请求会被分割为多个 TCP 数据包</p>
<p>提取 HTTP 请求的主机名和路径</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@pve:~# tcpdump -s 0 -v -n -l | egrep -i &quot;POST /|GET /|Host:&quot;</span><br><span class="line"></span><br><span class="line">tcpdump: listening on eno1, link-type EN10MB (Ethernet), snapshot length 262144 bytes</span><br><span class="line">        GET /gchatpic_new/2779153238/851197814-3116860870-F4902AF1432FE48B812982F082A31097/0?term=255&amp;pictype=0 HTTP/1.1</span><br><span class="line">        Host: 112.80.128.33</span><br><span class="line">        GET /gchatpic_new/2779153238/851197814-3116860870-F4902AF1432FE48B812982F082A31097/0?term=255&amp;pictype=0 HTTP/1.1</span><br><span class="line">        Host: 112.80.128.33</span><br><span class="line">        POST /mmtls/74ce36ed HTTP/1.1</span><br><span class="line">        Host: extshort.weixin.qq.com</span><br><span class="line">        POST /mmtls/74ce36ed HTTP/1.1</span><br><span class="line">        Host: extshort.weixin.qq.com</span><br></pre></td></tr></table></figure>

<p>从 HTTP 请求中提取密码和主机名</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -s 0 -v -n -l | egrep -i &quot;POST /|GET /|pwd=|passwd=|password=|Host:&quot;</span><br><span class="line"></span><br><span class="line">        POST /index.php/action/login?_=b395d487431320461e9a6741e3828918 HTTP/1.1</span><br><span class="line">        Host: x.oiox.cn</span><br><span class="line">        name=cby&amp;password=Cby****&amp;referer=http%3A%2F%2Fx.oiox.cn%2Fadmin%2Fwelcome.php [|http]</span><br><span class="line">        POST /index.php/action/login?_=b395d487431320461e9a6741e3828918 HTTP/1.1</span><br><span class="line">        Host: x.oiox.cn</span><br><span class="line">        name=cby&amp;password=Cby****&amp;referer=http%3A%2F%2Fx.oiox.cn%2Fadmin%2Fwelcome.php [|http]</span><br><span class="line">        GET /admin/welcome.php HTTP/1.1</span><br><span class="line">        Host: x.oiox.cn</span><br></pre></td></tr></table></figure>

<p>从 HTTP 请求中提取Cookie信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -nn -A -s0 -l -v | egrep -i &#x27;Set-Cookie|Host:|Cookie:&#x27;</span><br><span class="line"></span><br><span class="line">Host: x.oiox.cn</span><br><span class="line">Cookie: 8bf110c223e1a04b7b63ca5aa97c9f61__typecho_uid=1; 8bf110cxxxxxxxb7b63ca5aa97c9f61__typecho_authCode=%24T%24W3hV7B9vRfefa6593049ba02c33b3c4796a7cfa35; PHPSESSID=bq67s1n0cb9ml6dq254qpdvfec</span><br></pre></td></tr></table></figure>

<p>通过排除 echo 和 reply 类型的数据包使抓取到的数据包不包括标准的 ping 包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump &#x27;icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply&#x27;</span><br><span class="line"></span><br><span class="line">11:20:32.285428 IP localhost &gt; localhost: ICMP localhost udp port 64594 unreachable, length 36</span><br><span class="line">11:20:32.522061 IP localhost &gt; localhost: ICMP localhost udp port 58617 unreachable, length 36</span><br><span class="line">11:20:37.736249 IP localhost &gt; localhost: ICMP redirect 204.79.197.219 to host localhost, length 48</span><br><span class="line">11:20:44.379646 IP localhost &gt; 111.206.187.34: ICMP localhost udp port 37643 unreachable, length 36</span><br><span class="line">11:20:44.379778 IP localhost &gt; 111.206.187.34: ICMP localhost udp port 37643 unreachable, length 36</span><br><span class="line">11:20:46.351245 IP localhost &gt; localhost: ICMP redirect lt-in-f188.1e100.net to host localhost, length 49</span><br></pre></td></tr></table></figure>

<p>可以通过过滤器 ip6 来抓取 IPv6 流量，同时可以指定协议如 TCP</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@vm371841:~# tcpdump -nn ip6 proto 6 -v</span><br><span class="line"></span><br><span class="line">tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">06:40:26.060313 IP6 (flowlabel 0xfe65e, hlim 64, next-header TCP (6) payload length: 40) 2a00:b700::e831:2aff:fe27:e9d9.44428 &gt; 2001:2030:21:181::26e7.443: Flags [S], cksum 0x451c (incorrect -&gt; 0x24cd), seq 3503520271, win 64800, options [mss 1440,sackOK,TS val 2504544710 ecr 0,nop,wscale 6], length 0</span><br><span class="line">06:40:34.296847 IP6 (flowlabel 0xc9f9c, hlim 64, next-header TCP (6) payload length: 40) 2a00:b700::e831:2aff:fe27:e9d9.55082 &gt; 2a00:1450:4010:c0e::84.443: Flags [S], cksum 0x6754 (incorrect -&gt; 0x0813), seq 3899361154, win 64800, options [mss 1440,sackOK,TS val 2141524802 ecr 0,nop,wscale 6], length 0</span><br></pre></td></tr></table></figure>

<p>发起的出站 DNS 请求和 A 记录响应</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0 -s0 port 53</span><br><span class="line"></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">06:44:10.499529 IP vm371841.37357 &gt; dns.yandex.ru.domain: 34151+ [1au] A? czr12g1e.slt-dk.sched.tdnsv8.com. (61)</span><br><span class="line">06:44:10.500992 IP vm371841.56195 &gt; dns.yandex.ru.domain: 45667+ [1au] PTR? 219.3.144.45.in-addr.arpa. (54)</span><br><span class="line">06:44:10.661142 IP dns.yandex.ru.domain &gt; vm371841.56195: 45667 NXDomain 0/1/1 (112)</span><br><span class="line">06:44:10.661438 IP vm371841.56195 &gt; dns.yandex.ru.domain: 45667+ PTR? 219.3.144.45.in-addr.arpa. (43)</span><br><span class="line">06:44:10.687147 IP dns.yandex.ru.domain &gt; vm371841.56195: 45667 NXDomain 0/1/0 (101)</span><br><span class="line">06:44:10.806349 IP dns.yandex.ru.domain &gt; vm371841.37357: 34151 11/0/1 A 139.170.156.155, A 220.200.129.141, A 58.243.200.63, A 113.59.43.25, A 124.152.41.39, A 139.170.156.154, A 59.83.204.154, A 123.157.255.158, A 113.200.17.157, A 43.242.166.42, A 116.177.248.23 (237)</span><br></pre></td></tr></table></figure>

<p>抓取 DHCP 服务的请求和响应报文</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcpdump -v -n port 67 or 68</span><br><span class="line"></span><br><span class="line">11:50:28.939726 IP (tos 0x0, ttl 64, id 35862, offset 0, flags [DF], proto UDP (17), length 320)</span><br><span class="line">    192.168.1.136.68 &gt; 255.255.255.255.67: BOOTP/DHCP, Request from 70:3a:a6:cb:27:3c, length 292, xid 0x3ccba40c, secs 11529, Flags [none]</span><br><span class="line">          Client-IP 192.168.1.136</span><br><span class="line">          Client-Ethernet-Address 70:3a:a6:cb:27:3c</span><br><span class="line">          Vendor-rfc1048 Extensions</span><br><span class="line">            Magic Cookie 0x63825363</span><br><span class="line">            DHCP-Message (53), length 1: Request</span><br><span class="line">            Client-ID (61), length 7: ether 70:3a:a6:cb:27:3c</span><br><span class="line">            Hostname (12), length 11: &quot;S24G-U_273C&quot;</span><br><span class="line">            Vendor-Class (60), length 13: &quot;CloudSwitch_1&quot;</span><br><span class="line">            MSZ (57), length 2: 800</span><br><span class="line">            Parameter-Request (55), length 5: </span><br><span class="line">              Subnet-Mask (1), Default-Gateway (3), Hostname (12), Domain-Name-Server (6)</span><br><span class="line">              Vendor-Class (60)</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a299144af1648f6afe7204e8fd26485~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>81篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a004bb5e94d14000b8b03d922c231461~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Kubernetes（K8S）内核优化常用参数详解</title>
    <url>/2022/02/10/2022-02-10-Kubernetes%EF%BC%88K8S%EF%BC%89%E5%86%85%E6%A0%B8%E4%BC%98%E5%8C%96%E5%B8%B8%E7%94%A8%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1f2345b8f7124d4a9569c7429d0403fb~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_keepalive_time=600</span><br><span class="line">net.ipv4.tcp_keepalive_intvl=30</span><br><span class="line">net.ipv4.tcp_keepalive_probes=10</span><br><span class="line">net.ipv6.conf.all.disable_ipv6=1</span><br><span class="line">net.ipv6.conf.default.disable_ipv6=1</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6=1</span><br><span class="line">net.ipv4.neigh.default.gc_stale_time=120</span><br><span class="line">net.ipv4.conf.all.rp_filter=0 </span><br><span class="line">net.ipv4.conf.default.rp_filter=0</span><br><span class="line">net.ipv4.conf.default.arp_announce=2</span><br><span class="line">net.ipv4.conf.lo.arp_announce=2</span><br><span class="line">net.ipv4.conf.all.arp_announce=2</span><br><span class="line">net.ipv4.ip_local_port_range= 45001 65000</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets=6000</span><br><span class="line">net.ipv4.tcp_syncookies=1</span><br><span class="line">net.ipv4.tcp_synack_retries=2</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line">net.ipv6.neigh.default.gc_thresh1=8192</span><br><span class="line">net.ipv6.neigh.default.gc_thresh2=32768</span><br><span class="line">net.ipv6.neigh.default.gc_thresh3=65536</span><br><span class="line">net.core.netdev_max_backlog=16384</span><br><span class="line">net.core.rmem_max = 16777216 </span><br><span class="line">net.core.wmem_max = 16777216</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 8096 </span><br><span class="line">net.core.somaxconn = 32768 </span><br><span class="line">fs.inotify.max_user_instances=8192 </span><br><span class="line">fs.inotify.max_user_watches=524288 </span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">kernel.pid_max = 4194303</span><br><span class="line">net.bridge.bridge-nf-call-arptables=1</span><br><span class="line">vm.swappiness=0 </span><br><span class="line">vm.overcommit_memory=1 </span><br><span class="line">vm.panic_on_oom=0 </span><br><span class="line">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure>

<p>内核参数解释</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_keepalive_time=600 #此参数表示TCP发送keepalive探测消息的间隔时间(秒)</span><br><span class="line">net.ipv4.tcp_keepalive_intvl=30 #tcp检查间隔时间（keepalive探测包的发送间隔）</span><br><span class="line">net.ipv4.tcp_keepalive_probes=10  #tcp检查次数（如果对方不予应答，探测包的发送次数）</span><br><span class="line">net.ipv6.conf.all.disable_ipv6=1 #禁用IPv6，修为0为启用IPv6</span><br><span class="line">net.ipv6.conf.default.disable_ipv6=1 #禁用IPv6，修为0为启用IPv6</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6=1 #禁用IPv6，修为0为启用IPv6</span><br><span class="line">net.ipv4.neigh.default.gc_stale_time=120 #ARP缓存条目超时</span><br><span class="line">net.ipv4.conf.all.rp_filter=0  #默认为1，系统会严格校验数据包的反向路径，可能导致丢包</span><br><span class="line">net.ipv4.conf.default.rp_filter=0 #不开启源地址校验</span><br><span class="line">net.ipv4.conf.default.arp_announce=2 #始终使用与目的IP地址对应的最佳本地IP地址作为ARP请求的源IP地址</span><br><span class="line">net.ipv4.conf.lo.arp_announce=2 #始终使用与目的IP地址对应的最佳本地IP地址作为ARP请求的源IP地址</span><br><span class="line">net.ipv4.conf.all.arp_announce=2 #始终使用与目的IP地址对应的最佳本地IP地址作为ARP请求的源IP地址</span><br><span class="line">net.ipv4.ip_local_port_range= 45001 65000 # 定义网络连接可用作其源（本地）端口的最小和最大端口的限制，同时适用于TCP和UDP连接。</span><br><span class="line">net.ipv4.ip_forward=1 # 其值为0,说明禁止进行IP转发；如果是1,则说明IP转发功能已经打开。</span><br><span class="line">net.ipv4.tcp_max_tw_buckets=6000 #配置服务器 TIME_WAIT 数量</span><br><span class="line">net.ipv4.tcp_syncookies=1 #此参数应该设置为1，防止SYN Flood</span><br><span class="line">net.ipv4.tcp_synack_retries=2 #表示回应第二个握手包（SYN+ACK包）给客户端IP后，如果收不到第三次握手包（ACK包），进行重试的次数（默认为5）</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1 # 是否在ip6tables链中过滤IPv6包</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1 # 二层的网桥在转发包时也会被iptables的FORWARD规则所过滤，这样有时会出现L3层的iptables rules去过滤L2的帧的问题</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720 #连接跟踪表的大小，建议根据内存计算该值CONNTRACK_MAX = RAMSIZE (in bytes) / 16384 / (x / 32)，并满足nf_conntrack_max=4*nf_conntrack_buckets，默认262144</span><br><span class="line"></span><br><span class="line">net.ipv6.neigh.default.gc_thresh1=8192</span><br><span class="line">net.ipv6.neigh.default.gc_thresh2=32768</span><br><span class="line">net.ipv6.neigh.default.gc_thresh3=65536</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">gc_thresh3 是表大小的绝对限制</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">gc_thresh2 设置为等于系统的最大预期邻居条目数的值</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在这种情况下，gc_thresh3 应该设置为一个比 gc_thresh2 值高的值，例如，比 gc_thresh2 高 25%-50%，将其视为浪涌容量。</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">gc_thresh1 提高到较大的值；此设置的作用是，如果表包含的条目少于 gc_thresh1，内核将永远不会删除（超时）过时的条目。</span></span><br><span class="line"></span><br><span class="line">net.core.netdev_max_backlog=16384 # 每CPU网络设备积压队列长度</span><br><span class="line">net.core.rmem_max = 16777216 # 所有协议类型读写的缓存区大小</span><br><span class="line">net.core.wmem_max = 16777216 # 最大的TCP数据发送窗口大小</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 8096 # 第一个积压队列长度</span><br><span class="line">net.core.somaxconn = 32768 # 第二个积压队列长度</span><br><span class="line">fs.inotify.max_user_instances=8192 # 表示每一个real user ID可创建的inotify instatnces的数量上限，默认128.</span><br><span class="line">fs.inotify.max_user_watches=524288 # 同一用户同时可以添加的watch数目，默认8192。</span><br><span class="line">fs.file-max=52706963 # 文件描述符的最大值</span><br><span class="line">fs.nr_open=52706963 #设置最大微博号打开数</span><br><span class="line">kernel.pid_max = 4194303 #最大进程数</span><br><span class="line">net.bridge.bridge-nf-call-arptables=1 #是否在arptables的FORWARD中过滤网桥的ARP包</span><br><span class="line">vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它</span><br><span class="line">vm.overcommit_memory=1 # 不检查物理内存是否够用</span><br><span class="line">vm.panic_on_oom=0 # 开启 OOM</span><br><span class="line">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3ddf552cf5334cce914774cb862f6037~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>82篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2a8ad52b4bd04c6ea2e40a1fb2fdaf57~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>使用二进制方式安装Docker</title>
    <url>/2022/02/11/2022-02-11-%E4%BD%BF%E7%94%A8%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85Docker/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c00fc713caab4f9eb63bf906cd86338f~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>长期使用安装工具进行安装docker，今天用二进制方式手动安装一下docker环境。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar xf docker-20.10.9.tgz </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">拷贝二进制文件</span></span><br><span class="line">cp docker/* /usr/bin/</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建containerd的service文件,并且启动</span></span><br><span class="line">cat &gt;/etc/systemd/system/containerd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=containerd container runtime</span><br><span class="line">Documentation=https://containerd.io</span><br><span class="line">After=network.target local-fs.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=-/sbin/modprobe overlay</span><br><span class="line">ExecStart=/usr/bin/containerd</span><br><span class="line">Type=notify</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">TasksMax=infinity</span><br><span class="line">OOMScoreAdjust=-999</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">systemctl enable --now containerd.service</span><br></pre></td></tr></table></figure>

<p>准备docker的service文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">准备docker的service文件</span></span><br><span class="line">cat &gt; /etc/systemd/system/docker.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">After=network-online.target firewalld.service containerd.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Requires=docker.socket containerd.service</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">TimeoutSec=0</span><br><span class="line">RestartSec=2</span><br><span class="line">Restart=always</span><br><span class="line">StartLimitBurst=3</span><br><span class="line">StartLimitInterval=60s</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">TasksMax=infinity</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">OOMScoreAdjust=-500</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">准备docker的socket文件</span></span><br><span class="line">cat &gt; /etc/systemd/system/docker.socket &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Socket for the API</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Socket]</span><br><span class="line">ListenStream=/var/run/docker.sock</span><br><span class="line">SocketMode=0660</span><br><span class="line">SocketUser=root</span><br><span class="line">SocketGroup=docker</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=sockets.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>启动验证  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建docker组</span></span><br><span class="line">groupadd docker</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动docker</span></span><br><span class="line">systemctl enable --now docker.socket  &amp;&amp; systemctl enable --now docker.service</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证</span></span><br><span class="line">docker info</span><br></pre></td></tr></table></figure>

<p>创建docker配置文件  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;/etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;registry-mirrors&quot;: [</span><br><span class="line">    &quot;https://docker.mirrors.ustc.edu.cn&quot;,</span><br><span class="line">    &quot;http://hub-mirror.c.163.com&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;max-concurrent-downloads&quot;: 10,</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-level&quot;: &quot;warn&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;10m&quot;,</span><br><span class="line">    &quot;max-file&quot;: &quot;3&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">  &quot;data-root&quot;: &quot;/var/lib/docker&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8533ac899a07494eb2246d82e20a5b4f~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>84篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a00b4962b82443a48fd24f7ecbf349a0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>CentOS安装时钟同步服务</title>
    <url>/2022/02/15/2022-02-15-CentOS%E5%AE%89%E8%A3%85%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dc6cf2866ac64e0698e289c141aa34a7~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>使用chrony用于时间同步</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install chrony -y</span><br><span class="line"></span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line"></span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">allow 10.0.0.0/8</span><br><span class="line">local stratum 10</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">systemctl restart chronyd</span><br><span class="line">systemctl enable chronyd</span><br></pre></td></tr></table></figure>

<p>客户端安装并配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install chrony -y</span><br><span class="line"></span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line"></span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool 10.0.0.20 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd ; systemctl enable chronyd</span><br></pre></td></tr></table></figure>

<p>使用客户端进行验证</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chronyc sources -v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  .-- Source mode  &#x27;^&#x27; = server, &#x27;=&#x27; = peer, &#x27;#&#x27; = local clock.</span><br><span class="line"> / .- Source state &#x27;*&#x27; = current best, &#x27;+&#x27; = combined, &#x27;-&#x27; = not combined,</span><br><span class="line">| /             &#x27;x&#x27; = may be in error, &#x27;~&#x27; = too variable, &#x27;?&#x27; = unusable.</span><br><span class="line">||                                                 .- xxxx [ yyyy ] +/- zzzz</span><br><span class="line">||      Reachability register (octal) -.           |  xxxx = adjusted offset,</span><br><span class="line">||      Log2(Polling interval) --.      |          |  yyyy = measured offset,</span><br><span class="line">||                                \     |          |  zzzz = estimated error.</span><br><span class="line">||                                 |    |           \</span><br><span class="line">MS Name/IP address         Stratum Poll Reach LastRx Last sample               </span><br><span class="line">===============================================================================</span><br><span class="line">^* master01                      3   6    17     7  -2539ns[  -29us] +/-   16ms</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>安装部署keepalived的HA环境</title>
    <url>/2022/02/23/2022-02-23-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2keepalived%E7%9A%84HA%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c45170c66b0d47aeb9bb02fe9527e720~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>每一台配置下keepalived</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">master01 配置：</span></span><br><span class="line">cat &gt;/etc/keepalived/keepalived.conf&lt;&lt;&quot;EOF&quot;</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">   script_user root</span><br><span class="line">   enable_script_security</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">   script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">   interval 5</span><br><span class="line">   weight -5</span><br><span class="line">   fall 2</span><br><span class="line">   rise 1 #检测一次成功，则认为在线</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">   state BACKUP</span><br><span class="line">   nopreempt</span><br><span class="line">   interface ens160</span><br><span class="line">   mcast_src_ip 10.0.0.20</span><br><span class="line">   virtual_router_id 51</span><br><span class="line">   priority 100</span><br><span class="line">   advert_int 2</span><br><span class="line">   authentication &#123;</span><br><span class="line">       auth_type PASS</span><br><span class="line">       auth_pass K8SHA_KA_AUTH</span><br><span class="line">   &#125;</span><br><span class="line">   virtual_ipaddress &#123;</span><br><span class="line">       10.0.0.30</span><br><span class="line">   &#125;</span><br><span class="line">   track_script &#123;</span><br><span class="line">      chk_apiserver</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Master02 配置：</span></span><br><span class="line">cat &gt;/etc/keepalived/keepalived.conf&lt;&lt;&quot;EOF&quot;</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">   script_user root</span><br><span class="line">   enable_script_security</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">   script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">  interval 5</span><br><span class="line">   weight -5</span><br><span class="line">   fall 2 </span><br><span class="line">   rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">   state BACKUP</span><br><span class="line">   nopreempt</span><br><span class="line">   interface ens160</span><br><span class="line">   mcast_src_ip 10.0.0.21</span><br><span class="line">   virtual_router_id 51</span><br><span class="line">   priority 99</span><br><span class="line">   advert_int 2</span><br><span class="line">   authentication &#123;</span><br><span class="line">       auth_type PASS</span><br><span class="line">       auth_pass K8SHA_KA_AUTH</span><br><span class="line">   &#125;</span><br><span class="line">   virtual_ipaddress &#123;</span><br><span class="line">       10.0.0.30</span><br><span class="line">   &#125;</span><br><span class="line">   track_script &#123;</span><br><span class="line">      chk_apiserver</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Master03 配置：</span></span><br><span class="line">cat &gt;/etc/keepalived/keepalived.conf&lt;&lt;&quot;EOF&quot;</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">   script_user root</span><br><span class="line">   enable_script_security</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">   script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line"> interval 5</span><br><span class="line">   weight -5</span><br><span class="line">   fall 2 </span><br><span class="line">   rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">   state BACKUP</span><br><span class="line">   nopreempt</span><br><span class="line">   interface ens160</span><br><span class="line">   mcast_src_ip 10.0.0.22</span><br><span class="line">   virtual_router_id 51</span><br><span class="line">   priority 98</span><br><span class="line">   advert_int 2</span><br><span class="line">   authentication &#123;</span><br><span class="line">       auth_type PASS</span><br><span class="line">       auth_pass K8SHA_KA_AUTH</span><br><span class="line">   &#125;</span><br><span class="line">   virtual_ipaddress &#123;</span><br><span class="line">       10.0.0.30</span><br><span class="line">   &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver</span><br><span class="line">   &#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>健康检查脚本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/keepalived/check_apiserver.sh &lt;&lt;&quot;EOF&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">err=0</span><br><span class="line">for k in $(seq 1 3)</span><br><span class="line">do</span><br><span class="line">   check_code=$(pgrep haproxy)</span><br><span class="line">   if [[ $check_code == &quot;&quot; ]]; then</span><br><span class="line">       err=$(expr $err + 1)</span><br><span class="line">       sleep 1</span><br><span class="line">       continue</span><br><span class="line">   else</span><br><span class="line">       err=0</span><br><span class="line">       break</span><br><span class="line">   fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [[ $err != &quot;0&quot; ]]; then</span><br><span class="line">   echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">   /usr/bin/systemctl stop keepalived</span><br><span class="line">   exit 1</span><br><span class="line">else</span><br><span class="line">   exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">chmod u+x /etc/keepalived/check_apiserver.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">启动服务</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now keepalived</span><br></pre></td></tr></table></figure>


<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装Kubernetes，一键安装脚本</title>
    <url>/2022/03/01/2022-03-01-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85Kubernetes%EF%BC%8C%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<p><strong>背景</strong>，最近几天闲着研究Kubernetes，发现使用手动二进制安装会有些繁琐。经过突发奇想，就出现这个脚本。</p>
<p><strong>声明</strong>，该脚本不及互联网上其他大佬的一件脚本，该脚本仅仅是突发奇想编写的，希望大佬不喜勿喷。</p>
<p>这个脚本执行环境比较苛刻，我写的这个脚本比较垃圾，还未能达到各种环境下都可以执行。  </p>
<p>当前脚本Kubernetes集群，以及lb负载均衡，需要在CentOS系统，执行脚本节点可以选择Ubuntu或者CentOS系统。  </p>
<p>当前脚本中引用的Kubernetes二进制包是v1.23.3</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/31d5ac532dde4228996cc7404e4ec823~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<table>
<thead>
<tr>
<th>主机名称</th>
<th>IP地址</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td>Master01</td>
<td>192.168.1.40</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master02</td>
<td>192.168.1.41</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master03</td>
<td>192.168.1.42</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node01</td>
<td>192.168.1.43</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node02</td>
<td>192.168.1.44</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Lb01</td>
<td>192.168.1.45</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Lb02</td>
<td>192.168.1.46</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td></td>
<td>192.168.1.55</td>
<td>vip</td>
<td></td>
</tr>
<tr>
<td>cby</td>
<td>192.168.1.60</td>
<td>执行脚本节点</td>
<td>bash</td>
</tr>
</tbody></table>
<p>作者：陈步云</p>
<p>微信：15648907522</p>
<p>项目地址：<a href="https://github.com/cby-chen/Binary/_installation/_of/_Kubernetes">https://github.com/cby-chen/Binary\_installation\_of\_Kubernetes</a></p>
<p>使用说明：</p>
<p>该脚本需要八台服务器，在八台服务器中有一台是用于执行该脚本的，另外有五台k8s服务器，其他俩台作为lb负载均衡服务器。</p>
<p>将其中七台服务器配置好静态IP，修改如下变量中的IP即可。</p>
<p>同时查看服务器中的网卡名，并将其修改。</p>
<p>执行脚本可使用bash -x 即可显示执行中详细信息。</p>
<p>该脚本暂时不支持自定义k8s结构，需要严格执行该结构。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">脚本中是需要在GitHub上下载软件包</span><br><span class="line">可以手动提前下载好</span><br><span class="line"></span><br><span class="line">wget https://github.com/cby-chen/Kubernetes/releases/download/cby/Kubernetes.tar​</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">下载脚本</span><br><span class="line"></span><br><span class="line">wget https://www.oiox.cn/Binary_installation_of_Kubernetes.sh</span><br><span class="line"></span><br><span class="line">修改参数</span><br><span class="line"></span><br><span class="line">vim Binary_installation_of_Kubernetes.sh</span><br><span class="line"></span><br><span class="line">如下：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">每个节点的IP，以及vip</span></span><br><span class="line">export k8s_master01=&quot;192.168.1.40&quot;</span><br><span class="line">export k8s_master02=&quot;192.168.1.41&quot;</span><br><span class="line">export k8s_master03=&quot;192.168.1.42&quot;</span><br><span class="line">export k8s_node01=&quot;192.168.1.43&quot;</span><br><span class="line">export k8s_node02=&quot;192.168.1.44&quot;</span><br><span class="line">export lb_01=&quot;192.168.1.45&quot;</span><br><span class="line">export lb_02=&quot;192.168.1.46&quot;</span><br><span class="line">export lb_vip=&quot;192.168.1.55&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">物理网络ip地址段，注意反斜杠转译</span></span><br><span class="line">export ip_segment=&quot;192.168.1.0\/24&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">k8s自定义域名</span></span><br><span class="line">export domain=&quot;x.oiox.cn&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">服务器网卡名</span></span><br><span class="line">export eth=&quot;ens18&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">执行脚本</span><br><span class="line"></span><br><span class="line">bash -x Binary_installation_of_Kubernetes.sh</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a><br><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、<br>腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>​KubeSphere离线无网络环境部署</title>
    <url>/2022/01/13/2022-01-13-%E2%80%8BKubeSphere%E7%A6%BB%E7%BA%BF%E6%97%A0%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1 id="KubeSphere离线无网络环境部署"><a href="#KubeSphere离线无网络环境部署" class="headerlink" title="KubeSphere离线无网络环境部署"></a><strong>KubeSphere离线无网络环境部署</strong></h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/79d332c424e348aa972488f3ae51f1d1~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>KubeSphere 是 GitHub 上的一个开源项目，是成千上万名社区用户的聚集地。很多用户都在使用 KubeSphere 运行工作负载。对于在 Linux 上的安装，KubeSphere 既可以部署在云端，也可以部署在本地环境中，例如 AWS EC2、Azure VM 和裸机等。</p>
<p>KubeSphere 为用户提供轻量级安装程序 KubeKey（该程序支持安装 Kubernetes、KubeSphere 及相关插件），安装过程简单而友好。KubeKey 不仅能帮助用户在线创建集群，还能作为离线安装解决方案。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dbe0a5301f4b4f85a59db30ba39716f8~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="前期准备所需包"><a href="#前期准备所需包" class="headerlink" title="前期准备所需包"></a><strong>前期准备所需包</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">前期准备所需包</span></span><br><span class="line">root@hello:~# wget https://github.com/kubesphere/kubekey/releases/download/v1.2.1/kubekey-v1.2.1-linux-amd64.tar.gz</span><br><span class="line">root@hello:~# tar xvf kubekey-v1.2.1-linux-amd64.tar.gz </span><br><span class="line">root@hello:~# ls kk </span><br><span class="line">kk</span><br><span class="line">root@hello:~#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# curl -L -O https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/images-list.txt</span><br><span class="line">root@hello:~# curl -L -O https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/offline-installation-tool.sh</span><br><span class="line"></span><br><span class="line">root@hello:~# chmod +x offline-installation-tool.sh</span><br><span class="line"></span><br><span class="line">root@hello:~# export KKZONE=cn</span><br><span class="line">root@hello:~# ./offline-installation-tool.sh -b</span><br><span class="line"></span><br><span class="line">root@hello:~# ./offline-installation-tool.sh -s -l images-list.txt -d ./kubesphere-images</span><br><span class="line"></span><br><span class="line">root@hello:~# curl -L -o /root/kubekey/v1.21.5/amd64/docker-20.10.8.tgz https://download.docker.com/linux/static/stable/x86_64/docker-20.10.8.tgz</span><br><span class="line"></span><br><span class="line">root@hello:~# curl -L -o /root/kubekey/v1.21.5/amd64/crictl-v1.22.0-linux-amd64.tar.gz https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.22.0/crictl-v1.22.0-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h1 id="离线环境安装"><a href="#离线环境安装" class="headerlink" title="离线环境安装"></a><strong>离线环境安装</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建证书，注意“Common Name” 需要写域名</span></span><br><span class="line"></span><br><span class="line">root@cby:~# mkdir -p certs</span><br><span class="line">root@cby:~# openssl req \</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">-newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \</span></span><br><span class="line"><span class="language-bash">&gt; -x509 -days 36500 -out certs/domain.crt</span></span><br><span class="line">Generating a RSA private key</span><br><span class="line">............++++</span><br><span class="line">.......++++</span><br><span class="line">writing new private key to &#x27;certs/domain.key&#x27;</span><br><span class="line">-----</span><br><span class="line">You are about to be asked to enter information that will be incorporated</span><br><span class="line">into your certificate request.</span><br><span class="line">What you are about to enter is what is called a Distinguished Name or a DN.</span><br><span class="line">There are quite a few fields but you can leave some blank</span><br><span class="line">For some fields there will be a default value,</span><br><span class="line">If you enter &#x27;.&#x27;, the field will be left blank.</span><br><span class="line">-----</span><br><span class="line">Country Name (2 letter code) [AU]:</span><br><span class="line">State or Province Name (full name) [Some-State]:</span><br><span class="line">Locality Name (eg, city) []:</span><br><span class="line">Organization Name (eg, company) [Internet Widgits Pty Ltd]:</span><br><span class="line">Organizational Unit Name (eg, section) []:</span><br><span class="line">Common Name (e.g. server FQDN or YOUR name) []:dockerhub.kubekey.local</span><br><span class="line">Email Address []:</span><br><span class="line">root@cby:~#</span><br></pre></td></tr></table></figure>

<h1 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a><strong>安装docker</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装docker</span></span><br><span class="line"></span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~/package# ll</span><br><span class="line">total 94776</span><br><span class="line">drwxr-xr-x 2 root root     4096 Jan 12 07:17 ./</span><br><span class="line">drwx------ 7 root root     4096 Jan 12 07:16 ../</span><br><span class="line">-rw-r--r-- 1 root root 23703726 Jan 12 07:17 containerd.io_1.4.12-1_amd64.deb</span><br><span class="line">-rw-r--r-- 1 root root 21234738 Jan 12 07:16 docker-ce_5%3a20.10.12~3-0~ubuntu-focal_amd64.deb</span><br><span class="line">-rw-r--r-- 1 root root 40652850 Jan 12 07:16 docker-ce-cli_5%3a20.10.12~3-0~ubuntu-focal_amd64.deb</span><br><span class="line">-rw-r--r-- 1 root root  7921036 Jan 12 07:16 docker-ce-rootless-extras_5%3a20.10.12~3-0~ubuntu-focal_amd64.deb</span><br><span class="line">-rw-r--r-- 1 root root  3517780 Jan 12 07:16 docker-scan-plugin_0.12.0~ubuntu-focal_amd64.deb</span><br><span class="line">root@cby:~/package# </span><br><span class="line">root@cby:~/package# apt install ./*</span><br></pre></td></tr></table></figure>

<h1 id="部署镜像仓库"><a href="#部署镜像仓库" class="headerlink" title="部署镜像仓库"></a><strong>部署镜像仓库</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">导入镜像</span></span><br><span class="line">root@cby:~/cby# docker load -i registry.tar</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动 Docker 仓库</span></span><br><span class="line">root@cby:~# docker run -d   --restart=always   --name registry   -v &quot;$(pwd)&quot;/certs:/certs   -v /mnt/registry:/var/lib/registry   -e REGISTRY_HTTP_ADDR=0.0.0.0:443   -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt   -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key   -p 443:443   registry:2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置仓库</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在 /etc/hosts 中添加一个条目</span></span><br><span class="line">root@cby:~# vim /etc/hosts</span><br><span class="line">root@cby:~# cat /etc/hosts</span><br><span class="line">3.7.191.234 dockerhub.kubekey.local</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置免证书</span></span><br><span class="line">root@cby:~# mkdir -p  /etc/docker/certs.d/dockerhub.kubekey.local</span><br><span class="line">root@cby:~# cp certs/domain.crt  /etc/docker/certs.d/dockerhub.kubekey.local/ca.crt</span><br><span class="line">root@cby:~# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置免验证</span></span><br><span class="line">root@cby:~# cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">   &quot;insecure-registries&quot;:[&quot;https://dockerhub.kubekey.local&quot;]</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重载配置，并重启</span></span><br><span class="line">root@cby:~# systemctl daemon-reload</span><br><span class="line">root@cby:~# systemctl restart docker</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="部署-KubeSphere-和-kubernetes"><a href="#部署-KubeSphere-和-kubernetes" class="headerlink" title="部署 KubeSphere 和 kubernetes"></a><strong>部署 KubeSphere 和 kubernetes</strong></h1><p><strong>注意添加字段“privateRegistry”</strong>  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加执行权限</span></span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# chmod +x kk</span><br><span class="line">root@cby:~# chmod +x offline-installation-tool.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">推送镜像到私有仓库</span></span><br><span class="line">root@cby:~# ./offline-installation-tool.sh -l images-list.txt -d ./kubesphere-images -r dockerhub.kubekey.local</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~# apt install conntrack</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~# ./kk create config --with-kubernetes v1.21.5 --with-kubesphere v3.2.1 -f config-sample.yaml</span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# vim config-sample.yaml </span><br><span class="line">root@cby:~# cat config-sample.yaml</span><br><span class="line">apiVersion: kubekey.kubesphere.io/v1alpha1</span><br><span class="line">kind: Cluster</span><br><span class="line">metadata:</span><br><span class="line">  name: sample</span><br><span class="line">spec:</span><br><span class="line">  hosts:</span><br><span class="line">  - &#123;name: master, address: 3.7.191.234, internalAddress: 3.7.191.234, user: root, password: Cby23..&#125;</span><br><span class="line">  - &#123;name: node1, address: 3.7.191.235, internalAddress: 3.7.191.235, user: root, password: Cby23..&#125;</span><br><span class="line">  - &#123;name: node2, address: 3.7.191.238, internalAddress: 3.7.191.238, user: root, password: Cby23..&#125;</span><br><span class="line">  roleGroups:</span><br><span class="line">    etcd:</span><br><span class="line">    - master</span><br><span class="line">    master: </span><br><span class="line">    - node1</span><br><span class="line">    worker:</span><br><span class="line">    - node1</span><br><span class="line">    - node2</span><br><span class="line">  controlPlaneEndpoint:</span><br><span class="line">    ##Internal loadbalancer for apiservers </span><br><span class="line">    #internalLoadbalancer: haproxy</span><br><span class="line"></span><br><span class="line">    domain: lb.kubesphere.local</span><br><span class="line">    address: &quot;&quot;</span><br><span class="line">    port: 6443</span><br><span class="line">  kubernetes:</span><br><span class="line">    version: v1.21.5</span><br><span class="line">    clusterName: cluster.local</span><br><span class="line">  network:</span><br><span class="line">    plugin: calico</span><br><span class="line">    kubePodsCIDR: 10.233.64.0/18</span><br><span class="line">    kubeServiceCIDR: 10.233.0.0/18</span><br><span class="line">  registry:</span><br><span class="line">    registryMirrors: []</span><br><span class="line">    insecureRegistries: []</span><br><span class="line">    privateRegistry: dockerhub.kubekey.local</span><br><span class="line">  addons: []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: installer.kubesphere.io/v1alpha1</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  name: ks-installer</span><br><span class="line">  namespace: kubesphere-system</span><br><span class="line">  labels:</span><br><span class="line">    version: v3.2.1</span><br><span class="line">spec:</span><br><span class="line">  persistence:</span><br><span class="line">    storageClass: &quot;&quot;</span><br><span class="line">  authentication:</span><br><span class="line">    jwtSecret: &quot;&quot;</span><br><span class="line">  local_registry: &quot;&quot;</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">dev_tag: <span class="string">&quot;&quot;</span></span></span><br><span class="line">  etcd:</span><br><span class="line">    monitoring: false</span><br><span class="line">    endpointIps: localhost</span><br><span class="line">    port: 2379</span><br><span class="line">    tlsEnable: true</span><br><span class="line">  common:</span><br><span class="line">    core:</span><br><span class="line">      console:</span><br><span class="line">        enableMultiLogin: true</span><br><span class="line">        port: 30880</span><br><span class="line">        type: NodePort</span><br><span class="line">    # apiserver:</span><br><span class="line">    #  resources: &#123;&#125;</span><br><span class="line">    # controllerManager:</span><br><span class="line">    #  resources: &#123;&#125;</span><br><span class="line">    redis:</span><br><span class="line">      enabled: false</span><br><span class="line">      volumeSize: 2Gi</span><br><span class="line">    openldap:</span><br><span class="line">      enabled: false</span><br><span class="line">      volumeSize: 2Gi</span><br><span class="line">    minio:</span><br><span class="line">      volumeSize: 20Gi</span><br><span class="line">    monitoring:</span><br><span class="line">      # type: external</span><br><span class="line">      endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090</span><br><span class="line">      GPUMonitoring:</span><br><span class="line">        enabled: false</span><br><span class="line">    gpu:</span><br><span class="line">      kinds:         </span><br><span class="line">      - resourceName: &quot;nvidia.com/gpu&quot;</span><br><span class="line">        resourceType: &quot;GPU&quot;</span><br><span class="line">        default: true</span><br><span class="line">    es:</span><br><span class="line">      # master:</span><br><span class="line">      #   volumeSize: 4Gi</span><br><span class="line">      #   replicas: 1</span><br><span class="line">      #   resources: &#123;&#125;</span><br><span class="line">      # data:</span><br><span class="line">      #   volumeSize: 20Gi</span><br><span class="line">      #   replicas: 1</span><br><span class="line">      #   resources: &#123;&#125;</span><br><span class="line">      logMaxAge: 7</span><br><span class="line">      elkPrefix: logstash</span><br><span class="line">      basicAuth:</span><br><span class="line">        enabled: false</span><br><span class="line">        username: &quot;&quot;</span><br><span class="line">        password: &quot;&quot;</span><br><span class="line">      externalElasticsearchHost: &quot;&quot;</span><br><span class="line">      externalElasticsearchPort: &quot;&quot;</span><br><span class="line">  alerting:</span><br><span class="line">    enabled: false</span><br><span class="line">    # thanosruler:</span><br><span class="line">    #   replicas: 1</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">  auditing:</span><br><span class="line">    enabled: false</span><br><span class="line">    # operator:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # webhook:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">  devops:</span><br><span class="line">    enabled: false</span><br><span class="line">    jenkinsMemoryLim: 2Gi</span><br><span class="line">    jenkinsMemoryReq: 1500Mi</span><br><span class="line">    jenkinsVolumeSize: 8Gi</span><br><span class="line">    jenkinsJavaOpts_Xms: 512m</span><br><span class="line">    jenkinsJavaOpts_Xmx: 512m</span><br><span class="line">    jenkinsJavaOpts_MaxRAM: 2g</span><br><span class="line">  events:</span><br><span class="line">    enabled: false</span><br><span class="line">    # operator:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # exporter:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # ruler:</span><br><span class="line">    #   enabled: true</span><br><span class="line">    #   replicas: 2</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">  logging:</span><br><span class="line">    enabled: false</span><br><span class="line">    containerruntime: docker</span><br><span class="line">    logsidecar:</span><br><span class="line">      enabled: true</span><br><span class="line">      replicas: 2</span><br><span class="line">      # resources: &#123;&#125;</span><br><span class="line">  metrics_server:</span><br><span class="line">    enabled: false</span><br><span class="line">  monitoring:</span><br><span class="line">    storageClass: &quot;&quot;</span><br><span class="line">    # kube_rbac_proxy:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # kube_state_metrics:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # prometheus:</span><br><span class="line">    #   replicas: 1</span><br><span class="line">    #   volumeSize: 20Gi</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    #   operator:</span><br><span class="line">    #     resources: &#123;&#125;</span><br><span class="line">    #   adapter:</span><br><span class="line">    #     resources: &#123;&#125;</span><br><span class="line">    # node_exporter:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # alertmanager:</span><br><span class="line">    #   replicas: 1</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    # notification_manager:</span><br><span class="line">    #   resources: &#123;&#125;</span><br><span class="line">    #   operator:</span><br><span class="line">    #     resources: &#123;&#125;</span><br><span class="line">    #   proxy:</span><br><span class="line">    #     resources: &#123;&#125;</span><br><span class="line">    gpu:</span><br><span class="line">      nvidia_dcgm_exporter:</span><br><span class="line">        enabled: false</span><br><span class="line">        # resources: &#123;&#125;</span><br><span class="line">  multicluster:</span><br><span class="line">    clusterRole: none </span><br><span class="line">  network:</span><br><span class="line">    networkpolicy:</span><br><span class="line">      enabled: false</span><br><span class="line">    ippool:</span><br><span class="line">      type: none</span><br><span class="line">    topology:</span><br><span class="line">      type: none</span><br><span class="line">  openpitrix:</span><br><span class="line">    store:</span><br><span class="line">      enabled: false</span><br><span class="line">  servicemesh:</span><br><span class="line">    enabled: false</span><br><span class="line">  kubeedge:</span><br><span class="line">    enabled: false   </span><br><span class="line">    cloudCore:</span><br><span class="line">      nodeSelector: &#123;&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;&#125;</span><br><span class="line">      tolerations: []</span><br><span class="line">      cloudhubPort: &quot;10000&quot;</span><br><span class="line">      cloudhubQuicPort: &quot;10001&quot;</span><br><span class="line">      cloudhubHttpsPort: &quot;10002&quot;</span><br><span class="line">      cloudstreamPort: &quot;10003&quot;</span><br><span class="line">      tunnelPort: &quot;10004&quot;</span><br><span class="line">      cloudHub:</span><br><span class="line">        advertiseAddress:</span><br><span class="line">          - &quot;&quot;</span><br><span class="line">        nodeLimit: &quot;100&quot;</span><br><span class="line">      service:</span><br><span class="line">        cloudhubNodePort: &quot;30000&quot;</span><br><span class="line">        cloudhubQuicNodePort: &quot;30001&quot;</span><br><span class="line">        cloudhubHttpsNodePort: &quot;30002&quot;</span><br><span class="line">        cloudstreamNodePort: &quot;30003&quot;</span><br><span class="line">        tunnelNodePort: &quot;30004&quot;</span><br><span class="line">    edgeWatcher:</span><br><span class="line">      nodeSelector: &#123;&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;&#125;</span><br><span class="line">      tolerations: []</span><br><span class="line">      edgeWatcherAgent:</span><br><span class="line">        nodeSelector: &#123;&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;&#125;</span><br><span class="line">        tolerations: []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# </span><br><span class="line">root@cby:~# ./kk create cluster -f config-sample.yaml</span><br><span class="line"></span><br><span class="line">----略</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##              Welcome to KubeSphere!           ###</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"></span><br><span class="line">Console: http://3.7.191.235:30880</span><br><span class="line">Account: admin</span><br><span class="line">Password: P@88w0rd</span><br><span class="line"></span><br><span class="line">NOTES：</span><br><span class="line">  1. After you log into the console, please check the</span><br><span class="line">     monitoring status of service components in</span><br><span class="line">     &quot;Cluster Management&quot;. If any service is not</span><br><span class="line">     ready, please wait patiently until all components </span><br><span class="line">     are up and running.</span><br><span class="line">  2. Please change the default password after login.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line">https://kubesphere.io             2022-01-12 09:42:36</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line">INFO[09:42:45 UTC] Installation is complete.</span><br><span class="line"></span><br><span class="line">Please check the result using the command:</span><br><span class="line"></span><br><span class="line">       kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br><span class="line"> </span><br><span class="line">root@cby:~#</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a1b19233820f41b98ceb81901e3ed74b~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p><strong>Linux运维交流社区</strong></p>
<p>Linux运维交流社区，互联网新闻以及技术交流。</p>
<p>80篇原创内容</p>
<p>公众号</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94c73468482249cb92600879733f214d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kube-apiserver启动命令参数解释</title>
    <url>/2022/03/07/2022-03-07-kube-apiserver%E5%90%AF%E5%8A%A8%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A/</url>
    <content><![CDATA[<p>在apiserver启动时候会有很多参数来配置启动命令，有些时候不是很明白这些参数具体指的是什么意思。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5dec6da363b54737bf341d947489e7e8~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>我的kube-apiserver启动命令参数：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.30 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.30:2379,https://192.168.1.31:2379,https://192.168.1.32:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>解释</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-v, --v int</span><br><span class="line">日志级别详细程度的数字。</span><br><span class="line"></span><br><span class="line">--logtostderr     默认值：true</span><br><span class="line">在标准错误而不是文件中输出日志记录。</span><br><span class="line">--bind-address string     默认值：&quot;0.0.0.0&quot;</span><br><span class="line">用来监听 --secure-port 端口的 IP 地址。集群的其余部分以及 CLI/web 客户端必须可以访问所关联的接口。如果为空白或未指定地址（0.0.0.0 或 ::），则将使用所有接口。</span><br><span class="line"></span><br><span class="line">--secure-port int     默认值：6443</span><br><span class="line">带身份验证和鉴权机制的 HTTPS 服务端口。不能用 0 关闭。</span><br><span class="line"></span><br><span class="line">--advertise-address string</span><br><span class="line">向集群成员通知 apiserver 消息的 IP 地址。这个地址必须能够被集群中其他成员访问。如果 IP 地址为空，将会使用 --bind-address， 如果未指定 --bind-address，将会使用主机的默认接口地址。</span><br><span class="line"></span><br><span class="line">--service-cluster-ip-range string</span><br><span class="line">CIDR 表示的 IP 范围用来为服务分配集群 IP。此地址不得与指定给节点或 Pod 的任何 IP 范围重叠。</span><br><span class="line"></span><br><span class="line">--service-node-port-range &lt;形式为 &#x27;N1-N2&#x27; 的字符串&gt;     默认值：30000-32767</span><br><span class="line">保留给具有 NodePort 可见性的服务的端口范围。例如：&quot;30000-32767&quot;。范围的两端都包括在内。</span><br><span class="line"></span><br><span class="line">--etcd-servers strings</span><br><span class="line">要连接的 etcd 服务器列表（scheme://ip:port），以逗号分隔。</span><br><span class="line"></span><br><span class="line">--etcd-cafile string</span><br><span class="line">用于保护 etcd 通信的 SSL 证书颁发机构文件。</span><br><span class="line"></span><br><span class="line">--etcd-certfile string</span><br><span class="line">用于保护 etcd 通信的 SSL 证书文件。</span><br><span class="line"></span><br><span class="line">--etcd-keyfile string</span><br><span class="line">用于保护 etcd 通信的 SSL 密钥文件。</span><br><span class="line"></span><br><span class="line">--client-ca-file string</span><br><span class="line">如果已设置，则使用与客户端证书的 CommonName 对应的标识对任何出示由 client-ca 文件中的授权机构之一签名的客户端证书的请求进行身份验证。</span><br><span class="line"></span><br><span class="line">--tls-cert-file string</span><br><span class="line">包含用于 HTTPS 的默认 x509 证书的文件。（CA 证书（如果有）在服务器证书之后并置）。如果启用了 HTTPS 服务，并且未提供 --tls-cert-file 和 --tls-private-key-file， 为公共地址生成一个自签名证书和密钥，并将其保存到 --cert-dir 指定的目录中。</span><br><span class="line"></span><br><span class="line">--tls-private-key-file string</span><br><span class="line">包含匹配 --tls-cert-file 的 x509 证书私钥的文件。</span><br><span class="line"></span><br><span class="line">--kubelet-client-certificate string</span><br><span class="line">TLS 的客户端证书文件的路径。</span><br><span class="line"></span><br><span class="line">--kubelet-client-key string</span><br><span class="line">TLS 客户端密钥文件的路径。</span><br><span class="line"></span><br><span class="line">--service-account-key-file strings</span><br><span class="line">包含 PEM 编码的 x509 RSA 或 ECDSA 私钥或公钥的文件，用于验证 ServiceAccount 令牌。指定的文件可以包含多个键，并且可以使用不同的文件多次指定标志。如果未指定，则使用 --tls-private-key-file。提供 --service-account-signing-key 时必须指定。</span><br><span class="line"></span><br><span class="line">--service-account-signing-key-file string</span><br><span class="line">包含服务帐户令牌颁发者当前私钥的文件的路径。颁发者将使用此私钥签署所颁发的 ID 令牌。</span><br><span class="line"></span><br><span class="line">--service-account-issuer strings</span><br><span class="line">服务帐号令牌颁发者的标识符。颁发者将在已办法令牌的 &quot;iss&quot; 声明中检查此标识符。此值为字符串或 URI。如果根据 OpenID Discovery 1.0 规范检查此选项不是有效的 URI，则即使特性门控设置为 true， ServiceAccountIssuerDiscovery 功能也将保持禁用状态。强烈建议该值符合 OpenID 规范：https://openid.net/specs/openid-connect-discovery-1_0.html。实践中，这意味着 service-account-issuer 取值必须是 HTTPS URL。还强烈建议此 URL 能够在 &#123;service-account-issuer&#125;/.well-known/openid-configuration 处提供 OpenID 发现文档。当此值被多次指定时，第一次的值用于生成令牌，所有的值用于确定接受哪些发行人。</span><br><span class="line"></span><br><span class="line">--kubelet-preferred-address-types strings     默认值：Hostname,InternalDNS,InternalIP,ExternalDNS,ExternalIP</span><br><span class="line">用于 kubelet 连接的首选 NodeAddressTypes 列表。</span><br><span class="line"></span><br><span class="line">--enable-admission-plugins stringSlice</span><br><span class="line">除了默认启用的插件（NamespaceLifecycle、LimitRanger、ServiceAccount、TaintNodesByCondition、PodSecurity、Priority、DefaultTolerationSeconds、DefaultStorageClass、StorageObjectInUseProtection、PersistentVolumeClaimResize、RuntimeClass、CertificateApproval、CertificateSigning、CertificateSubjectRestriction、DefaultIngressClass、MutatingAdmissionWebhook、ValidatingAdmissionWebhook、ResourceQuota）之外要启用的插件</span><br><span class="line">取值为逗号分隔的准入插件列表：AlwaysAdmit、AlwaysDeny、AlwaysPullImages、CertificateApproval、CertificateSigning、CertificateSubjectRestriction、DefaultIngressClass、DefaultStorageClass、DefaultTolerationSeconds、DenyServiceExternalIPs、EventRateLimit、ExtendedResourceToleration、ImagePolicyWebhook、LimitPodHardAntiAffinityTopology、LimitRanger、MutatingAdmissionWebhook、NamespaceAutoProvision、NamespaceExists、NamespaceLifecycle、NodeRestriction、OwnerReferencesPermissionEnforcement、PersistentVolumeClaimResize、PersistentVolumeLabel、PodNodeSelector、PodSecurity、PodSecurityPolicy、PodTolerationRestriction、Priority、ResourceQuota、RuntimeClass、SecurityContextDeny、ServiceAccount、StorageObjectInUseProtection、TaintNodesByCondition、ValidatingAdmissionWebhook</span><br><span class="line">该标志中插件的顺序无关紧要。</span><br><span class="line"></span><br><span class="line">--authorization-mode stringSlice     默认值：&quot;AlwaysAllow&quot;</span><br><span class="line">在安全端口上进行鉴权的插件的顺序列表。逗号分隔的列表：AlwaysAllow、AlwaysDeny、ABAC、Webhook、RBAC、Node。</span><br><span class="line"></span><br><span class="line">--enable-bootstrap-token-auth</span><br><span class="line">启用以允许将 &quot;kube-system&quot; 名字空间中类型为 &quot;bootstrap.kubernetes.io/token&quot; 的 Secret 用于 TLS 引导身份验证。</span><br><span class="line"></span><br><span class="line">--requestheader-client-ca-file string</span><br><span class="line">在信任请求头中以 --requestheader-username-headers 指示的用户名之前， 用于验证接入请求中客户端证书的根证书包。警告：一般不要假定传入请求已被授权。</span><br><span class="line"></span><br><span class="line">--proxy-client-cert-file string</span><br><span class="line">当必须调用外部程序以处理请求时，用于证明聚合器或者 kube-apiserver 的身份的客户端证书。包括代理转发到用户 api-server 的请求和调用 Webhook 准入控制插件的请求。Kubernetes 期望此证书包含来自于 --requestheader-client-ca-file 标志中所给 CA 的签名。该 CA 在 kube-system 命名空间的 &quot;extension-apiserver-authentication&quot; ConfigMap 中公开。从 kube-aggregator 收到调用的组件应该使用该 CA 进行各自的双向 TLS 验证。</span><br><span class="line"></span><br><span class="line">--proxy-client-key-file string</span><br><span class="line">当必须调用外部程序来处理请求时，用来证明聚合器或者 kube-apiserver 的身份的客户端私钥。这包括代理转发给用户 api-server 的请求和调用 Webhook 准入控制插件的请求。</span><br><span class="line"></span><br><span class="line">--requestheader-allowed-names strings</span><br><span class="line">此值为客户端证书通用名称（Common Name）的列表；表中所列的表项可以用来提供用户名， 方式是使用 --requestheader-username-headers 所指定的头部。如果为空，能够通过 --requestheader-client-ca-file 中机构 认证的客户端证书都是被允许的。</span><br><span class="line"></span><br><span class="line">--requestheader-group-headers strings</span><br><span class="line">用于查验用户组的请求头部列表。建议使用 X-Remote-Group。</span><br><span class="line"></span><br><span class="line">--requestheader-extra-headers-prefix strings</span><br><span class="line">用于查验请求头部的前缀列表。建议使用 X-Remote-Extra-。</span><br><span class="line"></span><br><span class="line">--requestheader-username-headers strings</span><br><span class="line">用于查验用户名的请求头头列表。建议使用 X-Remote-User。</span><br><span class="line"></span><br><span class="line">--token-auth-file string</span><br><span class="line">如果设置该值，这个文件将被用于通过令牌认证来保护 API 服务的安全端口。</span><br><span class="line"></span><br><span class="line">官方文档：</span><br><span class="line">https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/</span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装Kubernetes（k8s） v1.23.3</title>
    <url>/2022/02/15/2022-02-15-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85Kubernetes%EF%BC%88k8s%EF%BC%89_v1.23.3/</url>
    <content><![CDATA[<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1.环境"></a>1.环境</h1><table>
<thead>
<tr>
<th>主机名称</th>
<th>IP地址</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td>Master01</td>
<td>192.168.1.76</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master02</td>
<td>192.168.1.77</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master03</td>
<td>192.168.1.78</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node01</td>
<td>192.168.1.79</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node02</td>
<td>192.168.1.80</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Lb01</td>
<td>192.168.1.86</td>
<td>Lb01节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td>Lb02</td>
<td>192.168.1.87</td>
<td>Lb02节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td></td>
<td>192.168.1.88</td>
<td>VIP</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">软件</th>
<th align="left">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">内核</td>
<td align="left">5.16.7-1.el8.elrepo.x86_64</td>
</tr>
<tr>
<td align="left">CentOS 8</td>
<td align="left">v8</td>
</tr>
<tr>
<td align="left">kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy</td>
<td align="left">v1.23.3</td>
</tr>
<tr>
<td align="left">etcd</td>
<td align="left">v3.5.2</td>
</tr>
<tr>
<td align="left">docker-ce</td>
<td align="left">v20.10.9</td>
</tr>
<tr>
<td align="left">containerd</td>
<td align="left">v1.6.0</td>
</tr>
<tr>
<td align="left">cfssl</td>
<td align="left">v1.6.1</td>
</tr>
<tr>
<td align="left">cni</td>
<td align="left">v1.6.0</td>
</tr>
<tr>
<td align="left">crictl</td>
<td align="left">v1.23.0</td>
</tr>
<tr>
<td align="left">haproxy</td>
<td align="left">v1.8.27</td>
</tr>
<tr>
<td align="left">keepalived</td>
<td align="left">v2.1.5</td>
</tr>
</tbody></table>
<p>网段</p>
<p>物理主机：192.168.1.0&#x2F;24</p>
<p>service：10.96.0.0&#x2F;12</p>
<p>pod：172.16.0.0&#x2F;12</p>
<p>如果有条件建议k8s集群与etcd集群分开安装</p>
<h2 id="1-1-k8s基础系统环境配置"><a href="#1-1-k8s基础系统环境配置" class="headerlink" title="1.1.k8s基础系统环境配置"></a>1.1.k8s基础系统环境配置</h2><h3 id="1-2-配置IP"><a href="#1-2-配置IP" class="headerlink" title="1.2.配置IP"></a>1.2.配置IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@192.168.1.100 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.76/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.125 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.77/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.116 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.78/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.108 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.79/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.106 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.80/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.154 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.86/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.161 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.87/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br></pre></td></tr></table></figure>



<h3 id="1-3-设置主机名"><a href="#1-3-设置主机名" class="headerlink" title="1.3.设置主机名"></a>1.3.设置主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-master02</span><br><span class="line">hostnamectl set-hostname k8s-master03</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br><span class="line">hostnamectl set-hostname lb01</span><br><span class="line">hostnamectl set-hostname lb02</span><br></pre></td></tr></table></figure>



<h3 id="1-4-配置yum源"><a href="#1-4-配置yum源" class="headerlink" title="1.4.配置yum源"></a>1.4.配置yum源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=http://192.168.1.123/centos|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="1-5-安装一些必备工具"><a href="#1-5-安装一些必备工具" class="headerlink" title="1.5.安装一些必备工具"></a>1.5.安装一些必备工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install wget jq psmisc vim net-tools  telnet yum-utils device-mapper-persistent-data lvm2 git network-scripts tar curl -y</span><br></pre></td></tr></table></figure>



<h3 id="1-6-安装docker工具"><a href="#1-6-安装docker工具" class="headerlink" title="1.6.安装docker工具"></a>1.6.安装docker工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br></pre></td></tr></table></figure>



<h3 id="1-7-关闭防火墙"><a href="#1-7-关闭防火墙" class="headerlink" title="1.7.关闭防火墙"></a>1.7.关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br></pre></td></tr></table></figure>



<h3 id="1-8-关闭SELinux"><a href="#1-8-关闭SELinux" class="headerlink" title="1.8.关闭SELinux"></a>1.8.关闭SELinux</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/sysconfig/selinux</span><br></pre></td></tr></table></figure>



<h3 id="1-9-关闭交换分区"><a href="#1-9-关闭交换分区" class="headerlink" title="1.9.关闭交换分区"></a>1.9.关闭交换分区</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">cat /etc/fstab</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>



<h3 id="1-10-关闭NetworkManager-并启用-network"><a href="#1-10-关闭NetworkManager-并启用-network" class="headerlink" title="1.10.关闭NetworkManager 并启用 network"></a>1.10.关闭NetworkManager 并启用 network</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now NetworkManager</span><br><span class="line">systemctl start network &amp;&amp; systemctl enable network</span><br></pre></td></tr></table></figure>



<h3 id="1-11-进行时间同步"><a href="#1-11-进行时间同步" class="headerlink" title="1.11.进行时间同步"></a>1.11.进行时间同步</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">服务端</span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">allow 192.168.1.0/24</span><br><span class="line">local stratum 10</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd</span><br><span class="line">systemctl enable chronyd</span><br><span class="line"></span><br><span class="line">客户端</span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool 10.0.0.21 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum install chrony -y ; sed -i &quot;s#2.centos.pool.ntp.org#10.0.0.21#g&quot; /etc/chrony.conf ; systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">使用客户端进行验证</span><br><span class="line"></span><br><span class="line">chronyc sources -v</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="1-12-配置ulimit"><a href="#1-12-配置ulimit" class="headerlink" title="1.12.配置ulimit"></a>1.12.配置ulimit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -SHn 65535</span><br><span class="line">cat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOF</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* seft memlock unlimited</span><br><span class="line">* hard memlock unlimitedd</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="1-13-配置免密登录"><a href="#1-13-配置免密登录" class="headerlink" title="1.13.配置免密登录"></a>1.13.配置免密登录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br><span class="line">ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;</span><br><span class="line">export IP=&quot;192.168.1.76 192.168.1.77 192.168.1.78 192.168.1.79 192.168.1.80 192.168.1.86 192.168.1.87&quot;</span><br><span class="line">export SSHPASS=123123</span><br><span class="line">for HOST in $IP;do</span><br><span class="line">     sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $HOST</span><br><span class="line">done</span><br></pre></td></tr></table></figure>



<h3 id="1-14-添加启用源"><a href="#1-14-添加启用源" class="headerlink" title="1.14.添加启用源"></a>1.14.添加启用源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">为 RHEL-8或 CentOS-8配置源</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line">为 RHEL-7 SL-7 或 CentOS-7 安装 ELRepo </span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line">查看可用安装包</span><br><span class="line">yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="1-15-升级内核至4-18版本以上"><a href="#1-15-升级内核至4-18版本以上" class="headerlink" title="1.15.升级内核至4.18版本以上"></a>1.15.升级内核至4.18版本以上</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装最新的内核</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我这里选择的是稳定版kernel-ml   如需更新长期维护版本kernel-lt</span>  </span><br><span class="line">yum  --enablerepo=elrepo-kernel  install  kernel-ml</span><br><span class="line"></span><br><span class="line">查看已安装那些内核</span><br><span class="line">rpm -qa | grep kernel</span><br><span class="line">kernel-core-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-core-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-ml-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-modules-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-libs-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-modules-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">查看默认内核</span><br><span class="line">grubby --default-kernel</span><br><span class="line">/boot/vmlinuz-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">若不是最新的使用命令设置</span><br><span class="line">grubby --set-default /boot/vmlinuz-「您的内核版本」.x86_64</span><br><span class="line"></span><br><span class="line">重启生效</span><br><span class="line">reboot</span><br><span class="line"></span><br><span class="line">整合命令为：</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --default-kernel ; reboot</span><br></pre></td></tr></table></figure>



<h3 id="1-16-安装ipvsadm"><a href="#1-16-安装ipvsadm" class="headerlink" title="1.16.安装ipvsadm"></a>1.16.安装ipvsadm</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;EOF</span><br><span class="line">cat </span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">ip_tables</span><br><span class="line">ip_set</span><br><span class="line">xt_set</span><br><span class="line">ipt_set</span><br><span class="line">ipt_rpfilter</span><br><span class="line">ipt_REJECT</span><br><span class="line">ipip</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart systemd-modules-load.service</span><br><span class="line"></span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack</span><br><span class="line">ip_vs_sh               16384  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          176128  1 ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure>



<h3 id="1-17-修改内核参数"><a href="#1-17-修改内核参数" class="headerlink" title="1.17.修改内核参数"></a>1.17.修改内核参数</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>



<h3 id="1-18-所有节点配置hosts本地解析"><a href="#1-18-所有节点配置hosts本地解析" class="headerlink" title="1.18.所有节点配置hosts本地解析"></a>1.18.所有节点配置hosts本地解析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.1.76 k8s-master01</span><br><span class="line">192.168.1.77 k8s-master02</span><br><span class="line">192.168.1.78 k8s-master03</span><br><span class="line">192.168.1.79 k8s-node01</span><br><span class="line">192.168.1.80 k8s-node02</span><br><span class="line">192.168.1.86 lb01</span><br><span class="line">192.168.1.87 lb02</span><br><span class="line">192.168.1.88 lb-vip</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h1 id="2-k8s基本组件安装"><a href="#2-k8s基本组件安装" class="headerlink" title="2.k8s基本组件安装"></a>2.k8s基本组件安装</h1><h2 id="2-1-所有k8s节点安装Containerd作为Runtime"><a href="#2-1-所有k8s节点安装Containerd作为Runtime" class="headerlink" title="2.1.所有k8s节点安装Containerd作为Runtime"></a>2.1.所有k8s节点安装Containerd作为Runtime</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install containerd -y</span><br></pre></td></tr></table></figure>



<h3 id="2-1-1配置Containerd所需的模块"><a href="#2-1-1配置Containerd所需的模块" class="headerlink" title="2.1.1配置Containerd所需的模块"></a>2.1.1配置Containerd所需的模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="2-1-2加载模块"><a href="#2-1-2加载模块" class="headerlink" title="2.1.2加载模块"></a>2.1.2加载模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl restart systemd-modules-load.service</span><br></pre></td></tr></table></figure>



<h3 id="2-1-3配置Containerd所需的内核"><a href="#2-1-3配置Containerd所需的内核" class="headerlink" title="2.1.3配置Containerd所需的内核"></a>2.1.3配置Containerd所需的内核</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载内核</span></span><br><span class="line"></span><br><span class="line">sysctl --system</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="2-1-4创建Containerd的配置文件"><a href="#2-1-4创建Containerd的配置文件" class="headerlink" title="2.1.4创建Containerd的配置文件"></a>2.1.4创建Containerd的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改Containerd的配置文件</span><br><span class="line">vim /etc/containerd/config.toml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到containerd.runtimes.runc.options，在其下加入SystemdCgroup = <span class="literal">true</span></span></span><br><span class="line"></span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">              SystemdCgroup = true</span><br><span class="line">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sandbox_image默认地址改为符合版本地址</span></span><br><span class="line"></span><br><span class="line">    sandbox_image = &quot;registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&quot;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="2-1-5启动并设置为开机启动"><a href="#2-1-5启动并设置为开机启动" class="headerlink" title="2.1.5启动并设置为开机启动"></a>2.1.5启动并设置为开机启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="2-1-6配置crictl客户端连接的运行时位置"><a href="#2-1-6配置crictl客户端连接的运行时位置" class="headerlink" title="2.1.6配置crictl客户端连接的运行时位置"></a>2.1.6配置crictl客户端连接的运行时位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/crictl.yaml &lt;&lt;EOF</span><br><span class="line">runtime-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">image-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">timeout: 10</span><br><span class="line">debug: false</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2-2-k8s与etcd下载及安装（仅在master01操作）"><a href="#2-2-k8s与etcd下载及安装（仅在master01操作）" class="headerlink" title="2.2.k8s与etcd下载及安装（仅在master01操作）"></a>2.2.k8s与etcd下载及安装（仅在master01操作）</h2><h3 id="2-2-1下载k8s安装包（你用哪个下哪个）"><a href="#2-2-1下载k8s安装包（你用哪个下哪个）" class="headerlink" title="2.2.1下载k8s安装包（你用哪个下哪个）"></a>2.2.1下载k8s安装包（你用哪个下哪个）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1.下载kubernetes1.23.+的二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md</span><br><span class="line"></span><br><span class="line">wget https://dl.k8s.io/v1.23.3/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">2.下载etcdctl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/etcd-io/etcd/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.5.2/etcd-v3.5.2-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">3.docker-ce二进制包下载地址</span><br><span class="line">二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><br><span class="line"></span><br><span class="line">这里需要下载20.10.+版本</span><br><span class="line"></span><br><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-20.10.9.tgz</span><br><span class="line"></span><br><span class="line">4.containerd二进制包下载</span><br><span class="line">github下载地址：https://github.com/containerd/containerd/releases</span><br><span class="line"></span><br><span class="line">containerd下载时下载带cni插件的二进制包。</span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.0-rc.2/cri-containerd-cni-1.6.0-rc.2-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">5.下载cfssl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/cloudflare/cfssl/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.1_linux_amd64</span><br><span class="line"></span><br><span class="line">6.cni插件下载</span><br><span class="line">github下载地址：https://github.com/containernetworking/plugins/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.0.1/cni-plugins-linux-amd64-v1.0.1.tgz</span><br><span class="line"></span><br><span class="line">7.crictl客户端二进制下载</span><br><span class="line">github下载：https://github.com/kubernetes-sigs/cri-tools/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.23.0/crictl-v1.23.0-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">解压k8s安装文件</span><br><span class="line">tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;</span><br><span class="line"></span><br><span class="line">解压etcd安装文件</span><br><span class="line">tar -xf etcd-v3.5.2-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.2-linux-amd64/etcd&#123;,ctl&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看/usr/local/bin下内容</span></span><br><span class="line"></span><br><span class="line">ls /usr/local/bin/</span><br><span class="line">etcd  etcdctl  kube-apiserver  kube-controller-manager  kubectl  kubelet  kube-proxy  kube-scheduler</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="2-2-2查看版本"><a href="#2-2-2查看版本" class="headerlink" title="2.2.2查看版本"></a>2.2.2查看版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubelet --version</span><br><span class="line">Kubernetes v1.23.3</span><br><span class="line">[root@k8s-master01 ~]# etcdctl version</span><br><span class="line">etcdctl version: 3.5.1</span><br><span class="line">API version: 3.5</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="2-2-3将组件发送至其他k8s节点"><a href="#2-2-3将组件发送至其他k8s节点" class="headerlink" title="2.2.3将组件发送至其他k8s节点"></a>2.2.3将组件发送至其他k8s节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">Work=&#x27;k8s-node01 k8s-node02&#x27;</span><br><span class="line">for NODE in $Master; do echo $NODE; scp /usr/local/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done</span><br><span class="line">for NODE in $Work; do     scp /usr/local/bin/kube&#123;let,-proxy&#125; $NODE:/usr/local/bin/ ; done</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="2-2-4克隆证书相关文件"><a href="#2-2-4克隆证书相关文件" class="headerlink" title="2.2.4克隆证书相关文件"></a>2.2.4克隆证书相关文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/cby-chen/Kubernetes.git</span><br></pre></td></tr></table></figure>



<h3 id="2-2-5所有k8s节点创建目录"><a href="#2-2-5所有k8s节点创建目录" class="headerlink" title="2.2.5所有k8s节点创建目录"></a>2.2.5所有k8s节点创建目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /opt/cni/bin</span><br></pre></td></tr></table></figure>



<h1 id="3-相关证书生成"><a href="#3-相关证书生成" class="headerlink" title="3.相关证书生成"></a>3.相关证书生成</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">master01节点下载证书生成工具</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssl</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssljson</span><br><span class="line">chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3-1-生成etcd证书"><a href="#3-1-生成etcd证书" class="headerlink" title="3.1.生成etcd证书"></a>3.1.生成etcd证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-1-1所有master节点创建证书存放目录"><a href="#3-1-1所有master节点创建证书存放目录" class="headerlink" title="3.1.1所有master节点创建证书存放目录"></a>3.1.1所有master节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/etcd/ssl -p</span><br></pre></td></tr></table></figure>



<h3 id="3-1-2master01节点生成etcd证书"><a href="#3-1-2master01节点生成etcd证书" class="headerlink" title="3.1.2master01节点生成etcd证书"></a>3.1.2master01节点生成etcd证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd Kubernetes/pki/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成etcd证书和etcd证书的key（如果你觉得以后可能会扩容，可以在ip那多写几个预留出来）</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,192.168.1.76,192.168.1.77,192.168.1.78 \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-1-3将证书复制到其他节点"><a href="#3-1-3将证书复制到其他节点" class="headerlink" title="3.1.3将证书复制到其他节点"></a>3.1.3将证书复制到其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">for NODE in $Master; do</span><br><span class="line">     ssh $NODE &quot;mkdir -p /etc/etcd/ssl&quot;</span><br><span class="line">     for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do</span><br><span class="line">       scp /etc/etcd/ssl/$&#123;FILE&#125; $NODE:/etc/etcd/ssl/$&#123;FILE&#125;</span><br><span class="line">     done</span><br><span class="line"> done</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="3-2-生成k8s相关证书"><a href="#3-2-生成k8s相关证书" class="headerlink" title="3.2.生成k8s相关证书"></a>3.2.生成k8s相关证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-2-1所有k8s节点创建证书存放目录"><a href="#3-2-1所有k8s节点创建证书存放目录" class="headerlink" title="3.2.1所有k8s节点创建证书存放目录"></a>3.2.1所有k8s节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki</span><br></pre></td></tr></table></figure>



<h3 id="3-2-2master01节点生成k8s证书"><a href="#3-2-2master01节点生成k8s证书" class="headerlink" title="3.2.2master01节点生成k8s证书"></a>3.2.2master01节点生成k8s证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成一个根证书</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.96.0.1是service网段的第一个地址，需要计算，192.168.1.88为高可用vip地址</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   \</span><br><span class="line">-ca=/etc/kubernetes/pki/ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-hostname=10.96.0.1,192.168.1.88,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,x.oiox.cn,k.oiox.cn,l.oiox.cn,o.oiox.cn,192.168.1.76,192.168.1.77,192.168.1.78   \</span><br><span class="line">-profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-2-3生成apiserver聚合证书"><a href="#3-2-3生成apiserver聚合证书" class="headerlink" title="3.2.3生成apiserver聚合证书"></a>3.2.3生成apiserver聚合证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有一个警告，可以忽略</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   -ca=/etc/kubernetes/pki/front-proxy-ca.pem   -ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   -config=ca-config.json   -profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-2-4生成controller-manage的证书"><a href="#3-2-4生成controller-manage的证书" class="headerlink" title="3.2.4生成controller-manage的证书"></a>3.2.4生成controller-manage的证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个集群项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://192.168.1.88:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个环境项，一个上下文</span></span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=system:kube-controller-manager \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个用户项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置默认环境</span></span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://192.168.1.88:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/scheduler.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/scheduler-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --cluster=kubernetes \</span><br><span class="line">     --user=system:kube-scheduler \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.88:8443     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes-admin     --client-certificate=/etc/kubernetes/pki/admin.pem     --client-key=/etc/kubernetes/pki/admin-key.pem     --embed-certs=true     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes     --cluster=kubernetes     --user=kubernetes-admin     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-2-5创建ServiceAccount-Key-——secret"><a href="#3-2-5创建ServiceAccount-Key-——secret" class="headerlink" title="3.2.5创建ServiceAccount Key ——secret"></a>3.2.5创建ServiceAccount Key ——secret</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out /etc/kubernetes/pki/sa.key 2048</span><br><span class="line">openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-2-6将证书发送到其他master节点"><a href="#3-2-6将证书发送到其他master节点" class="headerlink" title="3.2.6将证书发送到其他master节点"></a>3.2.6将证书发送到其他master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do </span><br><span class="line">for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do </span><br><span class="line">scp /etc/kubernetes/pki/$&#123;FILE&#125; $NODE:/etc/kubernetes/pki/$&#123;FILE&#125;;</span><br><span class="line">done; </span><br><span class="line">for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do </span><br><span class="line">scp /etc/kubernetes/$&#123;FILE&#125; $NODE:/etc/kubernetes/$&#123;FILE&#125;;</span><br><span class="line">done;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-2-7查看证书"><a href="#3-2-7查看证书" class="headerlink" title="3.2.7查看证书"></a>3.2.7查看证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /etc/kubernetes/pki/</span><br><span class="line">admin.csr      apiserver-key.pem  ca.pem                      front-proxy-ca.csr      front-proxy-client-key.pem  scheduler.csr</span><br><span class="line">admin-key.pem  apiserver.pem      controller-manager.csr      front-proxy-ca-key.pem  front-proxy-client.pem      scheduler-key.pem</span><br><span class="line">admin.pem      ca.csr             controller-manager-key.pem  front-proxy-ca.pem      sa.key                      scheduler.pem</span><br><span class="line">apiserver.csr  ca-key.pem         controller-manager.pem      front-proxy-client.csr  sa.pub</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一共23个就对了</span></span><br><span class="line"></span><br><span class="line">ls /etc/kubernetes/pki/ |wc -l</span><br><span class="line">23</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="4-k8s系统组件配置"><a href="#4-k8s系统组件配置" class="headerlink" title="4.k8s系统组件配置"></a>4.k8s系统组件配置</h1><h2 id="4-1-etcd配置"><a href="#4-1-etcd配置" class="headerlink" title="4.1.etcd配置"></a>4.1.etcd配置</h2><h3 id="4-1-1master01配置"><a href="#4-1-1master01配置" class="headerlink" title="4.1.1master01配置"></a>4.1.1master01配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master01&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.76:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.76:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.76:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.76:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.76:2380,k8s-master02=https://192.168.1.77:2380,k8s-master03=https://192.168.1.78:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="4-1-2master02配置"><a href="#4-1-2master02配置" class="headerlink" title="4.1.2master02配置"></a>4.1.2master02配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master02&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.77:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.77:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.77:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.77:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.76:2380,k8s-master02=https://192.168.1.77:2380,k8s-master03=https://192.168.1.78:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="4-1-3master03配置"><a href="#4-1-3master03配置" class="headerlink" title="4.1.3master03配置"></a>4.1.3master03配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master03&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.78:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.78:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.78:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.78:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.76:2380,k8s-master02=https://192.168.1.77:2380,k8s-master03=https://192.168.1.78:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h2 id="4-2-创建service（所有master节点操作）"><a href="#4-2-创建service（所有master节点操作）" class="headerlink" title="4.2.创建service（所有master节点操作）"></a>4.2.创建service（所有master节点操作）</h2><h3 id="4-2-1创建etcd-service并启动"><a href="#4-2-1创建etcd-service并启动" class="headerlink" title="4.2.1创建etcd.service并启动"></a>4.2.1创建etcd.service并启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="4-2-2创建etcd证书目录"><a href="#4-2-2创建etcd证书目录" class="headerlink" title="4.2.2创建etcd证书目录"></a>4.2.2创建etcd证书目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/kubernetes/pki/etcd</span><br><span class="line">ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now etcd</span><br></pre></td></tr></table></figure>



<h3 id="4-2-3查看etcd状态"><a href="#4-2-3查看etcd状态" class="headerlink" title="4.2.3查看etcd状态"></a>4.2.3查看etcd状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --endpoints=&quot;192.168.1.78:2379,192.168.1.77:2379,192.168.1.76:2379&quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|     ENDPOINT      |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| 192.168.1.78:2379 | 56875ab4a12c94e8 |   3.5.1 |   25 kB |     false |      false |         2 |          8 |                  8 |        |</span><br><span class="line">| 192.168.1.77:2379 | 33df6a8fe708d3fd |   3.5.1 |   25 kB |      true |      false |         2 |          8 |                  8 |        |</span><br><span class="line">| 192.168.1.76:2379 | 58fbe5ec9743048f |   3.5.1 |   20 kB |     false |      false |         2 |          8 |                  8 |        |</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="5-高可用配置"><a href="#5-高可用配置" class="headerlink" title="5.高可用配置"></a>5.高可用配置</h1><h2 id="5-1在lb01和lb02两台服务器上操作"><a href="#5-1在lb01和lb02两台服务器上操作" class="headerlink" title="5.1在lb01和lb02两台服务器上操作"></a>5.1在lb01和lb02两台服务器上操作</h2><h3 id="5-1-1安装keepalived和haproxy服务"><a href="#5-1-1安装keepalived和haproxy服务" class="headerlink" title="5.1.1安装keepalived和haproxy服务"></a>5.1.1安装keepalived和haproxy服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install keepalived haproxy</span><br></pre></td></tr></table></figure>



<h3 id="5-1-2修改haproxy配置文件（两台配置文件一样）"><a href="#5-1-2修改haproxy配置文件（两台配置文件一样）" class="headerlink" title="5.1.2修改haproxy配置文件（两台配置文件一样）"></a>5.1.2修改haproxy配置文件（两台配置文件一样）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt;/etc/haproxy/haproxy.cfg&lt;&lt;&quot;EOF&quot;</span><br><span class="line">global</span><br><span class="line"> maxconn 2000</span><br><span class="line"> ulimit-n 16384</span><br><span class="line"> log 127.0.0.1 local0 err</span><br><span class="line"> stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"> log global</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> timeout connect 5000</span><br><span class="line"> timeout client 50000</span><br><span class="line"> timeout server 50000</span><br><span class="line"> timeout http-request 15s</span><br><span class="line"> timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line"> bind *:33305</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line"> bind 0.0.0.0:8443</span><br><span class="line"> bind 127.0.0.1:8443</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> tcp-request inspect-delay 5s</span><br><span class="line"> default_backend k8s-master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> option tcp-check</span><br><span class="line"> balance roundrobin</span><br><span class="line"> default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line"> server  master01  192.168.1.76:6443 check</span><br><span class="line"> server  master02  192.168.1.77:6443 check</span><br><span class="line"> server  master03  192.168.1.78:6443 check</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="5-1-3lb01配置keepalived-master节点"><a href="#5-1-3lb01配置keepalived-master节点" class="headerlink" title="5.1.3lb01配置keepalived master节点"></a>5.1.3lb01配置keepalived master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens18</span><br><span class="line">    mcast_src_ip 192.168.1.86</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.88</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="5-1-4lb02配置keepalived-backup节点"><a href="#5-1-4lb02配置keepalived-backup节点" class="headerlink" title="5.1.4lb02配置keepalived backup节点"></a>5.1.4lb02配置keepalived backup节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens18</span><br><span class="line">    mcast_src_ip 192.168.1.87</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 50</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.88</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="5-1-5健康检查脚本配置（两台lb主机）"><a href="#5-1-5健康检查脚本配置（两台lb主机）" class="headerlink" title="5.1.5健康检查脚本配置（两台lb主机）"></a>5.1.5健康检查脚本配置（两台lb主机）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/keepalived/check_apiserver.sh &lt;&lt; EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">err=0</span><br><span class="line">for k in \$(seq 1 3)</span><br><span class="line">do</span><br><span class="line">    check_code=\$(pgrep haproxy)</span><br><span class="line">    if [[ \$check_code == &quot;&quot; ]]; then</span><br><span class="line">        err=\$(expr \$err + 1)</span><br><span class="line">        sleep 1</span><br><span class="line">        continue</span><br><span class="line">    else</span><br><span class="line">        err=0</span><br><span class="line">        break</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ \$err != &quot;0&quot; ]]; then</span><br><span class="line">    echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">    /usr/bin/systemctl stop keepalived</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给脚本授权</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_apiserver.sh</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="5-1-6启动服务"><a href="#5-1-6启动服务" class="headerlink" title="5.1.6启动服务"></a>5.1.6启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now haproxy</span><br><span class="line">systemctl enable --now keepalived</span><br></pre></td></tr></table></figure>



<h3 id="5-1-7测试高可用"><a href="#5-1-7测试高可用" class="headerlink" title="5.1.7测试高可用"></a>5.1.7测试高可用</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能ping同</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# ping 192.168.1.88</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能telnet访问</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# telnet 192.168.1.88 8443</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭主节点，看vip是否漂移到备节点</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="6-k8s组件配置（区别于第4点）"><a href="#6-k8s组件配置（区别于第4点）" class="headerlink" title="6.k8s组件配置（区别于第4点）"></a>6.k8s组件配置（区别于第4点）</h1><p>所有k8s节点创建以下目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes</span><br></pre></td></tr></table></figure>



<h2 id="6-1-创建apiserver（所有master节点）"><a href="#6-1-创建apiserver（所有master节点）" class="headerlink" title="6.1.创建apiserver（所有master节点）"></a>6.1.创建apiserver（所有master节点）</h2><h3 id="6-1-1master01节点配置"><a href="#6-1-1master01节点配置" class="headerlink" title="6.1.1master01节点配置"></a>6.1.1master01节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.76 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.76:2379,https://192.168.1.77:2379,https://192.168.1.78:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="6-1-2master02节点配置"><a href="#6-1-2master02节点配置" class="headerlink" title="6.1.2master02节点配置"></a>6.1.2master02节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.77 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.76:2379,https://192.168.1.77:2379,https://192.168.1.78:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="6-1-3master03节点配置"><a href="#6-1-3master03节点配置" class="headerlink" title="6.1.3master03节点配置"></a>6.1.3master03节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service  &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.78 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.76:2379,https://192.168.1.77:2379,https://192.168.1.78:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="6-1-4启动apiserver（所有master节点）"><a href="#6-1-4启动apiserver（所有master节点）" class="headerlink" title="6.1.4启动apiserver（所有master节点）"></a>6.1.4启动apiserver（所有master节点）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl enable --now kube-apiserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意查看状态是否启动正常</span></span><br><span class="line"></span><br><span class="line">systemctl status kube-apiserver</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="6-2-配置kube-controller-manager-service"><a href="#6-2-配置kube-controller-manager-service" class="headerlink" title="6.2.配置kube-controller-manager service"></a>6.2.配置kube-controller-manager service</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">所有master节点配置，且配置相同</span><br><span class="line">172.16.0.0/12为pod网段，按需求设置你自己的网段</span><br><span class="line"></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --use-service-account-credentials=true \</span><br><span class="line">      --node-monitor-grace-period=40s \</span><br><span class="line">      --node-monitor-period=5s \</span><br><span class="line">      --pod-eviction-timeout=2m0s \</span><br><span class="line">      --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">      --allocate-node-cidrs=true \</span><br><span class="line">      --cluster-cidr=172.16.0.0/12 \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem \</span><br><span class="line">      --node-cidr-mask-size=24</span><br><span class="line">      </span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="6-2-1启动kube-controller-manager，并查看状态"><a href="#6-2-1启动kube-controller-manager，并查看状态" class="headerlink" title="6.2.1启动kube-controller-manager，并查看状态"></a>6.2.1启动kube-controller-manager，并查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-controller-manager</span><br><span class="line">systemctl  status kube-controller-manager</span><br></pre></td></tr></table></figure>



<h2 id="6-3-配置kube-scheduler-service"><a href="#6-3-配置kube-scheduler-service" class="headerlink" title="6.3.配置kube-scheduler service"></a>6.3.配置kube-scheduler service</h2><h3 id="6-3-1所有master节点配置，且配置相同"><a href="#6-3-1所有master节点配置，且配置相同" class="headerlink" title="6.3.1所有master节点配置，且配置相同"></a>6.3.1所有master节点配置，且配置相同</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="6-3-2启动并查看服务状态"><a href="#6-3-2启动并查看服务状态" class="headerlink" title="6.3.2启动并查看服务状态"></a>6.3.2启动并查看服务状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-scheduler</span><br><span class="line">systemctl status kube-scheduler</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="7-TLS-Bootstrapping配置"><a href="#7-TLS-Bootstrapping配置" class="headerlink" title="7.TLS Bootstrapping配置"></a>7.TLS Bootstrapping配置</h1><h2 id="7-1在master01上配置"><a href="#7-1在master01上配置" class="headerlink" title="7.1在master01上配置"></a>7.1在master01上配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/bootstrap</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.88:8443     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials tls-bootstrap-token-user     --token=c8ad9c.2e4d610cf3e7426e --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context tls-bootstrap-token-user@kubernetes     --cluster=kubernetes     --user=tls-bootstrap-token-user     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context tls-bootstrap-token-user@kubernetes     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">token的位置在bootstrap.secret.yaml，如果修改的话到这个文件修改</span></span><br><span class="line"></span><br><span class="line">mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="7-2查看集群状态，没问题的话继续后续操作"><a href="#7-2查看集群状态，没问题的话继续后续操作" class="headerlink" title="7.2查看集群状态，没问题的话继续后续操作"></a>7.2查看集群状态，没问题的话继续后续操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE                         ERROR</span><br><span class="line">controller-manager   Healthy   ok                              </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">scheduler            Healthy   ok                              </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;  </span><br><span class="line"></span><br><span class="line">kubectl create -f bootstrap.secret.yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="8-node节点配置"><a href="#8-node节点配置" class="headerlink" title="8.node节点配置"></a>8.node节点配置</h1><h2 id="8-1-在master01上将证书复制到node节点"><a href="#8-1-在master01上将证书复制到node节点" class="headerlink" title="8.1.在master01上将证书复制到node节点"></a>8.1.在master01上将证书复制到node节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/kubernetes/</span><br><span class="line"></span><br><span class="line">for NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02; do</span><br><span class="line">     ssh $NODE mkdir -p /etc/kubernetes/pki</span><br><span class="line">     for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig; do</span><br><span class="line">       scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&#123;FILE&#125;</span><br><span class="line"> done</span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="8-2-kubelet配置"><a href="#8-2-kubelet配置" class="headerlink" title="8.2.kubelet配置"></a>8.2.kubelet配置</h2><h3 id="8-2-1所有k8s节点创建相关目录"><a href="#8-2-1所有k8s节点创建相关目录" class="headerlink" title="8.2.1所有k8s节点创建相关目录"></a>8.2.1所有k8s节点创建相关目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">所有k8s节点配置kubelet service</span><br><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kubelet</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="8-2-2所有k8s节点配置kubelet-service的配置文件"><a href="#8-2-2所有k8s节点配置kubelet-service的配置文件" class="headerlink" title="8.2.2所有k8s节点配置kubelet service的配置文件"></a>8.2.2所有k8s节点配置kubelet service的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/systemd/system/kubelet.service.d/10-kubelet.conf &lt;&lt; EOF</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig&quot;</span><br><span class="line">Environment=&quot;KUBELET_SYSTEM_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin --container-runtime=remote --runtime-request-timeout=15m --container-runtime-endpoint=unix:///run/containerd/containerd.sock --cgroup-driver=systemd&quot;</span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml&quot;</span><br><span class="line">Environment=&quot;KUBELET_EXTRA_ARGS=--node-labels=node.kubernetes.io/node=&#x27;&#x27; &quot;</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \$KUBELET_KUBECONFIG_ARGS \$KUBELET_CONFIG_ARGS \$KUBELET_SYSTEM_ARGS \$KUBELET_EXTRA_ARGS</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="8-2-3所有k8s节点创建kubelet的配置文件"><a href="#8-2-3所有k8s节点创建kubelet的配置文件" class="headerlink" title="8.2.3所有k8s节点创建kubelet的配置文件"></a>8.2.3所有k8s节点创建kubelet的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="8-2-4启动kubelet"><a href="#8-2-4启动kubelet" class="headerlink" title="8.2.4启动kubelet"></a>8.2.4启动kubelet</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">systemctl enable --now kubelet</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="8-2-5查看集群"><a href="#8-2-5查看集群" class="headerlink" title="8.2.5查看集群"></a>8.2.5查看集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get node</span><br><span class="line">NAME           STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   NotReady   &lt;none&gt;   18m   v1.23.3</span><br><span class="line">k8s-master02   NotReady   &lt;none&gt;   18m   v1.23.3</span><br><span class="line">k8s-master03   NotReady   &lt;none&gt;   18m   v1.23.3</span><br><span class="line">k8s-node01     NotReady   &lt;none&gt;   18m   v1.23.3</span><br><span class="line">k8s-node02     NotReady   &lt;none&gt;   18m   v1.23.3</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="8-3-kube-proxy配置"><a href="#8-3-kube-proxy配置" class="headerlink" title="8.3.kube-proxy配置"></a>8.3.kube-proxy配置</h2><h3 id="8-3-1此配置只在master01操作"><a href="#8-3-1此配置只在master01操作" class="headerlink" title="8.3.1此配置只在master01操作"></a>8.3.1此配置只在master01操作</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/</span><br><span class="line">kubectl -n kube-system create serviceaccount kube-proxy</span><br><span class="line"></span><br><span class="line">kubectl create clusterrolebinding system:kube-proxy         --clusterrole system:node-proxier         --serviceaccount kube-system:kube-proxy</span><br><span class="line"></span><br><span class="line">SECRET=$(kubectl -n kube-system get sa/kube-proxy \</span><br><span class="line">    --output=jsonpath=&#x27;&#123;.secrets[0].name&#125;&#x27;)</span><br><span class="line"></span><br><span class="line">JWT_TOKEN=$(kubectl -n kube-system get secret/$SECRET \</span><br><span class="line">--output=jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class="line"></span><br><span class="line">PKI_DIR=/etc/kubernetes/pki</span><br><span class="line">K8S_DIR=/etc/kubernetes</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.88:8443     --kubeconfig=$&#123;K8S_DIR&#125;/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes     --token=$&#123;JWT_TOKEN&#125;     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes     --cluster=kubernetes     --user=kubernetes     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="8-3-2将kubeconfig发送至其他节点"><a href="#8-3-2将kubeconfig发送至其他节点" class="headerlink" title="8.3.2将kubeconfig发送至其他节点"></a>8.3.2将kubeconfig发送至其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do</span><br><span class="line">     scp /etc/kubernetes/kube-proxy.kubeconfig  $NODE:/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line">for NODE in k8s-node01 k8s-node02; do</span><br><span class="line">     scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="8-3-3所有k8s节点添加kube-proxy的配置和service文件"><a href="#8-3-3所有k8s节点添加kube-proxy的配置和service文件" class="headerlink" title="8.3.3所有k8s节点添加kube-proxy的配置和service文件"></a>8.3.3所有k8s节点添加kube-proxy的配置和service文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy.yaml \</span><br><span class="line">  --v=2</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="8-3-4启动kube-proxy"><a href="#8-3-4启动kube-proxy" class="headerlink" title="8.3.4启动kube-proxy"></a>8.3.4启动kube-proxy</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-proxy</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="9-安装Calico"><a href="#9-安装Calico" class="headerlink" title="9.安装Calico"></a>9.安装Calico</h1><h2 id="9-1以下步骤只在master01操作"><a href="#9-1以下步骤只在master01操作" class="headerlink" title="9.1以下步骤只在master01操作"></a>9.1以下步骤只在master01操作</h2><h3 id="9-1-1更改calico网段"><a href="#9-1-1更改calico网段" class="headerlink" title="9.1.1更改calico网段"></a>9.1.1更改calico网段</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/calico/</span><br><span class="line">sed -i &quot;s#POD_CIDR#172.16.0.0/12#g&quot; calico.yaml</span><br><span class="line">grep &quot;IPV4POOL_CIDR&quot; calico.yaml  -A 1</span><br><span class="line">            - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">              value: &quot;172.16.0.0/12&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建</span></span><br><span class="line"></span><br><span class="line">kubectl apply -f calico.yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="9-1-2查看容器状态"><a href="#9-1-2查看容器状态" class="headerlink" title="9.1.2查看容器状态"></a>9.1.2查看容器状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get po -n kube-system</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS        AGE</span><br><span class="line">calico-kube-controllers-5dffd5886b-4blh6   1/1     Running   0               4m24s</span><br><span class="line">calico-node-fvbdq                          1/1     Running   1 (2m51s ago)   4m23s</span><br><span class="line">calico-node-g8nqd                          1/1     Running   0               4m23s</span><br><span class="line">calico-node-mdps8                          1/1     Running   0               4m24s</span><br><span class="line">calico-node-nf4nt                          1/1     Running   0               4m24s</span><br><span class="line">calico-node-sq2ml                          1/1     Running   0               4m24s</span><br><span class="line">calico-typha-8445487f56-mg6p8              1/1     Running   0               4m24s</span><br><span class="line">calico-typha-8445487f56-pxbpj              1/1     Running   0               4m24s</span><br><span class="line">calico-typha-8445487f56-tnssl              1/1     Running   0               4m24s</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="10-安装CoreDNS"><a href="#10-安装CoreDNS" class="headerlink" title="10.安装CoreDNS"></a>10.安装CoreDNS</h1><h2 id="10-1以下步骤只在master01操作"><a href="#10-1以下步骤只在master01操作" class="headerlink" title="10.1以下步骤只在master01操作"></a>10.1以下步骤只在master01操作</h2><h3 id="10-1-1修改文件"><a href="#10-1-1修改文件" class="headerlink" title="10.1.1修改文件"></a>10.1.1修改文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/CoreDNS/</span><br><span class="line">sed -i &quot;s#KUBEDNS_SERVICE_IP#10.96.0.10#g&quot; coredns.yaml</span><br><span class="line"></span><br><span class="line">cat coredns.yaml | grep clusterIP:</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="10-1-2安装"><a href="#10-1-2安装" class="headerlink" title="10.1.2安装"></a>10.1.2安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  create -f coredns.yaml </span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.apps/coredns created</span><br><span class="line">service/kube-dns created</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="11-安装Metrics-Server"><a href="#11-安装Metrics-Server" class="headerlink" title="11.安装Metrics Server"></a>11.安装Metrics Server</h1><h2 id="11-1以下步骤只在master01操作"><a href="#11-1以下步骤只在master01操作" class="headerlink" title="11.1以下步骤只在master01操作"></a>11.1以下步骤只在master01操作</h2><h3 id="11-1-1安装Metrics-server"><a href="#11-1-1安装Metrics-server" class="headerlink" title="11.1.1安装Metrics-server"></a>11.1.1安装Metrics-server</h3><p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装metrics server</span><br><span class="line">cd /root/Kubernetes/metrics-server/</span><br><span class="line"></span><br><span class="line">kubectl  create -f . </span><br><span class="line"></span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">deployment.apps/metrics-server created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="11-1-2稍等片刻查看状态"><a href="#11-1-2稍等片刻查看状态" class="headerlink" title="11.1.2稍等片刻查看状态"></a>11.1.2稍等片刻查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   172m         2%     1307Mi          16%       </span><br><span class="line">k8s-master02   157m         1%     1189Mi          15%       </span><br><span class="line">k8s-master03   155m         1%     1105Mi          14%       </span><br><span class="line">k8s-node01     99m          1%     710Mi           9%        </span><br><span class="line">k8s-node02     79m          0%     585Mi           7%</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="12-集群验证"><a href="#12-集群验证" class="headerlink" title="12.集群验证"></a>12.集群验证</h1><h2 id="12-1部署pod资源"><a href="#12-1部署pod资源" class="headerlink" title="12.1部署pod资源"></a>12.1部署pod资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line"></span><br><span class="line">kubectl  get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox   1/1     Running   0          17s</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="12-2用pod解析默认命名空间中的kubernetes"><a href="#12-2用pod解析默认命名空间中的kubernetes" class="headerlink" title="12.2用pod解析默认命名空间中的kubernetes"></a>12.2用pod解析默认命名空间中的kubernetes</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   17h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl exec  busybox -n default -- nslookup kubernetes</span><br><span class="line">3Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="12-3测试跨命名空间是否可以解析"><a href="#12-3测试跨命名空间是否可以解析" class="headerlink" title="12.3测试跨命名空间是否可以解析"></a>12.3测试跨命名空间是否可以解析</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl exec  busybox -n default -- nslookup kube-dns.kube-system</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kube-dns.kube-system</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53"><a href="#12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53" class="headerlink" title="12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53"></a>12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">telnet 10.96.0.1 443</span><br><span class="line">Trying 10.96.0.1...</span><br><span class="line">Connected to 10.96.0.1.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line"> telnet 10.96.0.10 53</span><br><span class="line">Trying 10.96.0.10...</span><br><span class="line">Connected to 10.96.0.10.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line">curl 10.96.0.10:53</span><br><span class="line">curl: (52) Empty reply from server</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="12-5Pod和Pod之前要能通"><a href="#12-5Pod和Pod之前要能通" class="headerlink" title="12.5Pod和Pod之前要能通"></a>12.5Pod和Pod之前要能通</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get po -owide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox   1/1     Running   0          17m   172.27.14.193   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"> kubectl get po -n kube-system -owide</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS      AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-5dffd5886b-4blh6   1/1     Running   0             77m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-fvbdq                          1/1     Running   1 (75m ago)   77m   192.168.1.76     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-g8nqd                          1/1     Running   0             77m   192.168.1.79     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-mdps8                          1/1     Running   0             77m   192.168.1.80     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-nf4nt                          1/1     Running   0             77m   192.168.1.78     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-sq2ml                          1/1     Running   0             77m   192.168.1.77     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-mg6p8              1/1     Running   0             77m   192.168.1.80     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-pxbpj              1/1     Running   0             77m   192.168.1.76     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-tnssl              1/1     Running   0             77m   192.168.1.79     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5db5696c7-67h79                    1/1     Running   0             63m   172.25.92.65     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">metrics-server-6bf7dcd649-5fhrw            1/1     Running   0             61m   172.18.195.1     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入busybox ping其他节点上的pod</span></span><br><span class="line"></span><br><span class="line">kubectl exec -ti busybox -- sh</span><br><span class="line">/ # ping 192.168.1.79</span><br><span class="line">PING 192.168.1.79 (192.168.1.79): 56 data bytes</span><br><span class="line">64 bytes from 192.168.1.79: seq=0 ttl=63 time=0.358 ms</span><br><span class="line">64 bytes from 192.168.1.79: seq=1 ttl=63 time=0.668 ms</span><br><span class="line">64 bytes from 192.168.1.79: seq=2 ttl=63 time=0.637 ms</span><br><span class="line">64 bytes from 192.168.1.79: seq=3 ttl=63 time=0.624 ms</span><br><span class="line">64 bytes from 192.168.1.79: seq=4 ttl=63 time=0.907 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以连通证明这个pod是可以跨命名空间和跨主机通信的</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"><a href="#12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）" class="headerlink" title="12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"></a>12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; deployments.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl  apply -f deployments.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">kubectl  get pod </span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                            1/1     Running   0          6m25s</span><br><span class="line">nginx-deployment-9456bbbf9-4bmvk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-9rcdk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-dqv8s   1/1     Running   0          8s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除nginx</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f deployments.yaml </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="13-安装dashboard"><a href="#13-安装dashboard" class="headerlink" title="13.安装dashboard"></a>13.安装dashboard</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/dashboard/</span><br><span class="line"></span><br><span class="line">kubectl  create -f .</span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line">namespace/kubernetes-dashboard created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-csrf created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/dashboard-metrics-scraper created</span><br><span class="line">deployment.apps/dashboard-metrics-scraper created</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="13-1创建管理员用户"><a href="#13-1创建管理员用户" class="headerlink" title="13.1创建管理员用户"></a>13.1创建管理员用户</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; admin.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line"></span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding </span><br><span class="line">metadata: </span><br><span class="line">  name: admin-user</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h2 id="13-2执行yaml文件"><a href="#13-2执行yaml文件" class="headerlink" title="13.2执行yaml文件"></a>13.2执行yaml文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f admin.yaml -n kube-system</span><br><span class="line"></span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="13-3更改dashboard的svc为NodePort，如果已是请忽略"><a href="#13-3更改dashboard的svc为NodePort，如果已是请忽略" class="headerlink" title="13.3更改dashboard的svc为NodePort，如果已是请忽略"></a>13.3更改dashboard的svc为NodePort，如果已是请忽略</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="13-4查看端口号"><a href="#13-4查看端口号" class="headerlink" title="13.4查看端口号"></a>13.4查看端口号</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.98.201.22   &lt;none&gt;        443:31245/TCP   10m</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="13-5查看token"><a href="#13-5查看token" class="headerlink" title="13.5查看token"></a>13.5查看token</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;)</span><br><span class="line">Name:         admin-user-token-k545k</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: c308071c-4cf5-4583-83a2-eaf7812512b4</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6InYzV2dzNnQzV3hHb2FQWnYzdnlOSmpudmtpVmNjQW5VM3daRi12SFM4dEEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWs1NDVrIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjMzA4MDcxYy00Y2Y1LTQ1ODMtODNhMi1lYWY3ODEyNTEyYjQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pshvZPi9ZJkXUWuWilcYs1wawTpzV-nMKesgF3d_l7qyTPaK2N5ofzIThd0SjzU7BFNb4_rOm1dw1Be5kLeHjY_YW5lDnM5TAxVPXmZQ0HJ2pAQ0pjQqCHFnPD0bZFIYkeyz8pZx0Hmwcd3ZdC1yztr0ADpTAmMgI9NC2ZFIeoFFo4Ue9ZM_ulhqJQjmgoAlI_qbyjuKCNsWeEQBwM6HHHAsH1gOQIdVxqQ83OQZUuynDQRpqlHHFIndbK2zVRYFA3GgUnTu2-VRQ-DXBFRjvZR5qArnC1f383jmIjGT6VO7l04QJteG_LFetRbXa-T4mcnbsd8XutSgO0INqwKpjw</span><br><span class="line">ca.crt:     1363 bytes</span><br><span class="line">namespace:  11 bytes</span><br></pre></td></tr></table></figure>

<h2 id="13-6登录dashboard"><a href="#13-6登录dashboard" class="headerlink" title="13.6登录dashboard"></a>13.6登录dashboard</h2><p><a href="https://192.168.1.76:31245/">https://192.168.1.76:31245/</a></p>
<p>eyJhbGciOiJSUzI1NiIsImtpZCI6InYzV2dzNnQzV3hHb2FQWnYzdnlOSmpudmtpVmNjQW5VM3daRi12SFM4dEEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWs1NDVrIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjMzA4MDcxYy00Y2Y1LTQ1ODMtODNhMi1lYWY3ODEyNTEyYjQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pshvZPi9ZJkXUWuWilcYs1wawTpzV-nMKesgF3d_l7qyTPaK2N5ofzIThd0SjzU7BFNb4_rOm1dw1Be5kLeHjY_YW5lDnM5TAxVPXmZQ0HJ2pAQ0pjQqCHFnPD0bZFIYkeyz8pZx0Hmwcd3ZdC1yztr0ADpTAmMgI9NC2ZFIeoFFo4Ue9ZM_ulhqJQjmgoAlI_qbyjuKCNsWeEQBwM6HHHAsH1gOQIdVxqQ83OQZUuynDQRpqlHHFIndbK2zVRYFA3GgUnTu2-VRQ-DXBFRjvZR5qArnC1f383jmIjGT6VO7l04QJteG_LFetRbXa-T4mcnbsd8XutSgO0INqwKpjw</p>
<h1 id="14-安装命令行自动补全功能"><a href="#14-安装命令行自动补全功能" class="headerlink" title="14.安装命令行自动补全功能"></a>14.安装命令行自动补全功能</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install bash-completion -y</span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>

<h1 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h1><p>配置kube-controller-manager有效期100年（能不能生效的先配上再说）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">[Service]下找个地方加上</span></span><br><span class="line"></span><br><span class="line">--cluster-signing-duration=876000h0m0s \</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启</span></span><br><span class="line"></span><br><span class="line">systemctl daemon-reload </span><br><span class="line">systemctl restart kube-controller-manager</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>防止漏洞扫描</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf</span><br><span class="line"></span><br><span class="line">[Service] </span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--kubeconfig=/etc/kubernetes/kubelet.kubeconfig --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig&quot; </span><br><span class="line">Environment=&quot;KUBELET_SYSTEM_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin&quot; </span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml  --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&quot; </span><br><span class="line">Environment=&quot;KUBELET_EXTRA_ARGS=--tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384    --image-pull-progress-deadline=30m&quot; </span><br><span class="line">ExecStart= </span><br><span class="line">ExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_SYSTEM_ARGS $KUBELET_EXTRA_ARGS </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>预留空间，按需分配</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/kubernetes/kubelet-conf.yml</span><br><span class="line"></span><br><span class="line">rotateServerCertificates: true</span><br><span class="line">allowedUnsafeSysctls:</span><br><span class="line"></span><br><span class="line"> - &quot;net.core*&quot;</span><br><span class="line"> - &quot;net.ipv4.*&quot;</span><br><span class="line">   kubeReserved:</span><br><span class="line">     cpu: &quot;1&quot;</span><br><span class="line">     memory: 1Gi</span><br><span class="line">     ephemeral-storage: 10Gi</span><br><span class="line">   systemReserved:</span><br><span class="line">     cpu: &quot;1&quot;</span><br><span class="line">     memory: 1Gi</span><br><span class="line">     ephemeral-storage: 10Gi</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>数据盘要与系统盘分开；etcd使用ssd磁盘</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Kubernetes 各个组件 启动参数介绍</title>
    <url>/2022/03/08/2022-03-08-Kubernetes_%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6_%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8d859edb86c542e894815f35edc810b7~tplv-k3u1fbpfcp-zoom-1.image" alt="图片">  </p>
<p><strong>kube-controller-manager</strong></p>
<p>Kubernetes 控制器管理器是一个守护进程，内嵌随 Kubernetes 一起发布的核心控制回路。在机器人和自动化的应用中，控制回路是一个永不休止的循环，用于调节系统状态。在 Kubernetes 中，每个控制器是一个控制回路，通过 API 服务器监视集群的共享状态， 并尝试进行更改以将当前状态转为期望状态。目前，Kubernetes 自带的控制器例子包括副本控制器、节点控制器、命名空间控制器和服务账号控制器等。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">--v=2 \</span><br><span class="line">--logtostderr=true \</span><br><span class="line">--address=127.0.0.1 \</span><br><span class="line">--root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">--cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">--cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">--service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">--kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">--leader-elect=true \</span><br><span class="line">--use-service-account-credentials=true \</span><br><span class="line">--node-monitor-grace-period=40s \</span><br><span class="line">--node-monitor-period=5s \</span><br><span class="line">--pod-eviction-timeout=2m0s \</span><br><span class="line">--controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">--allocate-node-cidrs=true \</span><br><span class="line">--cluster-cidr=172.16.0.0/12 \</span><br><span class="line">--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem \</span><br><span class="line">--node-cidr-mask-size=24</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-v, --v int</span><br><span class="line">日志级别详细程度取值。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--logtostderr     默认值：true</span><br><span class="line">将日志写出到标准错误输出（stderr）而不是写入到日志文件。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--root-ca-file string</span><br><span class="line">如果此标志非空，则在服务账号的令牌 Secret 中会包含此根证书机构。所指定标志值必须是一个合法的 PEM 编码的 CA 证书包。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--cluster-signing-cert-file string</span><br><span class="line">包含 PEM 编码格式的 X509 CA 证书的文件名。该证书用来发放集群范围的证书。如果设置了此标志，则不能指定更具体的--cluster-signing-* 标志。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--cluster-signing-key-file string</span><br><span class="line">包含 PEM 编码的 RSA 或 ECDSA 私钥的文件名。该私钥用来对集群范围证书签名。若指定了此选项，则不可再设置 --cluster-signing-* 参数。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--kubeconfig string</span><br><span class="line">指向 kubeconfig 文件的路径。该文件中包含主控节点位置以及鉴权凭据信息。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--leader-elect     默认值：true</span><br><span class="line">在执行主循环之前，启动领导选举（Leader Election）客户端，并尝试获得领导者身份。在运行多副本组件时启用此标志有助于提高可用性。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--use-service-account-credentials</span><br><span class="line">当此标志为 true 时，为每个控制器单独使用服务账号凭据。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--node-monitor-grace-period duration     默认值：40s</span><br><span class="line">在将一个 Node 标记为不健康之前允许其无响应的时长上限。必须比 kubelet 的 nodeStatusUpdateFrequency 大 N 倍；这里 N 指的是 kubelet 发送节点状态的重试次数。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--node-monitor-period duration     默认值：5s</span><br><span class="line">节点控制器对节点状态进行同步的重复周期。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--pod-eviction-timeout duration     默认值：5m0s</span><br><span class="line">在失效的节点上删除 Pods 时为其预留的宽限期。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--controllers strings     默认值：[*]</span><br><span class="line">要启用的控制器列表。\* 表示启用所有默认启用的控制器；foo 启用名为 foo 的控制器；-foo 表示禁用名为 foo 的控制器。</span><br><span class="line">控制器的全集：attachdetach、bootstrapsigner、cloud-node-lifecycle、clusterrole-aggregation、cronjob、csrapproving、csrcleaner、csrsigning、daemonset、deployment、disruption、endpoint、endpointslice、endpointslicemirroring、ephemeral-volume、garbagecollector、horizontalpodautoscaling、job、namespace、nodeipam、nodelifecycle、persistentvolume-binder、persistentvolume-expander、podgc、pv-protection、pvc-protection、replicaset、replicationcontroller、resourcequota、root-ca-cert-publisher、route、service、serviceaccount、serviceaccount-token、statefulset、tokencleaner、ttl、ttl-after-finished</span><br><span class="line">默认禁用的控制器有：bootstrapsigner 和 tokencleaner。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--allocate-node-cidrs</span><br><span class="line">基于云驱动来为 Pod 分配和设置子网掩码。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--requestheader-client-ca-file string</span><br><span class="line">根证书包文件名。在信任通过 --requestheader-username-headers 所指定的任何用户名之前，要使用这里的证书来检查请求中的客户证书。警告：一般不要依赖对请求所作的鉴权结果。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--node-cidr-mask-size int32</span><br><span class="line">集群中节点 CIDR 的掩码长度。对 IPv4 而言默认为 24；对 IPv6 而言默认为 64。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--node-cidr-mask-size-ipv4 int32</span><br><span class="line">在双堆栈（同时支持 IPv4 和 IPv6）的集群中，节点 IPV4 CIDR 掩码长度。默认为 24。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--node-cidr-mask-size-ipv6 int32</span><br><span class="line">在双堆栈（同时支持 IPv4 和 IPv6）的集群中，节点 IPv6 CIDR 掩码长度。默认为 64。</span><br></pre></td></tr></table></figure>

<p><strong>kube-scheduler</strong></p>
<p>Kubernetes 调度器是一个控制面进程，负责将 Pods 指派到节点上。调度器基于约束和可用资源为调度队列中每个 Pod 确定其可合法放置的节点。调度器之后对所有合法的节点进行排序，将 Pod 绑定到一个合适的节点。在同一个集群中可以使用多个不同的调度器；kube-scheduler 是其参考实现。参阅调度 以获得关于调度和 kube-scheduler 组件的更多信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \</span><br><span class="line">--v=2 \</span><br><span class="line">--logtostderr=true \</span><br><span class="line">--address=127.0.0.1 \</span><br><span class="line">--leader-elect=true \</span><br><span class="line">--kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--logtostderr     默认值：true</span><br><span class="line">日志记录到标准错误输出而不是文件。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--leader-elect     默认值：true</span><br><span class="line">在执行主循环之前，开始领导者选举并选出领导者。使用多副本来实现高可用性时，可启用此标志。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--kubeconfig string</span><br><span class="line">已弃用: 包含鉴权和主节点位置信息的 kubeconfig 文件的路径。如果 --config 指定了一个配置文件，那么这个参数将被忽略。</span><br></pre></td></tr></table></figure>

<p><strong>kubelet</strong></p>
<p>kubelet 是在每个 Node 节点上运行的主要 “节点代理”。它可以使用以下之一向 apiserver 注册：主机名（hostname）；覆盖主机名的参数；某云驱动的特定逻辑。</p>
<p>kubelet 是基于 PodSpec 来工作的。每个 PodSpec 是一个描述 Pod 的 YAML 或 JSON 对象。kubelet 接受通过各种机制（主要是通过 apiserver）提供的一组 PodSpec，并确保这些 PodSpec 中描述的容器处于运行状态且运行状况良好。kubelet 不管理不是由 Kubernetes 创建的容器。</p>
<p>除了来自 apiserver 的 PodSpec 之外，还可以通过以下三种方式将容器清单（manifest）提供给 kubelet。</p>
<p>文件（File）：利用命令行参数传递路径。kubelet 周期性地监视此路径下的文件是否有更新。监视周期默认为 20s，且可通过参数进行配置。</p>
<p>HTTP 端点（HTTP endpoint）：利用命令行参数指定 HTTP 端点。此端点的监视周期默认为 20 秒，也可以使用参数进行配置。</p>
<p>HTTP 服务器（HTTP server）：kubelet 还可以侦听 HTTP 并响应简单的 API （目前没有完整规范）来提交新的清单。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/systemd/system/kubelet.service.d/10-kubelet.conf &lt;&lt; EOF</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig&quot;</span><br><span class="line">Environment=&quot;KUBELET_SYSTEM_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin --container-runtime=remote --runtime-request-timeout=15m --container-runtime-endpoint=unix:///run/containerd/containerd.sock --cgroup-driver=systemd&quot;</span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml&quot;</span><br><span class="line">Environment=&quot;KUBELET_EXTRA_ARGS=--node-labels=node.kubernetes.io/node=&#x27;&#x27; &quot;</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \$KUBELET_KUBECONFIG_ARGS \$KUBELET_CONFIG_ARGS \$KUBELET_SYSTEM_ARGS \$KUBELET_EXTRA_ARGS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--bootstrap-kubeconfig string</span><br><span class="line">某 kubeconfig 文件的路径，该文件将用于获取 kubelet 的客户端证书。如果 --kubeconfig 所指定的文件不存在，则使用引导所用 kubeconfig 从 API 服务器请求客户端证书。成功后，将引用生成的客户端证书和密钥的 kubeconfig 写入 --kubeconfig 所指定的路径。客户端证书和密钥文件将存储在 --cert-dir 所指的目录。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--kubeconfig string</span><br><span class="line">kubeconfig 配置文件的路径，指定如何连接到 API 服务器。提供 --kubeconfig 将启用 API 服务器模式，而省略 --kubeconfig 将启用独立模式。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--network-plugin string</span><br><span class="line">&lt;警告：alpha 特性&gt; 设置 kubelet/Pod 生命周期中各种事件调用的网络插件的名称。仅当容器运行环境设置为 docker 时，此特定于 docker 的参数才有效。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--cni-conf-dir string     默认值：/etc/cni/net.d</span><br><span class="line">&lt;警告：alpha 特性&gt; 此值为某目录的全路径名。kubelet 将在其中搜索 CNI 配置文件。仅当容器运行环境设置为 docker 时，此特定于 docker 的参数才有效。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--cni-bin-dir string     默认值：/opt/cni/bin</span><br><span class="line">&lt;警告：alpha 特性&gt; 此值为以逗号分隔的完整路径列表。kubelet 将在所指定路径中搜索 CNI 插件的可执行文件。仅当容器运行环境设置为 docker 时，此特定于 docker 的参数才有效。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--container-runtime string     默认值：docker</span><br><span class="line">要使用的容器运行时。目前支持 docker、remote。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--runtime-request-timeout duration     默认值：2m0s</span><br><span class="line">设置除了长时间运行的请求（包括 pull、logs、exec 和 attach 等操作）之外的其他运行时请求的超时时间。到达超时时间时，请求会被取消，抛出一个错误并会等待重试。已弃用：应在 --config 所给的配置文件中进行设置。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--container-runtime-endpoint string     默认值：unix:///var/run/dockershim.sock</span><br><span class="line">[实验性特性] 远程运行时服务的端点。目前支持 Linux 系统上的 UNIX 套接字和 Windows 系统上的 npipe 和 TCP 端点。例如：unix:///var/run/dockershim.sock、 npipe:////./pipe/dockershim。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--cgroup-driver string     默认值：cgroupfs</span><br><span class="line">kubelet 用来操作本机 cgroup 时使用的驱动程序。支持的选项包括 cgroupfs 和 systemd。已弃用：应在 --config 所给的配置文件中进行设置。</span><br></pre></td></tr></table></figure>

<p><strong>kube-proxy</strong></p>
<p>Kubernetes 网络代理在每个节点上运行。网络代理反映了每个节点上 Kubernetes API 中定义的服务，并且可以执行简单的 TCP、UDP 和 SCTP 流转发，或者在一组后端进行 循环 TCP、UDP 和 SCTP 转发。当前可通过 Docker-links-compatible 环境变量找到服务集群 IP 和端口， 这些环境变量指定了服务代理打开的端口。有一个可选的插件，可以为这些集群 IP 提供集群 DNS。用户必须使用 apiserver API 创建服务才能配置代理。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \</span><br><span class="line">--config=/etc/kubernetes/kube-proxy.yaml \</span><br><span class="line">--v=2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--config string</span><br><span class="line">配置文件的路径。</span><br></pre></td></tr></table></figure>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>利用NGINX搭建部署直播流媒体服务器</title>
    <url>/2022/03/23/2022-03-23-%E5%88%A9%E7%94%A8NGINX%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E7%9B%B4%E6%92%AD%E6%B5%81%E5%AA%92%E4%BD%93%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5dfb3a7d70874dc5acedba95eb63499d~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>直播如今是一个老生常谈的问题，怎么用于直播，大多数人只晓得，大佬某平台直播软件，点击开始即可直播。那么如何来搭建一个简易的直播平台呢？仅仅是有直播功能，没有涉及转码以及播放软件。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装nginx以及rtmp模块</span><br><span class="line"></span><br><span class="line">root@cby:~# apt install nginx</span><br><span class="line">root@cby:~# apt install libnginx-mod-rtmp</span><br><span class="line"></span><br><span class="line">修改配置以支持rtmp</span><br><span class="line">root@cby:~# vim /etc/nginx/nginx.conf</span><br><span class="line">rtmp &#123;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 1935;</span><br><span class="line">        chunk_size 4096;</span><br><span class="line">        application live &#123;</span><br><span class="line">            live on;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">检查是否有报错</span><br><span class="line">root@cby:~# nginx -t</span><br><span class="line">nginx: the configuration file /etc/nginx/nginx.conf syntax is ok</span><br><span class="line">nginx: configuration file /etc/nginx/nginx.conf test is successful</span><br><span class="line">root@cby:~# </span><br><span class="line"></span><br><span class="line">重启nginx</span><br><span class="line">root@cby:~# systemctl restart nginx</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用obs直播工具进行推流操作  </p>
<p>rtmp:&#x2F;&#x2F;&lt;你的域名或者IP&gt;:1935&#x2F;live</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b45d78b6803a4461a72ac6f84b4a0430~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>使用vlc拉流播放</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/213ab9de78394063be0d21d55a4e4aa2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>查看效果</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d2cf4ac8ff1f4eacb0139284bfdc6208~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Containerd 入门基础操作</title>
    <url>/2022/03/21/2022-03-21-Containerd_%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>Containerd 被 Docker、Kubernetes  CRI 和其他一些项目使用</p>
<p>Containerd 旨在轻松嵌入到更大的系统中。Docker 在后台使用 containerd来运行容器。Kubernetes 可以通过 CRI 使用 containerd来管理单个节点上的容器。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0fc6fe64ea794d388dd0abbb196c8ac0~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>生成默认配置</p>
<pre><code class="shell">root@hello:~# containerd config default &gt; /etc/containerd/config.toml


root@hello:~# vim /etc/containerd/config.toml 


root@hello:~# cat /etc/containerd/config.toml
version = 2
root = &quot;/var/lib/containerd&quot;
state = &quot;/run/containerd&quot;
plugin_dir = &quot;&quot;
disabled_plugins = []
required_plugins = []
oom_score = 0


[grpc]
  address = &quot;/run/containerd/containerd.sock&quot;
  tcp_address = &quot;&quot;
  tcp_tls_cert = &quot;&quot;
  tcp_tls_key = &quot;&quot;
  uid = 0
  gid = 0
  max_recv_message_size = 16777216
  max_send_message_size = 16777216


[ttrpc]
  address = &quot;&quot;
  uid = 0
  gid = 0


[debug]
  address = &quot;&quot;
  uid = 0
  gid = 0
  level = &quot;&quot;


[metrics]
  address = &quot;&quot;
  grpc_histogram = false


[cgroup]
  path = &quot;&quot;


[timeouts]
  &quot;io.containerd.timeout.shim.cleanup&quot; = &quot;5s&quot;
  &quot;io.containerd.timeout.shim.load&quot; = &quot;5s&quot;
  &quot;io.containerd.timeout.shim.shutdown&quot; = &quot;3s&quot;
  &quot;io.containerd.timeout.task.state&quot; = &quot;2s&quot;


[plugins]
  [plugins.&quot;io.containerd.gc.v1.scheduler&quot;]
    pause_threshold = 0.02
    deletion_threshold = 0
    mutation_threshold = 100
    schedule_delay = &quot;0s&quot;
    startup_delay = &quot;100ms&quot;
  [plugins.&quot;io.containerd.grpc.v1.cri&quot;]
    disable_tcp_service = true
    stream_server_address = &quot;127.0.0.1&quot;
    stream_server_port = &quot;0&quot;
    stream_idle_timeout = &quot;4h0m0s&quot;
    enable_selinux = false
    selinux_category_range = 1024
    sandbox_image = &quot;k8s.gcr.io/pause:3.2&quot;
    stats_collect_period = 10
    systemd_cgroup = false
    enable_tls_streaming = false
    max_container_log_line_size = 16384
    disable_cgroup = false
    disable_apparmor = false
    restrict_oom_score_adj = false
    max_concurrent_downloads = 3
    disable_proc_mount = false
    unset_seccomp_profile = &quot;&quot;
    tolerate_missing_hugetlb_controller = true
    disable_hugetlb_controller = true
    ignore_image_defined_volumes = false
    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd]
      snapshotter = &quot;overlayfs&quot;
      default_runtime_name = &quot;runc&quot;
      no_pivot = false
      disable_snapshot_annotations = true
      discard_unpacked_layers = false
      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.default_runtime]
        runtime_type = &quot;&quot;
        runtime_engine = &quot;&quot;
        runtime_root = &quot;&quot;
        privileged_without_host_devices = false
        base_runtime_spec = &quot;&quot;
      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.untrusted_workload_runtime]
        runtime_type = &quot;&quot;
        runtime_engine = &quot;&quot;
        runtime_root = &quot;&quot;
        privileged_without_host_devices = false
        base_runtime_spec = &quot;&quot;
      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes]
        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc]
          runtime_type = &quot;io.containerd.runc.v2&quot;
          runtime_engine = &quot;&quot;
          runtime_root = &quot;&quot;
          privileged_without_host_devices = false
          base_runtime_spec = &quot;&quot;
          [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]
    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]
      bin_dir = &quot;/opt/cni/bin&quot;
      conf_dir = &quot;/etc/cni/net.d&quot;
      max_conf_num = 1
      conf_template = &quot;&quot;
    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]
      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors]
        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]
          endpoint = [&quot;https://registry-1.docker.io&quot;]
    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.image_decryption]
      key_model = &quot;&quot;
    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.x509_key_pair_streaming]
      tls_cert_file = &quot;&quot;
      tls_key_file = &quot;&quot;
  [plugins.&quot;io.containerd.internal.v1.opt&quot;]
    path = &quot;/opt/containerd&quot;
  [plugins.&quot;io.containerd.internal.v1.restart&quot;]
    interval = &quot;10s&quot;
  [plugins.&quot;io.containerd.metadata.v1.bolt&quot;]
    content_sharing_policy = &quot;shared&quot;
  [plugins.&quot;io.containerd.monitor.v1.cgroups&quot;]
    no_prometheus = false
  [plugins.&quot;io.containerd.runtime.v1.linux&quot;]
    shim = &quot;containerd-shim&quot;
    runtime = &quot;runc&quot;
    runtime_root = &quot;&quot;
    no_shim = false
    shim_debug = false
  [plugins.&quot;io.containerd.runtime.v2.task&quot;]
    platforms = [&quot;linux/amd64&quot;]
  [plugins.&quot;io.containerd.service.v1.diff-service&quot;]
    default = [&quot;walking&quot;]
  [plugins.&quot;io.containerd.snapshotter.v1.devmapper&quot;]
    root_path = &quot;&quot;
    pool_name = &quot;&quot;
    base_image_size = &quot;&quot;
    async_remove = false
root@hello:~# 
```shell

  

配置镜像加速器

  

```shell
    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]
      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors]
        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]
          endpoint = [&quot;https://ted9wxpi.mirror.aliyuncs.com&quot;]
```shell

  

  

ctr 相当于核心组件，通过加载插件的方式来支持各种操作。

  

使用 ctr plugins ls 来查看当前加载的插件和支持的操作。

  

```shell
[root@k8s-master01 ~]# ctr plugins ls
TYPE                            ID                       PLATFORMS      STATUS    
io.containerd.content.v1        content                  -              ok        
io.containerd.snapshotter.v1    aufs                     linux/amd64    error     
io.containerd.snapshotter.v1    devmapper                linux/amd64    error     
io.containerd.snapshotter.v1    native                   linux/amd64    ok        
io.containerd.snapshotter.v1    overlayfs                linux/amd64    ok        
io.containerd.snapshotter.v1    zfs                      linux/amd64    error     
io.containerd.metadata.v1       bolt                     -              ok        
io.containerd.differ.v1         walking                  linux/amd64    ok        
io.containerd.gc.v1             scheduler                -              ok        
io.containerd.service.v1        introspection-service    -              ok        
io.containerd.service.v1        containers-service       -              ok        
io.containerd.service.v1        content-service          -              ok        
io.containerd.service.v1        diff-service             -              ok        
io.containerd.service.v1        images-service           -              ok        
io.containerd.service.v1        leases-service           -              ok        
io.containerd.service.v1        namespaces-service       -              ok        
io.containerd.service.v1        snapshots-service        -              ok        
io.containerd.runtime.v1        linux                    linux/amd64    ok        
io.containerd.runtime.v2        task                     linux/amd64    ok        
io.containerd.monitor.v1        cgroups                  linux/amd64    ok        
io.containerd.service.v1        tasks-service            -              ok        
io.containerd.internal.v1       restart                  -              ok        
io.containerd.grpc.v1           containers               -              ok        
io.containerd.grpc.v1           content                  -              ok        
io.containerd.grpc.v1           diff                     -              ok        
io.containerd.grpc.v1           events                   -              ok        
io.containerd.grpc.v1           healthcheck              -              ok        
io.containerd.grpc.v1           images                   -              ok        
io.containerd.grpc.v1           leases                   -              ok        
io.containerd.grpc.v1           namespaces               -              ok        
io.containerd.internal.v1       opt                      -              ok        
io.containerd.grpc.v1           snapshots                -              ok        
io.containerd.grpc.v1           tasks                    -              ok        
io.containerd.grpc.v1           version                  -              ok        
io.containerd.grpc.v1           cri                      linux/amd64    ok        
[root@k8s-master01 ~]#
```shell

  

ctr plugins ls 命令会展示三列 ，第二列 ID 就是对应的命令。

  

  

例如 plugins 的 id 为 content 可使用 ctr content --help 来查看帮助，以及其他命令来执行操作。

  

```shell
[root@k8s-master01 ~]# ctr content --help
NAME:
   ctr content - manage content


USAGE:
   ctr content [global options] command [command options] [arguments...]


VERSION:
   1.4.13


COMMANDS:
   active                   display active transfers
   delete, del, remove, rm  permanently delete one or more blobs
   edit                     edit a blob and return a new digest
   fetch                    fetch all content for an image into containerd
   fetch-object             retrieve objects from a remote
   get                      get the data for an object
   ingest                   accept content into the store
   list, ls                 list all blobs in the store
   push-object              push an object to a remote
   label                    add labels to content


GLOBAL OPTIONS:
   --help, -h  show help
[root@k8s-master01 ~]# 
```shell

  

  

查看有哪些命名空间

  

```shell
[root@k8s-master01 ~]# ctr namespace ls
NAME    LABELS 
default        
k8s.io         
[root@k8s-master01 ~]# 
```shell

  

  

查看 k8s.io 空间下的镜像有哪些

  

```shell
[root@k8s-master01 ~]# ctr -n k8s.io  images ls
REF                                                                                                                                 TYPE                                                      DIGEST                                                                  SIZE      PLATFORMS                                                                    LABELS                          
k8s.gcr.io/ingress-nginx/kube-webhook-certgen@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660               application/vnd.docker.distribution.manifest.list.v2+json sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660 18.0 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/s390x
```shell

  

接下来 从 容器的 生命周期流程 来说明 ctr 命令的使用。

  

ctr images ls 查看镜像

  

```shell
[root@k8s-master01 ~]# ctr images ls
REF                            TYPE                                                      DIGEST                                                                  SIZE    PLATFORMS                                                                                LABELS 
docker.io/library/nginx:alpine application/vnd.docker.distribution.manifest.list.v2+json sha256:77cc350019d0188d3115084265483dcefdd8489ccf719ff4e4c956b48de8ff6a 9.7 MiB linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x -      
[root@k8s-master01 ~]#
```shell

  

  

  

ctr images pull 拉取镜像 

  

```shell
[root@k8s-master01 ~]# ctr images pull docker.io/library/nginx:alpine
docker.io/library/nginx:alpine:                                                   resolved       |++++++++++++++++++++++++++++++++++++++| 
index-sha256:77cc350019d0188d3115084265483dcefdd8489ccf719ff4e4c956b48de8ff6a:    done           |++++++++++++++++++++++++++++++++++++++| 
manifest-sha256:1e3458b8841319dec826a9a63b66f98c0bb260d50454dcdbdfe414eed362a3c4: done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:9a9d990f68b82fceea08b4b08a0549e3de8ba7840ac721e0b8cc4d2d27e33ccf:    done           |++++++++++++++++++++++++++++++++++++++| 
config-sha256:7d73f57a7cf733ff46e22c3d60cb237f7b29e8e7ec6753922f2daa7f5af5d186:   done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:6c53e58c6af6338b6ea1ddeb46b638a719e4afdd2cffb5cf80362af3e61099d1:    done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:bda3fba8f6c468c5b9f60cec056498ebdedf711410c8864f956f0b8d3408428c:    done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:e07cc103cea6f44382a40ffe1f7d893781521aa2723765c069f23480e674dd0c:    done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:3d243047344378e9b7136d552d48feb7ea8b6fe14ce0990e0cc011d5e369626a:    done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:4ba4f346920eaf3fd54877cf123ac46a7bbea16f23d4b0bdc210988ebe7969f0:    done           |++++++++++++++++++++++++++++++++++++++| 
elapsed: 14.8s                                                                    total:  9.7 Mi (671.0 KiB/s)                                     
unpacking linux/amd64 sha256:77cc350019d0188d3115084265483dcefdd8489ccf719ff4e4c956b48de8ff6a...
done
[root@k8s-master01 ~]# 
```shell

  

只有通过 crictl 或者 Kubernetes 调用时 mirror 才会生效，通过 ctr 拉取是不会生效的。

  

  

ctr images rm 删除镜像

  

```shell
[root@k8s-master01 ~]# ctr images rm docker.io/library/nginx:alpine
docker.io/library/nginx:alpine


[root@k8s-master01 ~]# 
[root@k8s-master01 ~]# ctr images ls
REF TYPE DIGEST SIZE PLATFORMS LABELS 
[root@k8s-master01 ~]# 
```shell

  

ctr images mount 挂载

  

```shell
[root@k8s-master01 ~]# ctr images ls
REF                            TYPE                                                      DIGEST                                                                  SIZE    PLATFORMS                                                                                LABELS 
docker.io/library/nginx:alpine application/vnd.docker.distribution.manifest.list.v2+json sha256:77cc350019d0188d3115084265483dcefdd8489ccf719ff4e4c956b48de8ff6a 9.7 MiB linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x -      


[root@k8s-master01 ~]# ctr images mount docker.io/library/nginx:alpine /cby
sha256:7a7cbbee0f17b403a980a36ae708bbd9ee428511a7219da36c50ce7e33662d43
/cby
[root@k8s-master01 ~]# 


[root@k8s-master01 ~]# ls /cby/
bin  docker-entrypoint.d   etc   lib    mnt  proc  run   srv  tmp  var
dev  docker-entrypoint.sh  home  media  opt  root  sbin  sys  usr
[root@k8s-master01 ~]# 
```shell

  

ctr images unmount 卸载

  

```shell
[root@k8s-master01 ~]# ctr images  unmount  /cby
/cby
[root@k8s-master01 ~]#
```shell

  

ctr images  export 导出镜像

  

```shell
root@hello:~# ctr images  export nginx.tar docker.io/library/nginx:alpine
root@hello:~# 
root@hello:~# ls nginx.tar 
nginx.tar
root@hello:~# 
```shell

  

ctr images import 导入镜像

  

```shell
root@hello:~# ctr images import nginx.tar
unpacking docker.io/library/nginx:alpine (sha256:77cc350019d0188d3115084265483dcefdd8489ccf719ff4e4c956b48de8ff6a)...done
root@hello:~# 
```shell

  

  

ctr中 containers 是镜像实例化的一个虚拟环境，提供一个磁盘，模拟空间，就好比你电脑处于关机状态一样。

  

ctr中 tasks 是将容器运行起来，电脑开机了 ，初始化进程等 ，task就是的这么个形式。

  

  

ctr containers ls 查看容器

  

```shell
root@hello:~# ctr containers  ls
CONTAINER    IMAGE                             RUNTIME                  
nginx        docker.io/library/nginx:alpine    io.containerd.runc.v2    
root@hello:~# 
```shell

  

ctr containers create 创建容器

  

```shell
root@hello:~# ctr containers create docker.io/library/nginx:alpine nginx
root@hello:~# 
```shell

  

ctr containers rm 删除容器

  

```shell
root@hello:~# ctr containers rm nginx

root@hello:~# ctr containers  ls
CONTAINER    IMAGE    RUNTIME    
root@hello:~# 
```shell

  

ctr containers info 查看详细信息

  

```shell
root@hello:~# ctr containers info nginx
&#123;
    &quot;ID&quot;: &quot;nginx&quot;,
    &quot;Labels&quot;: &#123;
        &quot;io.containerd.image.config.stop-signal&quot;: &quot;SIGQUIT&quot;
    &#125;,
    &quot;Image&quot;: &quot;docker.io/library/nginx:alpine&quot;,
    &quot;Runtime&quot;: &#123;
        &quot;Name&quot;: &quot;io.containerd.runc.v2&quot;,
        &quot;Options&quot;: &#123;
            &quot;type_url&quot;: &quot;containerd.runc.v1.Options&quot;
        &#125;
    &#125;,
    &quot;SnapshotKey&quot;: &quot;nginx&quot;,
    &quot;Snapshotter&quot;: &quot;overlayfs&quot;,
    &quot;CreatedAt&quot;: &quot;2022-03-21T08:51:45.127872097Z&quot;,
    &quot;UpdatedAt&quot;: &quot;2022-03-21T08:51:45.127872097Z&quot;,
    &quot;Extensions&quot;: null,
    &quot;Spec&quot;: &#123;
---略---
```shell

  

  

create 的命令创建了容器后，并没有处于运行状态，只是一个静态的容器。一个 container 对象只是包含了运行一个容器所需的资源及配置的数据结构，这意味着 namespaces、rootfs 和容器的配置都已经初始化成功了，只是用户进程(这里是 nginx)还没有启动。

  

  

ctr tasks start -d 在后台运行容器

  

```shell
root@hello:~# ctr tasks start -d  nginx


root@hello:~# ctr tasks ls
TASK     PID       STATUS    
nginx    118454    RUNNING
root@hello:~# 
```shell

  

ctr task exec 进入容器，id随便写就行，需要将其唯一

  

```shell
root@hello:~# ctr task exec --exec-id 1 -t nginx sh
/ # 
```shell

  

ctr task pause 暂停容器

  

```shell
root@hello:~# ctr task pause nginx
root@hello:~# ctr task ls
TASK     PID       STATUS    
nginx    118454    PAUSED
root@hello:~#
```shell

  

ctr task resume 恢复容器

  

```shell
root@hello:~# ctr task resume nginx
root@hello:~# ctr task ls
TASK     PID       STATUS    
nginx    118454    RUNNING
root@hello:~# 
```shell

  

ctr task kill 杀死容器

  

```shell
root@hello:~# ctr task kill nginx
root@hello:~# ctr task ls
TASK     PID       STATUS    
nginx    118454    STOPPED
root@hello:~# 
```shell

  

ctr task metrics获取容器信息

  

```shell
root@hello:~# ctr task metrics nginx
ID       TIMESTAMP                                  
nginx    2022-03-21 09:05:49.949321537 +0000 UTC    


METRIC                   VALUE                                                                       
memory.usage_in_bytes    3821568                                                                     
memory.limit_in_bytes    9223372036854771712                                                         
memory.stat.cache        135168                                                                      
cpuacct.usage            176641571                                                                   
cpuacct.usage_percpu     [24856408 21740008 12150472 37947198 31775746 28169704 7366623 12635412]    
pids.current             0                                                                           
pids.limit               0                                                                           
root@hello:~# 
```shell

  

ctr tasks rm 删除容器

  

```shell
root@hello:~# ctr tasks rm nginx
root@hello:~# ctr tasks ls
TASK    PID    STATUS    
root@hello:~#
```shell

  
  

  

https://www.oiox.cn/

https://www.chenby.cn/

https://cby-chen.github.io/

https://weibo.com/u/5982474121

https://blog.csdn.net/qq_33921750

https://my.oschina.net/u/3981543

https://www.zhihu.com/people/chen-bu-yun-2

https://segmentfault.com/u/hppyvyv6/articles

https://juejin.cn/user/3315782802482007

https://space.bilibili.com/352476552/article

https://cloud.tencent.com/developer/column/93230

https://www.jianshu.com/u/0f894314ae2c

https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/

CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》
</code></pre>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装Kubernetes（k8s） v1.23.4</title>
    <url>/2022/02/26/2022-02-26-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85Kubernetes%EF%BC%88k8s%EF%BC%89_v1.23.4/</url>
    <content><![CDATA[<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1.环境"></a>1.环境</h1><table>
<thead>
<tr>
<th>主机名称</th>
<th>IP地址</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td>Master01</td>
<td>192.168.1.30</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master02</td>
<td>192.168.1.31</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master03</td>
<td>192.168.1.32</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node01</td>
<td>192.168.1.33</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node02</td>
<td>192.168.1.34</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node03</td>
<td>192.168.1.35</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node04</td>
<td>192.168.1.36</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node05</td>
<td>192.168.1.37</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Lb01</td>
<td>192.168.1.38</td>
<td>Lb01节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td>Lb02</td>
<td>192.168.1.39</td>
<td>Lb02节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td></td>
<td>192.168.1.88</td>
<td>VIP</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">软件</th>
<th align="left">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">内核</td>
<td align="left">5.16.7-1.el8.elrepo.x86_64</td>
</tr>
<tr>
<td align="left">CentOS 8</td>
<td align="left">v8</td>
</tr>
<tr>
<td align="left">kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy</td>
<td align="left">v1.23.4</td>
</tr>
<tr>
<td align="left">etcd</td>
<td align="left">v3.5.2</td>
</tr>
<tr>
<td align="left">docker-ce</td>
<td align="left">v20.10.9</td>
</tr>
<tr>
<td align="left">containerd</td>
<td align="left">v1.6.0</td>
</tr>
<tr>
<td align="left">cfssl</td>
<td align="left">v1.6.1</td>
</tr>
<tr>
<td align="left">cni</td>
<td align="left">v1.6.0</td>
</tr>
<tr>
<td align="left">crictl</td>
<td align="left">v1.23.0</td>
</tr>
<tr>
<td align="left">haproxy</td>
<td align="left">v1.8.27</td>
</tr>
<tr>
<td align="left">keepalived</td>
<td align="left">v2.1.5</td>
</tr>
</tbody></table>
<p>网段</p>
<p>物理主机：192.168.1.0&#x2F;24</p>
<p>service：10.96.0.0&#x2F;12</p>
<p>pod：172.16.0.0&#x2F;12</p>
<p>如果有条件建议k8s集群与etcd集群分开安装</p>
<h2 id="1-1-k8s基础系统环境配置"><a href="#1-1-k8s基础系统环境配置" class="headerlink" title="1.1.k8s基础系统环境配置"></a>1.1.k8s基础系统环境配置</h2><h3 id="1-2-配置IP"><a href="#1-2-配置IP" class="headerlink" title="1.2.配置IP"></a>1.2.配置IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@192.168.1.76 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.30/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.77 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.31/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.78 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.32/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.79 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.33/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.80 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.34/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.86 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.35/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.87 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.36/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.166 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.37/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.100 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.38/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.191 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.39/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br></pre></td></tr></table></figure>

<h3 id="1-3-设置主机名"><a href="#1-3-设置主机名" class="headerlink" title="1.3.设置主机名"></a>1.3.设置主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-master02</span><br><span class="line">hostnamectl set-hostname k8s-master03</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br><span class="line">hostnamectl set-hostname k8s-node03</span><br><span class="line">hostnamectl set-hostname k8s-node04</span><br><span class="line">hostnamectl set-hostname k8s-node05</span><br><span class="line">hostnamectl set-hostname lb01</span><br><span class="line">hostnamectl set-hostname lb02</span><br></pre></td></tr></table></figure>

<h3 id="1-4-配置yum源"><a href="#1-4-配置yum源" class="headerlink" title="1.4.配置yum源"></a>1.4.配置yum源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=http://192.168.1.123/centos|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; -e &#x27;s|^#baseurl=http://mirror.centos.org/\$contentdir|baseurl=http://192.168.1.123/centos|g&#x27; -i.bak  /etc/yum.repos.d/CentOS-*.repo</span><br></pre></td></tr></table></figure>

<h3 id="1-5-安装一些必备工具"><a href="#1-5-安装一些必备工具" class="headerlink" title="1.5.安装一些必备工具"></a>1.5.安装一些必备工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install wget jq psmisc vim net-tools  telnet yum-utils device-mapper-persistent-data lvm2 git network-scripts tar curl -y</span><br></pre></td></tr></table></figure>

<h3 id="1-6-安装docker工具"><a href="#1-6-安装docker工具" class="headerlink" title="1.6.安装docker工具"></a>1.6.安装docker工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br></pre></td></tr></table></figure>

<h3 id="1-7-关闭防火墙"><a href="#1-7-关闭防火墙" class="headerlink" title="1.7.关闭防火墙"></a>1.7.关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br></pre></td></tr></table></figure>

<h3 id="1-8-关闭SELinux"><a href="#1-8-关闭SELinux" class="headerlink" title="1.8.关闭SELinux"></a>1.8.关闭SELinux</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/sysconfig/selinux</span><br></pre></td></tr></table></figure>

<h3 id="1-9-关闭交换分区"><a href="#1-9-关闭交换分区" class="headerlink" title="1.9.关闭交换分区"></a>1.9.关闭交换分区</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">cat /etc/fstab</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>

<h3 id="1-10-关闭NetworkManager-并启用-network"><a href="#1-10-关闭NetworkManager-并启用-network" class="headerlink" title="1.10.关闭NetworkManager 并启用 network"></a>1.10.关闭NetworkManager 并启用 network</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now NetworkManager</span><br><span class="line">systemctl start network &amp;&amp; systemctl enable network</span><br></pre></td></tr></table></figure>

<h3 id="1-11-进行时间同步"><a href="#1-11-进行时间同步" class="headerlink" title="1.11.进行时间同步"></a>1.11.进行时间同步</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">服务端</span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">cat &gt; /etc/chrony.conf &lt;&lt; EOF </span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">allow 192.168.1.0/24</span><br><span class="line">local stratum 10</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd</span><br><span class="line">systemctl enable chronyd</span><br><span class="line"></span><br><span class="line">客户端</span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool 192.168.1.30 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum install chrony -y ; sed -i &quot;s#2.centos.pool.ntp.org#192.168.1.30#g&quot; /etc/chrony.conf ; systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">使用客户端进行验证</span><br><span class="line"></span><br><span class="line">chronyc sources -v</span><br></pre></td></tr></table></figure>

<h3 id="1-12-配置ulimit"><a href="#1-12-配置ulimit" class="headerlink" title="1.12.配置ulimit"></a>1.12.配置ulimit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -SHn 65535</span><br><span class="line">cat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOF</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* seft memlock unlimited</span><br><span class="line">* hard memlock unlimitedd</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="1-13-配置免密登录"><a href="#1-13-配置免密登录" class="headerlink" title="1.13.配置免密登录"></a>1.13.配置免密登录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br><span class="line">ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;</span><br><span class="line">export IP=&quot;192.168.1.30 192.168.1.31 192.168.1.32 192.168.1.33 192.168.1.34 192.168.1.35 192.168.1.36 192.168.1.37 192.168.1.38 192.168.1.39&quot;</span><br><span class="line">export SSHPASS=123123</span><br><span class="line">for HOST in $IP;do</span><br><span class="line">     sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $HOST</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="1-14-添加启用源"><a href="#1-14-添加启用源" class="headerlink" title="1.14.添加启用源"></a>1.14.添加启用源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">为 RHEL-8或 CentOS-8配置源</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line">为 RHEL-7 SL-7 或 CentOS-7 安装 ELRepo </span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line">查看可用安装包</span><br><span class="line">yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available</span><br></pre></td></tr></table></figure>

<h3 id="1-15-升级内核至4-18版本以上"><a href="#1-15-升级内核至4-18版本以上" class="headerlink" title="1.15.升级内核至4.18版本以上"></a>1.15.升级内核至4.18版本以上</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装最新的内核</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我这里选择的是稳定版kernel-ml   如需更新长期维护版本kernel-lt</span>  </span><br><span class="line">yum  --enablerepo=elrepo-kernel  install  kernel-ml</span><br><span class="line"></span><br><span class="line">查看已安装那些内核</span><br><span class="line">rpm -qa | grep kernel</span><br><span class="line">kernel-core-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-core-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-ml-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-modules-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-libs-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-modules-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">查看默认内核</span><br><span class="line">grubby --default-kernel</span><br><span class="line">/boot/vmlinuz-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">若不是最新的使用命令设置</span><br><span class="line">grubby --set-default /boot/vmlinuz-「您的内核版本」.x86_64</span><br><span class="line"></span><br><span class="line">重启生效</span><br><span class="line">reboot</span><br><span class="line"></span><br><span class="line">整合命令为：</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --default-kernel ; reboot</span><br></pre></td></tr></table></figure>

<h3 id="1-16-安装ipvsadm"><a href="#1-16-安装ipvsadm" class="headerlink" title="1.16.安装ipvsadm"></a>1.16.安装ipvsadm</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;EOF </span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">ip_tables</span><br><span class="line">ip_set</span><br><span class="line">xt_set</span><br><span class="line">ipt_set</span><br><span class="line">ipt_rpfilter</span><br><span class="line">ipt_REJECT</span><br><span class="line">ipip</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart systemd-modules-load.service</span><br><span class="line"></span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack</span><br><span class="line">ip_vs_sh               16384  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          176128  1 ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure>

<h3 id="1-17-修改内核参数"><a href="#1-17-修改内核参数" class="headerlink" title="1.17.修改内核参数"></a>1.17.修改内核参数</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="1-18-所有节点配置hosts本地解析"><a href="#1-18-所有节点配置hosts本地解析" class="headerlink" title="1.18.所有节点配置hosts本地解析"></a>1.18.所有节点配置hosts本地解析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.1.30 k8s-master01</span><br><span class="line">192.168.1.31 k8s-master02</span><br><span class="line">192.168.1.32 k8s-master03</span><br><span class="line">192.168.1.33 k8s-node01</span><br><span class="line">192.168.1.34 k8s-node02</span><br><span class="line">192.168.1.35 k8s-node03</span><br><span class="line">192.168.1.36 k8s-node04</span><br><span class="line">192.168.1.37 k8s-node05</span><br><span class="line">192.168.1.38 lb01</span><br><span class="line">192.168.1.39 lb02</span><br><span class="line">192.168.1.88 lb-vip</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="2-k8s基本组件安装"><a href="#2-k8s基本组件安装" class="headerlink" title="2.k8s基本组件安装"></a>2.k8s基本组件安装</h1><h2 id="2-1-所有k8s节点安装Containerd作为Runtime"><a href="#2-1-所有k8s节点安装Containerd作为Runtime" class="headerlink" title="2.1.所有k8s节点安装Containerd作为Runtime"></a>2.1.所有k8s节点安装Containerd作为Runtime</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install containerd -y</span><br></pre></td></tr></table></figure>

<h3 id="2-1-1配置Containerd所需的模块"><a href="#2-1-1配置Containerd所需的模块" class="headerlink" title="2.1.1配置Containerd所需的模块"></a>2.1.1配置Containerd所需的模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2加载模块"><a href="#2-1-2加载模块" class="headerlink" title="2.1.2加载模块"></a>2.1.2加载模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl restart systemd-modules-load.service</span><br></pre></td></tr></table></figure>

<h3 id="2-1-3配置Containerd所需的内核"><a href="#2-1-3配置Containerd所需的内核" class="headerlink" title="2.1.3配置Containerd所需的内核"></a>2.1.3配置Containerd所需的内核</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载内核</span></span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4创建Containerd的配置文件"><a href="#2-1-4创建Containerd的配置文件" class="headerlink" title="2.1.4创建Containerd的配置文件"></a>2.1.4创建Containerd的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改Containerd的配置文件</span><br><span class="line">sed -i &#x27;/containerd\.runtimes\.runc\.options/ a\\t\tSystemdCgroup\ =\ true&#x27; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">cat /etc/containerd/config.toml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到containerd.runtimes.runc.options，在其下加入SystemdCgroup = <span class="literal">true</span></span></span><br><span class="line"></span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">              SystemdCgroup = true</span><br><span class="line">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sandbox_image默认地址改为符合版本地址</span></span><br><span class="line"></span><br><span class="line">    sandbox_image = &quot;registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&quot;</span><br></pre></td></tr></table></figure>

<h3 id="2-1-5启动并设置为开机启动"><a href="#2-1-5启动并设置为开机启动" class="headerlink" title="2.1.5启动并设置为开机启动"></a>2.1.5启动并设置为开机启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now </span><br></pre></td></tr></table></figure>

<h3 id="2-1-6配置crictl客户端连接的运行时位置"><a href="#2-1-6配置crictl客户端连接的运行时位置" class="headerlink" title="2.1.6配置crictl客户端连接的运行时位置"></a>2.1.6配置crictl客户端连接的运行时位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/crictl.yaml &lt;&lt;EOF</span><br><span class="line">runtime-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">image-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">timeout: 10</span><br><span class="line">debug: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="2-2-k8s与etcd下载及安装（仅在master01操作）"><a href="#2-2-k8s与etcd下载及安装（仅在master01操作）" class="headerlink" title="2.2.k8s与etcd下载及安装（仅在master01操作）"></a>2.2.k8s与etcd下载及安装（仅在master01操作）</h2><h3 id="2-2-1下载k8s安装包（你用哪个下哪个）"><a href="#2-2-1下载k8s安装包（你用哪个下哪个）" class="headerlink" title="2.2.1下载k8s安装包（你用哪个下哪个）"></a>2.2.1下载k8s安装包（你用哪个下哪个）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1.下载kubernetes1.23.+的二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md</span><br><span class="line"></span><br><span class="line">wget https://dl.k8s.io/v1.23.4/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">2.下载etcdctl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/etcd-io/etcd/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.5.2/etcd-v3.5.2-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">3.docker-ce二进制包下载地址</span><br><span class="line">二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><br><span class="line"></span><br><span class="line">这里需要下载20.10.+版本</span><br><span class="line"></span><br><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-20.10.9.tgz</span><br><span class="line"></span><br><span class="line">4.containerd二进制包下载</span><br><span class="line">github下载地址：https://github.com/containerd/containerd/releases</span><br><span class="line"></span><br><span class="line">containerd下载时下载带cni插件的二进制包。</span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.0-rc.2/cri-containerd-cni-1.6.0-rc.2-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">5.下载cfssl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/cloudflare/cfssl/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.1_linux_amd64</span><br><span class="line"></span><br><span class="line">6.cni插件下载</span><br><span class="line">github下载地址：https://github.com/containernetworking/plugins/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.0.1/cni-plugins-linux-amd64-v1.0.1.tgz</span><br><span class="line"></span><br><span class="line">7.crictl客户端二进制下载</span><br><span class="line">github下载：https://github.com/kubernetes-sigs/cri-tools/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.23.0/crictl-v1.23.0-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">解压k8s安装文件</span><br><span class="line">tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;</span><br><span class="line"></span><br><span class="line">解压etcd安装文件</span><br><span class="line">tar -xf etcd-v3.5.2-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.2-linux-amd64/etcd&#123;,ctl&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看/usr/local/bin下内容</span></span><br><span class="line"></span><br><span class="line">ls /usr/local/bin/</span><br><span class="line">etcd  etcdctl  kube-apiserver  kube-controller-manager  kubectl  kubelet  kube-proxy  kube-scheduler</span><br><span class="line"></span><br><span class="line">已经整理好的：</span><br><span class="line">wget https://github.com/cby-chen/Kubernetes/releases/download/cby/Kubernetes.tar</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2查看版本"><a href="#2-2-2查看版本" class="headerlink" title="2.2.2查看版本"></a>2.2.2查看版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubelet --version</span><br><span class="line">Kubernetes v1.23.4</span><br><span class="line">[root@k8s-master01 ~]# etcdctl version</span><br><span class="line">etcdctl version: 3.5.1</span><br><span class="line">API version: 3.5</span><br></pre></td></tr></table></figure>

<h3 id="2-2-3将组件发送至其他k8s节点"><a href="#2-2-3将组件发送至其他k8s节点" class="headerlink" title="2.2.3将组件发送至其他k8s节点"></a>2.2.3将组件发送至其他k8s节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">Work=&#x27;k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05&#x27;</span><br><span class="line">for NODE in $Master; do echo $NODE; scp /usr/local/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done</span><br><span class="line">for NODE in $Work; do     scp /usr/local/bin/kube&#123;let,-proxy&#125; $NODE:/usr/local/bin/ ; done</span><br></pre></td></tr></table></figure>

<h3 id="2-2-4克隆证书相关文件"><a href="#2-2-4克隆证书相关文件" class="headerlink" title="2.2.4克隆证书相关文件"></a>2.2.4克隆证书相关文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/cby-chen/Kubernetes.git</span><br></pre></td></tr></table></figure>

<h3 id="2-2-5所有k8s节点创建目录"><a href="#2-2-5所有k8s节点创建目录" class="headerlink" title="2.2.5所有k8s节点创建目录"></a>2.2.5所有k8s节点创建目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /opt/cni/bin</span><br></pre></td></tr></table></figure>

<h1 id="3-相关证书生成"><a href="#3-相关证书生成" class="headerlink" title="3.相关证书生成"></a>3.相关证书生成</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">master01节点下载证书生成工具</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssl</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssljson</span><br><span class="line">chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</span><br></pre></td></tr></table></figure>

<h2 id="3-1-生成etcd证书"><a href="#3-1-生成etcd证书" class="headerlink" title="3.1.生成etcd证书"></a>3.1.生成etcd证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-1-1所有master节点创建证书存放目录"><a href="#3-1-1所有master节点创建证书存放目录" class="headerlink" title="3.1.1所有master节点创建证书存放目录"></a>3.1.1所有master节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/etcd/ssl -p</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2master01节点生成etcd证书"><a href="#3-1-2master01节点生成etcd证书" class="headerlink" title="3.1.2master01节点生成etcd证书"></a>3.1.2master01节点生成etcd证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd Kubernetes/pki/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成etcd证书和etcd证书的key（如果你觉得以后可能会扩容，可以在ip那多写几个预留出来）</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,192.168.1.30,192.168.1.31,192.168.1.32 \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</span><br></pre></td></tr></table></figure>

<h3 id="3-1-3将证书复制到其他节点"><a href="#3-1-3将证书复制到其他节点" class="headerlink" title="3.1.3将证书复制到其他节点"></a>3.1.3将证书复制到其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">for NODE in $Master; do</span><br><span class="line">     ssh $NODE &quot;mkdir -p /etc/etcd/ssl&quot;</span><br><span class="line">     for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do</span><br><span class="line">       scp /etc/etcd/ssl/$&#123;FILE&#125; $NODE:/etc/etcd/ssl/$&#123;FILE&#125;</span><br><span class="line">     done</span><br><span class="line"> done</span><br></pre></td></tr></table></figure>

<h2 id="3-2-生成k8s相关证书"><a href="#3-2-生成k8s相关证书" class="headerlink" title="3.2.生成k8s相关证书"></a>3.2.生成k8s相关证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-2-1所有k8s节点创建证书存放目录"><a href="#3-2-1所有k8s节点创建证书存放目录" class="headerlink" title="3.2.1所有k8s节点创建证书存放目录"></a>3.2.1所有k8s节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2master01节点生成k8s证书"><a href="#3-2-2master01节点生成k8s证书" class="headerlink" title="3.2.2master01节点生成k8s证书"></a>3.2.2master01节点生成k8s证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成一个根证书</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.96.0.1是service网段的第一个地址，需要计算，192.168.1.88为高可用vip地址</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   \</span><br><span class="line">-ca=/etc/kubernetes/pki/ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-hostname=10.96.0.1,192.168.1.88,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,x.oiox.cn,k.oiox.cn,l.oiox.cn,o.oiox.cn,192.168.1.30,192.168.1.31,192.168.1.32,192.168.1.33,192.168.1.34,192.168.1.35,192.168.1.36,192.168.1.37,192.168.1.38,192.168.1.39,192.168.1.40,192.168.1.41   \</span><br><span class="line">-profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3生成apiserver聚合证书"><a href="#3-2-3生成apiserver聚合证书" class="headerlink" title="3.2.3生成apiserver聚合证书"></a>3.2.3生成apiserver聚合证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有一个警告，可以忽略</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   -ca=/etc/kubernetes/pki/front-proxy-ca.pem   -ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   -config=ca-config.json   -profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4生成controller-manage的证书"><a href="#3-2-4生成controller-manage的证书" class="headerlink" title="3.2.4生成controller-manage的证书"></a>3.2.4生成controller-manage的证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个集群项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://192.168.1.88:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个环境项，一个上下文</span></span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=system:kube-controller-manager \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个用户项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置默认环境</span></span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://192.168.1.88:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/scheduler.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/scheduler-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --cluster=kubernetes \</span><br><span class="line">     --user=system:kube-scheduler \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.88:8443     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes-admin     --client-certificate=/etc/kubernetes/pki/admin.pem     --client-key=/etc/kubernetes/pki/admin-key.pem     --embed-certs=true     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes     --cluster=kubernetes     --user=kubernetes-admin     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5创建ServiceAccount-Key-——secret"><a href="#3-2-5创建ServiceAccount-Key-——secret" class="headerlink" title="3.2.5创建ServiceAccount Key ——secret"></a>3.2.5创建ServiceAccount Key ——secret</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out /etc/kubernetes/pki/sa.key 2048</span><br><span class="line">openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</span><br></pre></td></tr></table></figure>

<h3 id="3-2-6将证书发送到其他master节点"><a href="#3-2-6将证书发送到其他master节点" class="headerlink" title="3.2.6将证书发送到其他master节点"></a>3.2.6将证书发送到其他master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do </span><br><span class="line">for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do </span><br><span class="line">scp /etc/kubernetes/pki/$&#123;FILE&#125; $NODE:/etc/kubernetes/pki/$&#123;FILE&#125;;</span><br><span class="line">done; </span><br><span class="line">for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do </span><br><span class="line">scp /etc/kubernetes/$&#123;FILE&#125; $NODE:/etc/kubernetes/$&#123;FILE&#125;;</span><br><span class="line">done;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="3-2-7查看证书"><a href="#3-2-7查看证书" class="headerlink" title="3.2.7查看证书"></a>3.2.7查看证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /etc/kubernetes/pki/</span><br><span class="line">admin.csr      apiserver-key.pem  ca.pem                      front-proxy-ca.csr      front-proxy-client-key.pem  scheduler.csr</span><br><span class="line">admin-key.pem  apiserver.pem      controller-manager.csr      front-proxy-ca-key.pem  front-proxy-client.pem      scheduler-key.pem</span><br><span class="line">admin.pem      ca.csr             controller-manager-key.pem  front-proxy-ca.pem      sa.key                      scheduler.pem</span><br><span class="line">apiserver.csr  ca-key.pem         controller-manager.pem      front-proxy-client.csr  sa.pub</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一共23个就对了</span></span><br><span class="line"></span><br><span class="line">ls /etc/kubernetes/pki/ |wc -l</span><br><span class="line">23</span><br></pre></td></tr></table></figure>

<h1 id="4-k8s系统组件配置"><a href="#4-k8s系统组件配置" class="headerlink" title="4.k8s系统组件配置"></a>4.k8s系统组件配置</h1><h2 id="4-1-etcd配置"><a href="#4-1-etcd配置" class="headerlink" title="4.1.etcd配置"></a>4.1.etcd配置</h2><h3 id="4-1-1master01配置"><a href="#4-1-1master01配置" class="headerlink" title="4.1.1master01配置"></a>4.1.1master01配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master01&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.30:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.30:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.30:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.30:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.30:2380,k8s-master02=https://192.168.1.31:2380,k8s-master03=https://192.168.1.32:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2master02配置"><a href="#4-1-2master02配置" class="headerlink" title="4.1.2master02配置"></a>4.1.2master02配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master02&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.31:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.31:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.31:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.31:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.30:2380,k8s-master02=https://192.168.1.31:2380,k8s-master03=https://192.168.1.32:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3master03配置"><a href="#4-1-3master03配置" class="headerlink" title="4.1.3master03配置"></a>4.1.3master03配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master03&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.32:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.32:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.32:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.32:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.30:2380,k8s-master02=https://192.168.1.31:2380,k8s-master03=https://192.168.1.32:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="4-2-创建service（所有master节点操作）"><a href="#4-2-创建service（所有master节点操作）" class="headerlink" title="4.2.创建service（所有master节点操作）"></a>4.2.创建service（所有master节点操作）</h2><h3 id="4-2-1创建etcd-service并启动"><a href="#4-2-1创建etcd-service并启动" class="headerlink" title="4.2.1创建etcd.service并启动"></a>4.2.1创建etcd.service并启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2创建etcd证书目录"><a href="#4-2-2创建etcd证书目录" class="headerlink" title="4.2.2创建etcd证书目录"></a>4.2.2创建etcd证书目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/kubernetes/pki/etcd</span><br><span class="line">ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now etcd</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3查看etcd状态"><a href="#4-2-3查看etcd状态" class="headerlink" title="4.2.3查看etcd状态"></a>4.2.3查看etcd状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --endpoints=&quot;192.168.1.32:2379,192.168.1.31:2379,192.168.1.30:2379&quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|     ENDPOINT      |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| 192.168.1.32:2379 | 56875ab4a12c94e8 |   3.5.1 |   25 kB |     false |      false |         2 |          8 |                  8 |        |</span><br><span class="line">| 192.168.1.31:2379 | 33df6a8fe708d3fd |   3.5.1 |   25 kB |      true |      false |         2 |          8 |                  8 |        |</span><br><span class="line">| 192.168.1.30:2379 | 58fbe5ec9743048f |   3.5.1 |   20 kB |     false |      false |         2 |          8 |                  8 |        |</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>

<h1 id="5-高可用配置"><a href="#5-高可用配置" class="headerlink" title="5.高可用配置"></a>5.高可用配置</h1><h2 id="5-1在lb01和lb02两台服务器上操作"><a href="#5-1在lb01和lb02两台服务器上操作" class="headerlink" title="5.1在lb01和lb02两台服务器上操作"></a>5.1在lb01和lb02两台服务器上操作</h2><h3 id="5-1-1安装keepalived和haproxy服务"><a href="#5-1-1安装keepalived和haproxy服务" class="headerlink" title="5.1.1安装keepalived和haproxy服务"></a>5.1.1安装keepalived和haproxy服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">systemctl disable --now firewalld</span><br><span class="line"></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/sysconfig/selinux</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum -y install keepalived haproxy</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2修改haproxy配置文件（两台配置文件一样）"><a href="#5-1-2修改haproxy配置文件（两台配置文件一样）" class="headerlink" title="5.1.2修改haproxy配置文件（两台配置文件一样）"></a>5.1.2修改haproxy配置文件（两台配置文件一样）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt;/etc/haproxy/haproxy.cfg&lt;&lt;&quot;EOF&quot;</span><br><span class="line">global</span><br><span class="line"> maxconn 2000</span><br><span class="line"> ulimit-n 16384</span><br><span class="line"> log 127.0.0.1 local0 err</span><br><span class="line"> stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"> log global</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> timeout connect 5000</span><br><span class="line"> timeout client 50000</span><br><span class="line"> timeout server 50000</span><br><span class="line"> timeout http-request 15s</span><br><span class="line"> timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line"> bind *:33305</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line"> bind 0.0.0.0:8443</span><br><span class="line"> bind 127.0.0.1:8443</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> tcp-request inspect-delay 5s</span><br><span class="line"> default_backend k8s-master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> option tcp-check</span><br><span class="line"> balance roundrobin</span><br><span class="line"> default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line"> server  k8s-master01  192.168.1.30:6443 check</span><br><span class="line"> server  k8s-master02  192.168.1.31:6443 check</span><br><span class="line"> server  k8s-master03  192.168.1.32:6443 check</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-3lb01配置keepalived-master节点"><a href="#5-1-3lb01配置keepalived-master节点" class="headerlink" title="5.1.3lb01配置keepalived master节点"></a>5.1.3lb01配置keepalived master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens18</span><br><span class="line">    mcast_src_ip 192.168.1.38</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.88</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4lb02配置keepalived-backup节点"><a href="#5-1-4lb02配置keepalived-backup节点" class="headerlink" title="5.1.4lb02配置keepalived backup节点"></a>5.1.4lb02配置keepalived backup节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens18</span><br><span class="line">    mcast_src_ip 192.168.1.39</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 50</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.88</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-5健康检查脚本配置（两台lb主机）"><a href="#5-1-5健康检查脚本配置（两台lb主机）" class="headerlink" title="5.1.5健康检查脚本配置（两台lb主机）"></a>5.1.5健康检查脚本配置（两台lb主机）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/keepalived/check_apiserver.sh &lt;&lt; EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">err=0</span><br><span class="line">for k in \$(seq 1 3)</span><br><span class="line">do</span><br><span class="line">    check_code=\$(pgrep haproxy)</span><br><span class="line">    if [[ \$check_code == &quot;&quot; ]]; then</span><br><span class="line">        err=\$(expr \$err + 1)</span><br><span class="line">        sleep 1</span><br><span class="line">        continue</span><br><span class="line">    else</span><br><span class="line">        err=0</span><br><span class="line">        break</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ \$err != &quot;0&quot; ]]; then</span><br><span class="line">    echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">    /usr/bin/systemctl stop keepalived</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给脚本授权</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_apiserver.sh</span><br></pre></td></tr></table></figure>

<h3 id="5-1-6启动服务"><a href="#5-1-6启动服务" class="headerlink" title="5.1.6启动服务"></a>5.1.6启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now haproxy</span><br><span class="line">systemctl enable --now keepalived</span><br></pre></td></tr></table></figure>

<h3 id="5-1-7测试高可用"><a href="#5-1-7测试高可用" class="headerlink" title="5.1.7测试高可用"></a>5.1.7测试高可用</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能ping同</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# ping 192.168.1.88</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能telnet访问</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# telnet 192.168.1.88 8443</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭主节点，看vip是否漂移到备节点</span></span><br></pre></td></tr></table></figure>

<h1 id="6-k8s组件配置（区别于第4点）"><a href="#6-k8s组件配置（区别于第4点）" class="headerlink" title="6.k8s组件配置（区别于第4点）"></a>6.k8s组件配置（区别于第4点）</h1><p>所有k8s节点创建以下目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes</span><br></pre></td></tr></table></figure>

<h2 id="6-1-创建apiserver（所有master节点）"><a href="#6-1-创建apiserver（所有master节点）" class="headerlink" title="6.1.创建apiserver（所有master节点）"></a>6.1.创建apiserver（所有master节点）</h2><h3 id="6-1-1master01节点配置"><a href="#6-1-1master01节点配置" class="headerlink" title="6.1.1master01节点配置"></a>6.1.1master01节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.30 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.30:2379,https://192.168.1.31:2379,https://192.168.1.32:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-2master02节点配置"><a href="#6-1-2master02节点配置" class="headerlink" title="6.1.2master02节点配置"></a>6.1.2master02节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.31 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.30:2379,https://192.168.1.31:2379,https://192.168.1.32:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-3master03节点配置"><a href="#6-1-3master03节点配置" class="headerlink" title="6.1.3master03节点配置"></a>6.1.3master03节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service  &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.32 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.30:2379,https://192.168.1.31:2379,https://192.168.1.32:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-4启动apiserver（所有master节点）"><a href="#6-1-4启动apiserver（所有master节点）" class="headerlink" title="6.1.4启动apiserver（所有master节点）"></a>6.1.4启动apiserver（所有master节点）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl enable --now kube-apiserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意查看状态是否启动正常</span></span><br><span class="line"></span><br><span class="line">systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>

<h2 id="6-2-配置kube-controller-manager-service"><a href="#6-2-配置kube-controller-manager-service" class="headerlink" title="6.2.配置kube-controller-manager service"></a>6.2.配置kube-controller-manager service</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">所有master节点配置，且配置相同</span><br><span class="line">172.16.0.0/12为pod网段，按需求设置你自己的网段</span><br><span class="line"></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --use-service-account-credentials=true \</span><br><span class="line">      --node-monitor-grace-period=40s \</span><br><span class="line">      --node-monitor-period=5s \</span><br><span class="line">      --pod-eviction-timeout=2m0s \</span><br><span class="line">      --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">      --allocate-node-cidrs=true \</span><br><span class="line">      --cluster-cidr=172.16.0.0/12 \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem \</span><br><span class="line">      --node-cidr-mask-size=24</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-2-1启动kube-controller-manager，并查看状态"><a href="#6-2-1启动kube-controller-manager，并查看状态" class="headerlink" title="6.2.1启动kube-controller-manager，并查看状态"></a>6.2.1启动kube-controller-manager，并查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-controller-manager</span><br><span class="line">systemctl  status kube-controller-manager</span><br></pre></td></tr></table></figure>

<h2 id="6-3-配置kube-scheduler-service"><a href="#6-3-配置kube-scheduler-service" class="headerlink" title="6.3.配置kube-scheduler service"></a>6.3.配置kube-scheduler service</h2><h3 id="6-3-1所有master节点配置，且配置相同"><a href="#6-3-1所有master节点配置，且配置相同" class="headerlink" title="6.3.1所有master节点配置，且配置相同"></a>6.3.1所有master节点配置，且配置相同</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-3-2启动并查看服务状态"><a href="#6-3-2启动并查看服务状态" class="headerlink" title="6.3.2启动并查看服务状态"></a>6.3.2启动并查看服务状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-scheduler</span><br><span class="line">systemctl status kube-scheduler</span><br></pre></td></tr></table></figure>

<h1 id="7-TLS-Bootstrapping配置"><a href="#7-TLS-Bootstrapping配置" class="headerlink" title="7.TLS Bootstrapping配置"></a>7.TLS Bootstrapping配置</h1><h2 id="7-1在master01上配置"><a href="#7-1在master01上配置" class="headerlink" title="7.1在master01上配置"></a>7.1在master01上配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/bootstrap</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.88:8443     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials tls-bootstrap-token-user     --token=c8ad9c.2e4d610cf3e7426e --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context tls-bootstrap-token-user@kubernetes     --cluster=kubernetes     --user=tls-bootstrap-token-user     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context tls-bootstrap-token-user@kubernetes     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">token的位置在bootstrap.secret.yaml，如果修改的话到这个文件修改</span></span><br><span class="line"></span><br><span class="line">mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config</span><br></pre></td></tr></table></figure>

<h2 id="7-2查看集群状态，没问题的话继续后续操作"><a href="#7-2查看集群状态，没问题的话继续后续操作" class="headerlink" title="7.2查看集群状态，没问题的话继续后续操作"></a>7.2查看集群状态，没问题的话继续后续操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line"></span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE                         ERROR</span><br><span class="line">controller-manager   Healthy   ok                              </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">scheduler            Healthy   ok                              </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;  </span><br><span class="line"></span><br><span class="line">kubectl create -f bootstrap.secret.yaml</span><br></pre></td></tr></table></figure>

<h1 id="8-node节点配置"><a href="#8-node节点配置" class="headerlink" title="8.node节点配置"></a>8.node节点配置</h1><h2 id="8-1-在master01上将证书复制到node节点"><a href="#8-1-在master01上将证书复制到node节点" class="headerlink" title="8.1.在master01上将证书复制到node节点"></a>8.1.在master01上将证书复制到node节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/kubernetes/</span><br><span class="line"></span><br><span class="line">for NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do</span><br><span class="line">     ssh $NODE mkdir -p /etc/kubernetes/pki</span><br><span class="line">     for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig; do</span><br><span class="line">       scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&#123;FILE&#125;</span><br><span class="line"> done</span><br><span class="line"> done</span><br></pre></td></tr></table></figure>

<h2 id="8-2-kubelet配置"><a href="#8-2-kubelet配置" class="headerlink" title="8.2.kubelet配置"></a>8.2.kubelet配置</h2><h3 id="8-2-1所有k8s节点创建相关目录"><a href="#8-2-1所有k8s节点创建相关目录" class="headerlink" title="8.2.1所有k8s节点创建相关目录"></a>8.2.1所有k8s节点创建相关目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">所有k8s节点配置kubelet service</span><br><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kubelet</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-2所有k8s节点配置kubelet-service的配置文件"><a href="#8-2-2所有k8s节点配置kubelet-service的配置文件" class="headerlink" title="8.2.2所有k8s节点配置kubelet service的配置文件"></a>8.2.2所有k8s节点配置kubelet service的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/systemd/system/kubelet.service.d/10-kubelet.conf &lt;&lt; EOF</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig&quot;</span><br><span class="line">Environment=&quot;KUBELET_SYSTEM_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin --container-runtime=remote --runtime-request-timeout=15m --container-runtime-endpoint=unix:///run/containerd/containerd.sock --cgroup-driver=systemd&quot;</span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml&quot;</span><br><span class="line">Environment=&quot;KUBELET_EXTRA_ARGS=--node-labels=node.kubernetes.io/node=&#x27;&#x27; &quot;</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \$KUBELET_KUBECONFIG_ARGS \$KUBELET_CONFIG_ARGS \$KUBELET_SYSTEM_ARGS \$KUBELET_EXTRA_ARGS</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-3所有k8s节点创建kubelet的配置文件"><a href="#8-2-3所有k8s节点创建kubelet的配置文件" class="headerlink" title="8.2.3所有k8s节点创建kubelet的配置文件"></a>8.2.3所有k8s节点创建kubelet的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-4启动kubelet"><a href="#8-2-4启动kubelet" class="headerlink" title="8.2.4启动kubelet"></a>8.2.4启动kubelet</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">systemctl enable --now kubelet</span><br></pre></td></tr></table></figure>

<h3 id="8-2-5查看集群"><a href="#8-2-5查看集群" class="headerlink" title="8.2.5查看集群"></a>8.2.5查看集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get node</span><br><span class="line">NAME           STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   Ready    &lt;none&gt;   80s   v1.23.4</span><br><span class="line">k8s-master02   Ready    &lt;none&gt;   78s   v1.23.4</span><br><span class="line">k8s-master03   Ready    &lt;none&gt;   74s   v1.23.4</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;   86s   v1.23.4</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;   95s   v1.23.4</span><br><span class="line">k8s-node03     Ready    &lt;none&gt;   87s   v1.23.4</span><br><span class="line">k8s-node04     Ready    &lt;none&gt;   65s   v1.23.4</span><br><span class="line">k8s-node05     Ready    &lt;none&gt;   77s   v1.23.4</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="8-3-kube-proxy配置"><a href="#8-3-kube-proxy配置" class="headerlink" title="8.3.kube-proxy配置"></a>8.3.kube-proxy配置</h2><h3 id="8-3-1此配置只在master01操作"><a href="#8-3-1此配置只在master01操作" class="headerlink" title="8.3.1此配置只在master01操作"></a>8.3.1此配置只在master01操作</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/</span><br><span class="line">kubectl -n kube-system create serviceaccount kube-proxy</span><br><span class="line"></span><br><span class="line">kubectl create clusterrolebinding system:kube-proxy         --clusterrole system:node-proxier         --serviceaccount kube-system:kube-proxy</span><br><span class="line"></span><br><span class="line">SECRET=$(kubectl -n kube-system get sa/kube-proxy \</span><br><span class="line">    --output=jsonpath=&#x27;&#123;.secrets[0].name&#125;&#x27;)</span><br><span class="line"></span><br><span class="line">JWT_TOKEN=$(kubectl -n kube-system get secret/$SECRET \</span><br><span class="line">--output=jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class="line"></span><br><span class="line">PKI_DIR=/etc/kubernetes/pki</span><br><span class="line">K8S_DIR=/etc/kubernetes</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.88:8443     --kubeconfig=$&#123;K8S_DIR&#125;/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes     --token=$&#123;JWT_TOKEN&#125;     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes     --cluster=kubernetes     --user=kubernetes     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="8-3-2将kubeconfig发送至其他节点"><a href="#8-3-2将kubeconfig发送至其他节点" class="headerlink" title="8.3.2将kubeconfig发送至其他节点"></a>8.3.2将kubeconfig发送至其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do</span><br><span class="line">     scp /etc/kubernetes/kube-proxy.kubeconfig  $NODE:/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line">for NODE in k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do</span><br><span class="line">     scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"> done</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3所有k8s节点添加kube-proxy的配置和service文件"><a href="#8-3-3所有k8s节点添加kube-proxy的配置和service文件" class="headerlink" title="8.3.3所有k8s节点添加kube-proxy的配置和service文件"></a>8.3.3所有k8s节点添加kube-proxy的配置和service文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy.yaml \</span><br><span class="line">  --v=2</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4启动kube-proxy"><a href="#8-3-4启动kube-proxy" class="headerlink" title="8.3.4启动kube-proxy"></a>8.3.4启动kube-proxy</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-proxy</span><br></pre></td></tr></table></figure>

<h1 id="9-安装Calico"><a href="#9-安装Calico" class="headerlink" title="9.安装Calico"></a>9.安装Calico</h1><h2 id="9-1以下步骤只在master01操作"><a href="#9-1以下步骤只在master01操作" class="headerlink" title="9.1以下步骤只在master01操作"></a>9.1以下步骤只在master01操作</h2><h3 id="9-1-1更改calico网段"><a href="#9-1-1更改calico网段" class="headerlink" title="9.1.1更改calico网段"></a>9.1.1更改calico网段</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/calico/</span><br><span class="line">sed -i &quot;s#POD_CIDR#172.16.0.0/12#g&quot; calico.yaml</span><br><span class="line">grep &quot;IPV4POOL_CIDR&quot; calico.yaml  -A 1</span><br><span class="line">            - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">              value: &quot;172.16.0.0/12&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建</span></span><br><span class="line"></span><br><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure>

<h3 id="9-1-2查看容器状态"><a href="#9-1-2查看容器状态" class="headerlink" title="9.1.2查看容器状态"></a>9.1.2查看容器状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  get pod -A</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-kube-controllers-6f6595874c-cf2sf   1/1     Running   0          14m</span><br><span class="line">kube-system   calico-node-2xd2q                          1/1     Running   0          2m25s</span><br><span class="line">kube-system   calico-node-jtzfh                          1/1     Running   0          2m3s</span><br><span class="line">kube-system   calico-node-k4jkc                          1/1     Running   0          2m24s</span><br><span class="line">kube-system   calico-node-msxwp                          1/1     Running   0          2m15s</span><br><span class="line">kube-system   calico-node-tv849                          1/1     Running   0          2m12s</span><br><span class="line">kube-system   calico-node-wdbzt                          1/1     Running   0          2m18s</span><br><span class="line">kube-system   calico-node-x9sjr                          1/1     Running   0          2m33s</span><br><span class="line">kube-system   calico-node-z2mz5                          1/1     Running   0          2m16s</span><br><span class="line">kube-system   calico-typha-6b6cf8cbdf-gshvt              1/1     Running   0          14m</span><br></pre></td></tr></table></figure>

<h1 id="10-安装CoreDNS"><a href="#10-安装CoreDNS" class="headerlink" title="10.安装CoreDNS"></a>10.安装CoreDNS</h1><h2 id="10-1以下步骤只在master01操作"><a href="#10-1以下步骤只在master01操作" class="headerlink" title="10.1以下步骤只在master01操作"></a>10.1以下步骤只在master01操作</h2><h3 id="10-1-1修改文件"><a href="#10-1-1修改文件" class="headerlink" title="10.1.1修改文件"></a>10.1.1修改文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/CoreDNS/</span><br><span class="line">sed -i &quot;s#KUBEDNS_SERVICE_IP#10.96.0.10#g&quot; coredns.yaml</span><br><span class="line"></span><br><span class="line">cat coredns.yaml | grep clusterIP:</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br></pre></td></tr></table></figure>

<h3 id="10-1-2安装"><a href="#10-1-2安装" class="headerlink" title="10.1.2安装"></a>10.1.2安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  create -f coredns.yaml </span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.apps/coredns created</span><br><span class="line">service/kube-dns created</span><br></pre></td></tr></table></figure>

<h1 id="11-安装Metrics-Server"><a href="#11-安装Metrics-Server" class="headerlink" title="11.安装Metrics Server"></a>11.安装Metrics Server</h1><h2 id="11-1以下步骤只在master01操作"><a href="#11-1以下步骤只在master01操作" class="headerlink" title="11.1以下步骤只在master01操作"></a>11.1以下步骤只在master01操作</h2><h3 id="11-1-1安装Metrics-server"><a href="#11-1-1安装Metrics-server" class="headerlink" title="11.1.1安装Metrics-server"></a>11.1.1安装Metrics-server</h3><p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装metrics server</span><br><span class="line">cd /root/Kubernetes/metrics-server/</span><br><span class="line"></span><br><span class="line">kubectl  create -f . </span><br><span class="line"></span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">deployment.apps/metrics-server created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br></pre></td></tr></table></figure>

<h3 id="11-1-2稍等片刻查看状态"><a href="#11-1-2稍等片刻查看状态" class="headerlink" title="11.1.2稍等片刻查看状态"></a>11.1.2稍等片刻查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   172m         2%     1307Mi          16%       </span><br><span class="line">k8s-master02   157m         1%     1189Mi          15%       </span><br><span class="line">k8s-master03   155m         1%     1105Mi          14%       </span><br><span class="line">k8s-node01     99m          1%     710Mi           9%        </span><br><span class="line">k8s-node02     79m          0%     585Mi           7%</span><br></pre></td></tr></table></figure>

<h1 id="12-集群验证"><a href="#12-集群验证" class="headerlink" title="12.集群验证"></a>12.集群验证</h1><h2 id="12-1部署pod资源"><a href="#12-1部署pod资源" class="headerlink" title="12.1部署pod资源"></a>12.1部署pod资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line"></span><br><span class="line">kubectl  get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox   1/1     Running   0          17s</span><br></pre></td></tr></table></figure>

<h2 id="12-2用pod解析默认命名空间中的kubernetes"><a href="#12-2用pod解析默认命名空间中的kubernetes" class="headerlink" title="12.2用pod解析默认命名空间中的kubernetes"></a>12.2用pod解析默认命名空间中的kubernetes</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   17h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl exec  busybox -n default -- nslookup kubernetes</span><br><span class="line">3Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-3测试跨命名空间是否可以解析"><a href="#12-3测试跨命名空间是否可以解析" class="headerlink" title="12.3测试跨命名空间是否可以解析"></a>12.3测试跨命名空间是否可以解析</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl exec  busybox -n default -- nslookup kube-dns.kube-system</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kube-dns.kube-system</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53"><a href="#12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53" class="headerlink" title="12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53"></a>12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">telnet 10.96.0.1 443</span><br><span class="line">Trying 10.96.0.1...</span><br><span class="line">Connected to 10.96.0.1.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line"> telnet 10.96.0.10 53</span><br><span class="line">Trying 10.96.0.10...</span><br><span class="line">Connected to 10.96.0.10.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line">curl 10.96.0.10:53</span><br><span class="line">curl: (52) Empty reply from server</span><br></pre></td></tr></table></figure>

<h2 id="12-5Pod和Pod之前要能通"><a href="#12-5Pod和Pod之前要能通" class="headerlink" title="12.5Pod和Pod之前要能通"></a>12.5Pod和Pod之前要能通</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get po -owide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox   1/1     Running   0          17m   172.27.14.193   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"> kubectl get po -n kube-system -owide</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS      AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-5dffd5886b-4blh6   1/1     Running   0             77m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-fvbdq                          1/1     Running   1 (75m ago)   77m   192.168.1.30     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-g8nqd                          1/1     Running   0             77m   192.168.1.33     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-mdps8                          1/1     Running   0             77m   192.168.1.34     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-nf4nt                          1/1     Running   0             77m   192.168.1.32     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-sq2ml                          1/1     Running   0             77m   192.168.1.31     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-mg6p8              1/1     Running   0             77m   192.168.1.34     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-pxbpj              1/1     Running   0             77m   192.168.1.30     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-tnssl              1/1     Running   0             77m   192.168.1.33     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5db5696c7-67h79                    1/1     Running   0             63m   172.25.92.65     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">metrics-server-6bf7dcd649-5fhrw            1/1     Running   0             61m   172.18.195.1     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入busybox ping其他节点上的pod</span></span><br><span class="line"></span><br><span class="line">kubectl exec -ti busybox -- sh</span><br><span class="line">/ # ping 192.168.1.33</span><br><span class="line">PING 192.168.1.33 (192.168.1.33): 56 data bytes</span><br><span class="line">64 bytes from 192.168.1.33: seq=0 ttl=63 time=0.358 ms</span><br><span class="line">64 bytes from 192.168.1.33: seq=1 ttl=63 time=0.668 ms</span><br><span class="line">64 bytes from 192.168.1.33: seq=2 ttl=63 time=0.637 ms</span><br><span class="line">64 bytes from 192.168.1.33: seq=3 ttl=63 time=0.624 ms</span><br><span class="line">64 bytes from 192.168.1.33: seq=4 ttl=63 time=0.907 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以连通证明这个pod是可以跨命名空间和跨主机通信的</span></span><br></pre></td></tr></table></figure>

<h2 id="12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"><a href="#12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）" class="headerlink" title="12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"></a>12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; deployments.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl  apply -f deployments.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">kubectl  get pod </span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                            1/1     Running   0          6m25s</span><br><span class="line">nginx-deployment-9456bbbf9-4bmvk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-9rcdk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-dqv8s   1/1     Running   0          8s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除nginx</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f deployments.yaml </span><br></pre></td></tr></table></figure>

<h1 id="13-安装dashboard"><a href="#13-安装dashboard" class="headerlink" title="13.安装dashboard"></a>13.安装dashboard</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/dashboard/</span><br><span class="line"></span><br><span class="line">kubectl  create -f .</span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line">namespace/kubernetes-dashboard created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-csrf created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/dashboard-metrics-scraper created</span><br><span class="line">deployment.apps/dashboard-metrics-scraper created</span><br></pre></td></tr></table></figure>

<h2 id="13-1创建管理员用户"><a href="#13-1创建管理员用户" class="headerlink" title="13.1创建管理员用户"></a>13.1创建管理员用户</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; admin.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line"></span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding </span><br><span class="line">metadata: </span><br><span class="line">  name: admin-user</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="13-2执行yaml文件"><a href="#13-2执行yaml文件" class="headerlink" title="13.2执行yaml文件"></a>13.2执行yaml文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f admin.yaml -n kube-system</span><br><span class="line"></span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br></pre></td></tr></table></figure>

<h2 id="13-3更改dashboard的svc为NodePort，如果已是请忽略"><a href="#13-3更改dashboard的svc为NodePort，如果已是请忽略" class="headerlink" title="13.3更改dashboard的svc为NodePort，如果已是请忽略"></a>13.3更改dashboard的svc为NodePort，如果已是请忽略</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure>

<h2 id="13-4查看端口号"><a href="#13-4查看端口号" class="headerlink" title="13.4查看端口号"></a>13.4查看端口号</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.98.201.22   &lt;none&gt;        443:31245/TCP   10m</span><br></pre></td></tr></table></figure>

<h2 id="13-5查看token"><a href="#13-5查看token" class="headerlink" title="13.5查看token"></a>13.5查看token</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;)</span><br><span class="line">Name:         admin-user-token-k545k</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: c308071c-4cf5-4583-83a2-eaf7812512b4</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6InYzV2dzNnQzV3hHb2FQWnYzdnlOSmpudmtpVmNjQW5VM3daRi12SFM4dEEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWs1NDVrIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjMzA4MDcxYy00Y2Y1LTQ1ODMtODNhMi1lYWY3ODEyNTEyYjQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pshvZPi9ZJkXUWuWilcYs1wawTpzV-nMKesgF3d_l7qyTPaK2N5ofzIThd0SjzU7BFNb4_rOm1dw1Be5kLeHjY_YW5lDnM5TAxVPXmZQ0HJ2pAQ0pjQqCHFnPD0bZFIYkeyz8pZx0Hmwcd3ZdC1yztr0ADpTAmMgI9NC2ZFIeoFFo4Ue9ZM_ulhqJQjmgoAlI_qbyjuKCNsWeEQBwM6HHHAsH1gOQIdVxqQ83OQZUuynDQRpqlHHFIndbK2zVRYFA3GgUnTu2-VRQ-DXBFRjvZR5qArnC1f383jmIjGT6VO7l04QJteG_LFetRbXa-T4mcnbsd8XutSgO0INqwKpjw</span><br><span class="line">ca.crt:     1363 bytes</span><br><span class="line">namespace:  11 bytes</span><br></pre></td></tr></table></figure>

<h2 id="13-6登录dashboard"><a href="#13-6登录dashboard" class="headerlink" title="13.6登录dashboard"></a>13.6登录dashboard</h2><p><a href="https://192.168.1.30:31245/">https://192.168.1.30:31245/</a></p>
<p>eyJhbGciOiJSUzI1NiIsImtpZCI6InYzV2dzNnQzV3hHb2FQWnYzdnlOSmpudmtpVmNjQW5VM3daRi12SFM4dEEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWs1NDVrIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjMzA4MDcxYy00Y2Y1LTQ1ODMtODNhMi1lYWY3ODEyNTEyYjQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pshvZPi9ZJkXUWuWilcYs1wawTpzV-nMKesgF3d_l7qyTPaK2N5ofzIThd0SjzU7BFNb4_rOm1dw1Be5kLeHjY_YW5lDnM5TAxVPXmZQ0HJ2pAQ0pjQqCHFnPD0bZFIYkeyz8pZx0Hmwcd3ZdC1yztr0ADpTAmMgI9NC2ZFIeoFFo4Ue9ZM_ulhqJQjmgoAlI_qbyjuKCNsWeEQBwM6HHHAsH1gOQIdVxqQ83OQZUuynDQRpqlHHFIndbK2zVRYFA3GgUnTu2-VRQ-DXBFRjvZR5qArnC1f383jmIjGT6VO7l04QJteG_LFetRbXa-T4mcnbsd8XutSgO0INqwKpjw</p>
<h1 id="14-安装命令行自动补全功能"><a href="#14-安装命令行自动补全功能" class="headerlink" title="14.安装命令行自动补全功能"></a>14.安装命令行自动补全功能</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install bash-completion -y</span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>

<h1 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h1><p>配置kube-controller-manager有效期100年（能不能生效的先配上再说）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">[Service]下找个地方加上</span></span><br><span class="line"></span><br><span class="line">--cluster-signing-duration=876000h0m0s \</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启</span></span><br><span class="line"></span><br><span class="line">systemctl daemon-reload </span><br><span class="line">systemctl restart kube-controller-manager</span><br></pre></td></tr></table></figure>

<p>防止漏洞扫描</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf</span><br><span class="line"></span><br><span class="line">[Service] </span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--kubeconfig=/etc/kubernetes/kubelet.kubeconfig --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig&quot; </span><br><span class="line">Environment=&quot;KUBELET_SYSTEM_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin&quot; </span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml  --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&quot; </span><br><span class="line">Environment=&quot;KUBELET_EXTRA_ARGS=--tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384    --image-pull-progress-deadline=30m&quot; </span><br><span class="line">ExecStart= </span><br><span class="line">ExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_SYSTEM_ARGS $KUBELET_EXTRA_ARGS </span><br></pre></td></tr></table></figure>

<p>预留空间，按需分配</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/kubernetes/kubelet-conf.yml</span><br><span class="line"></span><br><span class="line">rotateServerCertificates: true</span><br><span class="line">allowedUnsafeSysctls:</span><br><span class="line"></span><br><span class="line"> - &quot;net.core*&quot;</span><br><span class="line"> - &quot;net.ipv4.*&quot;</span><br><span class="line">   kubeReserved:</span><br><span class="line">     cpu: &quot;1&quot;</span><br><span class="line">     memory: 1Gi</span><br><span class="line">     ephemeral-storage: 10Gi</span><br><span class="line">   systemReserved:</span><br><span class="line">     cpu: &quot;1&quot;</span><br><span class="line">     memory: 1Gi</span><br><span class="line">     ephemeral-storage: 10Gi</span><br></pre></td></tr></table></figure>

<p>数据盘要与系统盘分开；etcd使用ssd磁盘</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes（k8s）命名空间一直Terminating</title>
    <url>/2022/04/01/2022-04-01-kubernetes%EF%BC%88k8s%EF%BC%89%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E4%B8%80%E7%9B%B4Terminating/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/874e30765f58470b92478a60b674a941~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  get ns</span><br><span class="line">NAME              STATUS        AGE</span><br><span class="line">auth              Terminating   34m</span><br><span class="line">default           Active        23h</span><br><span class="line">kube-node-lease   Active        23h</span><br><span class="line">kube-public       Active        23h</span><br><span class="line">kube-system       Active        23h</span><br></pre></td></tr></table></figure>

<p>新开命令行窗口打开proxy</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl proxy</span><br><span class="line">Starting to serve on 127.0.0.1:8001</span><br></pre></td></tr></table></figure>

<p>回到刚才窗口 将 terminating 状态的命名空间信息导出到 json 文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl get namespace auth -o json &gt;tmp.json</span><br></pre></td></tr></table></figure>

<p>修改json文件中的 finalizers，将其设置为空</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# vi tmp.json </span><br><span class="line">root@hello:~# cat tmp.json | grep finalizers</span><br><span class="line">        &quot;finalizers&quot;: []</span><br></pre></td></tr></table></figure>

<p>在 temp.json 文件所在位置调下面的接口</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# curl -k -H &quot;Content-Type: application/json&quot; -X PUT --data-binary @tmp.json http://127.0.0.1:8001/api/v1/namespaces/auth/finalize</span><br></pre></td></tr></table></figure>

<p>*auth 改为需要删除的 terminating 状态的命名空间的名字</p>
<p>验证</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  get ns</span><br><span class="line">NAME              STATUS        AGE</span><br><span class="line">default           Active        23h</span><br><span class="line">kube-node-lease   Active        23h</span><br><span class="line">kube-public       Active        23h</span><br><span class="line">kube-system       Active        23h</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes（k8s）部署 Metrics Server 资源</title>
    <url>/2022/03/28/2022-03-28-kubernetes%EF%BC%88k8s%EF%BC%89%E9%83%A8%E7%BD%B2_Metrics_Server_%E8%B5%84%E6%BA%90/</url>
    <content><![CDATA[<p>    资源使用指标，例如容器 CPU 和内存使用率，可通过 Metrics API 在 Kubernetes 中获得。这些指标可以直接被用户访问，比如使用 kubectl top 命令行，或者被集群中的控制器 （例如 Horizontal Pod Autoscalers) 使用来做决策。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ff3fe4c5534f4058b1e49d88f5ae978c~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><strong>配置api聚合层</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">添加配置api启动service文件</span><br><span class="line"></span><br><span class="line">--enable-aggregator-routing=true </span><br><span class="line"></span><br><span class="line">ps -ef |grep apiserver|grep enable-aggregator-routing</span><br><span class="line">root        1147       1 10 10:23 ?        00:30:13 /usr/local/bin/kube-apiserver --v=2 --logtostderr=true --allow-privileged=true --bind-address=0.0.0.0 --secure-port=6443 --insecure-port=0 --advertise-address=192.168.1.30 --service-cluster-ip-range=10.96.0.0/12 --service-node-port-range=30000-32767 --etcd-servers=https://192.168.1.30:2379,https://192.168.1.31:2379,https://192.168.1.32:2379 --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem --etcd-certfile=/etc/etcd/ssl/etcd.pem --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem --client-ca-file=/etc/kubernetes/pki/ca.pem --tls-cert-file=/etc/kubernetes/pki/apiserver.pem --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-account-signing-key-file=/etc/kubernetes/pki/sa.key --service-account-issuer=https://kubernetes.default.svc.cluster.local --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota --authorization-mode=Node,RBAC --enable-bootstrap-token-auth=true --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem --requestheader-allowed-names=aggregator --requestheader-group-headers=X-Remote-Group --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-username-headers=X-Remote-User --enable-aggregator-routing=true</span><br></pre></td></tr></table></figure>

<p><strong>创建应用权限 RBAC 资源文件</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/cby# cat metrics-rbac.yaml </span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: system:aggregated-metrics-reader</span><br><span class="line">  labels:</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-admin: &quot;true&quot;</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;metrics.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;pods&quot;, &quot;nodes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server:system:auth-delegator</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:auth-delegator</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: metrics-server</span><br><span class="line">    namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server-auth-reader</span><br><span class="line">  namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: extension-apiserver-authentication-reader</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: metrics-server</span><br><span class="line">    namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - pods</span><br><span class="line">      - nodes</span><br><span class="line">      - nodes/stats</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: metrics-server</span><br><span class="line">    namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">root@hello:~/cby#</span><br></pre></td></tr></table></figure>

<p><strong>创建 APIService 资源文件</strong></p>
<p>    设置扩展 API Service 工作于聚合层，允许使用其 API 扩展 Kubernetes apiserver，而这些 API 并不是核心 Kubernetes API 的一部分。这里部署 APIservice 资源，来提供 Kubernetes Metrics 指标 API 数据。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/cby# cat metrics-api-service.yaml </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># APIService</span></span></span><br><span class="line">apiVersion: apiregistration.k8s.io/v1</span><br><span class="line">kind: APIService</span><br><span class="line">metadata:</span><br><span class="line">  name: v1beta1.metrics.k8s.io</span><br><span class="line">spec:</span><br><span class="line">  service:</span><br><span class="line">    name: metrics-server</span><br><span class="line">    namespace: kube-system</span><br><span class="line">    port: 443</span><br><span class="line">  group: metrics.k8s.io</span><br><span class="line">  version: v1beta1</span><br><span class="line">  insecureSkipTLSVerify: true</span><br><span class="line">  groupPriorityMinimum: 100</span><br><span class="line">  versionPriority: 100</span><br><span class="line">root@hello:~/cby#</span><br></pre></td></tr></table></figure>

<p><strong>创建 Metrics Server 应用资源文件</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/cby# cat metrics-server-deploy.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: metrics-server</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      volumes:</span><br><span class="line">        # mount in tmp so we can safely use from-scratch images and/or read-only containers</span><br><span class="line">        - name: tmp-dir</span><br><span class="line">          emptyDir: &#123;&#125;</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      containers:</span><br><span class="line">        - name: metrics-server</span><br><span class="line">          image: bitnami/metrics-server</span><br><span class="line">          # command:</span><br><span class="line">          # - /metrics-server</span><br><span class="line">          # - --kubelet-insecure-tls</span><br><span class="line">          # - --kubelet-preferred-address-types=InternalIP</span><br><span class="line">          args:</span><br><span class="line">            - --cert-dir=/tmp</span><br><span class="line">            - --secure-port=4443</span><br><span class="line">            - --kubelet-insecure-tls=true</span><br><span class="line">            - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,externalDNS</span><br><span class="line">          ports:</span><br><span class="line">            - name: main-port</span><br><span class="line">              containerPort: 4443</span><br><span class="line">              protocol: TCP</span><br><span class="line">          securityContext:</span><br><span class="line">            readOnlyRootFilesystem: true</span><br><span class="line">            runAsNonRoot: true</span><br><span class="line">            runAsUser: 1000</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: tmp-dir</span><br><span class="line">              mountPath: /tmp</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io/os: linux</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/name: &quot;Metrics-server&quot;</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 4443</span><br><span class="line">root@hello:~/cby#</span><br></pre></td></tr></table></figure>

<p><strong>通过 Kubectl 命令部署</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/cby# kubectl apply -f metrics-rbac.yaml -n kube-system</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~/cby# kubectl apply -f metrics-api-service.yaml -n kube-system</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~/cby# kubectl apply -f metrics-server-deploy.yaml -n kube-system</span><br><span class="line">Warning: spec.template.spec.nodeSelector[beta.kubernetes.io/os]: deprecated since v1.14; use &quot;kubernetes.io/os&quot; instead</span><br><span class="line">deployment.apps/metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">root@hello:~/cby# </span><br><span class="line"></span><br><span class="line">验证</span><br><span class="line"></span><br><span class="line">root@hello:~/cby# kubectl  get pod -A | grep metrics-server</span><br><span class="line">kube-system   metrics-server-5c69d5d5b7-b6246              1/1     Running   0               2m25s</span><br><span class="line">root@hello:~/cby# </span><br><span class="line"></span><br><span class="line">查看日志</span><br><span class="line"></span><br><span class="line">root@hello:~/cby# kubectl  logs -n kube-system   metrics-server-5c69d5d5b7-b6246</span><br><span class="line">I0328 07:11:37.676490       1 serving.go:341] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)</span><br><span class="line">I0328 07:11:38.148457       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController</span><br><span class="line">I0328 07:11:38.148472       1 configmap_cafile_content.go:202] Starting client-ca::kube-system::extension-apiserver-authentication::client-ca-file</span><br><span class="line">I0328 07:11:38.148507       1 shared_informer.go:240] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file</span><br><span class="line">I0328 07:11:38.148475       1 configmap_cafile_content.go:202] Starting client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file</span><br><span class="line">I0328 07:11:38.148550       1 shared_informer.go:240] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file</span><br><span class="line">I0328 07:11:38.148490       1 shared_informer.go:240] Waiting for caches to sync for RequestHeaderAuthRequestController</span><br><span class="line">I0328 07:11:38.149073       1 dynamic_serving_content.go:130] Starting serving-cert::/tmp/apiserver.crt::/tmp/apiserver.key</span><br><span class="line">I0328 07:11:38.149428       1 secure_serving.go:202] Serving securely on [::]:4443</span><br><span class="line">I0328 07:11:38.149535       1 tlsconfig.go:240] Starting DynamicServingCertificateController</span><br><span class="line">I0328 07:11:38.248713       1 shared_informer.go:247] Caches are synced for RequestHeaderAuthRequestController </span><br><span class="line">I0328 07:11:38.248732       1 shared_informer.go:247] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file </span><br><span class="line">I0328 07:11:38.248754       1 shared_informer.go:247] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file </span><br><span class="line">root@hello:~/cby#</span><br><span class="line"></span><br><span class="line">查看node资源信息</span><br><span class="line"></span><br><span class="line">root@hello:~/cby# kubectl  top node </span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">192.168.1.50   184m         2%     4354Mi          56%       </span><br><span class="line">192.168.1.51   207m         2%     3892Mi          50%       </span><br><span class="line">192.168.1.52   197m         2%     3881Mi          50%       </span><br><span class="line">192.168.1.53   185m         2%     3528Mi          46%       </span><br><span class="line">192.168.1.54   109m         1%     3427Mi          44%       </span><br><span class="line">root@hello:~/cby# </span><br><span class="line"></span><br><span class="line">查看pod资源信息</span><br><span class="line"></span><br><span class="line">root@hello:~/cby# kubectl  top pod -n kube-system </span><br><span class="line">NAME                                         CPU(cores)   MEMORY(bytes)   </span><br><span class="line">calico-kube-controllers-754966f84c-jm7f7     5m           25Mi            </span><br><span class="line">calico-node-9tvck                            43m          69Mi            </span><br><span class="line">calico-node-kt2pk                            41m          68Mi            </span><br><span class="line">calico-node-skm82                            45m          70Mi            </span><br><span class="line">calico-node-t4lhb                            44m          65Mi            </span><br><span class="line">calico-node-tz5k9                            45m          66Mi            </span><br><span class="line">coredns-596755dbff-7ggzl                     3m           15Mi            </span><br><span class="line">dashboard-metrics-scraper-799d786dbf-s6r5f   1m           7Mi             </span><br><span class="line">kubernetes-dashboard-9f8c8b989-57fhz         1m           13Mi            </span><br><span class="line">metrics-server-5c69d5d5b7-b6246              4m           16Mi            </span><br><span class="line">node-local-dns-4hzvh                         5m           17Mi            </span><br><span class="line">node-local-dns-6zpdh                         3m           17Mi            </span><br><span class="line">node-local-dns-9jmzz                         5m           16Mi            </span><br><span class="line">node-local-dns-q8pcw                         5m           17Mi            </span><br><span class="line">node-local-dns-tpm6b                         5m           29Mi            </span><br><span class="line">root@hello:~/cby# </span><br><span class="line"></span><br><span class="line">查看单个pod资源信息</span><br><span class="line"></span><br><span class="line">root@hello:~/cby# kubectl  top pod  -n kube-system metrics-server-5c69d5d5b7-b6246</span><br><span class="line">NAME                              CPU(cores)   MEMORY(bytes)   </span><br><span class="line">metrics-server-5c69d5d5b7-b6246   4m           13Mi            </span><br><span class="line">root@hello:~/cby# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>使用HTMLform表单操作腾讯云DNS控制台</title>
    <url>/2022/03/29/2022-03-29-%E4%BD%BF%E7%94%A8HTMLform%E8%A1%A8%E5%8D%95%E6%93%8D%E4%BD%9C%E8%85%BE%E8%AE%AF%E4%BA%91DNS%E6%8E%A7%E5%88%B6%E5%8F%B0/</url>
    <content><![CDATA[<p>        在使用中经常需要修改DNS记录，或者查询、删除操作。每次都得登录腾讯云控制台，腾讯云比较鸡肋的一点就是需要进行微信扫码登录，每次操作太不方便。</p>
<p>        可以使用api接口进行操作腾讯云上的产品。所以使用HTML写了一个前端页面，暂时没有美化，目前只有基础功能。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3dfd96bec70e4c8f96ee85d99088d882~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>前端代码如下，同时可以访问：<a href="http://dns.oiox.cn/">http://dns.oiox.cn/</a> 使用</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment"> * @Author: 陈步云</span></span><br><span class="line"><span class="comment"> * @Date: 2022-01-07 16:52:23</span></span><br><span class="line"><span class="comment"> * @LastEditTime: 2022-03-29 15:09:56</span></span><br><span class="line"><span class="comment"> * @LastEditors: Please set LastEditors</span></span><br><span class="line"><span class="comment"> * @Description: 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE</span></span><br><span class="line"><span class="comment"> * @FilePath: /html/index.nginx-debian.html</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>Welcome to chenby!<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- &lt;script src=&quot;http://code.jquery.com/jquery-3.6.0.min.js&quot;&gt;&lt;/script&gt;</span></span><br><span class="line"><span class="comment">&lt;script src=&quot;http://oss.maxcdn.com/jquery.form/3.50/jquery.form.min.js&quot;&gt;&lt;/script&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">    <span class="selector-tag">body</span> &#123;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">width</span>: <span class="number">50em</span>;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">margin</span>:  auto;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">font-family</span>: Tahoma, Verdana, Arial, sans-serif;</span></span><br><span class="line"><span class="language-css">    &#125;</span></span><br><span class="line"><span class="language-css">    <span class="selector-tag">h1</span>&#123;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">text-align</span>:center</span></span><br><span class="line"><span class="language-css">    &#125;</span></span><br><span class="line"><span class="language-css">    <span class="selector-tag">button</span>&#123;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">display</span>:block;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">margin</span>:<span class="number">0</span> auto</span></span><br><span class="line"><span class="language-css">    &#125;</span></span><br><span class="line"><span class="language-css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>腾讯云DNS记录控制台<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span>&gt;</span>查询记录<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;https://dnsapi.cn/Record.List&quot;</span> <span class="attr">method</span>=<span class="string">&quot;POST&quot;</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 腾讯云token <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;login_token&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>    <span class="tag">&lt;<span class="name">br</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span>「去控制台创建  https://console.dnspod.cn/account/token/token  <span class="tag">&lt;<span class="name">br</span>&gt;</span> 比如 ID 为：13490,ToKen为：6b5976c68aba5b14a0558b77c17c3932。<span class="tag">&lt;<span class="name">br</span>&gt;</span> 即完整的 Token 为：13490,6b5976c68aba5b14a0558b77c17c3932 。」 <span class="tag">&lt;<span class="name">br</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">              返回类型 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;format&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">value</span>=<span class="string">&quot;json&quot;</span>&gt;</span>「默认json」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 操作域名 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;domain&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>「如 oiox.cn」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            子域名 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;sub_domain&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>「www」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;提交&quot;</span>&gt;</span>提交<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span>&gt;</span>新增记录<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;https://dnsapi.cn/Record.Create&quot;</span> <span class="attr">method</span>=<span class="string">&quot;POST&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 腾讯云token <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;login_token&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>    <span class="tag">&lt;<span class="name">br</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span>「去控制台创建  https://console.dnspod.cn/account/token/token  <span class="tag">&lt;<span class="name">br</span>&gt;</span> 比如 ID 为：13490,ToKen为：6b5976c68aba5b14a0558b77c17c3932。<span class="tag">&lt;<span class="name">br</span>&gt;</span> 即完整的 Token 为：13490,6b5976c68aba5b14a0558b77c17c3932 。」 <span class="tag">&lt;<span class="name">br</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">              返回类型 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;format&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">value</span>=<span class="string">&quot;json&quot;</span>&gt;</span> 「默认json」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 操作域名 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;domain&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span> 「如 oiox.cn」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">                * 记录类型：</span><br><span class="line">                <span class="tag">&lt;<span class="name">select</span> <span class="attr">name</span>=<span class="string">&quot;record_type&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;A&quot;</span>&gt;</span>A<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;AAAA&quot;</span>&gt;</span>AAAA<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;SPF&quot;</span>&gt;</span>SPF<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;CAA&quot;</span>&gt;</span>CAA<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;CNAME&quot;</span>&gt;</span>CNAME<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;MX&quot;</span>&gt;</span>MX<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;TXT&quot;</span>&gt;</span>TXT<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 主机记录 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;sub_domain&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span> 「如 www 」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">                解析线路：</span><br><span class="line">                <span class="tag">&lt;<span class="name">select</span> <span class="attr">name</span>=<span class="string">&quot;record_line&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;默认&quot;</span>&gt;</span>默认<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;联通&quot;</span>&gt;</span>联通<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;移动&quot;</span>&gt;</span>移动<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;电信&quot;</span>&gt;</span>电信<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;铁通&quot;</span>&gt;</span>铁通<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;境内&quot;</span>&gt;</span>境内<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;境外&quot;</span>&gt;</span>境外<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 记录值 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;value&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>  <span class="tag">&lt;<span class="name">br</span>&gt;</span>「如 IPv6:2620:119:35::35 IPv4:8.8.8.8, CNAME: cname.dnspod.com., MX: mail.dnspod.com. 等等」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;提交&quot;</span>&gt;</span>提交<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span>&gt;</span>修改记录<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;https://dnsapi.cn/Record.Modify&quot;</span> <span class="attr">method</span>=<span class="string">&quot;POST&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 腾讯云token <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;login_token&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>    <span class="tag">&lt;<span class="name">br</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span>「去控制台创建  https://console.dnspod.cn/account/token/token  <span class="tag">&lt;<span class="name">br</span>&gt;</span> 比如 ID 为：13490,ToKen为：6b5976c68aba5b14a0558b77c17c3932。<span class="tag">&lt;<span class="name">br</span>&gt;</span> 即完整的 Token 为：13490,6b5976c68aba5b14a0558b77c17c3932 。」 <span class="tag">&lt;<span class="name">br</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">              返回类型 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;format&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">value</span>=<span class="string">&quot;json&quot;</span>&gt;</span> 「默认json」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 操作域名 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;domain&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span> 「如 oiox.cn」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 记录ID <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;record_id&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>  「先使用查询功能查询到record_id」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">                * 记录类型：</span><br><span class="line">                <span class="tag">&lt;<span class="name">select</span> <span class="attr">name</span>=<span class="string">&quot;record_type&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;A&quot;</span>&gt;</span>A<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;AAAA&quot;</span>&gt;</span>AAAA<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;SPF&quot;</span>&gt;</span>SPF<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;CAA&quot;</span>&gt;</span>CAA<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;CNAME&quot;</span>&gt;</span>CNAME<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;MX&quot;</span>&gt;</span>MX<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;TXT&quot;</span>&gt;</span>TXT<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 主机记录 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;sub_domain&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>  「如 www 」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">                解析线路：</span><br><span class="line">                <span class="tag">&lt;<span class="name">select</span> <span class="attr">name</span>=<span class="string">&quot;record_line&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;默认&quot;</span>&gt;</span>默认<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;联通&quot;</span>&gt;</span>联通<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;移动&quot;</span>&gt;</span>移动<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;电信&quot;</span>&gt;</span>电信<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;铁通&quot;</span>&gt;</span>铁通<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;境内&quot;</span>&gt;</span>境内<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;境外&quot;</span>&gt;</span>境外<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 修改记录值 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;value&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>  <span class="tag">&lt;<span class="name">br</span>&gt;</span>「如 IPv6:2620:119:35::35 IPv4:8.8.8.8, CNAME: cname.dnspod.com., MX: mail.dnspod.com. 等等」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;提交&quot;</span>&gt;</span>提交<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span>&gt;</span>删除记录<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;https://dnsapi.cn/Record.Remove&quot;</span> <span class="attr">method</span>=<span class="string">&quot;POST&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 腾讯云token <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;login_token&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>    <span class="tag">&lt;<span class="name">br</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span>「去控制台创建  https://console.dnspod.cn/account/token/token  <span class="tag">&lt;<span class="name">br</span>&gt;</span> 比如 ID 为：13490,ToKen为：6b5976c68aba5b14a0558b77c17c3932。<span class="tag">&lt;<span class="name">br</span>&gt;</span> 即完整的 Token 为：13490,6b5976c68aba5b14a0558b77c17c3932 。」 <span class="tag">&lt;<span class="name">br</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            返回类型 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;format&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">value</span>=<span class="string">&quot;json&quot;</span>&gt;</span> 「默认json」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 操作域名 <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;domain&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>  「如 oiox.cn」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            * 记录ID <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">&quot;record_id&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span>&gt;</span>  「先使用查询功能查询到record_id」<span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;提交&quot;</span>&gt;</span>提交<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/95dccecc7814450ca0f9a85a51edc60b~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>会返回一个json解析，建议安装FeHelper工具，可以美化json，方便阅读。  </p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e043926ff2904b85a0e2740858772c17~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ab5e67a604bd45eb83285836cb5a37fe~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aa94fe2b79134af7a59e0d1543901f7e~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f6cb4848ba2c42c1bf79505948b5f623~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Linux磁盘LVM根目录扩容</title>
    <url>/2022/03/31/2022-03-31-Linux%E7%A3%81%E7%9B%98LVM%E6%A0%B9%E7%9B%AE%E5%BD%95%E6%89%A9%E5%AE%B9/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4b66badf2955413c829a4b6eee45c833~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>LVM 的基本概念</p>
<p>物理卷 Physical Volume (PV)：可以在上面建立卷组的媒介，可以是硬盘分区，也可以是硬盘本身或者回环文件（loopback file）。物理卷包括一个特殊的 header，其余部分被切割为一块块物理区域（physical extents）</p>
<p>卷组 Volume group (VG)：将一组物理卷收集为一个管理单元</p>
<p>逻辑卷 Logical volume (LV)：虚拟分区，由物理区域（physical extents）组成</p>
<p>物理区域 Physical extent (PE)：硬盘可供指派给逻辑卷的最小单位（通常为 4MB）</p>
<p>新建分区</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# fdisk /dev/sda</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Welcome to fdisk (util-linux 2.34).</span><br><span class="line">Changes will remain in memory only, until you decide to write them.</span><br><span class="line">Be careful before using the write command.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GPT PMBR size mismatch (209715199 != 629145599) will be corrected by write.</span><br><span class="line">The backup GPT table is not on the end of the device. This problem will be corrected by write.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Command (m for help): n</span><br><span class="line">Partition number (4-128, default 4): </span><br><span class="line">First sector (209713152-629145566, default 209713152): </span><br><span class="line">Last sector, +/-sectors or +/-size&#123;K,M,G,T,P&#125; (209713152-629145566, default 629145566): </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Created a new partition 4 of type &#x27;Linux filesystem&#x27; and of size 200 GiB.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Command (m for help): p</span><br><span class="line">Disk /dev/sda: 300 GiB, 322122547200 bytes, 629145600 sectors</span><br><span class="line">Disk model: QEMU HARDDISK   </span><br><span class="line">Units: sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disklabel type: gpt</span><br><span class="line">Disk identifier: 9FD87B41-A400-4DD9-AE87-C852ACB2854D</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Device         Start       End   Sectors  Size Type</span><br><span class="line">/dev/sda1       2048      4095      2048    1M BIOS boot</span><br><span class="line">/dev/sda2       4096   2101247   2097152    1G Linux filesystem</span><br><span class="line">/dev/sda3    2101248 209713151 207611904   99G Linux filesystem</span><br><span class="line">/dev/sda4  209713152 629145566 419432415  200G Linux filesystem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Command (m for help): w</span><br><span class="line">The partition table has been altered.</span><br><span class="line">Syncing disks.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>扩展pv并查看</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# pvcreate  /dev/sda4</span><br><span class="line">  Physical volume &quot;/dev/sda4&quot; successfully created.</span><br><span class="line"></span><br><span class="line">root@hello:~# pvdisplay </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sda3</span><br><span class="line">  VG Name               ubuntu-vg</span><br><span class="line">  PV Size               &lt;99.00 GiB / not usable 0   </span><br><span class="line">  Allocatable           yes (but full)</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              25343</span><br><span class="line">  Free PE               0</span><br><span class="line">  Allocated PE          25343</span><br><span class="line">  PV UUID               DfUNvp-F4D5-J6Rj-sMcS-PqE1-bKf6-2XLfb2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sda4</span><br><span class="line">  VG Name               ubuntu-vg</span><br><span class="line">  PV Size               200.00 GiB / not usable 4.98 MiB</span><br><span class="line">  Allocatable           yes (but full)</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              51199</span><br><span class="line">  Free PE               0</span><br><span class="line">  Allocated PE          51199</span><br><span class="line">  PV UUID               yeXSs6-mUWY-Q31q-oD0J-yWHA-zPfp-92AKrO</span><br></pre></td></tr></table></figure>

<p>扩展vg并查看</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# vgextend ubuntu-vg /dev/sda4</span><br><span class="line">  Volume group &quot;ubuntu-vg&quot; successfully extended</span><br><span class="line"></span><br><span class="line">root@hello:~# vgdisplay </span><br><span class="line">  --- Volume group ---</span><br><span class="line">  VG Name               ubuntu-vg</span><br><span class="line">  System ID             </span><br><span class="line">  Format                lvm2</span><br><span class="line">  Metadata Areas        2</span><br><span class="line">  Metadata Sequence No  4</span><br><span class="line">  VG Access             read/write</span><br><span class="line">  VG Status             resizable</span><br><span class="line">  MAX LV                0</span><br><span class="line">  Cur LV                1</span><br><span class="line">  Open LV               1</span><br><span class="line">  Max PV                0</span><br><span class="line">  Cur PV                2</span><br><span class="line">  Act PV                2</span><br><span class="line">  VG Size               298.99 GiB</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              76542</span><br><span class="line">  Alloc PE / Size       76542 / 298.99 GiB</span><br><span class="line">  Free  PE / Size       0 / 0   </span><br><span class="line">  VG UUID               QpG0NU-5tPY-q5Bw-mLIu-Axl6-mdtP-19WWq6</span><br></pre></td></tr></table></figure>

<p>扩展lv并查看</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# lvextend /dev/ubuntu-vg/ubuntu-lv /dev/sda4</span><br><span class="line">  Size of logical volume ubuntu-vg/ubuntu-lv changed from &lt;99.00 GiB (25343 extents) to 298.99 GiB (76542 extents).</span><br><span class="line">  Logical volume ubuntu-vg/ubuntu-lv successfully resized.</span><br><span class="line"></span><br><span class="line">root@hello:~# lvdisplay </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/ubuntu-vg/ubuntu-lv</span><br><span class="line">  LV Name                ubuntu-lv</span><br><span class="line">  VG Name                ubuntu-vg</span><br><span class="line">  LV UUID                ODU5p6-8E8i-30tn-3hzs-AifF-iF4Z-HzMuFL</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time ubuntu-server, 2022-03-29 09:07:30 +0000</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 1</span></span><br><span class="line">  LV Size                298.99 GiB</span><br><span class="line">  Current LE             76542</span><br><span class="line">  Segments               2</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     256</span><br><span class="line">  Block device           253:0</span><br></pre></td></tr></table></figure>

<p>扩展根文件系统  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# resize2fs /dev/ubuntu-vg/ubuntu-lv</span><br><span class="line">resize2fs 1.45.5 (07-Jan-2020)</span><br><span class="line">Filesystem at /dev/ubuntu-vg/ubuntu-lv is mounted on /; on-line resizing required</span><br><span class="line">old_desc_blocks = 13, new_desc_blocks = 38</span><br><span class="line">The filesystem on /dev/ubuntu-vg/ubuntu-lv is now 78379008 (4k) blocks long.</span><br></pre></td></tr></table></figure>

<p>若是xfs文件系统，可以使用xfs_growfs命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# df -hT | grep ubuntu--vg-ubuntu--lv</span><br><span class="line">/dev/mapper/ubuntu--vg-ubuntu--lv ext4      294G   14G  268G   5% /</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>查看块设备的依赖关系</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# lsblk</span><br><span class="line">NAME                      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">loop0                       7:0    0 31.1M  1 loop /snap/snapd/10707</span><br><span class="line">loop1                       7:1    0 55.4M  1 loop /snap/core18/1944</span><br><span class="line">loop2                       7:2    0 69.9M  1 loop /snap/lxd/19188</span><br><span class="line">sda                         8:0    0  300G  0 disk </span><br><span class="line">├─sda1                      8:1    0    1M  0 part </span><br><span class="line">├─sda2                      8:2    0    1G  0 part /boot</span><br><span class="line">├─sda3                      8:3    0   99G  0 part </span><br><span class="line">│ └─ubuntu--vg-ubuntu--lv 253:0    0  299G  0 lvm  /</span><br><span class="line">└─sda4                      8:4    0  200G  0 part </span><br><span class="line">  └─ubuntu--vg-ubuntu--lv 253:0    0  299G  0 lvm  /</span><br><span class="line">sr0                        11:0    1  1.1G  0 rom  </span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>自编写二进制安装kubernetes脚本v2.0版本</title>
    <url>/2022/04/04/2022-04-04-%E8%87%AA%E7%BC%96%E5%86%99%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85kubernetes%E8%84%9A%E6%9C%ACv2.0%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/63bf8ed4a3a744a5b0aae5d9275f2081~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>一键安装 二进制安装Kubernetes（k8s） v2.0</p>
<p>手动安装：<a href="https://github.com/cby-chen/Kubernetes">https://github.com/cby-chen/Kubernetes</a></p>
<p>脚本安装：<a href="https://github.com/cby-chen/Binary_installation_of_Kubernetes">https://github.com/cby-chen/Binary_installation_of_Kubernetes</a></p>
<p>使用说明：该脚本示例需要十一台服务器，在十一台服务器中有一台是用于执行该脚本的，</p>
<p>另外有八台k8s服务器，其他俩台作为lb负载均衡服务器。</p>
<p>将其中服务器配置好静态IP，修改如下变量中的IP即可。</p>
<p>同时查看服务器中的网卡名，并将其修改。</p>
<p>执行脚本可使用bash -x 即可显示执行中详细信息。</p>
<p>该脚本已适配centos7和centos8。</p>
<p>脚本中hosts有俩处，记得修改。</p>
<p>2022-03更新：</p>
<p>现已支持centos7 和centos8 自动适配</p>
<p>同时支持自定义k8s node节点结构.</p>
<p>在变量中需要几台节点就写几台节点即可 注意的是，新增节点，要在脚本中的hosts中也要修改 不建议乱改。</p>
<p>2022-04更新：</p>
<p>更新kubernetes自主版本选择</p>
<p>优化执行结构</p>
<p>适配多版本</p>
<p>修复BUG</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">脚本中是需要在GitHub上下载软件包</span><br><span class="line"></span><br><span class="line">手动提前下载好</span><br><span class="line"></span><br><span class="line">wget https://github.com/cby-chen/Kubernetes/releases/download/cby/Kubernetes.tar</span><br><span class="line">wget https://github.com/cby-chen/Kubernetes/releases/download/v1.23.4/kubernetes-v1.23.4.tar</span><br><span class="line">wget https://github.com/cby-chen/Kubernetes/releases/download/v1.23.5/kubernetes-v1.23.5.tar</span><br><span class="line"></span><br><span class="line">下载脚本</span><br><span class="line"></span><br><span class="line">wget https://www.oiox.cn/Binary_installation_of_Kubernetes.sh</span><br><span class="line"></span><br><span class="line">修改参数</span><br><span class="line"></span><br><span class="line">vim Binary_installation_of_Kubernetes.sh</span><br><span class="line"></span><br><span class="line">如下：</span><br><span class="line"></span><br><span class="line">#每个节点的IP，以及vip</span><br><span class="line">export k8s_master01=&quot;192.168.1.61&quot;</span><br><span class="line">export k8s_master02=&quot;192.168.1.61&quot;</span><br><span class="line">export k8s_master03=&quot;192.168.1.63&quot;</span><br><span class="line">export k8s_node01=&quot;192.168.1.64&quot;</span><br><span class="line">export k8s_node02=&quot;192.168.1.65&quot;</span><br><span class="line">export k8s_node03=&quot;192.168.1.66&quot;</span><br><span class="line">export k8s_node04=&quot;192.168.1.67&quot;</span><br><span class="line">export k8s_node05=&quot;192.168.1.68&quot;</span><br><span class="line">export lb_01=&quot;192.168.1.57&quot;</span><br><span class="line">export lb_02=&quot;192.168.1.58&quot;</span><br><span class="line">export lb_vip=&quot;192.168.1.59&quot;</span><br><span class="line"></span><br><span class="line">#物理网络ip地址段，注意反斜杠转译</span><br><span class="line">export ip_segment=&quot;192.168.1.0\/24&quot;</span><br><span class="line"></span><br><span class="line">#k8s自定义域名</span><br><span class="line">export domain=&quot;x.oiox.cn&quot;</span><br><span class="line"></span><br><span class="line">#服务器网卡名</span><br><span class="line">export eth=&quot;ens18&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改hosts（有俩处）</span><br><span class="line"></span><br><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">$k8s_master01 k8s-master01</span><br><span class="line">$k8s_master02 k8s-master02</span><br><span class="line">$k8s_master03 k8s-master03</span><br><span class="line">$k8s_node01 k8s-node01</span><br><span class="line">$k8s_node02 k8s-node02</span><br><span class="line">$k8s_node03 k8s-node03</span><br><span class="line">$k8s_node04 k8s-node04</span><br><span class="line">$k8s_node05 k8s-node05</span><br><span class="line">$lb_01 lb01</span><br><span class="line">$lb_02 lb02</span><br><span class="line">$lb_vip lb-vip</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">执行脚本</span><br><span class="line"></span><br><span class="line">bash -x Binary_installation_of_Kubernetes.sh</span><br><span class="line"></span><br><span class="line">dashboard</span><br><span class="line"></span><br><span class="line">查看端口号</span><br><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">查看token</span><br><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>docker方式实现minio数据持久化离线安装</title>
    <url>/2022/04/08/2022-04-08-docker%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0minio%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1942175b9f7c4b2285f931f31896ba71~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>保存镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker pull minio/minio</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from minio/minio</span><br><span class="line">d46336f50433: Pull complete </span><br><span class="line">be961ec68663: Pull complete </span><br><span class="line">44173c602141: Pull complete </span><br><span class="line">a9809a6a679b: Pull complete </span><br><span class="line">df29d4a76971: Pull complete </span><br><span class="line">2b5a8853d302: Pull complete </span><br><span class="line">84f01ee8dfc1: Pull complete </span><br><span class="line">Digest: sha256:d786220feef7d8fe0239d41b5d74501dc824f6e7dd0e5a05749c502fff225bf3</span><br><span class="line">Status: Downloaded newer image for minio/minio:latest</span><br><span class="line">docker.io/minio/minio:latest</span><br><span class="line">root@hello:~#</span><br><span class="line">root@hello:~# docker save &gt; minio.tar minio/minio</span><br><span class="line">root@hello:~# ll minio.tar</span><br><span class="line">-rw-r--r-- 1 root root 415240704 Mar 30 07:03 minio.tar</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>导入镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker load -i minio.tar </span><br><span class="line">744c86b54390: Loading layer [==================================================&gt;]  104.1MB/104.1MB</span><br><span class="line">1323ffbff4dd: Loading layer [==================================================&gt;]  20.48kB/20.48kB</span><br><span class="line">9a5123a464dc: Loading layer [==================================================&gt;]  3.584kB/3.584kB</span><br><span class="line">9e9eecfbe95d: Loading layer [==================================================&gt;]  3.584kB/3.584kB</span><br><span class="line">6088fcbd6a76: Loading layer [==================================================&gt;]  1.724MB/1.724MB</span><br><span class="line">678ce496e457: Loading layer [==================================================&gt;]  36.86kB/36.86kB</span><br><span class="line">50f383b04a07: Loading layer [==================================================&gt;]  309.3MB/309.3MB</span><br><span class="line">Loaded image: minio/minio:latest</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>创建目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# mkdir /data/config -p</span><br><span class="line">root@hello:~# mkdir /data/data -p</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>启动容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker run -itd -p 9000:9000 --name minio -p 9001:9001 -e &quot;MINIO_ACCESS_KEY=minio&quot; -e &quot;MINIO_SECRET_KEY=minio@123&quot; -v /data/data:/data -v /data/config:/root/.minio minio/minio server /data --address &#x27;0.0.0.0:9000&#x27;  --console-address &#x27;0.0.0.0:9001&#x27;</span><br><span class="line">5c69e875ce561ac311a85708594072eca8c1b4740773d83045f256d316efc06c</span><br><span class="line">root@hello:~# docker ps | grep minio</span><br><span class="line">5c69e875ce56   minio/minio             &quot;/usr/bin/docker-ent…&quot;   9 seconds ago   Up 8 seconds   0.0.0.0:9000-9001-&gt;9000-9001/tcp, :::9000-9001-&gt;9000-9001/tcp   minio</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>访问账号密码</p>
<p>url：<a href="http://ip:9001/login">http://ip:9001/login</a></p>
<p>user：minio</p>
<p>password：minio@123</p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>docker方式实现redis数据持久化离线安装</title>
    <url>/2022/04/06/2022-04-06-docker%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0redis%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5fb9968de62f47f18d2e931adf7d32e2~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>保存镜像  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker pull redis:latest</span><br><span class="line">latest: Pulling from library/redis</span><br><span class="line">a2abf6c4d29d: Already exists </span><br><span class="line">c7a4e4382001: Pull complete </span><br><span class="line">4044b9ba67c9: Pull complete </span><br><span class="line">c8388a79482f: Pull complete </span><br><span class="line">413c8bb60be2: Pull complete </span><br><span class="line">1abfd3011519: Pull complete </span><br><span class="line">Digest: sha256:db485f2e245b5b3329fdc7eff4eb00f913e09d8feb9ca720788059fdc2ed8339</span><br><span class="line">Status: Downloaded newer image for redis:latest</span><br><span class="line">docker.io/library/redis:latest</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# docker save &gt; redis.tar redis:latest </span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# ll redis.tar </span><br><span class="line">-rw-r--r-- 1 root root 116304384 Mar 30 07:30 redis.tar</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>导入镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker load -i redis.tar </span><br><span class="line">2edcec3590a4: Loading layer [==================================================&gt;]  83.86MB/83.86MB</span><br><span class="line">9b24afeb7c2f: Loading layer [==================================================&gt;]  338.4kB/338.4kB</span><br><span class="line">4b8e2801e0f9: Loading layer [==================================================&gt;]  4.274MB/4.274MB</span><br><span class="line">529cdb636f61: Loading layer [==================================================&gt;]   27.8MB/27.8MB</span><br><span class="line">9975392591f2: Loading layer [==================================================&gt;]  2.048kB/2.048kB</span><br><span class="line">8e5669d83291: Loading layer [==================================================&gt;]  3.584kB/3.584kB</span><br><span class="line">Loaded image: redis:latest</span><br></pre></td></tr></table></figure>

<p>创建目录，修改配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# mkdir /data/redis -p</span><br><span class="line">root@hello:~# mkdir /data/redis/data -p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# cp -p redis.conf /data/redis/</span><br><span class="line">root@hello:~# vim /data/redis/redis.conf</span><br></pre></td></tr></table></figure>

<p>修改redis.conf配置文件：</p>
<p>主要配置的如下：</p>
<p> bind 127.0.0.1 #注释掉这部分，使redis可以外部访问</p>
<p> daemonize no#用守护线程的方式启动</p>
<p> requirepass thinekr #给redis设置密码</p>
<p> appendonly yes #redis持久化　　默认是no</p>
<p> tcp-keepalive 300 #防止出现远程主机强迫关闭了一个现有的连接的错误 默认是300</p>
<p> 启动容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> root@hello:~# docker run -p 6379:6379 --name redis -v /data/redis/redis.conf:/etc/redis/redis.conf  -v /data/redis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes</span><br><span class="line">a59d3137a3ade6ec05588e0895d2265aff0e81746ec1847553fef6bd4df59348</span><br><span class="line">root@hello:~#</span><br></pre></td></tr></table></figure>

<p>测试</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# sudo docker logs redis</span><br><span class="line">1:C 30 Mar 2022 07:36:59.712 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo</span><br><span class="line">1:C 30 Mar 2022 07:36:59.712 # Redis version=6.2.6, bits=64, commit=00000000, modified=0, pid=1, just started</span><br><span class="line">1:C 30 Mar 2022 07:36:59.712 # Configuration loaded</span><br><span class="line">1:M 30 Mar 2022 07:36:59.713 * monotonic clock: POSIX clock_gettime</span><br><span class="line">                _._                                                  </span><br><span class="line">           _.-``__ &#x27;&#x27;-._                                             </span><br><span class="line">      _.-``    `.  `_.  &#x27;&#x27;-._           Redis 6.2.6 (00000000/0) 64 bit</span><br><span class="line">  .-`` .-```.  ```\/    _.,_ &#x27;&#x27;-._                                  </span><br><span class="line"> (    &#x27;      ,       .-`  | `,    )     Running in standalone mode</span><br><span class="line"> |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;|     Port: 6379</span><br><span class="line"> |    `-._   `._    /     _.-&#x27;    |     PID: 1</span><br><span class="line">  `-._    `-._  `-./  _.-&#x27;    _.-&#x27;                                   </span><br><span class="line"> |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;|                                  </span><br><span class="line"> |    `-._`-._        _.-&#x27;_.-&#x27;    |           https://redis.io       </span><br><span class="line">  `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27;                                   </span><br><span class="line"> |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;|                                  </span><br><span class="line"> |    `-._`-._        _.-&#x27;_.-&#x27;    |                                  </span><br><span class="line">  `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27;                                   </span><br><span class="line">      `-._    `-.__.-&#x27;    _.-&#x27;                                       </span><br><span class="line">          `-._        _.-&#x27;                                           </span><br><span class="line">              `-.__.-&#x27;                                               </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1:M 30 Mar 2022 07:36:59.714 # Server initialized</span><br><span class="line">1:M 30 Mar 2022 07:36:59.714 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &#x27;vm.overcommit_memory = 1&#x27; to /etc/sysctl.conf and then reboot or run the command &#x27;sysctl vm.overcommit_memory=1&#x27; for this to take effect.</span><br><span class="line">1:M 30 Mar 2022 07:36:59.715 * Ready to accept connections</span><br><span class="line">root@hello:~#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# redis-cli -h 3.7.191.194 -p 6379</span><br><span class="line">3.7.191.194:6379&gt; auth thinker</span><br><span class="line">OK</span><br><span class="line">3.7.191.194:6379&gt; ping</span><br><span class="line">PONG</span><br><span class="line">3.7.191.194:6379&gt;</span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>docker方式实现postgres数据持久化离线安装</title>
    <url>/2022/04/12/2022-04-12-docker%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0postgres%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/52545252ef3c4d689a27881538efc483~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h1 id="保存镜像"><a href="#保存镜像" class="headerlink" title="保存镜像"></a>保存镜像</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker pull postgres</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/postgres</span><br><span class="line">a2abf6c4d29d: Already exists </span><br><span class="line">e1769f49f910: Pull complete </span><br><span class="line">33a59cfee47c: Pull complete </span><br><span class="line">461b2090c345: Pull complete </span><br><span class="line">8ed8ab6290ac: Pull complete </span><br><span class="line">495e42c822a0: Pull complete </span><br><span class="line">18e858c71c58: Pull complete </span><br><span class="line">594792c80d5f: Pull complete </span><br><span class="line">794976979956: Pull complete </span><br><span class="line">eb5e1a73c3ca: Pull complete </span><br><span class="line">6d6360292cba: Pull complete </span><br><span class="line">131e916e1a28: Pull complete </span><br><span class="line">757a73507e2e: Pull complete </span><br><span class="line">Digest: sha256:f329d076a8806c0ce014ce5e554ca70f4ae9407a16bb03baa7fef287ee6371f1</span><br><span class="line">Status: Downloaded newer image for postgres:latest</span><br><span class="line">docker.io/library/postgres:latest</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# docker save &gt; postgres.tar postgres:latest </span><br><span class="line">root@hello:~# ll postgres.tar</span><br><span class="line">-rw-r--r-- 1 root root 381950976 Mar 30 08:04 postgres.tar</span><br><span class="line">root@hello:~#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="导入镜像"><a href="#导入镜像" class="headerlink" title="导入镜像"></a>导入镜像</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker load -i postgres.tar </span><br><span class="line">7ab4f6ae3ff7: Loading layer [==================================================&gt;]  10.18MB/10.18MB</span><br><span class="line">db8b35906c8d: Loading layer [==================================================&gt;]    340kB/340kB</span><br><span class="line">f9f2c722c092: Loading layer [==================================================&gt;]   4.19MB/4.19MB</span><br><span class="line">75be6af37d28: Loading layer [==================================================&gt;]   25.7MB/25.7MB</span><br><span class="line">15dd9dd29d12: Loading layer [==================================================&gt;]  1.682MB/1.682MB</span><br><span class="line">1d5d2439ed88: Loading layer [==================================================&gt;]  2.048kB/2.048kB</span><br><span class="line">920ba1e03a88: Loading layer [==================================================&gt;]  6.656kB/6.656kB</span><br><span class="line">eb96dca5c689: Loading layer [==================================================&gt;]  255.8MB/255.8MB</span><br><span class="line">3acb2bfab7b0: Loading layer [==================================================&gt;]  66.56kB/66.56kB</span><br><span class="line">140aef27609a: Loading layer [==================================================&gt;]  2.048kB/2.048kB</span><br><span class="line">c06253083edb: Loading layer [==================================================&gt;]  3.584kB/3.584kB</span><br><span class="line">e7b07b473569: Loading layer [==================================================&gt;]  15.36kB/15.36kB</span><br><span class="line">Loaded image: postgres:latest</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# mkdir /data/postgres -p</span><br><span class="line"></span><br><span class="line">root@hello:~# docker run --name postgres -e POSTGRES_PASSWORD=thinker -p 5432:5432 -v /data/postgres:/var/lib/postgresql/data -d postgres</span><br><span class="line">ae30b561a607210d4cbb42f5cc344898341124feeb1a2e5fe68031ec1a46b5b4</span><br><span class="line"></span><br><span class="line">root@hello:~# docker ps | grep postgres </span><br><span class="line">ae30b561a607   postgres             &quot;docker-entrypoint.s…&quot;   About a minute ago   Up About a minute   0.0.0.0:5432-&gt;5432/tcp, :::5432-&gt;5432/tcp                       postgres</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="访问测试"><a href="#访问测试" class="headerlink" title="访问测试"></a>访问测试</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# docker exec -it ae30b561a607 bash</span><br><span class="line">root@ae30b561a607:/# su postgres</span><br><span class="line">postgres@ae30b561a607:/$ psql</span><br><span class="line">psql (14.1 (Debian 14.1-1.pgdg110+1))</span><br><span class="line">Type &quot;help&quot; for help.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">postgres-#</span><span class="language-bash"> \l</span></span><br><span class="line">                                 List of databases</span><br><span class="line">   Name    |  Owner   | Encoding |  Collate   |   Ctype    |   Access privileges   </span><br><span class="line">-----------+----------+----------+------------+------------+-----------------------</span><br><span class="line"> postgres  | postgres | UTF8     | en_US.utf8 | en_US.utf8 | </span><br><span class="line"> template0 | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres          +</span><br><span class="line">           |          |          |            |            | postgres=CTc/postgres</span><br><span class="line"> template1 | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres          +</span><br><span class="line">           |          |          |            |            | postgres=CTc/postgres</span><br><span class="line">(3 rows)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">postgres-#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"></span></span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装Kubernetes（k8s） v1.23.5</title>
    <url>/2022/04/02/2022-04-02-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85Kubernetes%EF%BC%88k8s%EF%BC%89_v1.23.5/</url>
    <content><![CDATA[<p>Github：<a href="https://github.com/cby-chen/Kubernetes/">https://github.com/cby-chen/Kubernetes/</a></p>
<p>1.23.3 和 1.23.4 和 1.23.5 文档以及安装包已生成。</p>
<p>后续尽可能第一时间更新新版本文档</p>
<p><a href="https://github.com/cby-chen/Kubernetes/releases">https://github.com/cby-chen/Kubernetes/releases</a></p>
<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1.环境"></a>1.环境</h1><table>
<thead>
<tr>
<th>主机名称</th>
<th>IP地址</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td>Master01</td>
<td>192.168.1.61</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master02</td>
<td>192.168.1.62</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master03</td>
<td>192.168.1.63</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node01</td>
<td>192.168.1.64</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node02</td>
<td>192.168.1.65</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node03</td>
<td>192.168.1.66</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node04</td>
<td>192.168.1.67</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node05</td>
<td>192.168.1.68</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Lb01</td>
<td>192.168.1.57</td>
<td>Lb01节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td>Lb02</td>
<td>192.168.1.58</td>
<td>Lb02节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td></td>
<td>192.168.1.59</td>
<td>VIP</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">软件</th>
<th align="left">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">内核</td>
<td align="left">5.17.1-1.el8.elrepo.x86_64</td>
</tr>
<tr>
<td align="left">CentOS 8</td>
<td align="left">v8</td>
</tr>
<tr>
<td align="left">kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy</td>
<td align="left">v1.23.5</td>
</tr>
<tr>
<td align="left">etcd</td>
<td align="left">v3.5.2</td>
</tr>
<tr>
<td align="left">docker-ce</td>
<td align="left">v20.10.14</td>
</tr>
<tr>
<td align="left">containerd</td>
<td align="left">v1.5.11</td>
</tr>
<tr>
<td align="left">cfssl</td>
<td align="left">v1.6.1</td>
</tr>
<tr>
<td align="left">cni</td>
<td align="left">v1.1.1</td>
</tr>
<tr>
<td align="left">crictl</td>
<td align="left">v1.23.0</td>
</tr>
<tr>
<td align="left">haproxy</td>
<td align="left">v1.8.27</td>
</tr>
<tr>
<td align="left">keepalived</td>
<td align="left">v2.1.5</td>
</tr>
</tbody></table>
<p>网段</p>
<p>物理主机：192.168.1.0&#x2F;24</p>
<p>service：10.96.0.0&#x2F;12</p>
<p>pod：172.16.0.0&#x2F;12</p>
<p>如果有条件建议k8s集群与etcd集群分开安装</p>
<h2 id="1-1-k8s基础系统环境配置"><a href="#1-1-k8s基础系统环境配置" class="headerlink" title="1.1.k8s基础系统环境配置"></a>1.1.k8s基础系统环境配置</h2><h3 id="1-2-配置IP"><a href="#1-2-配置IP" class="headerlink" title="1.2.配置IP"></a>1.2.配置IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@192.168.1.161 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.61/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.167 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.62/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.137 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.63/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.152 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.64/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.198 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.65/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.166 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.66/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.171 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.67/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.159 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.68/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.125 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.57/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.122 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.58/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br></pre></td></tr></table></figure>

<h3 id="1-3-设置主机名"><a href="#1-3-设置主机名" class="headerlink" title="1.3.设置主机名"></a>1.3.设置主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-master02</span><br><span class="line">hostnamectl set-hostname k8s-master03</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br><span class="line">hostnamectl set-hostname k8s-node03</span><br><span class="line">hostnamectl set-hostname k8s-node04</span><br><span class="line">hostnamectl set-hostname k8s-node05</span><br><span class="line">hostnamectl set-hostname lb01</span><br><span class="line">hostnamectl set-hostname lb02</span><br></pre></td></tr></table></figure>

<h3 id="1-4-配置yum源"><a href="#1-4-配置yum源" class="headerlink" title="1.4.配置yum源"></a>1.4.配置yum源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=http://192.168.1.123/centos|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; -e &#x27;s|^#baseurl=http://mirror.centos.org/\$contentdir|baseurl=http://192.168.1.123/centos|g&#x27; -i.bak  /etc/yum.repos.d/CentOS-*.repo</span><br></pre></td></tr></table></figure>

<h3 id="1-5-安装一些必备工具"><a href="#1-5-安装一些必备工具" class="headerlink" title="1.5.安装一些必备工具"></a>1.5.安装一些必备工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install wget jq psmisc vim net-tools  telnet yum-utils device-mapper-persistent-data lvm2 git network-scripts tar curl -y</span><br></pre></td></tr></table></figure>

<h3 id="1-6-安装docker工具-lb除外"><a href="#1-6-安装docker工具-lb除外" class="headerlink" title="1.6.安装docker工具 (lb除外)"></a>1.6.安装docker工具 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br></pre></td></tr></table></figure>

<h3 id="1-7-关闭防火墙"><a href="#1-7-关闭防火墙" class="headerlink" title="1.7.关闭防火墙"></a>1.7.关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br></pre></td></tr></table></figure>

<h3 id="1-8-关闭SELinux"><a href="#1-8-关闭SELinux" class="headerlink" title="1.8.关闭SELinux"></a>1.8.关闭SELinux</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure>

<h3 id="1-9-关闭交换分区"><a href="#1-9-关闭交换分区" class="headerlink" title="1.9.关闭交换分区"></a>1.9.关闭交换分区</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">cat /etc/fstab</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>

<h3 id="1-10-关闭NetworkManager-并启用-network-lb除外"><a href="#1-10-关闭NetworkManager-并启用-network-lb除外" class="headerlink" title="1.10.关闭NetworkManager 并启用 network (lb除外)"></a>1.10.关闭NetworkManager 并启用 network (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now NetworkManager</span><br><span class="line">systemctl start network &amp;&amp; systemctl enable network</span><br></pre></td></tr></table></figure>

<h3 id="1-11-进行时间同步-lb除外"><a href="#1-11-进行时间同步-lb除外" class="headerlink" title="1.11.进行时间同步 (lb除外)"></a>1.11.进行时间同步 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">服务端</span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">cat &gt; /etc/chrony.conf &lt;&lt; EOF </span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">allow 192.168.1.0/24</span><br><span class="line">local stratum 10</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd</span><br><span class="line">systemctl enable chronyd</span><br><span class="line"></span><br><span class="line">客户端</span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool 192.168.1.61 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum install chrony -y ; sed -i &quot;s#2.centos.pool.ntp.org#192.168.1.61#g&quot; /etc/chrony.conf ; systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">使用客户端进行验证</span><br><span class="line"></span><br><span class="line">chronyc sources -v</span><br></pre></td></tr></table></figure>

<h3 id="1-12-配置ulimit"><a href="#1-12-配置ulimit" class="headerlink" title="1.12.配置ulimit"></a>1.12.配置ulimit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -SHn 65535</span><br><span class="line">cat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOF</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* seft memlock unlimited</span><br><span class="line">* hard memlock unlimitedd</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="1-13-配置免密登录"><a href="#1-13-配置免密登录" class="headerlink" title="1.13.配置免密登录"></a>1.13.配置免密登录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br><span class="line">ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;</span><br><span class="line">export IP=&quot;192.168.1.61 192.168.1.62 192.168.1.63 192.168.1.64 192.168.1.65 192.168.1.66 192.168.1.67 192.168.1.68 192.168.1.57 192.168.1.58&quot;</span><br><span class="line">export SSHPASS=123123</span><br><span class="line">for HOST in $IP;do</span><br><span class="line">     sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $HOST</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="1-14-添加启用源-lb除外"><a href="#1-14-添加启用源-lb除外" class="headerlink" title="1.14.添加启用源 (lb除外)"></a>1.14.添加启用源 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">为 RHEL-8或 CentOS-8配置源</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line">为 RHEL-7 SL-7 或 CentOS-7 安装 ELRepo </span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line">查看可用安装包</span><br><span class="line">yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available</span><br></pre></td></tr></table></figure>

<h3 id="1-15-升级内核至4-18版本以上-lb除外"><a href="#1-15-升级内核至4-18版本以上-lb除外" class="headerlink" title="1.15.升级内核至4.18版本以上 (lb除外)"></a>1.15.升级内核至4.18版本以上 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装最新的内核</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我这里选择的是稳定版kernel-ml   如需更新长期维护版本kernel-lt</span>  </span><br><span class="line">yum  --enablerepo=elrepo-kernel  install  kernel-ml</span><br><span class="line"></span><br><span class="line">查看已安装那些内核</span><br><span class="line">rpm -qa | grep kernel</span><br><span class="line">kernel-core-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-core-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-ml-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-modules-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-libs-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-modules-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"></span><br><span class="line">查看默认内核</span><br><span class="line">grubby --default-kernel</span><br><span class="line">/boot/vmlinuz-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">若不是最新的使用命令设置</span><br><span class="line">grubby --set-default /boot/vmlinuz-「您的内核版本」.x86_64</span><br><span class="line"></span><br><span class="line">重启生效</span><br><span class="line">reboot</span><br><span class="line"></span><br><span class="line">整合命令为：</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --default-kernel ; reboot</span><br></pre></td></tr></table></figure>

<h3 id="1-16-安装ipvsadm-lb除外"><a href="#1-16-安装ipvsadm-lb除外" class="headerlink" title="1.16.安装ipvsadm (lb除外)"></a>1.16.安装ipvsadm (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;EOF </span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">ip_tables</span><br><span class="line">ip_set</span><br><span class="line">xt_set</span><br><span class="line">ipt_set</span><br><span class="line">ipt_rpfilter</span><br><span class="line">ipt_REJECT</span><br><span class="line">ipip</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart systemd-modules-load.service</span><br><span class="line"></span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack</span><br><span class="line">ip_vs_sh               16384  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          176128  1 ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure>

<h3 id="1-17-修改内核参数-lb除外"><a href="#1-17-修改内核参数-lb除外" class="headerlink" title="1.17.修改内核参数 (lb除外)"></a>1.17.修改内核参数 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="1-18-所有节点配置hosts本地解析"><a href="#1-18-所有节点配置hosts本地解析" class="headerlink" title="1.18.所有节点配置hosts本地解析"></a>1.18.所有节点配置hosts本地解析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.1.61 k8s-master01</span><br><span class="line">192.168.1.62 k8s-master02</span><br><span class="line">192.168.1.63 k8s-master03</span><br><span class="line">192.168.1.64 k8s-node01</span><br><span class="line">192.168.1.65 k8s-node02</span><br><span class="line">192.168.1.66 k8s-node03</span><br><span class="line">192.168.1.67 k8s-node04</span><br><span class="line">192.168.1.68 k8s-node05</span><br><span class="line">192.168.1.57 lb01</span><br><span class="line">192.168.1.58 lb02</span><br><span class="line">192.168.1.59 lb-vip</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="2-k8s基本组件安装"><a href="#2-k8s基本组件安装" class="headerlink" title="2.k8s基本组件安装"></a>2.k8s基本组件安装</h1><h2 id="2-1-所有k8s节点安装Containerd作为Runtime"><a href="#2-1-所有k8s节点安装Containerd作为Runtime" class="headerlink" title="2.1.所有k8s节点安装Containerd作为Runtime"></a>2.1.所有k8s节点安装Containerd作为Runtime</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install containerd -y</span><br></pre></td></tr></table></figure>

<h3 id="2-1-1配置Containerd所需的模块"><a href="#2-1-1配置Containerd所需的模块" class="headerlink" title="2.1.1配置Containerd所需的模块"></a>2.1.1配置Containerd所需的模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2加载模块"><a href="#2-1-2加载模块" class="headerlink" title="2.1.2加载模块"></a>2.1.2加载模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl restart systemd-modules-load.service</span><br></pre></td></tr></table></figure>

<h3 id="2-1-3配置Containerd所需的内核"><a href="#2-1-3配置Containerd所需的内核" class="headerlink" title="2.1.3配置Containerd所需的内核"></a>2.1.3配置Containerd所需的内核</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载内核</span></span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4创建Containerd的配置文件"><a href="#2-1-4创建Containerd的配置文件" class="headerlink" title="2.1.4创建Containerd的配置文件"></a>2.1.4创建Containerd的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改Containerd的配置文件</span><br><span class="line">sed -i &quot;s#SystemdCgroup\ \=\ false#SystemdCgroup\ \=\ true#g&quot; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">cat /etc/containerd/config.toml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到containerd.runtimes.runc.options，在其下加入SystemdCgroup = <span class="literal">true</span></span></span><br><span class="line"></span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">              SystemdCgroup = true</span><br><span class="line">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sandbox_image默认地址改为符合版本地址</span></span><br><span class="line"></span><br><span class="line">    sandbox_image = &quot;registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&quot;</span><br></pre></td></tr></table></figure>

<h3 id="2-1-5启动并设置为开机启动"><a href="#2-1-5启动并设置为开机启动" class="headerlink" title="2.1.5启动并设置为开机启动"></a>2.1.5启动并设置为开机启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now containerd</span><br></pre></td></tr></table></figure>

<h3 id="2-1-6配置crictl客户端连接的运行时位置"><a href="#2-1-6配置crictl客户端连接的运行时位置" class="headerlink" title="2.1.6配置crictl客户端连接的运行时位置"></a>2.1.6配置crictl客户端连接的运行时位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/crictl.yaml &lt;&lt;EOF</span><br><span class="line">runtime-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">image-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">timeout: 10</span><br><span class="line">debug: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="2-2-k8s与etcd下载及安装（仅在master01操作）"><a href="#2-2-k8s与etcd下载及安装（仅在master01操作）" class="headerlink" title="2.2.k8s与etcd下载及安装（仅在master01操作）"></a>2.2.k8s与etcd下载及安装（仅在master01操作）</h2><h3 id="2-2-1下载k8s安装包（你用哪个下哪个）"><a href="#2-2-1下载k8s安装包（你用哪个下哪个）" class="headerlink" title="2.2.1下载k8s安装包（你用哪个下哪个）"></a>2.2.1下载k8s安装包（你用哪个下哪个）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1.下载kubernetes1.23.+的二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md</span><br><span class="line"></span><br><span class="line">wget https://dl.k8s.io/v1.23.5/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">2.下载etcdctl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/etcd-io/etcd/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.5.2/etcd-v3.5.2-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">3.docker-ce二进制包下载地址</span><br><span class="line">二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><br><span class="line"></span><br><span class="line">这里需要下载20.10.+版本</span><br><span class="line"></span><br><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-20.10.14.tgz</span><br><span class="line"></span><br><span class="line">4.containerd二进制包下载</span><br><span class="line">github下载地址：https://github.com/containerd/containerd/releases</span><br><span class="line"></span><br><span class="line">containerd下载时下载带cni插件的二进制包。</span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.2/cri-containerd-cni-1.6.2-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">5.下载cfssl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/cloudflare/cfssl/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.1_linux_amd64</span><br><span class="line"></span><br><span class="line">6.cni插件下载</span><br><span class="line">github下载地址：https://github.com/containernetworking/plugins/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span><br><span class="line"></span><br><span class="line">7.crictl客户端二进制下载</span><br><span class="line">github下载：https://github.com/kubernetes-sigs/cri-tools/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.23.0/crictl-v1.23.0-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">解压k8s安装文件</span><br><span class="line">tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;</span><br><span class="line"></span><br><span class="line">解压etcd安装文件</span><br><span class="line">tar -xf etcd-v3.5.2-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.2-linux-amd64/etcd&#123;,ctl&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看/usr/local/bin下内容</span></span><br><span class="line"></span><br><span class="line">ls /usr/local/bin/</span><br><span class="line">etcd  etcdctl  kube-apiserver  kube-controller-manager  kubectl  kubelet  kube-proxy  kube-scheduler</span><br><span class="line"></span><br><span class="line">已经整理好的：</span><br><span class="line">wget https://github.com/cby-chen/Kubernetes/releases/download/v1.23.5/kubernetes-v1.23.5.tar</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2查看版本"><a href="#2-2-2查看版本" class="headerlink" title="2.2.2查看版本"></a>2.2.2查看版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubelet --version</span><br><span class="line">Kubernetes v1.23.5</span><br><span class="line">[root@k8s-master01 ~]# etcdctl version</span><br><span class="line">etcdctl version: 3.5.2</span><br><span class="line">API version: 3.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h3 id="2-2-3将组件发送至其他k8s节点"><a href="#2-2-3将组件发送至其他k8s节点" class="headerlink" title="2.2.3将组件发送至其他k8s节点"></a>2.2.3将组件发送至其他k8s节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">Work=&#x27;k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05&#x27;</span><br><span class="line">for NODE in $Master; do echo $NODE; scp /usr/local/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done</span><br><span class="line">for NODE in $Work; do     scp /usr/local/bin/kube&#123;let,-proxy&#125; $NODE:/usr/local/bin/ ; done</span><br></pre></td></tr></table></figure>

<h3 id="2-2-4克隆证书相关文件"><a href="#2-2-4克隆证书相关文件" class="headerlink" title="2.2.4克隆证书相关文件"></a>2.2.4克隆证书相关文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/cby-chen/Kubernetes.git</span><br></pre></td></tr></table></figure>

<h3 id="2-2-5所有k8s节点创建目录"><a href="#2-2-5所有k8s节点创建目录" class="headerlink" title="2.2.5所有k8s节点创建目录"></a>2.2.5所有k8s节点创建目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /opt/cni/bin</span><br></pre></td></tr></table></figure>

<h1 id="3-相关证书生成"><a href="#3-相关证书生成" class="headerlink" title="3.相关证书生成"></a>3.相关证书生成</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">master01节点下载证书生成工具</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssl</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssljson</span><br><span class="line">chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</span><br></pre></td></tr></table></figure>

<h2 id="3-1-生成etcd证书"><a href="#3-1-生成etcd证书" class="headerlink" title="3.1.生成etcd证书"></a>3.1.生成etcd证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-1-1所有master节点创建证书存放目录"><a href="#3-1-1所有master节点创建证书存放目录" class="headerlink" title="3.1.1所有master节点创建证书存放目录"></a>3.1.1所有master节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/etcd/ssl -p</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2master01节点生成etcd证书"><a href="#3-1-2master01节点生成etcd证书" class="headerlink" title="3.1.2master01节点生成etcd证书"></a>3.1.2master01节点生成etcd证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd Kubernetes/pki/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成etcd证书和etcd证书的key（如果你觉得以后可能会扩容，可以在ip那多写几个预留出来）</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,192.168.1.61,192.168.1.62,192.168.1.63 \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</span><br></pre></td></tr></table></figure>

<h3 id="3-1-3将证书复制到其他节点"><a href="#3-1-3将证书复制到其他节点" class="headerlink" title="3.1.3将证书复制到其他节点"></a>3.1.3将证书复制到其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">for NODE in $Master; do</span><br><span class="line">     ssh $NODE &quot;mkdir -p /etc/etcd/ssl&quot;</span><br><span class="line">     for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do</span><br><span class="line">       scp /etc/etcd/ssl/$&#123;FILE&#125; $NODE:/etc/etcd/ssl/$&#123;FILE&#125;</span><br><span class="line">     done</span><br><span class="line"> done</span><br></pre></td></tr></table></figure>

<h2 id="3-2-生成k8s相关证书"><a href="#3-2-生成k8s相关证书" class="headerlink" title="3.2.生成k8s相关证书"></a>3.2.生成k8s相关证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-2-1所有k8s节点创建证书存放目录"><a href="#3-2-1所有k8s节点创建证书存放目录" class="headerlink" title="3.2.1所有k8s节点创建证书存放目录"></a>3.2.1所有k8s节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2master01节点生成k8s证书"><a href="#3-2-2master01节点生成k8s证书" class="headerlink" title="3.2.2master01节点生成k8s证书"></a>3.2.2master01节点生成k8s证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成一个根证书</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.96.0.1是service网段的第一个地址，需要计算，192.168.1.59为高可用vip地址</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   \</span><br><span class="line">-ca=/etc/kubernetes/pki/ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-hostname=10.96.0.1,192.168.1.59,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,x.oiox.cn,k.oiox.cn,l.oiox.cn,o.oiox.cn,192.168.1.61,192.168.1.62,192.168.1.63,192.168.1.64,192.168.1.65,192.168.1.66,192.168.1.67,192.168.1.68,192.168.1.57,192.168.1.58,192.168.1.40,192.168.1.41   \</span><br><span class="line">-profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3生成apiserver聚合证书"><a href="#3-2-3生成apiserver聚合证书" class="headerlink" title="3.2.3生成apiserver聚合证书"></a>3.2.3生成apiserver聚合证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有一个警告，可以忽略</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   -ca=/etc/kubernetes/pki/front-proxy-ca.pem   -ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   -config=ca-config.json   -profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4生成controller-manage的证书"><a href="#3-2-4生成controller-manage的证书" class="headerlink" title="3.2.4生成controller-manage的证书"></a>3.2.4生成controller-manage的证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个集群项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://192.168.1.59:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个环境项，一个上下文</span></span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=system:kube-controller-manager \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个用户项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置默认环境</span></span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://192.168.1.59:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/scheduler.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/scheduler-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --cluster=kubernetes \</span><br><span class="line">     --user=system:kube-scheduler \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.59:8443     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes-admin     --client-certificate=/etc/kubernetes/pki/admin.pem     --client-key=/etc/kubernetes/pki/admin-key.pem     --embed-certs=true     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes     --cluster=kubernetes     --user=kubernetes-admin     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes     --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5创建ServiceAccount-Key-——secret"><a href="#3-2-5创建ServiceAccount-Key-——secret" class="headerlink" title="3.2.5创建ServiceAccount Key ——secret"></a>3.2.5创建ServiceAccount Key ——secret</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out /etc/kubernetes/pki/sa.key 2048</span><br><span class="line">openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</span><br></pre></td></tr></table></figure>

<h3 id="3-2-6将证书发送到其他master节点"><a href="#3-2-6将证书发送到其他master节点" class="headerlink" title="3.2.6将证书发送到其他master节点"></a>3.2.6将证书发送到其他master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do </span><br><span class="line">for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do </span><br><span class="line">scp /etc/kubernetes/pki/$&#123;FILE&#125; $NODE:/etc/kubernetes/pki/$&#123;FILE&#125;;</span><br><span class="line">done; </span><br><span class="line">for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do </span><br><span class="line">scp /etc/kubernetes/$&#123;FILE&#125; $NODE:/etc/kubernetes/$&#123;FILE&#125;;</span><br><span class="line">done;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="3-2-7查看证书"><a href="#3-2-7查看证书" class="headerlink" title="3.2.7查看证书"></a>3.2.7查看证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /etc/kubernetes/pki/</span><br><span class="line">admin.csr      apiserver-key.pem  ca.pem                      front-proxy-ca.csr      front-proxy-client-key.pem  scheduler.csr</span><br><span class="line">admin-key.pem  apiserver.pem      controller-manager.csr      front-proxy-ca-key.pem  front-proxy-client.pem      scheduler-key.pem</span><br><span class="line">admin.pem      ca.csr             controller-manager-key.pem  front-proxy-ca.pem      sa.key                      scheduler.pem</span><br><span class="line">apiserver.csr  ca-key.pem         controller-manager.pem      front-proxy-client.csr  sa.pub</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一共23个就对了</span></span><br><span class="line"></span><br><span class="line">ls /etc/kubernetes/pki/ |wc -l</span><br><span class="line">23</span><br></pre></td></tr></table></figure>

<h1 id="4-k8s系统组件配置"><a href="#4-k8s系统组件配置" class="headerlink" title="4.k8s系统组件配置"></a>4.k8s系统组件配置</h1><h2 id="4-1-etcd配置"><a href="#4-1-etcd配置" class="headerlink" title="4.1.etcd配置"></a>4.1.etcd配置</h2><h3 id="4-1-1master01配置"><a href="#4-1-1master01配置" class="headerlink" title="4.1.1master01配置"></a>4.1.1master01配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master01&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.61:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.61:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.61:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.61:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.61:2380,k8s-master02=https://192.168.1.62:2380,k8s-master03=https://192.168.1.63:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2master02配置"><a href="#4-1-2master02配置" class="headerlink" title="4.1.2master02配置"></a>4.1.2master02配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master02&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.62:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.62:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.62:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.62:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.61:2380,k8s-master02=https://192.168.1.62:2380,k8s-master03=https://192.168.1.63:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3master03配置"><a href="#4-1-3master03配置" class="headerlink" title="4.1.3master03配置"></a>4.1.3master03配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master03&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.63:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.63:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.63:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.63:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.61:2380,k8s-master02=https://192.168.1.62:2380,k8s-master03=https://192.168.1.63:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="4-2-创建service（所有master节点操作）"><a href="#4-2-创建service（所有master节点操作）" class="headerlink" title="4.2.创建service（所有master节点操作）"></a>4.2.创建service（所有master节点操作）</h2><h3 id="4-2-1创建etcd-service并启动"><a href="#4-2-1创建etcd-service并启动" class="headerlink" title="4.2.1创建etcd.service并启动"></a>4.2.1创建etcd.service并启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2创建etcd证书目录"><a href="#4-2-2创建etcd证书目录" class="headerlink" title="4.2.2创建etcd证书目录"></a>4.2.2创建etcd证书目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/kubernetes/pki/etcd</span><br><span class="line">ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now etcd</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3查看etcd状态"><a href="#4-2-3查看etcd状态" class="headerlink" title="4.2.3查看etcd状态"></a>4.2.3查看etcd状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 pki]# export ETCDCTL_API=3</span><br><span class="line">[root@k8s-master01 pki]# etcdctl --endpoints=&quot;192.168.1.63:2379,192.168.1.62:2379,192.168.1.61:2379&quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|     ENDPOINT      |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| 192.168.1.63:2379 | 7cb7be3df5c81965 |   3.5.2 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 192.168.1.62:2379 | c077939949ab3f8b |   3.5.2 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 192.168.1.61:2379 | 2ee388f67565dac9 |   3.5.2 |   20 kB |      true |      false |         2 |          9 |                  9 |        |</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">[root@k8s-master01 pki]# </span><br></pre></td></tr></table></figure>

<h1 id="5-高可用配置"><a href="#5-高可用配置" class="headerlink" title="5.高可用配置"></a>5.高可用配置</h1><h2 id="5-1在lb01和lb02两台服务器上操作"><a href="#5-1在lb01和lb02两台服务器上操作" class="headerlink" title="5.1在lb01和lb02两台服务器上操作"></a>5.1在lb01和lb02两台服务器上操作</h2><h3 id="5-1-1安装keepalived和haproxy服务"><a href="#5-1-1安装keepalived和haproxy服务" class="headerlink" title="5.1.1安装keepalived和haproxy服务"></a>5.1.1安装keepalived和haproxy服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br><span class="line"></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum -y install keepalived haproxy</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2修改haproxy配置文件（两台配置文件一样）"><a href="#5-1-2修改haproxy配置文件（两台配置文件一样）" class="headerlink" title="5.1.2修改haproxy配置文件（两台配置文件一样）"></a>5.1.2修改haproxy配置文件（两台配置文件一样）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt;/etc/haproxy/haproxy.cfg&lt;&lt;&quot;EOF&quot;</span><br><span class="line">global</span><br><span class="line"> maxconn 2000</span><br><span class="line"> ulimit-n 16384</span><br><span class="line"> log 127.0.0.1 local0 err</span><br><span class="line"> stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"> log global</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> timeout connect 5000</span><br><span class="line"> timeout client 50000</span><br><span class="line"> timeout server 50000</span><br><span class="line"> timeout http-request 15s</span><br><span class="line"> timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line"> bind *:33305</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line"> bind 0.0.0.0:8443</span><br><span class="line"> bind 127.0.0.1:8443</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> tcp-request inspect-delay 5s</span><br><span class="line"> default_backend k8s-master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> option tcp-check</span><br><span class="line"> balance roundrobin</span><br><span class="line"> default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line"> server  k8s-master01  192.168.1.61:6443 check</span><br><span class="line"> server  k8s-master02  192.168.1.62:6443 check</span><br><span class="line"> server  k8s-master03  192.168.1.63:6443 check</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-3lb01配置keepalived-master节点"><a href="#5-1-3lb01配置keepalived-master节点" class="headerlink" title="5.1.3lb01配置keepalived master节点"></a>5.1.3lb01配置keepalived master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens18</span><br><span class="line">    mcast_src_ip 192.168.1.57</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.59</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4lb02配置keepalived-backup节点"><a href="#5-1-4lb02配置keepalived-backup节点" class="headerlink" title="5.1.4lb02配置keepalived backup节点"></a>5.1.4lb02配置keepalived backup节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens18</span><br><span class="line">    mcast_src_ip 192.168.1.58</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 50</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.59</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-5健康检查脚本配置（两台lb主机）"><a href="#5-1-5健康检查脚本配置（两台lb主机）" class="headerlink" title="5.1.5健康检查脚本配置（两台lb主机）"></a>5.1.5健康检查脚本配置（两台lb主机）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/keepalived/check_apiserver.sh &lt;&lt; EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">err=0</span><br><span class="line">for k in \$(seq 1 3)</span><br><span class="line">do</span><br><span class="line">    check_code=\$(pgrep haproxy)</span><br><span class="line">    if [[ \$check_code == &quot;&quot; ]]; then</span><br><span class="line">        err=\$(expr \$err + 1)</span><br><span class="line">        sleep 1</span><br><span class="line">        continue</span><br><span class="line">    else</span><br><span class="line">        err=0</span><br><span class="line">        break</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ \$err != &quot;0&quot; ]]; then</span><br><span class="line">    echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">    /usr/bin/systemctl stop keepalived</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给脚本授权</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_apiserver.sh</span><br></pre></td></tr></table></figure>

<h3 id="5-1-6启动服务"><a href="#5-1-6启动服务" class="headerlink" title="5.1.6启动服务"></a>5.1.6启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now haproxy</span><br><span class="line">systemctl enable --now keepalived</span><br></pre></td></tr></table></figure>

<h3 id="5-1-7测试高可用"><a href="#5-1-7测试高可用" class="headerlink" title="5.1.7测试高可用"></a>5.1.7测试高可用</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能ping同</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# ping 192.168.1.59</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能telnet访问</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# telnet 192.168.1.59 8443</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭主节点，看vip是否漂移到备节点</span></span><br></pre></td></tr></table></figure>

<h1 id="6-k8s组件配置（区别于第4点）"><a href="#6-k8s组件配置（区别于第4点）" class="headerlink" title="6.k8s组件配置（区别于第4点）"></a>6.k8s组件配置（区别于第4点）</h1><p>所有k8s节点创建以下目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes</span><br></pre></td></tr></table></figure>

<h2 id="6-1-创建apiserver（所有master节点）"><a href="#6-1-创建apiserver（所有master节点）" class="headerlink" title="6.1.创建apiserver（所有master节点）"></a>6.1.创建apiserver（所有master节点）</h2><h3 id="6-1-1master01节点配置"><a href="#6-1-1master01节点配置" class="headerlink" title="6.1.1master01节点配置"></a>6.1.1master01节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.61 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-2master02节点配置"><a href="#6-1-2master02节点配置" class="headerlink" title="6.1.2master02节点配置"></a>6.1.2master02节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.62 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-3master03节点配置"><a href="#6-1-3master03节点配置" class="headerlink" title="6.1.3master03节点配置"></a>6.1.3master03节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service  &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.63 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-4启动apiserver（所有master节点）"><a href="#6-1-4启动apiserver（所有master节点）" class="headerlink" title="6.1.4启动apiserver（所有master节点）"></a>6.1.4启动apiserver（所有master节点）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl enable --now kube-apiserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意查看状态是否启动正常</span></span><br><span class="line"></span><br><span class="line">systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>

<h2 id="6-2-配置kube-controller-manager-service"><a href="#6-2-配置kube-controller-manager-service" class="headerlink" title="6.2.配置kube-controller-manager service"></a>6.2.配置kube-controller-manager service</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">所有master节点配置，且配置相同</span><br><span class="line">172.16.0.0/12为pod网段，按需求设置你自己的网段</span><br><span class="line"></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --use-service-account-credentials=true \</span><br><span class="line">      --node-monitor-grace-period=40s \</span><br><span class="line">      --node-monitor-period=5s \</span><br><span class="line">      --pod-eviction-timeout=2m0s \</span><br><span class="line">      --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">      --allocate-node-cidrs=true \</span><br><span class="line">      --cluster-cidr=172.16.0.0/12 \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem \</span><br><span class="line">      --node-cidr-mask-size=24</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-2-1启动kube-controller-manager，并查看状态"><a href="#6-2-1启动kube-controller-manager，并查看状态" class="headerlink" title="6.2.1启动kube-controller-manager，并查看状态"></a>6.2.1启动kube-controller-manager，并查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-controller-manager</span><br><span class="line">systemctl  status kube-controller-manager</span><br></pre></td></tr></table></figure>

<h2 id="6-3-配置kube-scheduler-service"><a href="#6-3-配置kube-scheduler-service" class="headerlink" title="6.3.配置kube-scheduler service"></a>6.3.配置kube-scheduler service</h2><h3 id="6-3-1所有master节点配置，且配置相同"><a href="#6-3-1所有master节点配置，且配置相同" class="headerlink" title="6.3.1所有master节点配置，且配置相同"></a>6.3.1所有master节点配置，且配置相同</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-3-2启动并查看服务状态"><a href="#6-3-2启动并查看服务状态" class="headerlink" title="6.3.2启动并查看服务状态"></a>6.3.2启动并查看服务状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-scheduler</span><br><span class="line">systemctl status kube-scheduler</span><br></pre></td></tr></table></figure>

<h1 id="7-TLS-Bootstrapping配置"><a href="#7-TLS-Bootstrapping配置" class="headerlink" title="7.TLS Bootstrapping配置"></a>7.TLS Bootstrapping配置</h1><h2 id="7-1在master01上配置"><a href="#7-1在master01上配置" class="headerlink" title="7.1在master01上配置"></a>7.1在master01上配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/bootstrap</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.59:8443     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials tls-bootstrap-token-user     --token=c8ad9c.2e4d610cf3e7426e --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context tls-bootstrap-token-user@kubernetes     --cluster=kubernetes     --user=tls-bootstrap-token-user     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context tls-bootstrap-token-user@kubernetes     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">token的位置在bootstrap.secret.yaml，如果修改的话到这个文件修改</span></span><br><span class="line"></span><br><span class="line">mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config</span><br></pre></td></tr></table></figure>

<h2 id="7-2查看集群状态，没问题的话继续后续操作"><a href="#7-2查看集群状态，没问题的话继续后续操作" class="headerlink" title="7.2查看集群状态，没问题的话继续后续操作"></a>7.2查看集群状态，没问题的话继续后续操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line"></span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE                         ERROR</span><br><span class="line">controller-manager   Healthy   ok                              </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">scheduler            Healthy   ok                              </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;  </span><br><span class="line"></span><br><span class="line">kubectl create -f bootstrap.secret.yaml</span><br></pre></td></tr></table></figure>

<h1 id="8-node节点配置"><a href="#8-node节点配置" class="headerlink" title="8.node节点配置"></a>8.node节点配置</h1><h2 id="8-1-在master01上将证书复制到node节点"><a href="#8-1-在master01上将证书复制到node节点" class="headerlink" title="8.1.在master01上将证书复制到node节点"></a>8.1.在master01上将证书复制到node节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/kubernetes/</span><br><span class="line"></span><br><span class="line">for NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do</span><br><span class="line">     ssh $NODE mkdir -p /etc/kubernetes/pki</span><br><span class="line">     for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig; do</span><br><span class="line">       scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&#123;FILE&#125;</span><br><span class="line"> done</span><br><span class="line"> done</span><br></pre></td></tr></table></figure>

<h2 id="8-2-kubelet配置"><a href="#8-2-kubelet配置" class="headerlink" title="8.2.kubelet配置"></a>8.2.kubelet配置</h2><h3 id="8-2-1所有k8s节点创建相关目录"><a href="#8-2-1所有k8s节点创建相关目录" class="headerlink" title="8.2.1所有k8s节点创建相关目录"></a>8.2.1所有k8s节点创建相关目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">所有k8s节点配置kubelet service</span><br><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \</span><br><span class="line">    --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">    --config=/etc/kubernetes/kubelet-conf.yml \</span><br><span class="line">    --network-plugin=cni  \</span><br><span class="line">    --cni-conf-dir=/etc/cni/net.d  \</span><br><span class="line">    --cni-bin-dir=/opt/cni/bin  \</span><br><span class="line">    --container-runtime=remote  \</span><br><span class="line">    --runtime-request-timeout=15m  \</span><br><span class="line">    --container-runtime-endpoint=unix:///run/containerd/containerd.sock  \</span><br><span class="line">    --cgroup-driver=systemd \</span><br><span class="line">    --node-labels=node.kubernetes.io/node=&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-2所有k8s节点创建kubelet的配置文件"><a href="#8-2-2所有k8s节点创建kubelet的配置文件" class="headerlink" title="8.2.2所有k8s节点创建kubelet的配置文件"></a>8.2.2所有k8s节点创建kubelet的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-3启动kubelet"><a href="#8-2-3启动kubelet" class="headerlink" title="8.2.3启动kubelet"></a>8.2.3启动kubelet</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">systemctl enable --now kubelet</span><br></pre></td></tr></table></figure>

<h3 id="8-2-4查看集群"><a href="#8-2-4查看集群" class="headerlink" title="8.2.4查看集群"></a>8.2.4查看集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master02   NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master03   NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node01     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node02     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node03     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node04     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node05     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">[root@k8s-master01 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="8-3-kube-proxy配置"><a href="#8-3-kube-proxy配置" class="headerlink" title="8.3.kube-proxy配置"></a>8.3.kube-proxy配置</h2><h3 id="8-3-1此配置只在master01操作"><a href="#8-3-1此配置只在master01操作" class="headerlink" title="8.3.1此配置只在master01操作"></a>8.3.1此配置只在master01操作</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/</span><br><span class="line">kubectl -n kube-system create serviceaccount kube-proxy</span><br><span class="line"></span><br><span class="line">kubectl create clusterrolebinding system:kube-proxy         --clusterrole system:node-proxier         --serviceaccount kube-system:kube-proxy</span><br><span class="line"></span><br><span class="line">SECRET=$(kubectl -n kube-system get sa/kube-proxy \</span><br><span class="line">    --output=jsonpath=&#x27;&#123;.secrets[0].name&#125;&#x27;)</span><br><span class="line"></span><br><span class="line">JWT_TOKEN=$(kubectl -n kube-system get secret/$SECRET \</span><br><span class="line">--output=jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class="line"></span><br><span class="line">PKI_DIR=/etc/kubernetes/pki</span><br><span class="line">K8S_DIR=/etc/kubernetes</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.59:8443     --kubeconfig=$&#123;K8S_DIR&#125;/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes     --token=$&#123;JWT_TOKEN&#125;     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes     --cluster=kubernetes     --user=kubernetes     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="8-3-2将kubeconfig发送至其他节点"><a href="#8-3-2将kubeconfig发送至其他节点" class="headerlink" title="8.3.2将kubeconfig发送至其他节点"></a>8.3.2将kubeconfig发送至其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do</span><br><span class="line">     scp /etc/kubernetes/kube-proxy.kubeconfig  $NODE:/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line">for NODE in k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do</span><br><span class="line">     scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"> done</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3所有k8s节点添加kube-proxy的配置和service文件"><a href="#8-3-3所有k8s节点添加kube-proxy的配置和service文件" class="headerlink" title="8.3.3所有k8s节点添加kube-proxy的配置和service文件"></a>8.3.3所有k8s节点添加kube-proxy的配置和service文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy.yaml \</span><br><span class="line">  --v=2</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4启动kube-proxy"><a href="#8-3-4启动kube-proxy" class="headerlink" title="8.3.4启动kube-proxy"></a>8.3.4启动kube-proxy</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-proxy</span><br></pre></td></tr></table></figure>

<h1 id="9-安装Calico"><a href="#9-安装Calico" class="headerlink" title="9.安装Calico"></a>9.安装Calico</h1><h2 id="9-1以下步骤只在master01操作"><a href="#9-1以下步骤只在master01操作" class="headerlink" title="9.1以下步骤只在master01操作"></a>9.1以下步骤只在master01操作</h2><h3 id="9-1-1更改calico网段"><a href="#9-1-1更改calico网段" class="headerlink" title="9.1.1更改calico网段"></a>9.1.1更改calico网段</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/calico/</span><br><span class="line">sed -i &quot;s#POD_CIDR#172.16.0.0/12#g&quot; calico.yaml</span><br><span class="line">grep &quot;IPV4POOL_CIDR&quot; calico.yaml  -A 1</span><br><span class="line">            - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">              value: &quot;172.16.0.0/12&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建</span></span><br><span class="line"></span><br><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure>

<h3 id="9-1-2查看容器状态"><a href="#9-1-2查看容器状态" class="headerlink" title="9.1.2查看容器状态"></a>9.1.2查看容器状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get pod -A</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-kube-controllers-6f6595874c-nb95g   1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-67dn4                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-79zxj                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-85bsf                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-8trsm                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-dvz72                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-qqzwx                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-rngzq                          1/1     Running   0          2m55s</span><br><span class="line">kube-system   calico-node-w8gqp                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-typha-6b6cf8cbdf-2b454              1/1     Running   0          2m55s</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master02   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master03   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node03     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node04     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node05     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h1 id="10-安装CoreDNS"><a href="#10-安装CoreDNS" class="headerlink" title="10.安装CoreDNS"></a>10.安装CoreDNS</h1><h2 id="10-1以下步骤只在master01操作"><a href="#10-1以下步骤只在master01操作" class="headerlink" title="10.1以下步骤只在master01操作"></a>10.1以下步骤只在master01操作</h2><h3 id="10-1-1修改文件"><a href="#10-1-1修改文件" class="headerlink" title="10.1.1修改文件"></a>10.1.1修改文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/CoreDNS/</span><br><span class="line">sed -i &quot;s#KUBEDNS_SERVICE_IP#10.96.0.10#g&quot; coredns.yaml</span><br><span class="line"></span><br><span class="line">cat coredns.yaml | grep clusterIP:</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br></pre></td></tr></table></figure>

<h3 id="10-1-2安装"><a href="#10-1-2安装" class="headerlink" title="10.1.2安装"></a>10.1.2安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  create -f coredns.yaml </span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.apps/coredns created</span><br><span class="line">service/kube-dns created</span><br></pre></td></tr></table></figure>

<h1 id="11-安装Metrics-Server"><a href="#11-安装Metrics-Server" class="headerlink" title="11.安装Metrics Server"></a>11.安装Metrics Server</h1><h2 id="11-1以下步骤只在master01操作"><a href="#11-1以下步骤只在master01操作" class="headerlink" title="11.1以下步骤只在master01操作"></a>11.1以下步骤只在master01操作</h2><h3 id="11-1-1安装Metrics-server"><a href="#11-1-1安装Metrics-server" class="headerlink" title="11.1.1安装Metrics-server"></a>11.1.1安装Metrics-server</h3><p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装metrics server</span><br><span class="line">cd /root/Kubernetes/metrics-server/</span><br><span class="line"></span><br><span class="line">kubectl  create -f . </span><br><span class="line"></span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">deployment.apps/metrics-server created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br></pre></td></tr></table></figure>

<h3 id="11-1-2稍等片刻查看状态"><a href="#11-1-2稍等片刻查看状态" class="headerlink" title="11.1.2稍等片刻查看状态"></a>11.1.2稍等片刻查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   154m         1%     1715Mi          21%       </span><br><span class="line">k8s-master02   151m         1%     1274Mi          16%       </span><br><span class="line">k8s-master03   523m         6%     1345Mi          17%       </span><br><span class="line">k8s-node01     84m          1%     671Mi           8%        </span><br><span class="line">k8s-node02     73m          0%     727Mi           9%        </span><br><span class="line">k8s-node03     96m          1%     769Mi           9%        </span><br><span class="line">k8s-node04     68m          0%     673Mi           8%        </span><br><span class="line">k8s-node05     82m          1%     679Mi           8% </span><br></pre></td></tr></table></figure>

<h1 id="12-集群验证"><a href="#12-集群验证" class="headerlink" title="12.集群验证"></a>12.集群验证</h1><h2 id="12-1部署pod资源"><a href="#12-1部署pod资源" class="headerlink" title="12.1部署pod资源"></a>12.1部署pod资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line"></span><br><span class="line">kubectl  get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox   1/1     Running   0          17s</span><br></pre></td></tr></table></figure>

<h2 id="12-2用pod解析默认命名空间中的kubernetes"><a href="#12-2用pod解析默认命名空间中的kubernetes" class="headerlink" title="12.2用pod解析默认命名空间中的kubernetes"></a>12.2用pod解析默认命名空间中的kubernetes</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   17h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl exec  busybox -n default -- nslookup kubernetes</span><br><span class="line">3Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-3测试跨命名空间是否可以解析"><a href="#12-3测试跨命名空间是否可以解析" class="headerlink" title="12.3测试跨命名空间是否可以解析"></a>12.3测试跨命名空间是否可以解析</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl exec  busybox -n default -- nslookup kube-dns.kube-system</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kube-dns.kube-system</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53"><a href="#12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53" class="headerlink" title="12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53"></a>12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">telnet 10.96.0.1 443</span><br><span class="line">Trying 10.96.0.1...</span><br><span class="line">Connected to 10.96.0.1.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line"> telnet 10.96.0.10 53</span><br><span class="line">Trying 10.96.0.10...</span><br><span class="line">Connected to 10.96.0.10.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line">curl 10.96.0.10:53</span><br><span class="line">curl: (52) Empty reply from server</span><br></pre></td></tr></table></figure>

<h2 id="12-5Pod和Pod之前要能通"><a href="#12-5Pod和Pod之前要能通" class="headerlink" title="12.5Pod和Pod之前要能通"></a>12.5Pod和Pod之前要能通</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get po -owide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox   1/1     Running   0          17m   172.27.14.193   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"> kubectl get po -n kube-system -owide</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS      AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-5dffd5886b-4blh6   1/1     Running   0             77m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-fvbdq                          1/1     Running   1 (75m ago)   77m   192.168.1.61     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-g8nqd                          1/1     Running   0             77m   192.168.1.64     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-mdps8                          1/1     Running   0             77m   192.168.1.65     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-nf4nt                          1/1     Running   0             77m   192.168.1.63     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-sq2ml                          1/1     Running   0             77m   192.168.1.62     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-mg6p8              1/1     Running   0             77m   192.168.1.65     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-pxbpj              1/1     Running   0             77m   192.168.1.61     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-tnssl              1/1     Running   0             77m   192.168.1.64     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5db5696c7-67h79                    1/1     Running   0             63m   172.25.92.65     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">metrics-server-6bf7dcd649-5fhrw            1/1     Running   0             61m   172.18.195.1     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入busybox ping其他节点上的pod</span></span><br><span class="line"></span><br><span class="line">kubectl exec -ti busybox -- sh</span><br><span class="line">/ # ping 192.168.1.64</span><br><span class="line">PING 192.168.1.64 (192.168.1.64): 56 data bytes</span><br><span class="line">64 bytes from 192.168.1.64: seq=0 ttl=63 time=0.358 ms</span><br><span class="line">64 bytes from 192.168.1.64: seq=1 ttl=63 time=0.668 ms</span><br><span class="line">64 bytes from 192.168.1.64: seq=2 ttl=63 time=0.637 ms</span><br><span class="line">64 bytes from 192.168.1.64: seq=3 ttl=63 time=0.624 ms</span><br><span class="line">64 bytes from 192.168.1.64: seq=4 ttl=63 time=0.907 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以连通证明这个pod是可以跨命名空间和跨主机通信的</span></span><br></pre></td></tr></table></figure>

<h2 id="12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"><a href="#12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）" class="headerlink" title="12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"></a>12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; deployments.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl  apply -f deployments.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">kubectl  get pod </span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                            1/1     Running   0          6m25s</span><br><span class="line">nginx-deployment-9456bbbf9-4bmvk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-9rcdk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-dqv8s   1/1     Running   0          8s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除nginx</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f deployments.yaml </span><br></pre></td></tr></table></figure>

<h1 id="13-安装dashboard"><a href="#13-安装dashboard" class="headerlink" title="13.安装dashboard"></a>13.安装dashboard</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/dashboard/</span><br><span class="line"></span><br><span class="line">kubectl  create -f .</span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line">namespace/kubernetes-dashboard created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-csrf created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/dashboard-metrics-scraper created</span><br><span class="line">deployment.apps/dashboard-metrics-scraper created</span><br></pre></td></tr></table></figure>

<h2 id="13-1创建管理员用户"><a href="#13-1创建管理员用户" class="headerlink" title="13.1创建管理员用户"></a>13.1创建管理员用户</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; admin.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line"></span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding </span><br><span class="line">metadata: </span><br><span class="line">  name: admin-user</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="13-2执行yaml文件"><a href="#13-2执行yaml文件" class="headerlink" title="13.2执行yaml文件"></a>13.2执行yaml文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f admin.yaml -n kube-system</span><br><span class="line"></span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br></pre></td></tr></table></figure>

<h2 id="13-3更改dashboard的svc为NodePort，如果已是请忽略"><a href="#13-3更改dashboard的svc为NodePort，如果已是请忽略" class="headerlink" title="13.3更改dashboard的svc为NodePort，如果已是请忽略"></a>13.3更改dashboard的svc为NodePort，如果已是请忽略</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure>

<h2 id="13-4查看端口号"><a href="#13-4查看端口号" class="headerlink" title="13.4查看端口号"></a>13.4查看端口号</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.98.201.22   &lt;none&gt;        443:31245/TCP   10m</span><br></pre></td></tr></table></figure>

<h2 id="13-5查看token"><a href="#13-5查看token" class="headerlink" title="13.5查看token"></a>13.5查看token</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;)</span><br><span class="line">Name:         admin-user-token-5vfk4</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: fc2535ae-8760-4037-9026-966f03ab9bf9</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1363 bytes</span><br><span class="line">namespace:  11 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6InVOMnhMdHFTRWxweUlfUm93VmhMZTVXZW1FXzFrT01nQ0dTcE5uYjJlNWMifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTV2Zms0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmYzI1MzVhZS04NzYwLTQwMzctOTAyNi05NjZmMDNhYjliZjkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.HSU1FeqY6pDVoXVIv4Lu27TDhCYHM-FzGsGybYL5QPJ5-P0b3tQqUH9i3AQlisiGPB--jCFT5CUeOeXneOyfV7XkC7frbn6VaQoh51n6ztkIvjUm8Q4xj_LQ2OSFfWlFUnaZsaYTdD-RCldwh63pX362T_FjgDknO4q1wtKZH5qR0mpL1dOjas50gnOSyBY0j-nSPrifhnNq3_GcDLE4LxjuzO1DfGNTEHZ6TojPJ_5ZElMolaYJsVejn2slfeUQEWdiD5AHFZlRd4exODCHyvUhRpzb9jO2rovN2LMqdE_vxBtNgXp19evQB9AgZyMMSmu1Ch2C2UAi4NxjKw8HNA</span><br></pre></td></tr></table></figure>

<h2 id="13-6登录dashboard"><a href="#13-6登录dashboard" class="headerlink" title="13.6登录dashboard"></a>13.6登录dashboard</h2><p><a href="https://192.168.1.61:31245/">https://192.168.1.61:31245/</a></p>
<p>eyJhbGciOiJSUzI1NiIsImtpZCI6InYzV2dzNnQzV3hHb2FQWnYzdnlOSmpudmtpVmNjQW5VM3daRi12SFM4dEEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWs1NDVrIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjMzA4MDcxYy00Y2Y1LTQ1ODMtODNhMi1lYWY3ODEyNTEyYjQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pshvZPi9ZJkXUWuWilcYs1wawTpzV-nMKesgF3d_l7qyTPaK2N5ofzIThd0SjzU7BFNb4_rOm1dw1Be5kLeHjY_YW5lDnM5TAxVPXmZQ0HJ2pAQ0pjQqCHFnPD0bZFIYkeyz8pZx0Hmwcd3ZdC1yztr0ADpTAmMgI9NC2ZFIeoFFo4Ue9ZM_ulhqJQjmgoAlI_qbyjuKCNsWeEQBwM6HHHAsH1gOQIdVxqQ83OQZUuynDQRpqlHHFIndbK2zVRYFA3GgUnTu2-VRQ-DXBFRjvZR5qArnC1f383jmIjGT6VO7l04QJteG_LFetRbXa-T4mcnbsd8XutSgO0INqwKpjw</p>
<h1 id="14-安装命令行自动补全功能"><a href="#14-安装命令行自动补全功能" class="headerlink" title="14.安装命令行自动补全功能"></a>14.安装命令行自动补全功能</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install bash-completion -y</span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>

<h1 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h1><p>配置kube-controller-manager有效期100年（能不能生效的先配上再说）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">[Service]下找个地方加上</span></span><br><span class="line"></span><br><span class="line">--cluster-signing-duration=876000h0m0s \</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启</span></span><br><span class="line"></span><br><span class="line">systemctl daemon-reload </span><br><span class="line">systemctl restart kube-controller-manager</span><br></pre></td></tr></table></figure>

<p>防止漏洞扫描</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf</span><br><span class="line"></span><br><span class="line">[Service] </span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--kubeconfig=/etc/kubernetes/kubelet.kubeconfig --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig&quot; </span><br><span class="line">Environment=&quot;KUBELET_SYSTEM_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin&quot; </span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml  --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&quot; </span><br><span class="line">Environment=&quot;KUBELET_EXTRA_ARGS=--tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384    --image-pull-progress-deadline=30m&quot; </span><br><span class="line">ExecStart= </span><br><span class="line">ExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_SYSTEM_ARGS $KUBELET_EXTRA_ARGS </span><br></pre></td></tr></table></figure>

<p>预留空间，按需分配</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/kubernetes/kubelet-conf.yml</span><br><span class="line"></span><br><span class="line">rotateServerCertificates: true</span><br><span class="line">allowedUnsafeSysctls:</span><br><span class="line"></span><br><span class="line"> - &quot;net.core*&quot;</span><br><span class="line"> - &quot;net.ipv4.*&quot;</span><br><span class="line">   kubeReserved:</span><br><span class="line">     cpu: &quot;1&quot;</span><br><span class="line">     memory: 1Gi</span><br><span class="line">     ephemeral-storage: 10Gi</span><br><span class="line">   systemReserved:</span><br><span class="line">     cpu: &quot;1&quot;</span><br><span class="line">     memory: 1Gi</span><br><span class="line">     ephemeral-storage: 10Gi</span><br></pre></td></tr></table></figure>

<p>数据盘要与系统盘分开；etcd使用ssd磁盘</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Let&#39;s Encrypt 泛域名证书申请</title>
    <url>/2022/04/15/2022-04-15-Let&#39;s_Encrypt_%E6%B3%9B%E5%9F%9F%E5%90%8D%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/</url>
    <content><![CDATA[<h1 id="泛域名"><a href="#泛域名" class="headerlink" title="泛域名"></a>泛域名</h1><p>泛域名证书又名通配符证书是SSL证书中的其中一种形式，一般会以通配符的形式(如：*.domain.com)来指定证书所要保护的域名。</p>
<p>OV证书和DV证书都会有通配符的域名形式提供，而EV证书一般没有通配符的证书形式。</p>
<p>1.配置灵活方便</p>
<p>由于采用了通配符的形式对域名进行配置，那么对于拥有多个二级域名的网站是一件非常便利的事情。只要申请一张通配符证书，就能用于所有的二级域名网站中。而且如果以后需要继续增加二级域名，也不需要再去申请购买证书，只需继续使用原有的证书就可以，对于网站管理者来说确实是非常的方便。</p>
<p>2.性价比高</p>
<p>一般而言，通配符证书是会比单域名证书会贵上不少，但是假如按每个二级域名的证书价格摊分下来，那其实证书单价是及其的低。当然这要看你的二级域名数量总数有多少而定。但如今互联网时代，很多公司企业他们都会用户多个二级域名。对于这些企业而言，通配符证书无疑是一种高性价比的SSL证书。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/54bf914a089f4666ad17c100745bc89c~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h1 id="安装所需环境"><a href="#安装所需环境" class="headerlink" title="安装所需环境"></a>安装所需环境</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# apt-get install socat -y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~# curl  https://get.acme.sh | sh</span><br><span class="line"><span class="meta prompt_">  %</span><span class="language-bash"> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0</span><br><span class="line">100   937    0   937    0     0    788      0 --:--:--  0:00:01 --:--:--   789</span><br><span class="line"><span class="meta prompt_">  %</span><span class="language-bash"> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100  210k  100  210k    0     0   131k      0  0:00:01  0:00:01 --:--:--  131k</span><br><span class="line">[Fri 15 Apr 2022 11:54:09 AM CST] Installing from online archive.</span><br><span class="line">[Fri 15 Apr 2022 11:54:09 AM CST] Downloading https://github.com/acmesh-official/acme.sh/archive/master.tar.gz</span><br><span class="line">[Fri 15 Apr 2022 11:54:11 AM CST] Extracting master.tar.gz</span><br><span class="line">[Fri 15 Apr 2022 11:54:11 AM CST] Installing to /root/.acme.sh</span><br><span class="line">[Fri 15 Apr 2022 11:54:11 AM CST] Installed to /root/.acme.sh/acme.sh</span><br><span class="line">[Fri 15 Apr 2022 11:54:11 AM CST] Installing alias to &#x27;/root/.bashrc&#x27;</span><br><span class="line">[Fri 15 Apr 2022 11:54:11 AM CST] OK, Close and reopen your terminal to start using acme.sh</span><br><span class="line">[Fri 15 Apr 2022 11:54:11 AM CST] Installing cron job</span><br><span class="line">49 0 * * * &quot;/root/.acme.sh&quot;/acme.sh --cron --home &quot;/root/.acme.sh&quot; &gt; /dev/null</span><br><span class="line">[Fri 15 Apr 2022 11:54:11 AM CST] Good, bash is found, so change the shebang to use bash as preferred.</span><br><span class="line">[Fri 15 Apr 2022 11:54:12 AM CST] OK</span><br><span class="line">[Fri 15 Apr 2022 11:54:12 AM CST] Install success!</span><br><span class="line">root@cby:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="进入导入环境变量并提出申请"><a href="#进入导入环境变量并提出申请" class="headerlink" title="进入导入环境变量并提出申请"></a>进入导入环境变量并提出申请</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# cd .acme.sh/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~/.acme.sh# export DP_Id=&quot;abcd&quot;</span><br><span class="line">root@cby:~/.acme.sh# export DP_Key=&quot;xxxxxxxxxx&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~/.acme.sh# ./acme.sh --issue --dns dns_dp -d *.oiox.cn -d oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:05:13 PM CST] Using CA: https://acme.zerossl.com/v2/DV90</span><br><span class="line">[Fri 15 Apr 2022 12:05:13 PM CST] Multi domain=&#x27;DNS:*.oiox.cn,DNS:oiox.cn&#x27;</span><br><span class="line">[Fri 15 Apr 2022 12:05:13 PM CST] Getting domain auth token for each domain</span><br><span class="line">[Fri 15 Apr 2022 12:05:38 PM CST] Getting webroot for domain=&#x27;*.oiox.cn&#x27;</span><br><span class="line">[Fri 15 Apr 2022 12:05:38 PM CST] Getting webroot for domain=&#x27;oiox.cn&#x27;</span><br><span class="line">[Fri 15 Apr 2022 12:05:39 PM CST] Adding txt value: DDuc5hd3b1RIoa5BefBkA53EpEtbAY0Fk8jOVVJcL6E for domain:  _acme-challenge.oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:05:39 PM CST] Adding record</span><br><span class="line">[Fri 15 Apr 2022 12:05:39 PM CST] The txt record is added: Success.</span><br><span class="line">[Fri 15 Apr 2022 12:05:40 PM CST] Adding txt value: 43GHnhiHjyxCxsdHSDRDP_A4YqP8dDjc_9YgnkFNk5I for domain:  _acme-challenge.oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:05:40 PM CST] Adding record</span><br><span class="line">[Fri 15 Apr 2022 12:05:40 PM CST] The txt record is added: Success.</span><br><span class="line">[Fri 15 Apr 2022 12:05:40 PM CST] Let&#x27;s check each DNS record now. Sleep 20 seconds first.</span><br><span class="line">[Fri 15 Apr 2022 12:06:01 PM CST] You can use &#x27;--dnssleep&#x27; to disable public dns checks.</span><br><span class="line">[Fri 15 Apr 2022 12:06:01 PM CST] See: https://github.com/acmesh-official/acme.sh/wiki/dnscheck</span><br><span class="line">[Fri 15 Apr 2022 12:06:02 PM CST] Checking oiox.cn for _acme-challenge.oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:06:04 PM CST] Domain oiox.cn &#x27;_acme-challenge.oiox.cn&#x27; success.</span><br><span class="line">[Fri 15 Apr 2022 12:06:04 PM CST] Checking oiox.cn for _acme-challenge.oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:06:05 PM CST] Domain oiox.cn &#x27;_acme-challenge.oiox.cn&#x27; success.</span><br><span class="line">[Fri 15 Apr 2022 12:06:05 PM CST] All success, let&#x27;s return</span><br><span class="line">[Fri 15 Apr 2022 12:06:05 PM CST] Verifying: *.oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:06:17 PM CST] Processing, The CA is processing your order, please just wait. (1/30)</span><br><span class="line">[Fri 15 Apr 2022 12:06:24 PM CST] Success</span><br><span class="line">[Fri 15 Apr 2022 12:06:24 PM CST] Verifying: oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:06:31 PM CST] Processing, The CA is processing your order, please just wait. (1/30)</span><br><span class="line">[Fri 15 Apr 2022 12:06:34 PM CST] Success</span><br><span class="line">[Fri 15 Apr 2022 12:06:34 PM CST] Removing DNS records.</span><br><span class="line">[Fri 15 Apr 2022 12:06:34 PM CST] Removing txt: DDuc5hd3b1RIoa5BefBkA53EpEtbAY0Fk8jOVVJcL6E for domain: _acme-challenge.oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:06:35 PM CST] Removed: Success</span><br><span class="line">[Fri 15 Apr 2022 12:06:35 PM CST] Removing txt: 43GHnhiHjyxCxsdHSDRDP_A4YqP8dDjc_9YgnkFNk5I for domain: _acme-challenge.oiox.cn</span><br><span class="line">[Fri 15 Apr 2022 12:06:36 PM CST] Removed: Success</span><br><span class="line">[Fri 15 Apr 2022 12:06:36 PM CST] Verify finished, start to sign.</span><br><span class="line">[Fri 15 Apr 2022 12:06:36 PM CST] Lets finalize the order.</span><br><span class="line">[Fri 15 Apr 2022 12:06:36 PM CST] Le_OrderFinalize=&#x27;https://acme.zerossl.com/v2/DV90/order/G4Sy37Y-eHjHX1wLMAh5nA/finalize&#x27;</span><br><span class="line">[Fri 15 Apr 2022 12:06:44 PM CST] Order status is processing, lets sleep and retry.</span><br><span class="line">[Fri 15 Apr 2022 12:06:44 PM CST] Retry after: 15</span><br><span class="line">[Fri 15 Apr 2022 12:07:00 PM CST] Polling order status: https://acme.zerossl.com/v2/DV90/order/G4Sy37Y-eHjHX1wLMAh5nA</span><br><span class="line">[Fri 15 Apr 2022 12:07:03 PM CST] Downloading cert.</span><br><span class="line">[Fri 15 Apr 2022 12:07:03 PM CST] Le_LinkCert=&#x27;https://acme.zerossl.com/v2/DV90/cert/r4l-4WevkiEwiZA3U340ig&#x27;</span><br><span class="line">[Fri 15 Apr 2022 12:07:10 PM CST] Cert success.</span><br><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">MIIGaDCCBFCgAwIBAgIRAPw9soTBNxRGIVE6ANgMifAwDQYJKoZIhvcNAQEMBQAw</span><br><span class="line">SzELMAkGA1UEBhMCQVQxEDAOBgNVBAoTB1plcm9TU0wxKjAoBgNVBAMTIVplcm9T</span><br><span class="line">U0wgUlNBIERvbWFpbiBTZWN1cmUgU2l0ZSBDQTAeFw0yMjA0MTUwMDAwMDBaFw0y</span><br><span class="line">MjA3MTQyMzU5NTlaMBQxEjAQBgNVBAMMCSoub2lveC5jbjCCASIwDQYJKoZIhvcN</span><br><span class="line">AQEBBQADggEPADCCAQoCggEBALj8qi39uAgrhdwzQ6zP+ADRZgO2qGAVN4Qmu/ul</span><br><span class="line">tANIVXuM/B3lbD6RM+Msb1Df5FKXJoga+hBjBQI9iX+k4M3uf2isIeZBJix1dj2N</span><br><span class="line">6o2NpcbCXEyPclOFSWHuOuMgCXKofThz9Vlgb1sZsuBv7+6mF/qGEmX2nsjIYlPh</span><br><span class="line">/x7NqB1+WF+ouKPWOvWTg/O+NaJd/8EkIhtqwYRH19JtIMxZAnVcnk/vlUirHFdl</span><br><span class="line">K0C21mCn4SZpG/k0tfLkUAJ/dokWAYKiAV5kCr1cpS/mEKGWKbgR0+e436ZlAXR8</span><br><span class="line">pPJLHvV19U+D4+YrjvEGrxh0p3sQmVLAQiKvX8H/2e6/lJUCAwEAAaOCAnwwggJ4</span><br><span class="line">MB8GA1UdIwQYMBaAFMjZeGii2Rlo1T1y3l8KPty1hoamMB0GA1UdDgQWBBQNQ6Tg</span><br><span class="line">Wc9VXEb7JBebpnqg07n6lDAOBgNVHQ8BAf8EBAMCBaAwDAYDVR0TAQH/BAIwADAd</span><br><span class="line">BgNVHSUEFjAUBggrBgEFBQcDAQYIKwYBBQUHAwIwSQYDVR0gBEIwQDA0BgsrBgEE</span><br><span class="line">AbIxAQICTjAlMCMGCCsGAQUFBwIBFhdodHRwczovL3NlY3RpZ28uY29tL0NQUzAI</span><br><span class="line">BgZngQwBAgEwgYgGCCsGAQUFBwEBBHwwejBLBggrBgEFBQcwAoY/aHR0cDovL3pl</span><br><span class="line">cm9zc2wuY3J0LnNlY3RpZ28uY29tL1plcm9TU0xSU0FEb21haW5TZWN1cmVTaXRl</span><br><span class="line">Q0EuY3J0MCsGCCsGAQUFBzABhh9odHRwOi8vemVyb3NzbC5vY3NwLnNlY3RpZ28u</span><br><span class="line">Y29tMIIBAgYKKwYBBAHWeQIEAgSB8wSB8ADuAHUARqVV63X6kSAwtaKJafTzfREs</span><br><span class="line">QXS+/Um4havy/HD+bUcAAAGAK2cJxgAABAMARjBEAiBqAyCsE36I+qUvZaEuWqNf</span><br><span class="line">XuLAgdaNl6Xi/XrtpEIQhAIgRxOZNoDnqjgxGxfuG4kaGvLzlJezgbzss49CK/pH</span><br><span class="line">g+MAdQBByMqx3yJGShDGoToJQodeTjGLGwPr60vHaPCQYpYG9gAAAYArZwmVAAAE</span><br><span class="line">AwBGMEQCIE4CJqmMWMJBpSMumrxsK4hBV2aVoG6zke9vqjvUD6mQAiBaCjPj2NJC</span><br><span class="line">ULsSB39TVW9maHtX9oQ8Wl9vLAD4dKirkDAdBgNVHREEFjAUggkqLm9pb3guY26C</span><br><span class="line">B29pb3guY24wDQYJKoZIhvcNAQEMBQADggIBAGdRf30QaQQ764Qe7e/+qFX6gcQ2</span><br><span class="line">nee8w4jKTLgcXL0un5Fb9lJi/cJtdsMDxvYyrFEhYIl3XosP2Kzl0DAwxYV2QcN0</span><br><span class="line">g0EulOfU46v/rueWuLo/AwzSVdSwxPTLa+QI69cPgQk/skqRigv17zjdbRRVY7jm</span><br><span class="line">/+a9wGc8st0CNUtCgH4N03HcexIqbo7wquNUE19rvhFOTPMewID7P8NviitM76vS</span><br><span class="line">K3C7SNqnyeIAZ3ydOFamZ4ye68mEQCJ0LGaSlDme8tY3eA3vliziKeouv6itGbRS</span><br><span class="line">X2Ze8Twk/8PADC0sxIjPjrh47ngE+DNpEEDr6PH89hnvjEl3V0ZFV9dW1McAoq2Q</span><br><span class="line">RW4LyXeSXasYPKQU1ncTjDsymquX5r7OJ1SCnXUCuEFohoGWkZTWUFQBy3C8Xwuz</span><br><span class="line">AHzYxzsSPyKV19sJEUkSaFIEQH5dbMqGSnk60gE+bqDfRTZ2PL9WGp+by60HSbzo</span><br><span class="line">3ehnUoyRkggmoD+SX8AAJLPuxkHFB/L68CL7knwWXzYcBYfj0yv+0T5HPhOofHud</span><br><span class="line">Fwv/h5loRN/1jeVwIblo9B+3KnNNDAxd5NTf1l80oZJgKqS6zoFJwKbE0X11Ved7</span><br><span class="line">m35ZEcj4UwrgSFLE7Y9+to66In2N/QpvFPFclE9Xfwdd03YAmxS/biIul2xrkzBf</span><br><span class="line">E9Q19NWLnTA2YU52</span><br><span class="line">-----END CERTIFICATE-----</span><br><span class="line">[Fri 15 Apr 2022 12:07:10 PM CST] Your cert is in: /root/.acme.sh/*.oiox.cn/*.oiox.cn.cer</span><br><span class="line">[Fri 15 Apr 2022 12:07:10 PM CST] Your cert key is in: /root/.acme.sh/*.oiox.cn/*.oiox.cn.key</span><br><span class="line">[Fri 15 Apr 2022 12:07:10 PM CST] The intermediate CA cert is in: /root/.acme.sh/*.oiox.cn/ca.cer</span><br><span class="line">[Fri 15 Apr 2022 12:07:10 PM CST] And the full chain certs is there: /root/.acme.sh/*.oiox.cn/fullchain.cer</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="查看已申请出来证书"><a href="#查看已申请出来证书" class="headerlink" title="查看已申请出来证书"></a>查看已申请出来证书</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~/.acme.sh# cd \*.oiox.cn</span><br><span class="line">root@cby:~/.acme.sh/*.oiox.cn# ll</span><br><span class="line">total 44</span><br><span class="line">drwxr-xr-x 2 root root 4096 Apr 15 12:07  ./</span><br><span class="line">drwx------ 8 root root 4096 Apr 15 11:55  ../</span><br><span class="line">-rw-r--r-- 1 root root 4399 Apr 15 12:07  ca.cer</span><br><span class="line">-rw-r--r-- 1 root root 6680 Apr 15 12:07  fullchain.cer</span><br><span class="line">-rw-r--r-- 1 root root 2281 Apr 15 12:07 &#x27;*.oiox.cn.cer&#x27;</span><br><span class="line">-rw-r--r-- 1 root root  563 Apr 15 12:07 &#x27;*.oiox.cn.conf&#x27;</span><br><span class="line">-rw-r--r-- 1 root root  956 Apr 15 12:05 &#x27;*.oiox.cn.csr&#x27;</span><br><span class="line">-rw-r--r-- 1 root root  156 Apr 15 12:05 &#x27;*.oiox.cn.csr.conf&#x27;</span><br><span class="line">-rw------- 1 root root 1675 Apr 15 11:55 &#x27;*.oiox.cn.key&#x27;</span><br><span class="line">root@cby:~/.acme.sh/*.oiox.cn#</span><br></pre></td></tr></table></figure>

<h1 id="Nginx部署证书"><a href="#Nginx部署证书" class="headerlink" title="Nginx部署证书"></a>Nginx部署证书</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">示例：</span><br><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        listen [::]:80;</span><br><span class="line"></span><br><span class="line">        listen 443 ssl;</span><br><span class="line">        listen [::]:443;</span><br><span class="line">        ssl_certificate /ssl/fullchain.cer;</span><br><span class="line">        ssl_certificate_key /ssl/*.oiox.cn.key;</span><br><span class="line">        ssl_session_timeout  5m;</span><br><span class="line">        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;</span><br><span class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">        ssl_prefer_server_ciphers on;</span><br><span class="line"></span><br><span class="line">        server_name dns.oiox.cn;</span><br><span class="line"></span><br><span class="line">        root /var/www/dns;</span><br><span class="line">        index index.html;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">                try_files $uri $uri/ =404;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>附录  </p>
<p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">上面使用DNSPOD进行动态解析申请证书</span><br><span class="line"></span><br><span class="line">阿里云DNS申请</span><br><span class="line">export Ali_Key=&quot;abcd&quot;</span><br><span class="line">export Ali_Secret=&quot;xxxxxxxxxx&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> RSA 证书</span></span><br><span class="line">acme.sh --issue --dns dns_ali -d blog.exsvc.cn -d *.exsvc.cn</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> ECC 证书</span></span><br><span class="line">acme.sh --issue --dns dns_ali -d blog.exsvc.cn -d *.exsvc.cn --keylength ec-256</span><br><span class="line"></span><br><span class="line">腾讯云DNS申请</span><br><span class="line">root@cby:~/.acme.sh# export DP_Id=&quot;abcd&quot;</span><br><span class="line">root@cby:~/.acme.sh# export DP_Key=&quot;xxxxxxxxxx&quot;</span><br><span class="line">root@cby:~/.acme.sh# ./acme.sh --issue --dns dns_dp -d *.oiox.cn -d oiox.cn</span><br><span class="line"></span><br><span class="line">更多申请方式见：https://github.com/acmesh-official/acme.sh/wiki/dnsapi</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a><br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>在Kubernetes上安装Netdata的方法</title>
    <url>/2022/04/20/2022-04-20-%E5%9C%A8Kubernetes%E4%B8%8A%E5%AE%89%E8%A3%85Netdata%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Netdata可用于监视kubernetes集群并显示有关集群的信息，包括节点内存使用率、CPU、网络等，简单的说，Netdata仪表板可让您全面了解Kubernetes集群，包括在每个节点上运行的服务和Pod。</p>
<h1 id="安装HELM"><a href="#安装HELM" class="headerlink" title="安装HELM"></a>安装HELM</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -</span><br><span class="line">root@hello:~# sudo apt-get install apt-transport-https --yes</span><br><span class="line">root@hello:~# echo &quot;deb https://baltocdn.com/helm/stable/debian/ all main&quot; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list</span><br><span class="line">root@hello:~# sudo apt-get update</span><br><span class="line">root@hello:~# sudo apt-get install helm</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="添加源并安装"><a href="#添加源并安装" class="headerlink" title="添加源并安装"></a>添加源并安装</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# helm repo add netdata https://netdata.github.io/helmchart/</span><br><span class="line">&quot;netdata&quot; has been added to your repositories</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# helm install netdata netdata/netdata</span><br><span class="line">W0420 09:20:51.993046 1306427 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+</span><br><span class="line">W0420 09:20:52.298158 1306427 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+</span><br><span class="line">NAME: netdata</span><br><span class="line">LAST DEPLOYED: Wed Apr 20 09:20:50 2022</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">TEST SUITE: None</span><br><span class="line">NOTES:</span><br><span class="line">1. netdata will be available on http://netdata.k8s.local/, on the exposed port of your ingress controller</span><br><span class="line"></span><br><span class="line">In a production environment, you </span><br><span class="line"> You can get that port via `kubectl get services`. e.g. in the following example, the http exposed port is 31737, the https one is 30069.</span><br><span class="line"> The hostname netdata.k8s.local will need to be added to /etc/hosts, so that it resolves to the exposed IP. That IP depends on how your cluster is set up: </span><br><span class="line">        - When no load balancer is available (e.g. with minikube), you get the IP shown on `kubectl cluster-info`</span><br><span class="line">        - In a production environment, the command `kubectl get services` will show the IP under the EXTERNAL-IP column</span><br><span class="line"></span><br><span class="line">The port can be retrieved in both cases from `kubectl get services`</span><br><span class="line"></span><br><span class="line">NAME                                         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">exiled-tapir-nginx-ingress-controller        LoadBalancer   10.98.132.169    &lt;pending&gt;     80:31737/TCP,443:30069/TCP   11h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# helm list</span><br><span class="line">NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span><br><span class="line">netdata default         1               2022-04-20 09:20:50.947921117 +0800 CST deployed        netdata-3.7.15  v1.33.1    </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="查看POD"><a href="#查看POD" class="headerlink" title="查看POD"></a>查看POD</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  get pod </span><br><span class="line">NAME                                      READY   STATUS    RESTARTS      AGE</span><br><span class="line">netdata-child-2h65n                       2/2     Running   0             77s</span><br><span class="line">netdata-child-dfv82                       2/2     Running   0             77s</span><br><span class="line">netdata-child-h6fw6                       2/2     Running   0             77s</span><br><span class="line">netdata-child-lc9fd                       2/2     Running   0             77s</span><br><span class="line">netdata-child-nh566                       2/2     Running   0             77s</span><br><span class="line">netdata-child-ns2p2                       2/2     Running   0             77s</span><br><span class="line">netdata-child-v74x5                       2/2     Running   0             77s</span><br><span class="line">netdata-child-xjlrv                       2/2     Running   0             77s</span><br><span class="line">netdata-parent-57bf6bf47d-vc6fq           1/1     Running   0             77s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="添加SVC使外部即可访问"><a href="#添加SVC使外部即可访问" class="headerlink" title="添加SVC使外部即可访问"></a>添加SVC使外部即可访问</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)     AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP     18d</span><br><span class="line">netdata      ClusterIP   10.102.160.106   &lt;none&gt;        19999/TCP   3m39s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl expose  deployment netdata-parent --type=&quot;NodePort&quot; --port 19999</span><br><span class="line">service/netdata-parent exposed</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  get svc</span><br><span class="line">NAME             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)           AGE</span><br><span class="line">kubernetes       ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP           18d</span><br><span class="line">netdata          ClusterIP   10.102.160.106   &lt;none&gt;        19999/TCP         3m43s</span><br><span class="line">netdata-parent   NodePort    10.100.122.173   &lt;none&gt;        19999:30518/TCP   2s</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line">通过http://&lt;yourmaster-IP&gt;:30518  访问浏览器中的netdata仪表板</span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2a8de81edea4462aac070499223de171~tplv-k3u1fbpfcp-zoom-1.image"></p>
<p>点击左侧可以查看具体每一台机器的信息  </p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》  </p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>经GitHub将kubernetes镜像推送到阿里云</title>
    <url>/2022/04/19/2022-04-19-%E7%BB%8FGitHub%E5%B0%86kubernetes%E9%95%9C%E5%83%8F%E6%8E%A8%E9%80%81%E5%88%B0%E9%98%BF%E9%87%8C%E4%BA%91/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在安装kubernetes时会出现无法访问镜像站的情况，通过GitHub将kubernetes镜像推送到阿里云之后，即可使用阿里云地址引用所需镜像，现已同步镜像5000+，当前还在陆续同步。仓库使用 Github Action 每天自动运行脚本同步镜像到阿里云。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c70943782dff4128b8d70c31b1ce1205~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="代码仓库"><a href="#代码仓库" class="headerlink" title="代码仓库"></a>代码仓库</h1><p><a href="https://github.com/cby-chen/sys/_images">https://github.com/cby-chen/sys\_images</a><br>若有需要自行研究 后续更新会在仓库更新</p>
<h1 id="目前有如下镜像仓库，后续会陆续增加"><a href="#目前有如下镜像仓库，后续会陆续增加" class="headerlink" title="目前有如下镜像仓库，后续会陆续增加"></a>目前有如下镜像仓库，后续会陆续增加</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">  docker.elastic.co:</span><br><span class="line">    - elasticsearch/elasticsearch</span><br><span class="line">    - kibana/kibana</span><br><span class="line">    - logstash/logstash</span><br><span class="line">    - beats/filebeat</span><br><span class="line">    - beats/heartbeat</span><br><span class="line">    - beats/packetbeat</span><br><span class="line">    - beats/auditbeat</span><br><span class="line">    - beats/journalbeat</span><br><span class="line">    - beats/metricbeat</span><br><span class="line">    - apm/apm-server</span><br><span class="line">    - app-search/app-search</span><br><span class="line">  quay.io:</span><br><span class="line">    - coreos/flannel</span><br><span class="line">    - ceph/ceph</span><br><span class="line">    - cephcsi/cephcsi</span><br><span class="line">    - csiaddons/k8s-sidecar</span><br><span class="line">    - csiaddons/volumereplication-operator</span><br><span class="line">    - prometheus/prometheus</span><br><span class="line">    - prometheus/alertmanager</span><br><span class="line">    - prometheus/pushgateway</span><br><span class="line">    - prometheus/blackbox-exporter</span><br><span class="line">    - prometheus/node-exporter</span><br><span class="line">    - prometheus-operator/prometheus-config-reloader</span><br><span class="line">    - prometheus-operator/prometheus-operator</span><br><span class="line">    - brancz/kube-rbac-proxy</span><br><span class="line">  k8s.gcr.io:</span><br><span class="line">    - etcd</span><br><span class="line">    - kube-proxy</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    - kube-scheduler</span><br><span class="line">    - kube-controller-manager</span><br><span class="line">    - coredns/coredns</span><br><span class="line">    - dns/k8s-dns-node-cache</span><br><span class="line">    - metrics-server/metrics-server</span><br><span class="line">    - ingress-nginx/controller</span><br><span class="line">    - ingress-nginx/kube-webhook-certgen</span><br><span class="line">    - kube-state-metrics/kube-state-metrics</span><br><span class="line">    - prometheus-adapter/prometheus-adapter</span><br><span class="line">    - sig-storage/nfs-subdir-external-provisioner</span><br><span class="line">    - sig-storage/csi-node-driver-registrar</span><br><span class="line">    - sig-storage/csi-provisioner</span><br><span class="line">    - sig-storage/csi-resizer</span><br><span class="line">    - sig-storage/csi-snapshotter</span><br><span class="line">    - sig-storage/csi-attacher</span><br><span class="line">  gcr.io:</span><br><span class="line">    - kaniko-project/executor</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker.elastic.co/kibana/&#123;image_name&#125;  ==&gt;  registry.cn-hangzhou.aliyuncs.com/chenby/&#123;image_name&#125;</span><br><span class="line">quay.io/csiaddons/&#123;image_name&#125;  ==&gt;  registry.cn-hangzhou.aliyuncs.com/chenby/&#123;image_name&#125;</span><br><span class="line">k8s.gcr.io/&#123;image_name&#125;  ==&gt;  registry.cn-hangzhou.aliyuncs.com/chenby/&#123;image_name&#125;</span><br><span class="line">....</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="拉去镜像"><a href="#拉去镜像" class="headerlink" title="拉去镜像"></a>拉去镜像</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/chenby/kube-scheduler:[镜像版本号]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4c1f91cee92c4c1bba037d531d90db5a~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a><br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客、全网可搜《小陈运维》  </p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>在k8s（kubernetes）上安装 ingress V1.1.3</title>
    <url>/2022/04/21/2022-04-21-%E5%9C%A8k8s%EF%BC%88kubernetes%EF%BC%89%E4%B8%8A%E5%AE%89%E8%A3%85_ingress_V1.1.3/</url>
    <content><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Ingress 公开了从集群外部到集群内服务的 HTTP 和 HTTPS 路由。流量路由由 Ingress 资源上定义的规则控制。</p>
<p>下面是一个将所有流量都发送到同一 Service 的简单 <strong>Ingress</strong> 示例：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bff59aa69c124a8a8e41a4514b4732ab~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h1 id="写入配置文件，并执行"><a href="#写入配置文件，并执行" class="headerlink" title="写入配置文件，并执行"></a>写入配置文件，并执行</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim deploy.yaml</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# cat deploy.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/controller-serviceaccount.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">automountServiceAccountToken: true</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/controller-configmap.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">data:</span><br><span class="line">  allow-snippet-annotations: &#x27;true&#x27;</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/clusterrole.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - endpoints</span><br><span class="line">      - nodes</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/clusterrolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/controller-role.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - endpoints</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    resourceNames:</span><br><span class="line">      - ingress-controller-leader</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/controller-rolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/controller-service-webhook.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - name: https-webhook</span><br><span class="line">      port: 443</span><br><span class="line">      targetPort: webhook</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/controller-service.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  externalTrafficPolicy: Local</span><br><span class="line">  ipFamilyPolicy: SingleStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">    - IPv4</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: http</span><br><span class="line">      appProtocol: http</span><br><span class="line">    - name: https</span><br><span class="line">      port: 443</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: https</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/controller-deployment.yaml</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: ingress-nginx</span><br><span class="line">      app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">      app.kubernetes.io/component: controller</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  minReadySeconds: 0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/component: controller</span><br><span class="line">    spec:</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      containers:</span><br><span class="line">        - name: controller</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/controller:v1.1.3 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          lifecycle:</span><br><span class="line">            preStop:</span><br><span class="line">              exec:</span><br><span class="line">                command:</span><br><span class="line">                  - /wait-shutdown</span><br><span class="line">          args:</span><br><span class="line">            - /nginx-ingress-controller</span><br><span class="line">            - --election-id=ingress-controller-leader</span><br><span class="line">            - --controller-class=k8s.io/ingress-nginx</span><br><span class="line">            - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller</span><br><span class="line">            - --validating-webhook=:8443</span><br><span class="line">            - --validating-webhook-certificate=/usr/local/certificates/cert</span><br><span class="line">            - --validating-webhook-key=/usr/local/certificates/key</span><br><span class="line">          securityContext:</span><br><span class="line">            capabilities:</span><br><span class="line">              drop:</span><br><span class="line">                - ALL</span><br><span class="line">              add:</span><br><span class="line">                - NET_BIND_SERVICE</span><br><span class="line">            runAsUser: 101</span><br><span class="line">            allowPrivilegeEscalation: true</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.name</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">            - name: LD_PRELOAD</span><br><span class="line">              value: /usr/local/lib/libmimalloc.so</span><br><span class="line">          livenessProbe:</span><br><span class="line">            failureThreshold: 5</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          readinessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          ports:</span><br><span class="line">            - name: http</span><br><span class="line">              containerPort: 80</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: https</span><br><span class="line">              containerPort: 443</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: webhook</span><br><span class="line">              containerPort: 8443</span><br><span class="line">              protocol: TCP</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: webhook-cert</span><br><span class="line">              mountPath: /usr/local/certificates/</span><br><span class="line">              readOnly: true</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 100m</span><br><span class="line">              memory: 90Mi</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      serviceAccountName: ingress-nginx</span><br><span class="line">      terminationGracePeriodSeconds: 300</span><br><span class="line">      volumes:</span><br><span class="line">        - name: webhook-cert</span><br><span class="line">          secret:</span><br><span class="line">            secretName: ingress-nginx-admission</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Source: ingress-nginx/templates/controller-ingressclass.yaml</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> We don<span class="string">&#x27;t support namespaced ingressClass yet</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> So a ClusterRole and a ClusterRoleBinding is required</span></span></span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: IngressClass</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  controller: k8s.io/ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> Source: ingress-nginx/templates/admission-webhooks/validating-webhook.yaml</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> before changing this value, check the required kubernetes version</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites</span></span></span><br><span class="line">apiVersion: admissionregistration.k8s.io/v1</span><br><span class="line">kind: ValidatingWebhookConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">webhooks:</span><br><span class="line">  - name: validate.nginx.ingress.kubernetes.io</span><br><span class="line">    matchPolicy: Equivalent</span><br><span class="line">    rules:</span><br><span class="line">      - apiGroups:</span><br><span class="line">          - networking.k8s.io</span><br><span class="line">        apiVersions:</span><br><span class="line">          - v1</span><br><span class="line">        operations:</span><br><span class="line">          - CREATE</span><br><span class="line">          - UPDATE</span><br><span class="line">        resources:</span><br><span class="line">          - ingresses</span><br><span class="line">    failurePolicy: Fail</span><br><span class="line">    sideEffects: None</span><br><span class="line">    admissionReviewVersions:</span><br><span class="line">      - v1</span><br><span class="line">    clientConfig:</span><br><span class="line">      service:</span><br><span class="line">        namespace: ingress-nginx</span><br><span class="line">        name: ingress-nginx-controller-admission</span><br><span class="line">        path: /networking/v1/ingresses</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> Source: ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - admissionregistration.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - validatingwebhookconfigurations</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> Source: ingress-nginx/templates/admission-webhooks/job-patch/role.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - create</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> Source: ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> Source: ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-create</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-create</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: create</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - create</span><br><span class="line">            - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string"> Source: ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-patch</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-patch</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: patch</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - patch</span><br><span class="line">            - --webhook-name=ingress-nginx-admission</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --patch-mutating=false</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">            - --patch-failure-policy=Fail</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="启用后端，写入配置文件执行"><a href="#启用后端，写入配置文件执行" class="headerlink" title="启用后端，写入配置文件执行"></a>启用后端，写入配置文件执行</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim backend.yaml</span><br><span class="line">[root@hello ~/yaml]# cat backend.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: default-http-backend</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: default-http-backend</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      containers:</span><br><span class="line">      - name: default-http-backend</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/chenby/defaultbackend-amd64:1.5 </span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /healthz</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="安装测试应用"><a href="#安装测试应用" class="headerlink" title="安装测试应用"></a>安装测试应用</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim ingress-demo-app.yaml</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# cat ingress-demo-app.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello-server</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-server</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-server</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx&quot;  </span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# kubectl  get ingress</span><br><span class="line">NAME               CLASS    HOSTS                            ADDRESS        PORTS   AGE</span><br><span class="line">ingress-demo-app   &lt;none&gt;   app.demo.com                     192.168.1.11   80      20m</span><br><span class="line">ingress-host-bar   nginx    hello.chenby.cn,demo.chenby.cn   192.168.1.11   80      2m17s</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="执行部署"><a href="#执行部署" class="headerlink" title="执行部署"></a>执行部署</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  apply -f deploy.yaml </span><br><span class="line">namespace/ingress-nginx created</span><br><span class="line">serviceaccount/ingress-nginx created</span><br><span class="line">configmap/ingress-nginx-controller created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/ingress-nginx created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created</span><br><span class="line">role.rbac.authorization.k8s.io/ingress-nginx created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/ingress-nginx created</span><br><span class="line">service/ingress-nginx-controller-admission created</span><br><span class="line">service/ingress-nginx-controller created</span><br><span class="line">deployment.apps/ingress-nginx-controller created</span><br><span class="line">ingressclass.networking.k8s.io/nginx created</span><br><span class="line">validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created</span><br><span class="line">serviceaccount/ingress-nginx-admission created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created</span><br><span class="line">role.rbac.authorization.k8s.io/ingress-nginx-admission created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created</span><br><span class="line">job.batch/ingress-nginx-admission-create created</span><br><span class="line">job.batch/ingress-nginx-admission-patch created</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  apply -f backend.yaml </span><br><span class="line">deployment.apps/default-http-backend created</span><br><span class="line">service/default-http-backend created</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  apply -f ingress-demo-app.yaml </span><br><span class="line">deployment.apps/hello-server created</span><br><span class="line">deployment.apps/nginx-demo created</span><br><span class="line">service/nginx-demo created</span><br><span class="line">service/hello-server created</span><br><span class="line">ingress.networking.k8s.io/ingress-host-bar created</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="过滤查看ingress端口"><a href="#过滤查看ingress端口" class="headerlink" title="过滤查看ingress端口"></a>过滤查看ingress端口</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  get svc -A | grep ingress</span><br><span class="line">default         ingress-demo-app                     ClusterIP   10.68.231.41    &lt;none&gt;        80/TCP                       51m</span><br><span class="line">ingress-nginx   ingress-nginx-controller             NodePort    10.68.93.71     &lt;none&gt;        80:32746/TCP,443:30538/TCP   32m</span><br><span class="line">ingress-nginx   ingress-nginx-controller-admission   ClusterIP   10.68.146.23    &lt;none&gt;        443/TCP                      32m</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes（k8s） 安装 Prometheus + Grafana</title>
    <url>/2022/04/24/2022-04-24-kubernetes%EF%BC%88k8s%EF%BC%89_%E5%AE%89%E8%A3%85_Prometheus_+_Grafana/</url>
    <content><![CDATA[<h1 id="kubernetes（k8s）-安装-Prometheus-Grafana"><a href="#kubernetes（k8s）-安装-Prometheus-Grafana" class="headerlink" title="kubernetes（k8s） 安装 Prometheus + Grafana"></a>kubernetes（k8s） 安装 Prometheus + Grafana</h1><h1 id="组件说明"><a href="#组件说明" class="headerlink" title="组件说明"></a>组件说明</h1><p><strong>MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如 kubectl,hpa,scheduler等。</strong></p>
<p><strong>PrometheusOperator：是一个系统监测和警报工具箱，用来存储监控数据。</strong></p>
<p><strong>NodeExporter：用于各node的关键度量指标状态数据。</strong></p>
<p><strong>KubeStateMetrics：收集kubernetes集群内资源对象数 据，制定告警规则。</strong></p>
<p><strong>Prometheus：采用pull方式收集apiserver，scheduler，controller-manager，kubelet组件数 据，通过http协议传输。</strong></p>
<p><strong>Grafana：是可视化数据统计和监控平台。</strong></p>
<p><strong><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a041fa6a689f48c3a45317369b2d13c5~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></strong></p>
<h1 id="克隆代码"><a href="#克隆代码" class="headerlink" title="克隆代码"></a>克隆代码</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~#   git clone -b release-0.10 https://github.com/prometheus-operator/kube-prometheus.git</span><br><span class="line">Cloning into &#x27;kube-prometheus&#x27;...</span><br><span class="line">remote: Enumerating objects: 16026, done.</span><br><span class="line">remote: Counting objects: 100% (2639/2639), done.</span><br><span class="line">remote: Compressing objects: 100% (165/165), done.</span><br><span class="line">remote: Total 16026 (delta 2524), reused 2485 (delta 2470), pack-reused 13387</span><br><span class="line">Receiving objects: 100% (16026/16026), 7.81 MiB | 2.67 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (10333/10333), done.</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="进入目录修改镜像地址"><a href="#进入目录修改镜像地址" class="headerlink" title="进入目录修改镜像地址"></a>进入目录修改镜像地址</h1><p>若访问Google畅通无阻即可无需修改，跳过即可</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# cd kube-prometheus/manifests</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i &quot;s#quay.io/prometheus/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i &quot;s#quay.io/brancz/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i &quot;s#k8s.gcr.io/prometheus-adapter/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i &quot;s#quay.io/prometheus-operator/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i &quot;s#k8s.gcr.io/kube-state-metrics/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="修改svc为NodePort"><a href="#修改svc为NodePort" class="headerlink" title="修改svc为NodePort"></a>修改svc为NodePort</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/kube-prometheus/manifests# sed -i  &quot;/ports:/i\  type: NodePort&quot; grafana-service.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i  &quot;/targetPort: http/i\    nodePort: 31100&quot; grafana-service.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# cat grafana-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/component: grafana</span><br><span class="line">    app.kubernetes.io/name: grafana</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">    app.kubernetes.io/version: 8.3.3</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 3000</span><br><span class="line">    nodePort: 31100</span><br><span class="line">    targetPort: http</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/component: grafana</span><br><span class="line">    app.kubernetes.io/name: grafana</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i  &quot;/ports:/i\  type: NodePort&quot; prometheus-service.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i  &quot;/targetPort: web/i\    nodePort: 31200&quot; prometheus-service.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i  &quot;/targetPort: reloader-web/i\    nodePort: 31300&quot; prometheus-service.yaml</span><br><span class="line">root@hello:~/kube-prometheus/manifests# cat prometheus-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/component: prometheus</span><br><span class="line">    app.kubernetes.io/instance: k8s</span><br><span class="line">    app.kubernetes.io/name: prometheus</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">    app.kubernetes.io/version: 2.32.1</span><br><span class="line">  name: prometheus-k8s</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 9090</span><br><span class="line">    nodePort: 31200</span><br><span class="line">    targetPort: web</span><br><span class="line">  - name: reloader-web</span><br><span class="line">    port: 8080</span><br><span class="line">    nodePort: 31300</span><br><span class="line">    targetPort: reloader-web</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/component: prometheus</span><br><span class="line">    app.kubernetes.io/instance: k8s</span><br><span class="line">    app.kubernetes.io/name: prometheus</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">  sessionAffinity: ClientIP</span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i  &quot;/ports:/i\  type: NodePort&quot; alertmanager-service.yaml </span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i  &quot;/targetPort: web/i\    nodePort: 31400&quot; alertmanager-service.yaml </span><br><span class="line">root@hello:~/kube-prometheus/manifests# sed -i  &quot;/targetPort: reloader-web/i\    nodePort: 31500&quot; alertmanager-service.yaml </span><br><span class="line">root@hello:~/kube-prometheus/manifests# cat alertmanager-service.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/component: alert-router</span><br><span class="line">    app.kubernetes.io/instance: main</span><br><span class="line">    app.kubernetes.io/name: alertmanager</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">    app.kubernetes.io/version: 0.23.0</span><br><span class="line">  name: alertmanager-main</span><br><span class="line">  namespace: monitoring</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: web</span><br><span class="line">    port: 9093</span><br><span class="line">    nodePort: 31400</span><br><span class="line">    targetPort: web</span><br><span class="line">  - name: reloader-web</span><br><span class="line">    port: 8080</span><br><span class="line">    nodePort: 31500</span><br><span class="line">    targetPort: reloader-web</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/component: alert-router</span><br><span class="line">    app.kubernetes.io/instance: main</span><br><span class="line">    app.kubernetes.io/name: alertmanager</span><br><span class="line">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class="line">  sessionAffinity: ClientIP</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="执行部署"><a href="#执行部署" class="headerlink" title="执行部署"></a>执行部署</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# </span><br><span class="line">root@hello:~#  kubectl create -f /root/kube-prometheus/manifests/setup</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com created</span><br><span class="line">namespace/monitoring created</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~#  kubectl create -f /root/kube-prometheus/manifests/</span><br><span class="line">alertmanager.monitoring.coreos.com/main created</span><br><span class="line">networkpolicy.networking.k8s.io/alertmanager-main created</span><br><span class="line">poddisruptionbudget.policy/alertmanager-main created</span><br><span class="line">prometheusrule.monitoring.coreos.com/alertmanager-main-rules created</span><br><span class="line">secret/alertmanager-main created</span><br><span class="line">service/alertmanager-main created</span><br><span class="line">serviceaccount/alertmanager-main created</span><br><span class="line">servicemonitor.monitoring.coreos.com/alertmanager-main created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/blackbox-exporter created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/blackbox-exporter created</span><br><span class="line">configmap/blackbox-exporter-configuration created</span><br><span class="line">deployment.apps/blackbox-exporter created</span><br><span class="line">networkpolicy.networking.k8s.io/blackbox-exporter created</span><br><span class="line">service/blackbox-exporter created</span><br><span class="line">serviceaccount/blackbox-exporter created</span><br><span class="line">servicemonitor.monitoring.coreos.com/blackbox-exporter created</span><br><span class="line">secret/grafana-config created</span><br><span class="line">secret/grafana-datasources created</span><br><span class="line">configmap/grafana-dashboard-alertmanager-overview created</span><br><span class="line">configmap/grafana-dashboard-apiserver created</span><br><span class="line">configmap/grafana-dashboard-cluster-total created</span><br><span class="line">configmap/grafana-dashboard-controller-manager created</span><br><span class="line">configmap/grafana-dashboard-grafana-overview created</span><br><span class="line">configmap/grafana-dashboard-k8s-resources-cluster created</span><br><span class="line">configmap/grafana-dashboard-k8s-resources-namespace created</span><br><span class="line">configmap/grafana-dashboard-k8s-resources-node created</span><br><span class="line">configmap/grafana-dashboard-k8s-resources-pod created</span><br><span class="line">configmap/grafana-dashboard-k8s-resources-workload created</span><br><span class="line">configmap/grafana-dashboard-k8s-resources-workloads-namespace created</span><br><span class="line">configmap/grafana-dashboard-kubelet created</span><br><span class="line">configmap/grafana-dashboard-namespace-by-pod created</span><br><span class="line">configmap/grafana-dashboard-namespace-by-workload created</span><br><span class="line">configmap/grafana-dashboard-node-cluster-rsrc-use created</span><br><span class="line">configmap/grafana-dashboard-node-rsrc-use created</span><br><span class="line">configmap/grafana-dashboard-nodes created</span><br><span class="line">configmap/grafana-dashboard-persistentvolumesusage created</span><br><span class="line">configmap/grafana-dashboard-pod-total created</span><br><span class="line">configmap/grafana-dashboard-prometheus-remote-write created</span><br><span class="line">configmap/grafana-dashboard-prometheus created</span><br><span class="line">configmap/grafana-dashboard-proxy created</span><br><span class="line">configmap/grafana-dashboard-scheduler created</span><br><span class="line">configmap/grafana-dashboard-workload-total created</span><br><span class="line">configmap/grafana-dashboards created</span><br><span class="line">deployment.apps/grafana created</span><br><span class="line">networkpolicy.networking.k8s.io/grafana created</span><br><span class="line">prometheusrule.monitoring.coreos.com/grafana-rules created</span><br><span class="line">service/grafana created</span><br><span class="line">serviceaccount/grafana created</span><br><span class="line">servicemonitor.monitoring.coreos.com/grafana created</span><br><span class="line">prometheusrule.monitoring.coreos.com/kube-prometheus-rules created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kube-state-metrics created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics created</span><br><span class="line">deployment.apps/kube-state-metrics created</span><br><span class="line">networkpolicy.networking.k8s.io/kube-state-metrics created</span><br><span class="line">prometheusrule.monitoring.coreos.com/kube-state-metrics-rules created</span><br><span class="line">service/kube-state-metrics created</span><br><span class="line">serviceaccount/kube-state-metrics created</span><br><span class="line">servicemonitor.monitoring.coreos.com/kube-state-metrics created</span><br><span class="line">prometheusrule.monitoring.coreos.com/kubernetes-monitoring-rules created</span><br><span class="line">servicemonitor.monitoring.coreos.com/kube-apiserver created</span><br><span class="line">servicemonitor.monitoring.coreos.com/coredns created</span><br><span class="line">servicemonitor.monitoring.coreos.com/kube-controller-manager created</span><br><span class="line">servicemonitor.monitoring.coreos.com/kube-scheduler created</span><br><span class="line">servicemonitor.monitoring.coreos.com/kubelet created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/node-exporter created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/node-exporter created</span><br><span class="line">daemonset.apps/node-exporter created</span><br><span class="line">networkpolicy.networking.k8s.io/node-exporter created</span><br><span class="line">prometheusrule.monitoring.coreos.com/node-exporter-rules created</span><br><span class="line">service/node-exporter created</span><br><span class="line">serviceaccount/node-exporter created</span><br><span class="line">servicemonitor.monitoring.coreos.com/node-exporter created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/prometheus-k8s created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/prometheus-k8s created</span><br><span class="line">networkpolicy.networking.k8s.io/prometheus-k8s created</span><br><span class="line">poddisruptionbudget.policy/prometheus-k8s created</span><br><span class="line">prometheus.monitoring.coreos.com/k8s created</span><br><span class="line">prometheusrule.monitoring.coreos.com/prometheus-k8s-prometheus-rules created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/prometheus-k8s-config created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/prometheus-k8s created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/prometheus-k8s created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/prometheus-k8s created</span><br><span class="line">role.rbac.authorization.k8s.io/prometheus-k8s-config created</span><br><span class="line">role.rbac.authorization.k8s.io/prometheus-k8s created</span><br><span class="line">role.rbac.authorization.k8s.io/prometheus-k8s created</span><br><span class="line">role.rbac.authorization.k8s.io/prometheus-k8s created</span><br><span class="line">service/prometheus-k8s created</span><br><span class="line">serviceaccount/prometheus-k8s created</span><br><span class="line">servicemonitor.monitoring.coreos.com/prometheus-k8s created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/prometheus-adapter created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/prometheus-adapter created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/resource-metrics:system:auth-delegator created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/resource-metrics-server-resources created</span><br><span class="line">configmap/adapter-config created</span><br><span class="line">deployment.apps/prometheus-adapter created</span><br><span class="line">networkpolicy.networking.k8s.io/prometheus-adapter created</span><br><span class="line">poddisruptionbudget.policy/prometheus-adapter created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/resource-metrics-auth-reader created</span><br><span class="line">service/prometheus-adapter created</span><br><span class="line">serviceaccount/prometheus-adapter created</span><br><span class="line">servicemonitor.monitoring.coreos.com/prometheus-adapter created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/prometheus-operator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator created</span><br><span class="line">deployment.apps/prometheus-operator created</span><br><span class="line">networkpolicy.networking.k8s.io/prometheus-operator created</span><br><span class="line">prometheusrule.monitoring.coreos.com/prometheus-operator-rules created</span><br><span class="line">service/prometheus-operator created</span><br><span class="line">serviceaccount/prometheus-operator created</span><br><span class="line">servicemonitor.monitoring.coreos.com/prometheus-operator created</span><br><span class="line">root@hello:~# </span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="查看验证"><a href="#查看验证" class="headerlink" title="查看验证"></a>查看验证</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  get pod -n monitoring </span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">alertmanager-main-0                    2/2     Running   0          69s</span><br><span class="line">alertmanager-main-1                    2/2     Running   0          69s</span><br><span class="line">alertmanager-main-2                    2/2     Running   0          69s</span><br><span class="line">blackbox-exporter-6c559c5c66-kw6vd     3/3     Running   0          83s</span><br><span class="line">grafana-7fd69887fb-jmpmp               1/1     Running   0          81s</span><br><span class="line">kube-state-metrics-867b64476b-h84g4    3/3     Running   0          81s</span><br><span class="line">node-exporter-576bm                    2/2     Running   0          80s</span><br><span class="line">node-exporter-94gn9                    2/2     Running   0          80s</span><br><span class="line">node-exporter-cbjqk                    2/2     Running   0          80s</span><br><span class="line">node-exporter-mhlh7                    2/2     Running   0          80s</span><br><span class="line">node-exporter-pdc6k                    2/2     Running   0          80s</span><br><span class="line">node-exporter-pqqds                    2/2     Running   0          80s</span><br><span class="line">node-exporter-s9cz4                    2/2     Running   0          80s</span><br><span class="line">node-exporter-tdlnt                    2/2     Running   0          81s</span><br><span class="line">prometheus-adapter-8f88b5b45-rrsh4     1/1     Running   0          78s</span><br><span class="line">prometheus-adapter-8f88b5b45-wh6pf     1/1     Running   0          78s</span><br><span class="line">prometheus-k8s-0                       2/2     Running   0          68s</span><br><span class="line">prometheus-k8s-1                       2/2     Running   0          68s</span><br><span class="line">prometheus-operator-7f9d9c77f8-h5gkt   2/2     Running   0          78s</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  get svc -n monitoring </span><br><span class="line">NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE</span><br><span class="line">alertmanager-main       NodePort    10.103.47.160    &lt;none&gt;        9093:31400/TCP,8080:31500/TCP   92s</span><br><span class="line">alertmanager-operated   ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP      78s</span><br><span class="line">blackbox-exporter       ClusterIP   10.102.108.160   &lt;none&gt;        9115/TCP,19115/TCP              92s</span><br><span class="line">grafana                 NodePort    10.106.2.21      &lt;none&gt;        3000:31100/TCP                  90s</span><br><span class="line">kube-state-metrics      ClusterIP   None             &lt;none&gt;        8443/TCP,9443/TCP               90s</span><br><span class="line">node-exporter           ClusterIP   None             &lt;none&gt;        9100/TCP                        90s</span><br><span class="line">prometheus-adapter      ClusterIP   10.108.65.108    &lt;none&gt;        443/TCP                         87s</span><br><span class="line">prometheus-k8s          NodePort    10.100.227.174   &lt;none&gt;        9090:31200/TCP,8080:31300/TCP   88s</span><br><span class="line">prometheus-operated     ClusterIP   None             &lt;none&gt;        9090/TCP                        77s</span><br><span class="line">prometheus-operator     ClusterIP   None             &lt;none&gt;        8443/TCP                        87s</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http://192.168.1.81:31400/</span><br><span class="line">http://192.168.1.81:31200/</span><br><span class="line">http://192.168.1.81:31100/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="一条命令执行"><a href="#一条命令执行" class="headerlink" title="一条命令执行"></a>一条命令执行</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root ; git clone -b release-0.10 https://github.com/prometheus-operator/kube-prometheus.git ;cd kube-prometheus/manifests ;sed -i &quot;s#quay.io/prometheus/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml ;sed -i &quot;s#quay.io/brancz/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml ;sed -i &quot;s#k8s.gcr.io/prometheus-adapter/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml ;sed -i &quot;s#quay.io/prometheus-operator/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml ;sed -i &quot;s#k8s.gcr.io/kube-state-metrics/#registry.cn-hangzhou.aliyuncs.com/chenby/#g&quot; *.yaml ;sed -i  &quot;/ports:/i\  type: NodePort&quot; grafana-service.yaml ;sed -i  &quot;/targetPort: http/i\    nodePort: 31100&quot; grafana-service.yaml ;sed -i  &quot;/ports:/i\  type: NodePort&quot; prometheus-service.yaml ;sed -i  &quot;/targetPort: web/i\    nodePort: 31200&quot; prometheus-service.yaml ;sed -i  &quot;/targetPort: reloader-web/i\    nodePort: 31300&quot; prometheus-service.yaml ;sed -i  &quot;/ports:/i\  type: NodePort&quot; alertmanager-service.yaml  ;sed -i  &quot;/targetPort: web/i\    nodePort: 31400&quot; alertmanager-service.yaml  ;sed -i  &quot;/targetPort: reloader-web/i\    nodePort: 31500&quot; alertmanager-service.yaml  ;kubectl create -f /root/kube-prometheus/manifests/setup ;kubectl create -f /root/kube-prometheus/manifests/ ; sleep 30 ; kubectl  get pod -n monitoring  ; kubectl  get svc -n monitoring  ;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装Kubernetes（k8s） v1.23.6</title>
    <url>/2022/04/21/2022-04-21-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85Kubernetes%EF%BC%88k8s%EF%BC%89_v1.23.6/</url>
    <content><![CDATA[<h1 id="二进制安装Kubernetes（k8s）-v1-23-6"><a href="#二进制安装Kubernetes（k8s）-v1-23-6" class="headerlink" title="二进制安装Kubernetes（k8s） v1.23.6"></a>二进制安装Kubernetes（k8s） v1.23.6</h1><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>kubernetes二进制安装</p>
<p>1.23.3 和 1.23.4 和 1.23.5 和 1.23.6 文档以及安装包已生成。</p>
<p>后续尽可能第一时间更新新版本文档</p>
<p><a href="https://github.com/cby-chen/Kubernetes/releases">https://github.com/cby-chen/Kubernetes/releases</a></p>
<p>脚本项目地址：<a href="https://github.com/cby-chen/Binary_installation_of_Kubernetes">https://github.com/cby-chen/Binary_installation_of_Kubernetes</a></p>
<p>手动项目地址：<a href="https://github.com/cby-chen/Kubernetes">https://github.com/cby-chen/Kubernetes</a></p>
<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1.环境"></a>1.环境</h1><table>
<thead>
<tr>
<th>主机名称</th>
<th>IP地址</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td>Master01</td>
<td>192.168.1.81</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master02</td>
<td>192.168.1.82</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master03</td>
<td>192.168.1.83</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node01</td>
<td>192.168.1.84</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node02</td>
<td>192.168.1.85</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node03</td>
<td>192.168.1.86</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node04</td>
<td>192.168.1.87</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node05</td>
<td>192.168.1.88</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Lb01</td>
<td>192.168.1.80</td>
<td>Lb01节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td>Lb02</td>
<td>192.168.1.90</td>
<td>Lb02节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td></td>
<td>192.168.1.89</td>
<td>VIP</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">软件</th>
<th align="left">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">内核</td>
<td align="left">4.18.0-373.el8.x86_64</td>
</tr>
<tr>
<td align="left">CentOS 8</td>
<td align="left">v8 或者 v7</td>
</tr>
<tr>
<td align="left">kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy</td>
<td align="left">v1.23.6</td>
</tr>
<tr>
<td align="left">etcd</td>
<td align="left">v3.5.3</td>
</tr>
<tr>
<td align="left">docker-ce</td>
<td align="left">v20.10.14</td>
</tr>
<tr>
<td align="left">containerd</td>
<td align="left">v1.5.11</td>
</tr>
<tr>
<td align="left">cfssl</td>
<td align="left">v1.6.1</td>
</tr>
<tr>
<td align="left">cni</td>
<td align="left">v1.1.1</td>
</tr>
<tr>
<td align="left">crictl</td>
<td align="left">v1.23.0</td>
</tr>
<tr>
<td align="left">haproxy</td>
<td align="left">v1.8.27</td>
</tr>
<tr>
<td align="left">keepalived</td>
<td align="left">v2.1.5</td>
</tr>
</tbody></table>
<p>网段</p>
<p>物理主机：192.168.1.0&#x2F;24</p>
<p>service：10.96.0.0&#x2F;12</p>
<p>pod：172.16.0.0&#x2F;12</p>
<p>如果有条件建议k8s集群与etcd集群分开安装</p>
<h2 id="1-1-k8s基础系统环境配置"><a href="#1-1-k8s基础系统环境配置" class="headerlink" title="1.1.k8s基础系统环境配置"></a>1.1.k8s基础系统环境配置</h2><h3 id="1-2-配置IP"><a href="#1-2-配置IP" class="headerlink" title="1.2.配置IP"></a>1.2.配置IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@192.168.1.161 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.81/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.167 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.82/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.137 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.83/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.152 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.84/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.198 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.85/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.166 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.86/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.171 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.87/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.159 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.88/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.122 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.80/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br><span class="line">ssh root@192.168.1.125 &quot;nmcli con mod ens18 ipv4.addresses 192.168.1.90/24; nmcli con mod ens18 ipv4.gateway 192.168.1.99; nmcli con mod ens18 ipv4.method manual; nmcli con mod ens18 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens18&quot;</span><br></pre></td></tr></table></figure>

<h3 id="1-3-设置主机名"><a href="#1-3-设置主机名" class="headerlink" title="1.3.设置主机名"></a>1.3.设置主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-master02</span><br><span class="line">hostnamectl set-hostname k8s-master03</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br><span class="line">hostnamectl set-hostname k8s-node03</span><br><span class="line">hostnamectl set-hostname k8s-node04</span><br><span class="line">hostnamectl set-hostname k8s-node05</span><br><span class="line">hostnamectl set-hostname lb01</span><br><span class="line">hostnamectl set-hostname lb02</span><br></pre></td></tr></table></figure>

<h3 id="1-4-配置yum源"><a href="#1-4-配置yum源" class="headerlink" title="1.4.配置yum源"></a>1.4.配置yum源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 7</span></span><br><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 8</span></span><br><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"></span><br><span class="line">sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; -e &#x27;s|^#baseurl=http://mirror.centos.org/\$contentdir|baseurl=http://192.168.1.123/centos|g&#x27; -i.bak  /etc/yum.repos.d/CentOS-*.repo</span><br></pre></td></tr></table></figure>

<h3 id="1-5-安装一些必备工具"><a href="#1-5-安装一些必备工具" class="headerlink" title="1.5.安装一些必备工具"></a>1.5.安装一些必备工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install wget jq psmisc vim net-tools nfs-utils telnet yum-utils device-mapper-persistent-data lvm2 git network-scripts tar curl -y</span><br></pre></td></tr></table></figure>

<h3 id="1-6-安装docker工具-lb除外"><a href="#1-6-安装docker工具-lb除外" class="headerlink" title="1.6.安装docker工具 (lb除外)"></a>1.6.安装docker工具 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">wget -O /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">sudo sed -i &#x27;s+download.docker.com+mirrors.tuna.tsinghua.edu.cn/docker-ce+&#x27; /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">yum makecache</span><br><span class="line">yum -y install docker-ce</span><br><span class="line">systemctl  enable --now docker</span><br></pre></td></tr></table></figure>

<h3 id="1-7-关闭防火墙"><a href="#1-7-关闭防火墙" class="headerlink" title="1.7.关闭防火墙"></a>1.7.关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br></pre></td></tr></table></figure>

<h3 id="1-8-关闭SELinux"><a href="#1-8-关闭SELinux" class="headerlink" title="1.8.关闭SELinux"></a>1.8.关闭SELinux</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure>

<h3 id="1-9-关闭交换分区"><a href="#1-9-关闭交换分区" class="headerlink" title="1.9.关闭交换分区"></a>1.9.关闭交换分区</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line"></span><br><span class="line">cat /etc/fstab</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>

<h3 id="1-10-关闭NetworkManager-并启用-network-lb除外"><a href="#1-10-关闭NetworkManager-并启用-network-lb除外" class="headerlink" title="1.10.关闭NetworkManager 并启用 network (lb除外)"></a>1.10.关闭NetworkManager 并启用 network (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now NetworkManager</span><br><span class="line">systemctl start network &amp;&amp; systemctl enable network</span><br></pre></td></tr></table></figure>

<h3 id="1-11-进行时间同步-lb除外"><a href="#1-11-进行时间同步-lb除外" class="headerlink" title="1.11.进行时间同步 (lb除外)"></a>1.11.进行时间同步 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">服务端</span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">cat &gt; /etc/chrony.conf &lt;&lt; EOF </span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">allow 192.168.1.0/24</span><br><span class="line">local stratum 10</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd</span><br><span class="line">systemctl enable chronyd</span><br><span class="line"></span><br><span class="line">客户端</span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool 192.168.1.81 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum install chrony -y ; sed -i &quot;s#2.centos.pool.ntp.org#192.168.1.81#g&quot; /etc/chrony.conf ; systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">使用客户端进行验证</span><br><span class="line"></span><br><span class="line">chronyc sources -v</span><br></pre></td></tr></table></figure>

<h3 id="1-12-配置ulimit"><a href="#1-12-配置ulimit" class="headerlink" title="1.12.配置ulimit"></a>1.12.配置ulimit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -SHn 65535</span><br><span class="line">cat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOF</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* seft memlock unlimited</span><br><span class="line">* hard memlock unlimitedd</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="1-13-配置免密登录"><a href="#1-13-配置免密登录" class="headerlink" title="1.13.配置免密登录"></a>1.13.配置免密登录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br><span class="line">ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;</span><br><span class="line">export IP=&quot;192.168.1.81 192.168.1.82 192.168.1.83 192.168.1.84 192.168.1.85 192.168.1.86 192.168.1.87 192.168.1.88 192.168.1.80 192.168.1.90&quot;</span><br><span class="line">export SSHPASS=123123</span><br><span class="line">for HOST in $IP;do</span><br><span class="line">     sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $HOST</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="1-14-添加启用源-lb除外"><a href="#1-14-添加启用源-lb除外" class="headerlink" title="1.14.添加启用源 (lb除外)"></a>1.14.添加启用源 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">为 RHEL-8或 CentOS-8配置源</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line">为 RHEL-7 SL-7 或 CentOS-7 安装 ELRepo </span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line">查看可用安装包</span><br><span class="line">yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available</span><br></pre></td></tr></table></figure>

<h3 id="1-15-升级内核至4-18版本以上-lb除外"><a href="#1-15-升级内核至4-18版本以上-lb除外" class="headerlink" title="1.15.升级内核至4.18版本以上 (lb除外)"></a>1.15.升级内核至4.18版本以上 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装最新的内核</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我这里选择的是稳定版kernel-ml   如需更新长期维护版本kernel-lt</span>  </span><br><span class="line">yum  --enablerepo=elrepo-kernel  install  kernel-ml</span><br><span class="line"></span><br><span class="line">查看已安装那些内核</span><br><span class="line">rpm -qa | grep kernel</span><br><span class="line">kernel-core-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-core-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-ml-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-modules-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-libs-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-modules-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"></span><br><span class="line">查看默认内核</span><br><span class="line">grubby --default-kernel</span><br><span class="line">/boot/vmlinuz-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">若不是最新的使用命令设置</span><br><span class="line">grubby --set-default /boot/vmlinuz-「您的内核版本」.x86_64</span><br><span class="line"></span><br><span class="line">重启生效</span><br><span class="line">reboot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">v8 整合命令为：</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --default-kernel ; reboot</span><br><span class="line"></span><br><span class="line">v7 整合命令为：</span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --set-default \$(ls /boot/vmlinuz-* | grep elrepo) ; grubby --default-kernel</span><br></pre></td></tr></table></figure>

<h3 id="1-16-安装ipvsadm-lb除外"><a href="#1-16-安装ipvsadm-lb除外" class="headerlink" title="1.16.安装ipvsadm (lb除外)"></a>1.16.安装ipvsadm (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;EOF </span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">ip_tables</span><br><span class="line">ip_set</span><br><span class="line">xt_set</span><br><span class="line">ipt_set</span><br><span class="line">ipt_rpfilter</span><br><span class="line">ipt_REJECT</span><br><span class="line">ipip</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart systemd-modules-load.service</span><br><span class="line"></span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack</span><br><span class="line">ip_vs_sh               16384  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          176128  1 ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure>

<h3 id="1-17-修改内核参数-lb除外"><a href="#1-17-修改内核参数-lb除外" class="headerlink" title="1.17.修改内核参数 (lb除外)"></a>1.17.修改内核参数 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="1-18-所有节点配置hosts本地解析"><a href="#1-18-所有节点配置hosts本地解析" class="headerlink" title="1.18.所有节点配置hosts本地解析"></a>1.18.所有节点配置hosts本地解析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.1.81 k8s-master01</span><br><span class="line">192.168.1.82 k8s-master02</span><br><span class="line">192.168.1.83 k8s-master03</span><br><span class="line">192.168.1.84 k8s-node01</span><br><span class="line">192.168.1.85 k8s-node02</span><br><span class="line">192.168.1.86 k8s-node03</span><br><span class="line">192.168.1.87 k8s-node04</span><br><span class="line">192.168.1.88 k8s-node05</span><br><span class="line">192.168.1.80 lb01</span><br><span class="line">192.168.1.90 lb02</span><br><span class="line">192.168.1.89 lb-vip</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="2-k8s基本组件安装"><a href="#2-k8s基本组件安装" class="headerlink" title="2.k8s基本组件安装"></a>2.k8s基本组件安装</h1><h2 id="2-1-所有k8s节点安装Containerd作为Runtime"><a href="#2-1-所有k8s节点安装Containerd作为Runtime" class="headerlink" title="2.1.所有k8s节点安装Containerd作为Runtime"></a>2.1.所有k8s节点安装Containerd作为Runtime</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install containerd -y</span><br></pre></td></tr></table></figure>

<h3 id="2-1-1配置Containerd所需的模块"><a href="#2-1-1配置Containerd所需的模块" class="headerlink" title="2.1.1配置Containerd所需的模块"></a>2.1.1配置Containerd所需的模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2加载模块"><a href="#2-1-2加载模块" class="headerlink" title="2.1.2加载模块"></a>2.1.2加载模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl restart systemd-modules-load.service</span><br></pre></td></tr></table></figure>

<h3 id="2-1-3配置Containerd所需的内核"><a href="#2-1-3配置Containerd所需的内核" class="headerlink" title="2.1.3配置Containerd所需的内核"></a>2.1.3配置Containerd所需的内核</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载内核</span></span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4创建Containerd的配置文件"><a href="#2-1-4创建Containerd的配置文件" class="headerlink" title="2.1.4创建Containerd的配置文件"></a>2.1.4创建Containerd的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改Containerd的配置文件</span><br><span class="line">sed -i &quot;s#SystemdCgroup\ \=\ false#SystemdCgroup\ \=\ true#g&quot; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">cat /etc/containerd/config.toml | grep SystemdCgroup</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到containerd.runtimes.runc.options，在其下加入SystemdCgroup = <span class="literal">true</span></span></span><br><span class="line"></span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">              SystemdCgroup = true</span><br><span class="line">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sandbox_image默认地址改为符合版本地址</span></span><br><span class="line"></span><br><span class="line">    sandbox_image = &quot;registry.cn-hangzhou.aliyuncs.com/chenby/pause:3.6&quot;</span><br></pre></td></tr></table></figure>

<h3 id="2-1-5启动并设置为开机启动"><a href="#2-1-5启动并设置为开机启动" class="headerlink" title="2.1.5启动并设置为开机启动"></a>2.1.5启动并设置为开机启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now containerd</span><br></pre></td></tr></table></figure>

<h3 id="2-1-6配置crictl客户端连接的运行时位置"><a href="#2-1-6配置crictl客户端连接的运行时位置" class="headerlink" title="2.1.6配置crictl客户端连接的运行时位置"></a>2.1.6配置crictl客户端连接的运行时位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/crictl.yaml &lt;&lt;EOF</span><br><span class="line">runtime-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">image-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">timeout: 10</span><br><span class="line">debug: false</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart  containerd</span><br></pre></td></tr></table></figure>

<h2 id="2-2-k8s与etcd下载及安装（仅在master01操作）"><a href="#2-2-k8s与etcd下载及安装（仅在master01操作）" class="headerlink" title="2.2.k8s与etcd下载及安装（仅在master01操作）"></a>2.2.k8s与etcd下载及安装（仅在master01操作）</h2><h3 id="2-2-1下载k8s安装包（你用哪个下哪个）"><a href="#2-2-1下载k8s安装包（你用哪个下哪个）" class="headerlink" title="2.2.1下载k8s安装包（你用哪个下哪个）"></a>2.2.1下载k8s安装包（你用哪个下哪个）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1.下载kubernetes1.23.+的二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md</span><br><span class="line"></span><br><span class="line">wget https://dl.k8s.io/v1.23.6/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">2.下载etcdctl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/etcd-io/etcd/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.5.3/etcd-v3.5.3-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">3.docker-ce二进制包下载地址</span><br><span class="line">二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><br><span class="line"></span><br><span class="line">这里需要下载20.10.+版本</span><br><span class="line"></span><br><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-20.10.14.tgz</span><br><span class="line"></span><br><span class="line">4.containerd二进制包下载</span><br><span class="line">github下载地址：https://github.com/containerd/containerd/releases</span><br><span class="line"></span><br><span class="line">containerd下载时下载带cni插件的二进制包。</span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.2/cri-containerd-cni-1.6.2-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">5.下载cfssl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/cloudflare/cfssl/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.1_linux_amd64</span><br><span class="line"></span><br><span class="line">6.cni插件下载</span><br><span class="line">github下载地址：https://github.com/containernetworking/plugins/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span><br><span class="line"></span><br><span class="line">7.crictl客户端二进制下载</span><br><span class="line">github下载：https://github.com/kubernetes-sigs/cri-tools/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.23.0/crictl-v1.23.0-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">解压k8s安装文件</span><br><span class="line">tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;</span><br><span class="line"></span><br><span class="line">解压etcd安装文件</span><br><span class="line">tar -xf etcd-v3.5.3-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.3-linux-amd64/etcd&#123;,ctl&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看/usr/local/bin下内容</span></span><br><span class="line"></span><br><span class="line">ls /usr/local/bin/</span><br><span class="line">etcd  etcdctl  kube-apiserver  kube-controller-manager  kubectl  kubelet  kube-proxy  kube-scheduler</span><br><span class="line"></span><br><span class="line">已经整理好的：</span><br><span class="line">wget https://github.com/cby-chen/Kubernetes/releases/download/v1.23.6/kubernetes-v1.23.6.tar</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2查看版本"><a href="#2-2-2查看版本" class="headerlink" title="2.2.2查看版本"></a>2.2.2查看版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubelet --version</span><br><span class="line">Kubernetes v1.23.6</span><br><span class="line">[root@k8s-master01 ~]# etcdctl version</span><br><span class="line">etcdctl version: 3.5.3</span><br><span class="line">API version: 3.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h3 id="2-2-3将组件发送至其他k8s节点"><a href="#2-2-3将组件发送至其他k8s节点" class="headerlink" title="2.2.3将组件发送至其他k8s节点"></a>2.2.3将组件发送至其他k8s节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">Work=&#x27;k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05&#x27;</span><br><span class="line"></span><br><span class="line">for NODE in $Master; do echo $NODE; scp /usr/local/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done</span><br><span class="line"></span><br><span class="line">for NODE in $Work; do     scp /usr/local/bin/kube&#123;let,-proxy&#125; $NODE:/usr/local/bin/ ; done</span><br></pre></td></tr></table></figure>

<h3 id="2-2-4克隆证书相关文件"><a href="#2-2-4克隆证书相关文件" class="headerlink" title="2.2.4克隆证书相关文件"></a>2.2.4克隆证书相关文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/cby-chen/Kubernetes.git</span><br></pre></td></tr></table></figure>

<h3 id="2-2-5所有k8s节点创建目录"><a href="#2-2-5所有k8s节点创建目录" class="headerlink" title="2.2.5所有k8s节点创建目录"></a>2.2.5所有k8s节点创建目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /opt/cni/bin</span><br></pre></td></tr></table></figure>

<h1 id="3-相关证书生成"><a href="#3-相关证书生成" class="headerlink" title="3.相关证书生成"></a>3.相关证书生成</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">master01节点下载证书生成工具</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssl</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssljson</span><br><span class="line">chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</span><br></pre></td></tr></table></figure>

<h2 id="3-1-生成etcd证书"><a href="#3-1-生成etcd证书" class="headerlink" title="3.1.生成etcd证书"></a>3.1.生成etcd证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-1-1所有master节点创建证书存放目录"><a href="#3-1-1所有master节点创建证书存放目录" class="headerlink" title="3.1.1所有master节点创建证书存放目录"></a>3.1.1所有master节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/etcd/ssl -p</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2master01节点生成etcd证书"><a href="#3-1-2master01节点生成etcd证书" class="headerlink" title="3.1.2master01节点生成etcd证书"></a>3.1.2master01节点生成etcd证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd Kubernetes/pki/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成etcd证书和etcd证书的key（如果你觉得以后可能会扩容，可以在ip那多写几个预留出来）</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,192.168.1.81,192.168.1.82,192.168.1.83 \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</span><br></pre></td></tr></table></figure>

<h3 id="3-1-3将证书复制到其他节点"><a href="#3-1-3将证书复制到其他节点" class="headerlink" title="3.1.3将证书复制到其他节点"></a>3.1.3将证书复制到其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line"></span><br><span class="line">for NODE in $Master; do ssh $NODE &quot;mkdir -p /etc/etcd/ssl&quot;; for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do scp /etc/etcd/ssl/$&#123;FILE&#125; $NODE:/etc/etcd/ssl/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h2 id="3-2-生成k8s相关证书"><a href="#3-2-生成k8s相关证书" class="headerlink" title="3.2.生成k8s相关证书"></a>3.2.生成k8s相关证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-2-1所有k8s节点创建证书存放目录"><a href="#3-2-1所有k8s节点创建证书存放目录" class="headerlink" title="3.2.1所有k8s节点创建证书存放目录"></a>3.2.1所有k8s节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2master01节点生成k8s证书"><a href="#3-2-2master01节点生成k8s证书" class="headerlink" title="3.2.2master01节点生成k8s证书"></a>3.2.2master01节点生成k8s证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成一个根证书</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.96.0.1是service网段的第一个地址，需要计算，192.168.1.89为高可用vip地址</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   \</span><br><span class="line">-ca=/etc/kubernetes/pki/ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-hostname=10.96.0.1,192.168.1.89,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,x.oiox.cn,k.oiox.cn,l.oiox.cn,o.oiox.cn,192.168.1.81,192.168.1.82,192.168.1.83,192.168.1.84,192.168.1.85,192.168.1.86,192.168.1.87,192.168.1.88,192.168.1.80,192.168.1.90,192.168.1.40,192.168.1.41   \</span><br><span class="line">-profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3生成apiserver聚合证书"><a href="#3-2-3生成apiserver聚合证书" class="headerlink" title="3.2.3生成apiserver聚合证书"></a>3.2.3生成apiserver聚合证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有一个警告，可以忽略</span></span><br><span class="line"></span><br><span class="line">cfssl gencert  \</span><br><span class="line">-ca=/etc/kubernetes/pki/front-proxy-ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4生成controller-manage的证书"><a href="#3-2-4生成controller-manage的证书" class="headerlink" title="3.2.4生成controller-manage的证书"></a>3.2.4生成controller-manage的证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个集群项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://192.168.1.89:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个环境项，一个上下文</span></span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=system:kube-controller-manager \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个用户项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置默认环境</span></span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://192.168.1.89:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/scheduler.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/scheduler-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --cluster=kubernetes \</span><br><span class="line">     --user=system:kube-scheduler \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --server=https://192.168.1.89:8443     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes-admin  \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/admin.pem     \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/admin-key.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes    \</span><br><span class="line">  --cluster=kubernetes     \</span><br><span class="line">  --user=kubernetes-admin     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5创建ServiceAccount-Key-——secret"><a href="#3-2-5创建ServiceAccount-Key-——secret" class="headerlink" title="3.2.5创建ServiceAccount Key ——secret"></a>3.2.5创建ServiceAccount Key ——secret</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out /etc/kubernetes/pki/sa.key 2048</span><br><span class="line">openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</span><br></pre></td></tr></table></figure>

<h3 id="3-2-6将证书发送到其他master节点"><a href="#3-2-6将证书发送到其他master节点" class="headerlink" title="3.2.6将证书发送到其他master节点"></a>3.2.6将证书发送到其他master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do  for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do  scp /etc/kubernetes/pki/$&#123;FILE&#125; $NODE:/etc/kubernetes/pki/$&#123;FILE&#125;; done;  for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do  scp /etc/kubernetes/$&#123;FILE&#125; $NODE:/etc/kubernetes/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h3 id="3-2-7查看证书"><a href="#3-2-7查看证书" class="headerlink" title="3.2.7查看证书"></a>3.2.7查看证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /etc/kubernetes/pki/</span><br><span class="line">admin.csr      apiserver-key.pem  ca.pem                      front-proxy-ca.csr      front-proxy-client-key.pem  scheduler.csr</span><br><span class="line">admin-key.pem  apiserver.pem      controller-manager.csr      front-proxy-ca-key.pem  front-proxy-client.pem      scheduler-key.pem</span><br><span class="line">admin.pem      ca.csr             controller-manager-key.pem  front-proxy-ca.pem      sa.key                      scheduler.pem</span><br><span class="line">apiserver.csr  ca-key.pem         controller-manager.pem      front-proxy-client.csr  sa.pub</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一共23个就对了</span></span><br><span class="line"></span><br><span class="line">ls /etc/kubernetes/pki/ |wc -l</span><br><span class="line">23</span><br></pre></td></tr></table></figure>

<h1 id="4-k8s系统组件配置"><a href="#4-k8s系统组件配置" class="headerlink" title="4.k8s系统组件配置"></a>4.k8s系统组件配置</h1><h2 id="4-1-etcd配置"><a href="#4-1-etcd配置" class="headerlink" title="4.1.etcd配置"></a>4.1.etcd配置</h2><h3 id="4-1-1master01配置"><a href="#4-1-1master01配置" class="headerlink" title="4.1.1master01配置"></a>4.1.1master01配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master01&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.81:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.81:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.81:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.81:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.81:2380,k8s-master02=https://192.168.1.82:2380,k8s-master03=https://192.168.1.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2master02配置"><a href="#4-1-2master02配置" class="headerlink" title="4.1.2master02配置"></a>4.1.2master02配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master02&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.82:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.82:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.82:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.82:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.81:2380,k8s-master02=https://192.168.1.82:2380,k8s-master03=https://192.168.1.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3master03配置"><a href="#4-1-3master03配置" class="headerlink" title="4.1.3master03配置"></a>4.1.3master03配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master03&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://192.168.1.83:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://192.168.1.83:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://192.168.1.83:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://192.168.1.83:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://192.168.1.81:2380,k8s-master02=https://192.168.1.82:2380,k8s-master03=https://192.168.1.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="4-2-创建service（所有master节点操作）"><a href="#4-2-创建service（所有master节点操作）" class="headerlink" title="4.2.创建service（所有master节点操作）"></a>4.2.创建service（所有master节点操作）</h2><h3 id="4-2-1创建etcd-service并启动"><a href="#4-2-1创建etcd-service并启动" class="headerlink" title="4.2.1创建etcd.service并启动"></a>4.2.1创建etcd.service并启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2创建etcd证书目录"><a href="#4-2-2创建etcd证书目录" class="headerlink" title="4.2.2创建etcd证书目录"></a>4.2.2创建etcd证书目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/kubernetes/pki/etcd</span><br><span class="line">ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now etcd</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3查看etcd状态"><a href="#4-2-3查看etcd状态" class="headerlink" title="4.2.3查看etcd状态"></a>4.2.3查看etcd状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --endpoints=&quot;192.168.1.83:2379,192.168.1.82:2379,192.168.1.81:2379&quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|     ENDPOINT      |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| 192.168.1.83:2379 | 7cb7be3df5c81965 |   3.5.2 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 192.168.1.82:2379 | c077939949ab3f8b |   3.5.2 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 192.168.1.81:2379 | 2ee388f67565dac9 |   3.5.2 |   20 kB |      true |      false |         2 |          9 |                  9 |        |</span><br><span class="line">+-------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">[root@k8s-master01 pki]# </span><br></pre></td></tr></table></figure>

<h1 id="5-高可用配置"><a href="#5-高可用配置" class="headerlink" title="5.高可用配置"></a>5.高可用配置</h1><h2 id="5-1在lb01和lb02两台服务器上操作"><a href="#5-1在lb01和lb02两台服务器上操作" class="headerlink" title="5.1在lb01和lb02两台服务器上操作"></a>5.1在lb01和lb02两台服务器上操作</h2><h3 id="5-1-1安装keepalived和haproxy服务"><a href="#5-1-1安装keepalived和haproxy服务" class="headerlink" title="5.1.1安装keepalived和haproxy服务"></a>5.1.1安装keepalived和haproxy服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br><span class="line"></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum -y install keepalived haproxy</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2修改haproxy配置文件（两台配置文件一样）"><a href="#5-1-2修改haproxy配置文件（两台配置文件一样）" class="headerlink" title="5.1.2修改haproxy配置文件（两台配置文件一样）"></a>5.1.2修改haproxy配置文件（两台配置文件一样）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt;/etc/haproxy/haproxy.cfg&lt;&lt;&quot;EOF&quot;</span><br><span class="line">global</span><br><span class="line"> maxconn 2000</span><br><span class="line"> ulimit-n 16384</span><br><span class="line"> log 127.0.0.1 local0 err</span><br><span class="line"> stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"> log global</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> timeout connect 5000</span><br><span class="line"> timeout client 50000</span><br><span class="line"> timeout server 50000</span><br><span class="line"> timeout http-request 15s</span><br><span class="line"> timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line"> bind *:33305</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line"> bind 0.0.0.0:8443</span><br><span class="line"> bind 127.0.0.1:8443</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> tcp-request inspect-delay 5s</span><br><span class="line"> default_backend k8s-master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> option tcp-check</span><br><span class="line"> balance roundrobin</span><br><span class="line"> default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line"> server  k8s-master01  192.168.1.81:6443 check</span><br><span class="line"> server  k8s-master02  192.168.1.82:6443 check</span><br><span class="line"> server  k8s-master03  192.168.1.83:6443 check</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-3lb01配置keepalived-master节点"><a href="#5-1-3lb01配置keepalived-master节点" class="headerlink" title="5.1.3lb01配置keepalived master节点"></a>5.1.3lb01配置keepalived master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens18</span><br><span class="line">    mcast_src_ip 192.168.1.80</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.89</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4lb02配置keepalived-backup节点"><a href="#5-1-4lb02配置keepalived-backup节点" class="headerlink" title="5.1.4lb02配置keepalived backup节点"></a>5.1.4lb02配置keepalived backup节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens18</span><br><span class="line">    mcast_src_ip 192.168.1.90</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 50</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.1.89</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-5健康检查脚本配置（两台lb主机）"><a href="#5-1-5健康检查脚本配置（两台lb主机）" class="headerlink" title="5.1.5健康检查脚本配置（两台lb主机）"></a>5.1.5健康检查脚本配置（两台lb主机）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/keepalived/check_apiserver.sh &lt;&lt; EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">err=0</span><br><span class="line">for k in \$(seq 1 3)</span><br><span class="line">do</span><br><span class="line">    check_code=\$(pgrep haproxy)</span><br><span class="line">    if [[ \$check_code == &quot;&quot; ]]; then</span><br><span class="line">        err=\$(expr \$err + 1)</span><br><span class="line">        sleep 1</span><br><span class="line">        continue</span><br><span class="line">    else</span><br><span class="line">        err=0</span><br><span class="line">        break</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ \$err != &quot;0&quot; ]]; then</span><br><span class="line">    echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">    /usr/bin/systemctl stop keepalived</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给脚本授权</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_apiserver.sh</span><br></pre></td></tr></table></figure>

<h3 id="5-1-6启动服务"><a href="#5-1-6启动服务" class="headerlink" title="5.1.6启动服务"></a>5.1.6启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now haproxy</span><br><span class="line">systemctl enable --now keepalived</span><br></pre></td></tr></table></figure>

<h3 id="5-1-7测试高可用"><a href="#5-1-7测试高可用" class="headerlink" title="5.1.7测试高可用"></a>5.1.7测试高可用</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能ping同</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# ping 192.168.1.89</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能telnet访问</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# telnet 192.168.1.89 8443</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭主节点，看vip是否漂移到备节点</span></span><br></pre></td></tr></table></figure>

<h1 id="6-k8s组件配置（区别于第4点）"><a href="#6-k8s组件配置（区别于第4点）" class="headerlink" title="6.k8s组件配置（区别于第4点）"></a>6.k8s组件配置（区别于第4点）</h1><p>所有k8s节点创建以下目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes</span><br></pre></td></tr></table></figure>

<h2 id="6-1-创建apiserver（所有master节点）"><a href="#6-1-创建apiserver（所有master节点）" class="headerlink" title="6.1.创建apiserver（所有master节点）"></a>6.1.创建apiserver（所有master节点）</h2><h3 id="6-1-1master01节点配置"><a href="#6-1-1master01节点配置" class="headerlink" title="6.1.1master01节点配置"></a>6.1.1master01节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.81 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.81:2379,https://192.168.1.82:2379,https://192.168.1.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-2master02节点配置"><a href="#6-1-2master02节点配置" class="headerlink" title="6.1.2master02节点配置"></a>6.1.2master02节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.82 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.81:2379,https://192.168.1.82:2379,https://192.168.1.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-3master03节点配置"><a href="#6-1-3master03节点配置" class="headerlink" title="6.1.3master03节点配置"></a>6.1.3master03节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service  &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.83 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.81:2379,https://192.168.1.82:2379,https://192.168.1.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-4启动apiserver（所有master节点）"><a href="#6-1-4启动apiserver（所有master节点）" class="headerlink" title="6.1.4启动apiserver（所有master节点）"></a>6.1.4启动apiserver（所有master节点）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl enable --now kube-apiserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意查看状态是否启动正常</span></span><br><span class="line"></span><br><span class="line">systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>

<h2 id="6-2-配置kube-controller-manager-service"><a href="#6-2-配置kube-controller-manager-service" class="headerlink" title="6.2.配置kube-controller-manager service"></a>6.2.配置kube-controller-manager service</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">所有master节点配置，且配置相同</span><br><span class="line">172.16.0.0/12为pod网段，按需求设置你自己的网段</span><br><span class="line"></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --use-service-account-credentials=true \</span><br><span class="line">      --node-monitor-grace-period=40s \</span><br><span class="line">      --node-monitor-period=5s \</span><br><span class="line">      --pod-eviction-timeout=2m0s \</span><br><span class="line">      --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">      --allocate-node-cidrs=true \</span><br><span class="line">      --cluster-cidr=172.16.0.0/12 \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem \</span><br><span class="line">      --node-cidr-mask-size=24</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-2-1启动kube-controller-manager，并查看状态"><a href="#6-2-1启动kube-controller-manager，并查看状态" class="headerlink" title="6.2.1启动kube-controller-manager，并查看状态"></a>6.2.1启动kube-controller-manager，并查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-controller-manager</span><br><span class="line">systemctl  status kube-controller-manager</span><br></pre></td></tr></table></figure>

<h2 id="6-3-配置kube-scheduler-service"><a href="#6-3-配置kube-scheduler-service" class="headerlink" title="6.3.配置kube-scheduler service"></a>6.3.配置kube-scheduler service</h2><h3 id="6-3-1所有master节点配置，且配置相同"><a href="#6-3-1所有master节点配置，且配置相同" class="headerlink" title="6.3.1所有master节点配置，且配置相同"></a>6.3.1所有master节点配置，且配置相同</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-3-2启动并查看服务状态"><a href="#6-3-2启动并查看服务状态" class="headerlink" title="6.3.2启动并查看服务状态"></a>6.3.2启动并查看服务状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-scheduler</span><br><span class="line">systemctl status kube-scheduler</span><br></pre></td></tr></table></figure>

<h1 id="7-TLS-Bootstrapping配置"><a href="#7-TLS-Bootstrapping配置" class="headerlink" title="7.TLS Bootstrapping配置"></a>7.TLS Bootstrapping配置</h1><h2 id="7-1在master01上配置"><a href="#7-1在master01上配置" class="headerlink" title="7.1在master01上配置"></a>7.1在master01上配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/bootstrap</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">--certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">--embed-certs=true     --server=https://192.168.1.89:8443     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials tls-bootstrap-token-user     \</span><br><span class="line">--token=c8ad9c.2e4d610cf3e7426e \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context tls-bootstrap-token-user@kubernetes     \</span><br><span class="line">--cluster=kubernetes     \</span><br><span class="line">--user=tls-bootstrap-token-user     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context tls-bootstrap-token-user@kubernetes     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">token的位置在bootstrap.secret.yaml，如果修改的话到这个文件修改</span></span><br><span class="line"></span><br><span class="line">mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config</span><br></pre></td></tr></table></figure>

<h2 id="7-2查看集群状态，没问题的话继续后续操作"><a href="#7-2查看集群状态，没问题的话继续后续操作" class="headerlink" title="7.2查看集群状态，没问题的话继续后续操作"></a>7.2查看集群状态，没问题的话继续后续操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line"></span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE                         ERROR</span><br><span class="line">scheduler            Healthy   ok                              </span><br><span class="line">controller-manager   Healthy   ok                              </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125; </span><br><span class="line"></span><br><span class="line">kubectl create -f bootstrap.secret.yaml</span><br></pre></td></tr></table></figure>

<h1 id="8-node节点配置"><a href="#8-node节点配置" class="headerlink" title="8.node节点配置"></a>8.node节点配置</h1><h2 id="8-1-在master01上将证书复制到node节点"><a href="#8-1-在master01上将证书复制到node节点" class="headerlink" title="8.1.在master01上将证书复制到node节点"></a>8.1.在master01上将证书复制到node节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/kubernetes/</span><br><span class="line"> </span><br><span class="line">for NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do ssh $NODE mkdir -p /etc/kubernetes/pki; for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig; do scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h2 id="8-2-kubelet配置"><a href="#8-2-kubelet配置" class="headerlink" title="8.2.kubelet配置"></a>8.2.kubelet配置</h2><h3 id="8-2-1所有k8s节点创建相关目录"><a href="#8-2-1所有k8s节点创建相关目录" class="headerlink" title="8.2.1所有k8s节点创建相关目录"></a>8.2.1所有k8s节点创建相关目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">所有k8s节点配置kubelet service</span><br><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \</span><br><span class="line">    --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">    --config=/etc/kubernetes/kubelet-conf.yml \</span><br><span class="line">    --network-plugin=cni  \</span><br><span class="line">    --cni-conf-dir=/etc/cni/net.d  \</span><br><span class="line">    --cni-bin-dir=/opt/cni/bin  \</span><br><span class="line">    --container-runtime=remote  \</span><br><span class="line">    --runtime-request-timeout=15m  \</span><br><span class="line">    --container-runtime-endpoint=unix:///run/containerd/containerd.sock  \</span><br><span class="line">    --cgroup-driver=systemd \</span><br><span class="line">    --node-labels=node.kubernetes.io/node=&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-2所有k8s节点创建kubelet的配置文件"><a href="#8-2-2所有k8s节点创建kubelet的配置文件" class="headerlink" title="8.2.2所有k8s节点创建kubelet的配置文件"></a>8.2.2所有k8s节点创建kubelet的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-3启动kubelet"><a href="#8-2-3启动kubelet" class="headerlink" title="8.2.3启动kubelet"></a>8.2.3启动kubelet</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">systemctl enable --now kubelet</span><br></pre></td></tr></table></figure>

<h3 id="8-2-4查看集群"><a href="#8-2-4查看集群" class="headerlink" title="8.2.4查看集群"></a>8.2.4查看集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master02   NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master03   NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node01     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node02     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node03     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node04     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node05     NotReady   &lt;none&gt;   14h   v1.23.5</span><br><span class="line">[root@k8s-master01 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="8-3-kube-proxy配置"><a href="#8-3-kube-proxy配置" class="headerlink" title="8.3.kube-proxy配置"></a>8.3.kube-proxy配置</h2><h3 id="8-3-1此配置只在master01操作"><a href="#8-3-1此配置只在master01操作" class="headerlink" title="8.3.1此配置只在master01操作"></a>8.3.1此配置只在master01操作</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/</span><br><span class="line">kubectl -n kube-system create serviceaccount kube-proxy</span><br><span class="line"></span><br><span class="line">kubectl create clusterrolebinding system:kube-proxy \</span><br><span class="line">--clusterrole system:node-proxier \</span><br><span class="line">--serviceaccount kube-system:kube-proxy</span><br><span class="line"></span><br><span class="line">SECRET=$(kubectl -n kube-system get sa/kube-proxy \</span><br><span class="line">    --output=jsonpath=&#x27;&#123;.secrets[0].name&#125;&#x27;)</span><br><span class="line"></span><br><span class="line">JWT_TOKEN=$(kubectl -n kube-system get secret/$SECRET \</span><br><span class="line">--output=jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class="line"></span><br><span class="line">PKI_DIR=/etc/kubernetes/pki</span><br><span class="line">K8S_DIR=/etc/kubernetes</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">--certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">--embed-certs=true \</span><br><span class="line">--server=https://192.168.1.89:8443 \</span><br><span class="line">--kubeconfig=$&#123;K8S_DIR&#125;/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes \</span><br><span class="line">--token=$&#123;JWT_TOKEN&#125; \</span><br><span class="line">--kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes \</span><br><span class="line">--cluster=kubernetes \</span><br><span class="line">--user=kubernetes \</span><br><span class="line">--kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes \</span><br><span class="line">--kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="8-3-2将kubeconfig发送至其他节点"><a href="#8-3-2将kubeconfig发送至其他节点" class="headerlink" title="8.3.2将kubeconfig发送至其他节点"></a>8.3.2将kubeconfig发送至其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig; done</span><br><span class="line"></span><br><span class="line">for NODE in k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig;  done</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3所有k8s节点添加kube-proxy的配置和service文件"><a href="#8-3-3所有k8s节点添加kube-proxy的配置和service文件" class="headerlink" title="8.3.3所有k8s节点添加kube-proxy的配置和service文件"></a>8.3.3所有k8s节点添加kube-proxy的配置和service文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy.yaml \</span><br><span class="line">  --v=2</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4启动kube-proxy"><a href="#8-3-4启动kube-proxy" class="headerlink" title="8.3.4启动kube-proxy"></a>8.3.4启动kube-proxy</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-proxy</span><br></pre></td></tr></table></figure>

<h1 id="9-安装Calico"><a href="#9-安装Calico" class="headerlink" title="9.安装Calico"></a>9.安装Calico</h1><h2 id="9-1以下步骤只在master01操作"><a href="#9-1以下步骤只在master01操作" class="headerlink" title="9.1以下步骤只在master01操作"></a>9.1以下步骤只在master01操作</h2><h3 id="9-1-1更改calico网段"><a href="#9-1-1更改calico网段" class="headerlink" title="9.1.1更改calico网段"></a>9.1.1更改calico网段</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/calico/</span><br><span class="line">sed -i &quot;s#POD_CIDR#172.16.0.0/12#g&quot; calico.yaml</span><br><span class="line">grep &quot;IPV4POOL_CIDR&quot; calico.yaml  -A 1</span><br><span class="line">            - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">              value: &quot;172.16.0.0/12&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建</span></span><br><span class="line"></span><br><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure>

<h3 id="9-1-2查看容器状态"><a href="#9-1-2查看容器状态" class="headerlink" title="9.1.2查看容器状态"></a>9.1.2查看容器状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get pod -A</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-kube-controllers-6f6595874c-nb95g   1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-67dn4                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-79zxj                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-85bsf                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-8trsm                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-dvz72                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-qqzwx                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-node-rngzq                          1/1     Running   0          2m55s</span><br><span class="line">kube-system   calico-node-w8gqp                          1/1     Running   0          2m54s</span><br><span class="line">kube-system   calico-typha-6b6cf8cbdf-2b454              1/1     Running   0          2m55s</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master02   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master03   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node03     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node04     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node05     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h1 id="10-安装CoreDNS"><a href="#10-安装CoreDNS" class="headerlink" title="10.安装CoreDNS"></a>10.安装CoreDNS</h1><h2 id="10-1以下步骤只在master01操作"><a href="#10-1以下步骤只在master01操作" class="headerlink" title="10.1以下步骤只在master01操作"></a>10.1以下步骤只在master01操作</h2><h3 id="10-1-1修改文件"><a href="#10-1-1修改文件" class="headerlink" title="10.1.1修改文件"></a>10.1.1修改文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/CoreDNS/</span><br><span class="line">sed -i &quot;s#KUBEDNS_SERVICE_IP#10.96.0.10#g&quot; coredns.yaml</span><br><span class="line"></span><br><span class="line">cat coredns.yaml | grep clusterIP:</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br></pre></td></tr></table></figure>

<h3 id="10-1-2安装"><a href="#10-1-2安装" class="headerlink" title="10.1.2安装"></a>10.1.2安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  create -f coredns.yaml </span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.apps/coredns created</span><br><span class="line">service/kube-dns created</span><br></pre></td></tr></table></figure>

<h1 id="11-安装Metrics-Server"><a href="#11-安装Metrics-Server" class="headerlink" title="11.安装Metrics Server"></a>11.安装Metrics Server</h1><h2 id="11-1以下步骤只在master01操作"><a href="#11-1以下步骤只在master01操作" class="headerlink" title="11.1以下步骤只在master01操作"></a>11.1以下步骤只在master01操作</h2><h3 id="11-1-1安装Metrics-server"><a href="#11-1-1安装Metrics-server" class="headerlink" title="11.1.1安装Metrics-server"></a>11.1.1安装Metrics-server</h3><p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">安装metrics server</span><br><span class="line">cd /root/Kubernetes/metrics-server/</span><br><span class="line"></span><br><span class="line">kubectl  create -f . </span><br><span class="line"></span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">deployment.apps/metrics-server created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br></pre></td></tr></table></figure>

<h3 id="11-1-2稍等片刻查看状态"><a href="#11-1-2稍等片刻查看状态" class="headerlink" title="11.1.2稍等片刻查看状态"></a>11.1.2稍等片刻查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   154m         1%     1715Mi          21%       </span><br><span class="line">k8s-master02   151m         1%     1274Mi          16%       </span><br><span class="line">k8s-master03   523m         6%     1345Mi          17%       </span><br><span class="line">k8s-node01     84m          1%     671Mi           8%        </span><br><span class="line">k8s-node02     73m          0%     727Mi           9%        </span><br><span class="line">k8s-node03     96m          1%     769Mi           9%        </span><br><span class="line">k8s-node04     68m          0%     673Mi           8%        </span><br><span class="line">k8s-node05     82m          1%     679Mi           8% </span><br></pre></td></tr></table></figure>

<h1 id="12-集群验证"><a href="#12-集群验证" class="headerlink" title="12.集群验证"></a>12.集群验证</h1><h2 id="12-1部署pod资源"><a href="#12-1部署pod资源" class="headerlink" title="12.1部署pod资源"></a>12.1部署pod资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line"></span><br><span class="line">kubectl  get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox   1/1     Running   0          17s</span><br></pre></td></tr></table></figure>

<h2 id="12-2用pod解析默认命名空间中的kubernetes"><a href="#12-2用pod解析默认命名空间中的kubernetes" class="headerlink" title="12.2用pod解析默认命名空间中的kubernetes"></a>12.2用pod解析默认命名空间中的kubernetes</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   17h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl exec  busybox -n default -- nslookup kubernetes</span><br><span class="line">3Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-3测试跨命名空间是否可以解析"><a href="#12-3测试跨命名空间是否可以解析" class="headerlink" title="12.3测试跨命名空间是否可以解析"></a>12.3测试跨命名空间是否可以解析</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl exec  busybox -n default -- nslookup kube-dns.kube-system</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kube-dns.kube-system</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53"><a href="#12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53" class="headerlink" title="12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53"></a>12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">telnet 10.96.0.1 443</span><br><span class="line">Trying 10.96.0.1...</span><br><span class="line">Connected to 10.96.0.1.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line"> telnet 10.96.0.10 53</span><br><span class="line">Trying 10.96.0.10...</span><br><span class="line">Connected to 10.96.0.10.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line">curl 10.96.0.10:53</span><br><span class="line">curl: (52) Empty reply from server</span><br></pre></td></tr></table></figure>

<h2 id="12-5Pod和Pod之前要能通"><a href="#12-5Pod和Pod之前要能通" class="headerlink" title="12.5Pod和Pod之前要能通"></a>12.5Pod和Pod之前要能通</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get po -owide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox   1/1     Running   0          17m   172.27.14.193   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"> kubectl get po -n kube-system -owide</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS      AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-5dffd5886b-4blh6   1/1     Running   0             77m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-fvbdq                          1/1     Running   1 (75m ago)   77m   192.168.1.81     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-g8nqd                          1/1     Running   0             77m   192.168.1.84     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-mdps8                          1/1     Running   0             77m   192.168.1.85     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-nf4nt                          1/1     Running   0             77m   192.168.1.83     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-sq2ml                          1/1     Running   0             77m   192.168.1.82     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-mg6p8              1/1     Running   0             77m   192.168.1.85     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-pxbpj              1/1     Running   0             77m   192.168.1.81     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-tnssl              1/1     Running   0             77m   192.168.1.84     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5db5696c7-67h79                    1/1     Running   0             63m   172.25.92.65     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">metrics-server-6bf7dcd649-5fhrw            1/1     Running   0             61m   172.18.195.1     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入busybox ping其他节点上的pod</span></span><br><span class="line"></span><br><span class="line">kubectl exec -ti busybox -- sh</span><br><span class="line">/ # ping 192.168.1.84</span><br><span class="line">PING 192.168.1.84 (192.168.1.84): 56 data bytes</span><br><span class="line">64 bytes from 192.168.1.84: seq=0 ttl=63 time=0.358 ms</span><br><span class="line">64 bytes from 192.168.1.84: seq=1 ttl=63 time=0.668 ms</span><br><span class="line">64 bytes from 192.168.1.84: seq=2 ttl=63 time=0.637 ms</span><br><span class="line">64 bytes from 192.168.1.84: seq=3 ttl=63 time=0.624 ms</span><br><span class="line">64 bytes from 192.168.1.84: seq=4 ttl=63 time=0.907 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以连通证明这个pod是可以跨命名空间和跨主机通信的</span></span><br></pre></td></tr></table></figure>

<h2 id="12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"><a href="#12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）" class="headerlink" title="12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"></a>12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; deployments.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl  apply -f deployments.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">kubectl  get pod </span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                            1/1     Running   0          6m25s</span><br><span class="line">nginx-deployment-9456bbbf9-4bmvk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-9rcdk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-dqv8s   1/1     Running   0          8s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除nginx</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f deployments.yaml </span><br></pre></td></tr></table></figure>

<h1 id="13-安装dashboard"><a href="#13-安装dashboard" class="headerlink" title="13.安装dashboard"></a>13.安装dashboard</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /root/Kubernetes/dashboard/</span><br><span class="line"></span><br><span class="line">kubectl  create -f .</span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line">namespace/kubernetes-dashboard created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-csrf created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/dashboard-metrics-scraper created</span><br><span class="line">deployment.apps/dashboard-metrics-scraper created</span><br></pre></td></tr></table></figure>

<h2 id="13-1创建管理员用户"><a href="#13-1创建管理员用户" class="headerlink" title="13.1创建管理员用户"></a>13.1创建管理员用户</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; admin.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line"></span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding </span><br><span class="line">metadata: </span><br><span class="line">  name: admin-user</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="13-2执行yaml文件"><a href="#13-2执行yaml文件" class="headerlink" title="13.2执行yaml文件"></a>13.2执行yaml文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f admin.yaml -n kube-system</span><br><span class="line"></span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br></pre></td></tr></table></figure>

<h2 id="13-3更改dashboard的svc为NodePort，如果已是请忽略"><a href="#13-3更改dashboard的svc为NodePort，如果已是请忽略" class="headerlink" title="13.3更改dashboard的svc为NodePort，如果已是请忽略"></a>13.3更改dashboard的svc为NodePort，如果已是请忽略</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure>

<h2 id="13-4查看端口号"><a href="#13-4查看端口号" class="headerlink" title="13.4查看端口号"></a>13.4查看端口号</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.98.201.22   &lt;none&gt;        443:31245/TCP   10m</span><br></pre></td></tr></table></figure>

<h2 id="13-5查看token"><a href="#13-5查看token" class="headerlink" title="13.5查看token"></a>13.5查看token</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;)</span><br><span class="line">Name:         admin-user-token-5vfk4</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: fc2535ae-8760-4037-9026-966f03ab9bf9</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1363 bytes</span><br><span class="line">namespace:  11 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6InVOMnhMdHFTRWxweUlfUm93VmhMZTVXZW1FXzFrT01nQ0dTcE5uYjJlNWMifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTV2Zms0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmYzI1MzVhZS04NzYwLTQwMzctOTAyNi05NjZmMDNhYjliZjkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.HSU1FeqY6pDVoXVIv4Lu27TDhCYHM-FzGsGybYL5QPJ5-P0b3tQqUH9i3AQlisiGPB--jCFT5CUeOeXneOyfV7XkC7frbn6VaQoh51n6ztkIvjUm8Q4xj_LQ2OSFfWlFUnaZsaYTdD-RCldwh63pX362T_FjgDknO4q1wtKZH5qR0mpL1dOjas50gnOSyBY0j-nSPrifhnNq3_GcDLE4LxjuzO1DfGNTEHZ6TojPJ_5ZElMolaYJsVejn2slfeUQEWdiD5AHFZlRd4exODCHyvUhRpzb9jO2rovN2LMqdE_vxBtNgXp19evQB9AgZyMMSmu1Ch2C2UAi4NxjKw8HNA</span><br></pre></td></tr></table></figure>

<h2 id="13-6登录dashboard"><a href="#13-6登录dashboard" class="headerlink" title="13.6登录dashboard"></a>13.6登录dashboard</h2><p><a href="https://192.168.1.81:31245/">https://192.168.1.81:31245/</a></p>
<p>eyJhbGciOiJSUzI1NiIsImtpZCI6InYzV2dzNnQzV3hHb2FQWnYzdnlOSmpudmtpVmNjQW5VM3daRi12SFM4dEEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWs1NDVrIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjMzA4MDcxYy00Y2Y1LTQ1ODMtODNhMi1lYWY3ODEyNTEyYjQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pshvZPi9ZJkXUWuWilcYs1wawTpzV-nMKesgF3d_l7qyTPaK2N5ofzIThd0SjzU7BFNb4_rOm1dw1Be5kLeHjY_YW5lDnM5TAxVPXmZQ0HJ2pAQ0pjQqCHFnPD0bZFIYkeyz8pZx0Hmwcd3ZdC1yztr0ADpTAmMgI9NC2ZFIeoFFo4Ue9ZM_ulhqJQjmgoAlI_qbyjuKCNsWeEQBwM6HHHAsH1gOQIdVxqQ83OQZUuynDQRpqlHHFIndbK2zVRYFA3GgUnTu2-VRQ-DXBFRjvZR5qArnC1f383jmIjGT6VO7l04QJteG_LFetRbXa-T4mcnbsd8XutSgO0INqwKpjw</p>
<h1 id="14-ingress安装"><a href="#14-ingress安装" class="headerlink" title="14.ingress安装"></a>14.ingress安装</h1><h2 id="14-1写入配置文件，并执行"><a href="#14-1写入配置文件，并执行" class="headerlink" title="14.1写入配置文件，并执行"></a>14.1写入配置文件，并执行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim deploy.yaml</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# cat deploy.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-serviceaccount.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">automountServiceAccountToken: true</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-configmap.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">data:</span><br><span class="line">  allow-snippet-annotations: &#x27;true&#x27;</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/clusterrole.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - endpoints</span><br><span class="line">      - nodes</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/clusterrolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-role.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - endpoints</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    resourceNames:</span><br><span class="line">      - ingress-controller-leader</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-rolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-service-webhook.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - name: https-webhook</span><br><span class="line">      port: 443</span><br><span class="line">      targetPort: webhook</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-service.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  externalTrafficPolicy: Local</span><br><span class="line">  ipFamilyPolicy: SingleStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">    - IPv4</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: http</span><br><span class="line">      appProtocol: http</span><br><span class="line">    - name: https</span><br><span class="line">      port: 443</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: https</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-deployment.yaml</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: ingress-nginx</span><br><span class="line">      app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">      app.kubernetes.io/component: controller</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  minReadySeconds: 0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/component: controller</span><br><span class="line">    spec:</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      containers:</span><br><span class="line">        - name: controller</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/controller:v1.1.3 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          lifecycle:</span><br><span class="line">            preStop:</span><br><span class="line">              exec:</span><br><span class="line">                command:</span><br><span class="line">                  - /wait-shutdown</span><br><span class="line">          args:</span><br><span class="line">            - /nginx-ingress-controller</span><br><span class="line">            - --election-id=ingress-controller-leader</span><br><span class="line">            - --controller-class=k8s.io/ingress-nginx</span><br><span class="line">            - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller</span><br><span class="line">            - --validating-webhook=:8443</span><br><span class="line">            - --validating-webhook-certificate=/usr/local/certificates/cert</span><br><span class="line">            - --validating-webhook-key=/usr/local/certificates/key</span><br><span class="line">          securityContext:</span><br><span class="line">            capabilities:</span><br><span class="line">              drop:</span><br><span class="line">                - ALL</span><br><span class="line">              add:</span><br><span class="line">                - NET_BIND_SERVICE</span><br><span class="line">            runAsUser: 101</span><br><span class="line">            allowPrivilegeEscalation: true</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.name</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">            - name: LD_PRELOAD</span><br><span class="line">              value: /usr/local/lib/libmimalloc.so</span><br><span class="line">          livenessProbe:</span><br><span class="line">            failureThreshold: 5</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          readinessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          ports:</span><br><span class="line">            - name: http</span><br><span class="line">              containerPort: 80</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: https</span><br><span class="line">              containerPort: 443</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: webhook</span><br><span class="line">              containerPort: 8443</span><br><span class="line">              protocol: TCP</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: webhook-cert</span><br><span class="line">              mountPath: /usr/local/certificates/</span><br><span class="line">              readOnly: true</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 100m</span><br><span class="line">              memory: 90Mi</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      serviceAccountName: ingress-nginx</span><br><span class="line">      terminationGracePeriodSeconds: 300</span><br><span class="line">      volumes:</span><br><span class="line">        - name: webhook-cert</span><br><span class="line">          secret:</span><br><span class="line">            secretName: ingress-nginx-admission</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-ingressclass.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">We don<span class="string">&#x27;t support namespaced ingressClass yet</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">So a ClusterRole and a ClusterRoleBinding is required</span></span></span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: IngressClass</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  controller: k8s.io/ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/validating-webhook.yaml</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">before changing this value, check the required kubernetes version</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites</span></span></span><br><span class="line">apiVersion: admissionregistration.k8s.io/v1</span><br><span class="line">kind: ValidatingWebhookConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">webhooks:</span><br><span class="line">  - name: validate.nginx.ingress.kubernetes.io</span><br><span class="line">    matchPolicy: Equivalent</span><br><span class="line">    rules:</span><br><span class="line">      - apiGroups:</span><br><span class="line">          - networking.k8s.io</span><br><span class="line">        apiVersions:</span><br><span class="line">          - v1</span><br><span class="line">        operations:</span><br><span class="line">          - CREATE</span><br><span class="line">          - UPDATE</span><br><span class="line">        resources:</span><br><span class="line">          - ingresses</span><br><span class="line">    failurePolicy: Fail</span><br><span class="line">    sideEffects: None</span><br><span class="line">    admissionReviewVersions:</span><br><span class="line">      - v1</span><br><span class="line">    clientConfig:</span><br><span class="line">      service:</span><br><span class="line">        namespace: ingress-nginx</span><br><span class="line">        name: ingress-nginx-controller-admission</span><br><span class="line">        path: /networking/v1/ingresses</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - admissionregistration.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - validatingwebhookconfigurations</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/role.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - create</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-create</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-create</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: create</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - create</span><br><span class="line">            - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-patch</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-patch</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: patch</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - patch</span><br><span class="line">            - --webhook-name=ingress-nginx-admission</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --patch-mutating=false</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">            - --patch-failure-policy=Fail</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="14-2启用后端，写入配置文件执行"><a href="#14-2启用后端，写入配置文件执行" class="headerlink" title="14.2启用后端，写入配置文件执行"></a>14.2启用后端，写入配置文件执行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim backend.yaml</span><br><span class="line">[root@hello ~/yaml]# cat backend.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: default-http-backend</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: default-http-backend</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      containers:</span><br><span class="line">      - name: default-http-backend</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/chenby/defaultbackend-amd64:1.5 </span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /healthz</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="14-3安装测试应用"><a href="#14-3安装测试应用" class="headerlink" title="14.3安装测试应用"></a>14.3安装测试应用</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim ingress-demo-app.yaml</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# cat ingress-demo-app.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello-server</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-server</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-server</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx&quot;  </span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# kubectl  get ingress</span><br><span class="line">NAME               CLASS    HOSTS                            ADDRESS        PORTS   AGE</span><br><span class="line">ingress-demo-app   &lt;none&gt;   app.demo.com                     192.168.1.11   80      20m</span><br><span class="line">ingress-host-bar   nginx    hello.chenby.cn,demo.chenby.cn   192.168.1.11   80      2m17s</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-4执行部署"><a href="#14-4执行部署" class="headerlink" title="14.4执行部署"></a>14.4执行部署</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  apply -f deploy.yaml </span><br><span class="line">namespace/ingress-nginx created</span><br><span class="line">serviceaccount/ingress-nginx created</span><br><span class="line">configmap/ingress-nginx-controller created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/ingress-nginx created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created</span><br><span class="line">role.rbac.authorization.k8s.io/ingress-nginx created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/ingress-nginx created</span><br><span class="line">service/ingress-nginx-controller-admission created</span><br><span class="line">service/ingress-nginx-controller created</span><br><span class="line">deployment.apps/ingress-nginx-controller created</span><br><span class="line">ingressclass.networking.k8s.io/nginx created</span><br><span class="line">validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created</span><br><span class="line">serviceaccount/ingress-nginx-admission created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created</span><br><span class="line">role.rbac.authorization.k8s.io/ingress-nginx-admission created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created</span><br><span class="line">job.batch/ingress-nginx-admission-create created</span><br><span class="line">job.batch/ingress-nginx-admission-patch created</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  apply -f backend.yaml </span><br><span class="line">deployment.apps/default-http-backend created</span><br><span class="line">service/default-http-backend created</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  apply -f ingress-demo-app.yaml </span><br><span class="line">deployment.apps/hello-server created</span><br><span class="line">deployment.apps/nginx-demo created</span><br><span class="line">service/nginx-demo created</span><br><span class="line">service/hello-server created</span><br><span class="line">ingress.networking.k8s.io/ingress-host-bar created</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-5过滤查看ingress端口"><a href="#14-5过滤查看ingress端口" class="headerlink" title="14.5过滤查看ingress端口"></a>14.5过滤查看ingress端口</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  get svc -A | grep ingress</span><br><span class="line">default         ingress-demo-app                     ClusterIP   10.68.231.41    &lt;none&gt;        80/TCP                       51m</span><br><span class="line">ingress-nginx   ingress-nginx-controller             NodePort    10.68.93.71     &lt;none&gt;        80:32746/TCP,443:30538/TCP   32m</span><br><span class="line">ingress-nginx   ingress-nginx-controller-admission   ClusterIP   10.68.146.23    &lt;none&gt;        443/TCP                      32m</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="15-安装命令行自动补全功能"><a href="#15-安装命令行自动补全功能" class="headerlink" title="15.安装命令行自动补全功能"></a>15.安装命令行自动补全功能</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install bash-completion -y</span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>

<h1 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h1><p>配置kube-controller-manager有效期100年（能不能生效的先配上再说）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">[Service]下找个地方加上</span></span><br><span class="line"></span><br><span class="line">--cluster-signing-duration=876000h0m0s \</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启</span></span><br><span class="line"></span><br><span class="line">systemctl daemon-reload </span><br><span class="line">systemctl restart kube-controller-manager</span><br></pre></td></tr></table></figure>

<p>防止漏洞扫描</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf</span><br><span class="line"></span><br><span class="line">[Service] </span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--kubeconfig=/etc/kubernetes/kubelet.kubeconfig --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig&quot; </span><br><span class="line">Environment=&quot;KUBELET_SYSTEM_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin&quot; </span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml  --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&quot; </span><br><span class="line">Environment=&quot;KUBELET_EXTRA_ARGS=--tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384    --image-pull-progress-deadline=30m&quot; </span><br><span class="line">ExecStart= </span><br><span class="line">ExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_SYSTEM_ARGS $KUBELET_EXTRA_ARGS </span><br></pre></td></tr></table></figure>

<p>预留空间，按需分配</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/kubernetes/kubelet-conf.yml</span><br><span class="line"></span><br><span class="line">rotateServerCertificates: true</span><br><span class="line">allowedUnsafeSysctls:</span><br><span class="line"></span><br><span class="line"> - &quot;net.core*&quot;</span><br><span class="line"> - &quot;net.ipv4.*&quot;</span><br><span class="line">   kubeReserved:</span><br><span class="line">     cpu: &quot;1&quot;</span><br><span class="line">     memory: 1Gi</span><br><span class="line">     ephemeral-storage: 10Gi</span><br><span class="line">   systemReserved:</span><br><span class="line">     cpu: &quot;1&quot;</span><br><span class="line">     memory: 1Gi</span><br><span class="line">     ephemeral-storage: 10Gi</span><br></pre></td></tr></table></figure>

<p>数据盘要与系统盘分开；etcd使用ssd磁盘</p>
<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a>   </p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a>  </p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a>  </p>
<p> <a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a>  </p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a>  </p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a>  </p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a>  </p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a>  </p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a>  </p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a>  </p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>使用Kubernetes快速启用一个静态页面</title>
    <url>/2022/04/28/2022-04-28-%E4%BD%BF%E7%94%A8Kubernetes%E5%BF%AB%E9%80%9F%E5%90%AF%E7%94%A8%E4%B8%80%E4%B8%AA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2/</url>
    <content><![CDATA[<h1 id="使用Kubernetes快速启用一个静态页面"><a href="#使用Kubernetes快速启用一个静态页面" class="headerlink" title="使用Kubernetes快速启用一个静态页面"></a>使用Kubernetes快速启用一个静态页面</h1><p>将html静态页面放置在nfs目录下，通过Deployment启动时挂在到nginx页面目录即可</p>
<h1 id="查看yaml内容"><a href="#查看yaml内容" class="headerlink" title="查看yaml内容"></a>查看yaml内容</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# cat cby.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: chenby</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: chenby</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: chenby</span><br><span class="line">        image: nginx</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: &quot;128Mi&quot;</span><br><span class="line">            cpu: &quot;500m&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cby-nfs</span><br><span class="line">          mountPath: /usr/share/nginx/html/</span><br><span class="line">      volumes:</span><br><span class="line">      - name: cby-nfs</span><br><span class="line">        nfs:</span><br><span class="line">          server: 192.168.1.123</span><br><span class="line">          path: /cby-3/nfs/html</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: chenby</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="查看验证"><a href="#查看验证" class="headerlink" title="查看验证"></a>查看验证</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl  get deployments.apps  chenby  -o wide</span><br><span class="line">NAME     READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES   SELECTOR</span><br><span class="line">chenby   3/3     3            3           4m44s   chenby       nginx    app=chenby</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  get pod -o wide | grep chenby</span><br><span class="line">chenby-77b57649c7-qv2ps                  1/1     Running   0          5m2s   172.17.125.19    k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">chenby-77b57649c7-rx98c                  1/1     Running   0          5m2s   172.25.214.207   k8s-node03     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">chenby-77b57649c7-tx2dz                  1/1     Running   0          5m2s   172.25.244.209   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  get svc -o wide | grep chenby</span><br><span class="line">chenby                NodePort    10.109.222.0    &lt;none&gt;        80:30971/TCP   5m8s   app=chenby</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="演示"><a href="#演示" class="headerlink" title="演示"></a>演示</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/05b307afd22544ef86046268b812fae4~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>在线体验：  </p>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a></p>
<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>Kubernetes（k8s）实现IPv4/IPv6网络双栈</title>
    <url>/2022/04/29/2022-04-29-Kubernetes%EF%BC%88k8s%EF%BC%89%E5%AE%9E%E7%8E%B0IPv4_IPv6%E7%BD%91%E7%BB%9C%E5%8F%8C%E6%A0%88/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>如今IPv4IP地址已经使用完毕，未来全球会以IPv6地址为中心，会大力发展IPv6网络环境，由于IPv6可以实现给任何一个设备分配到公网IP，所以资源是非常丰富的。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/95a7066334c9422fb9f4f160b23b8f57~tplv-k3u1fbpfcp-zoom-1.image"></p>
<h1 id="配置hosts"><a href="#配置hosts" class="headerlink" title="配置hosts"></a>配置hosts</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# vim /etc/hosts</span><br><span class="line">[root@k8s-master01 ~]# cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">2408:8207:78ce:7561::10 k8s-master01</span><br><span class="line">2408:8207:78ce:7561::20 k8s-master02</span><br><span class="line">2408:8207:78ce:7561::30 k8s-master03</span><br><span class="line">2408:8207:78ce:7561::40 k8s-node01</span><br><span class="line">2408:8207:78ce:7561::50 k8s-node02</span><br><span class="line">2408:8207:78ce:7561::60 k8s-node03</span><br><span class="line">2408:8207:78ce:7561::70 k8s-node04</span><br><span class="line">2408:8207:78ce:7561::80 k8s-node05</span><br><span class="line"></span><br><span class="line">10.0.0.81 k8s-master01</span><br><span class="line">10.0.0.82 k8s-master02</span><br><span class="line">10.0.0.83 k8s-master03</span><br><span class="line">10.0.0.84 k8s-node01</span><br><span class="line">10.0.0.85 k8s-node02</span><br><span class="line">10.0.0.86 k8s-node03</span><br><span class="line">10.0.0.87 k8s-node04</span><br><span class="line">10.0.0.88 k8s-node05</span><br><span class="line">10.0.0.80 lb01</span><br><span class="line">10.0.0.90 lb02</span><br><span class="line">10.0.0.99 lb-vip</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="配置ipv6地址"><a href="#配置ipv6地址" class="headerlink" title="配置ipv6地址"></a>配置ipv6地址</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens160 </span><br><span class="line">[root@k8s-master01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens160</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY_METHOD=none</span><br><span class="line">BROWSER_ONLY=no</span><br><span class="line">BOOTPROTO=none</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=no</span><br><span class="line">IPV6INIT=yes</span><br><span class="line">IPV6_AUTOCONF=no</span><br><span class="line">IPV6ADDR=2408:8207:78ce:7561::10/64</span><br><span class="line">IPV6_DEFAULTGW=2408:8207:78ce:7561::1</span><br><span class="line">IPV6_DEFROUTE=yes</span><br><span class="line">IPV6_FAILURE_FATAL=no</span><br><span class="line">NAME=ens160</span><br><span class="line">UUID=56ca7c8c-21c6-484f-acbd-349111b3ddb5</span><br><span class="line">DEVICE=ens160</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=10.0.0.81</span><br><span class="line">PREFIX=24</span><br><span class="line">GATEWAY=10.0.0.1</span><br><span class="line">DNS1=8.8.8.8</span><br><span class="line">DNS2=2408:8000:1010:1::8</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意：每一台主机都需要配置为静态IPv6地址！若不进行配置，在内核中开启IPv6数据包转发功能后会出现IPv6异常。</p>
<h1 id="sysctl参数启用ipv6"><a href="#sysctl参数启用ipv6" class="headerlink" title="sysctl参数启用ipv6"></a>sysctl参数启用ipv6</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# vim /etc/sysctl.d/k8s.conf</span><br><span class="line">[root@k8s-master01 ~]# cat /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.all.forwarding = 1</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line">[root@k8s-master01 ~]# reboot</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="测试访问公网IPv6"><a href="#测试访问公网IPv6" class="headerlink" title="测试访问公网IPv6"></a>测试访问公网IPv6</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# ping www.chenby.cn -6</span><br><span class="line">PING www.chenby.cn(2408:871a:5100:119:1d:: (2408:871a:5100:119:1d::)) 56 data bytes</span><br><span class="line">64 bytes from 2408:871a:5100:119:1d:: (2408:871a:5100:119:1d::): icmp_seq=1 ttl=53 time=10.6 ms</span><br><span class="line">64 bytes from 2408:871a:5100:119:1d:: (2408:871a:5100:119:1d::): icmp_seq=2 ttl=53 time=9.94 ms</span><br><span class="line">^C</span><br><span class="line">--- www.chenby.cn ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 1002ms</span><br><span class="line">rtt min/avg/max/mdev = 9.937/10.269/10.602/0.347 ms</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="修改kube-apiserver如下配置"><a href="#修改kube-apiserver如下配置" class="headerlink" title="修改kube-apiserver如下配置"></a>修改kube-apiserver如下配置</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--service-cluster-ip-range=10.96.0.0/12,fd00::/108  </span><br><span class="line">--feature-gates=IPv6DualStack=true </span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# vim /usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[root@k8s-master01 ~]# cat /usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --insecure-port=0  \</span><br><span class="line">      --advertise-address=192.168.1.81 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">      --feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://192.168.1.81:2379,https://192.168.1.82:2379,https://192.168.1.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="修改kube-controller-manager如下配置"><a href="#修改kube-controller-manager如下配置" class="headerlink" title="修改kube-controller-manager如下配置"></a>修改kube-controller-manager如下配置</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--feature-gates=IPv6DualStack=true</span><br><span class="line">--service-cluster-ip-range=10.96.0.0/12,fd00::/108</span><br><span class="line">--cluster-cidr=172.16.0.0/12,fc00::/48</span><br><span class="line">--node-cidr-mask-size-ipv4=24</span><br><span class="line">--node-cidr-mask-size-ipv6=64</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# vim /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[root@k8s-master01 ~]# cat /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --address=127.0.0.1 \</span><br><span class="line">      --root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --use-service-account-credentials=true \</span><br><span class="line">      --node-monitor-grace-period=40s \</span><br><span class="line">      --node-monitor-period=5s \</span><br><span class="line">      --pod-eviction-timeout=2m0s \</span><br><span class="line">      --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">      --allocate-node-cidrs=true \</span><br><span class="line">      --feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108 \</span><br><span class="line">      --cluster-cidr=172.16.0.0/12,fc00::/48 \</span><br><span class="line">      --node-cidr-mask-size-ipv4=24 \</span><br><span class="line">      --node-cidr-mask-size-ipv6=64 \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem \</span><br><span class="line">      --node-cidr-mask-size=24</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="修改kubelet如下配置"><a href="#修改kubelet如下配置" class="headerlink" title="修改kubelet如下配置"></a>修改kubelet如下配置</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--feature-gates=IPv6DualStack=true</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# vim /usr/lib/systemd/system/kubelet.service</span><br><span class="line">[root@k8s-master01 ~]# cat /usr/lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \</span><br><span class="line">    --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">    --config=/etc/kubernetes/kubelet-conf.yml \</span><br><span class="line">    --network-plugin=cni  \</span><br><span class="line">    --cni-conf-dir=/etc/cni/net.d  \</span><br><span class="line">    --cni-bin-dir=/opt/cni/bin  \</span><br><span class="line">    --container-runtime=remote  \</span><br><span class="line">    --runtime-request-timeout=15m  \</span><br><span class="line">    --container-runtime-endpoint=unix:///run/containerd/containerd.sock  \</span><br><span class="line">    --cgroup-driver=systemd \</span><br><span class="line">    --node-labels=node.kubernetes.io/node=&#x27;&#x27; \</span><br><span class="line">    --feature-gates=IPv6DualStack=true</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="修改kube-apiserver如下配置-1"><a href="#修改kube-apiserver如下配置-1" class="headerlink" title="修改kube-apiserver如下配置"></a>修改kube-apiserver如下配置</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">修改如下配置</span></span><br><span class="line">clusterCIDR: 172.16.0.0/12,fc00::/48 </span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# vim /etc/kubernetes/kube-proxy.yaml</span><br><span class="line">[root@k8s-master01 ~]# cat /etc/kubernetes/kube-proxy.yaml</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12,fc00::/48 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="修改calico如下配置"><a href="#修改calico如下配置" class="headerlink" title="修改calico如下配置"></a>修改calico如下配置</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> vim calico.yaml</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> calico-config ConfigMap处</span></span><br><span class="line">    &quot;ipam&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;calico-ipam&quot;,</span><br><span class="line">        &quot;assign_ipv4&quot;: &quot;true&quot;,</span><br><span class="line">        &quot;assign_ipv6&quot;: &quot;true&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    - name: IP</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: IP6</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">      value: &quot;172.16.0.0/16&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV6POOL_CIDR</span><br><span class="line">      value: &quot;fc00::/48&quot;</span><br><span class="line"></span><br><span class="line">    - name: FELIX_IPV6SUPPORT</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> kubectl apply -f calico.yaml</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">部署应用</span></span><br><span class="line">[root@k8s-master01 ~]# cat cby.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: chenby</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: chenby</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: chenby</span><br><span class="line">        image: nginx</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: &quot;128Mi&quot;</span><br><span class="line">            cpu: &quot;500m&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  ipFamilyPolicy: PreferDualStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">  - IPv6</span><br><span class="line">  - IPv4</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: chenby</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">[root@k8s-master01 ~]# kubectl  apply -f cby.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看端口</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl  get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">chenby       NodePort    fd00::d80a   &lt;none&gt;        80:31535/TCP   54s</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP        22h</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用内网访问</span></span><br><span class="line">[root@k8s-master01 ~]# curl -I http://[fd00::d80a]</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Fri, 29 Apr 2022 07:29:28 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用公网访问</span></span><br><span class="line">[root@k8s-master01 ~]# curl -I http://[2408:8207:78ce:7561::10]:31535</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Fri, 29 Apr 2022 07:25:16 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# curl -I http://10.0.0.81:31535</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Fri, 29 Apr 2022 07:26:16 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d8de32581aaf4257987ed41a29ed55e4~tplv-k3u1fbpfcp-zoom-1.image"></p>
<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装Kubernetes（k8s） v1.24.0 IPv4/IPv6双栈</title>
    <url>/2022/05/05/2022-05-05-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85Kubernetes%EF%BC%88k8s%EF%BC%89_v1.24.0_IPv4_IPv6%E5%8F%8C%E6%A0%88/</url>
    <content><![CDATA[<h1 id="二进制安装Kubernetes（k8s）-v1-24-0-IPv4-x2F-IPv6双栈"><a href="#二进制安装Kubernetes（k8s）-v1-24-0-IPv4-x2F-IPv6双栈" class="headerlink" title="二进制安装Kubernetes（k8s） v1.24.0 IPv4&#x2F;IPv6双栈"></a>二进制安装Kubernetes（k8s） v1.24.0 IPv4&#x2F;IPv6双栈</h1><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>kubernetes二进制安装</p>
<p>1.23.3 和 1.23.4 和 1.23.5 和 1.23.6 和 1.24.0 文档以及安装包已生成。</p>
<p>后续尽可能第一时间更新新版本文档</p>
<p><a href="https://github.com/cby-chen/Kubernetes/releases">https://github.com/cby-chen/Kubernetes/releases</a></p>
<p>手动项目地址：<a href="https://github.com/cby-chen/Kubernetes">https://github.com/cby-chen/Kubernetes</a></p>
<p>脚本项目地址：<a href="https://github.com/cby-chen/Binary_installation_of_Kubernetes">https://github.com/cby-chen/Binary_installation_of_Kubernetes</a></p>
<p>kubernetes 1.24 变化较大，详细见：<a href="https://kubernetes.io/zh/blog/2022/04/07/upcoming-changes-in-kubernetes-1-24/">https://kubernetes.io/zh/blog/2022/04/07/upcoming-changes-in-kubernetes-1-24/</a></p>
<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1.环境"></a>1.环境</h1><table>
<thead>
<tr>
<th>主机名称</th>
<th>IP地址</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td>Master01</td>
<td>10.0.0.81</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master02</td>
<td>10.0.0.82</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master03</td>
<td>10.0.0.83</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node01</td>
<td>10.0.0.84</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node02</td>
<td>10.0.0.85</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node03</td>
<td>10.0.0.86</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node04</td>
<td>10.0.0.87</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node05</td>
<td>10.0.0.88</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Lb01</td>
<td>10.0.0.80</td>
<td>Lb01节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td>Lb02</td>
<td>10.0.0.90</td>
<td>Lb02节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td></td>
<td>10.0.0.89</td>
<td>VIP</td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">软件</th>
<th align="left">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">内核</td>
<td align="left">5.17.5-1.el8.elrepo</td>
</tr>
<tr>
<td align="left">CentOS 8</td>
<td align="left">v8 或者 v7</td>
</tr>
<tr>
<td align="left">kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy</td>
<td align="left">v1.24.0</td>
</tr>
<tr>
<td align="left">etcd</td>
<td align="left">v3.5.4</td>
</tr>
<tr>
<td align="left">containerd</td>
<td align="left">v1.5.11</td>
</tr>
<tr>
<td align="left">cfssl</td>
<td align="left">v1.6.1</td>
</tr>
<tr>
<td align="left">cni</td>
<td align="left">v1.1.1</td>
</tr>
<tr>
<td align="left">crictl</td>
<td align="left">v1.23.0</td>
</tr>
<tr>
<td align="left">haproxy</td>
<td align="left">v1.8.27</td>
</tr>
<tr>
<td align="left">keepalived</td>
<td align="left">v2.1.5</td>
</tr>
</tbody></table>
<p>网段</p>
<p>物理主机：10.0.0.0&#x2F;24</p>
<p>service：10.96.0.0&#x2F;12</p>
<p>pod：172.16.0.0&#x2F;12</p>
<p>建议k8s集群与etcd集群分开安装</p>
<p>安装包已经整理好：<a href="https://github.com/cby-chen/Kubernetes/releases/download/v1.24.0/kubernetes-v1.24.0.tar">https://github.com/cby-chen/Kubernetes/releases/download/v1.24.0/kubernetes-v1.24.0.tar</a></p>
<h2 id="1-1-k8s基础系统环境配置"><a href="#1-1-k8s基础系统环境配置" class="headerlink" title="1.1.k8s基础系统环境配置"></a>1.1.k8s基础系统环境配置</h2><h3 id="1-2-配置IP"><a href="#1-2-配置IP" class="headerlink" title="1.2.配置IP"></a>1.2.配置IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@10.0.0.143 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.81/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.130 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.82/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.191 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.83/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.154 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.84/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.172 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.85/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.134 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.86/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.167 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.87/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.183 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.88/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.249 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.80/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.128 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.90/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ssh root@10.0.0.81 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::10; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.82 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::20; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.83 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::30; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.84 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::40; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.85 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::50; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.86 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::60; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.87 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::70; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.88 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::80; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.80 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::90; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.90 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ce:7561::100; nmcli con mod ens160 ipv6.gateway 2408:8207:78ce:7561::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="1-3-设置主机名"><a href="#1-3-设置主机名" class="headerlink" title="1.3.设置主机名"></a>1.3.设置主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-master02</span><br><span class="line">hostnamectl set-hostname k8s-master03</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br><span class="line">hostnamectl set-hostname k8s-node03</span><br><span class="line">hostnamectl set-hostname k8s-node04</span><br><span class="line">hostnamectl set-hostname k8s-node05</span><br><span class="line">hostnamectl set-hostname lb01</span><br><span class="line">hostnamectl set-hostname lb02</span><br></pre></td></tr></table></figure>

<h3 id="1-4-配置yum源"><a href="#1-4-配置yum源" class="headerlink" title="1.4.配置yum源"></a>1.4.配置yum源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 7</span></span><br><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 8</span></span><br><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于私有仓库</span></span><br><span class="line">sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; -e &#x27;s|^#baseurl=http://mirror.centos.org/\$contentdir|baseurl=http://10.0.0.123/centos|g&#x27; -i.bak  /etc/yum.repos.d/CentOS-*.repo</span><br></pre></td></tr></table></figure>

<h3 id="1-5-安装一些必备工具"><a href="#1-5-安装一些必备工具" class="headerlink" title="1.5.安装一些必备工具"></a>1.5.安装一些必备工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install wget jq psmisc vim net-tools nfs-utils telnet yum-utils device-mapper-persistent-data lvm2 git network-scripts tar curl -y</span><br></pre></td></tr></table></figure>

<h3 id="1-6-选择性下载需要工具"><a href="#1-6-选择性下载需要工具" class="headerlink" title="1.6.选择性下载需要工具"></a>1.6.选择性下载需要工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1.下载kubernetes1.24.+的二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md</span><br><span class="line"></span><br><span class="line">wget https://dl.k8s.io/v1.24.0/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">2.下载etcdctl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/etcd-io/etcd/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.5.4/etcd-v3.5.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">3.docker-ce二进制包下载地址</span><br><span class="line">二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><br><span class="line"></span><br><span class="line">这里需要下载20.10.+版本</span><br><span class="line"></span><br><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-20.10.14.tgz</span><br><span class="line"></span><br><span class="line">4.containerd二进制包下载</span><br><span class="line">github下载地址：https://github.com/containerd/containerd/releases</span><br><span class="line"></span><br><span class="line">containerd下载时下载带cni插件的二进制包。</span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">5.下载cfssl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/cloudflare/cfssl/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.1_linux_amd64</span><br><span class="line"></span><br><span class="line">6.cni插件下载</span><br><span class="line">github下载地址：https://github.com/containernetworking/plugins/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span><br><span class="line"></span><br><span class="line">7.crictl客户端二进制下载</span><br><span class="line">github下载：https://github.com/kubernetes-sigs/cri-tools/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.23.0/crictl-v1.23.0-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="1-7-关闭防火墙"><a href="#1-7-关闭防火墙" class="headerlink" title="1.7.关闭防火墙"></a>1.7.关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br></pre></td></tr></table></figure>

<h3 id="1-8-关闭SELinux"><a href="#1-8-关闭SELinux" class="headerlink" title="1.8.关闭SELinux"></a>1.8.关闭SELinux</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure>

<h3 id="1-9-关闭交换分区"><a href="#1-9-关闭交换分区" class="headerlink" title="1.9.关闭交换分区"></a>1.9.关闭交换分区</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line"></span><br><span class="line">cat /etc/fstab</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>

<h3 id="1-10-关闭NetworkManager-并启用-network-lb除外"><a href="#1-10-关闭NetworkManager-并启用-network-lb除外" class="headerlink" title="1.10.关闭NetworkManager 并启用 network (lb除外)"></a>1.10.关闭NetworkManager 并启用 network (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now NetworkManager</span><br><span class="line">systemctl start network &amp;&amp; systemctl enable network</span><br></pre></td></tr></table></figure>

<h3 id="1-11-进行时间同步-lb除外"><a href="#1-11-进行时间同步-lb除外" class="headerlink" title="1.11.进行时间同步 (lb除外)"></a>1.11.进行时间同步 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">服务端</span></span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">cat &gt; /etc/chrony.conf &lt;&lt; EOF </span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">allow 10.0.0.0/24</span><br><span class="line">local stratum 10</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd</span><br><span class="line">systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">客户端</span></span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool 10.0.0.81 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">客户端安装一条命令</span></span><br><span class="line">yum install chrony -y ; sed -i &quot;s#2.centos.pool.ntp.org#10.0.0.81#g&quot; /etc/chrony.conf ; systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用客户端进行验证</span></span><br><span class="line">chronyc sources -v</span><br></pre></td></tr></table></figure>

<h3 id="1-12-配置ulimit"><a href="#1-12-配置ulimit" class="headerlink" title="1.12.配置ulimit"></a>1.12.配置ulimit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -SHn 65535</span><br><span class="line">cat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOF</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* seft memlock unlimited</span><br><span class="line">* hard memlock unlimitedd</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="1-13-配置免密登录"><a href="#1-13-配置免密登录" class="headerlink" title="1.13.配置免密登录"></a>1.13.配置免密登录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br><span class="line">ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;</span><br><span class="line">export IP=&quot;10.0.0.81 10.0.0.82 10.0.0.83 10.0.0.84 10.0.0.85 10.0.0.86 10.0.0.87 10.0.0.88 10.0.0.80 10.0.0.90&quot;</span><br><span class="line">export SSHPASS=123123</span><br><span class="line">for HOST in $IP;do</span><br><span class="line">     sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $HOST</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="1-14-添加启用源-lb除外"><a href="#1-14-添加启用源-lb除外" class="headerlink" title="1.14.添加启用源 (lb除外)"></a>1.14.添加启用源 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为 RHEL-8或 CentOS-8配置源</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为 RHEL-7 SL-7 或 CentOS-7 安装 ELRepo</span> </span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看可用安装包</span></span><br><span class="line">yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available</span><br></pre></td></tr></table></figure>

<h3 id="1-15-升级内核至4-18版本以上-lb除外"><a href="#1-15-升级内核至4-18版本以上-lb除外" class="headerlink" title="1.15.升级内核至4.18版本以上 (lb除外)"></a>1.15.升级内核至4.18版本以上 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装最新的内核</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我这里选择的是稳定版kernel-ml   如需更新长期维护版本kernel-lt</span>  </span><br><span class="line">yum  --enablerepo=elrepo-kernel  install  kernel-ml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看已安装那些内核</span></span><br><span class="line">rpm -qa | grep kernel</span><br><span class="line">kernel-core-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-core-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-ml-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-modules-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-libs-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-modules-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看默认内核</span></span><br><span class="line">grubby --default-kernel</span><br><span class="line">/boot/vmlinuz-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">若不是最新的使用命令设置</span></span><br><span class="line">grubby --set-default /boot/vmlinuz-「您的内核版本」.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启生效</span></span><br><span class="line">reboot</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">v8 整合命令为：</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --default-kernel ; reboot</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">v7 整合命令为：</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --set-default \$(ls /boot/vmlinuz-* | grep elrepo) ; grubby --default-kernel</span><br></pre></td></tr></table></figure>

<h3 id="1-16-安装ipvsadm-lb除外"><a href="#1-16-安装ipvsadm-lb除外" class="headerlink" title="1.16.安装ipvsadm (lb除外)"></a>1.16.安装ipvsadm (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;EOF </span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">ip_tables</span><br><span class="line">ip_set</span><br><span class="line">xt_set</span><br><span class="line">ipt_set</span><br><span class="line">ipt_rpfilter</span><br><span class="line">ipt_REJECT</span><br><span class="line">ipip</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart systemd-modules-load.service</span><br><span class="line"></span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack</span><br><span class="line">ip_vs_sh               16384  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          176128  1 ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure>

<h3 id="1-17-修改内核参数-lb除外"><a href="#1-17-修改内核参数-lb除外" class="headerlink" title="1.17.修改内核参数 (lb除外)"></a>1.17.修改内核参数 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line"></span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.all.forwarding = 1</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="1-18-所有节点配置hosts本地解析"><a href="#1-18-所有节点配置hosts本地解析" class="headerlink" title="1.18.所有节点配置hosts本地解析"></a>1.18.所有节点配置hosts本地解析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">2408:8207:78ce:7561::10 k8s-master01</span><br><span class="line">2408:8207:78ce:7561::20 k8s-master02</span><br><span class="line">2408:8207:78ce:7561::30 k8s-master03</span><br><span class="line">2408:8207:78ce:7561::40 k8s-node01</span><br><span class="line">2408:8207:78ce:7561::50 k8s-node02</span><br><span class="line">2408:8207:78ce:7561::60 k8s-node03</span><br><span class="line">2408:8207:78ce:7561::70 k8s-node04</span><br><span class="line">2408:8207:78ce:7561::80 k8s-node05</span><br><span class="line">2408:8207:78ce:7561::90 lb01</span><br><span class="line">2408:8207:78ce:7561::100 lb02</span><br><span class="line"></span><br><span class="line">10.0.0.81 k8s-master01</span><br><span class="line">10.0.0.82 k8s-master02</span><br><span class="line">10.0.0.83 k8s-master03</span><br><span class="line">10.0.0.84 k8s-node01</span><br><span class="line">10.0.0.85 k8s-node02</span><br><span class="line">10.0.0.86 k8s-node03</span><br><span class="line">10.0.0.87 k8s-node04</span><br><span class="line">10.0.0.88 k8s-node05</span><br><span class="line">10.0.0.80 lb01</span><br><span class="line">10.0.0.90 lb02</span><br><span class="line">10.0.0.89 lb-vip</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="2-k8s基本组件安装"><a href="#2-k8s基本组件安装" class="headerlink" title="2.k8s基本组件安装"></a>2.k8s基本组件安装</h1><h2 id="2-1-所有k8s节点安装Containerd作为Runtime"><a href="#2-1-所有k8s节点安装Containerd作为Runtime" class="headerlink" title="2.1.所有k8s节点安装Containerd作为Runtime"></a>2.1.所有k8s节点安装Containerd作为Runtime</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建cni插件所需目录</span></span><br><span class="line">mkdir -p /etc/cni/net.d /opt/cni/bin </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压cni二进制包</span></span><br><span class="line">tar xf cni-plugins-linux-amd64-v1.1.1.tgz -C /opt/cni/bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar -C / -xzf cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建服务启动文件</span></span><br><span class="line">cat &gt; /etc/systemd/system/containerd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=containerd container runtime</span><br><span class="line">Documentation=https://containerd.io</span><br><span class="line">After=network.target local-fs.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=-/sbin/modprobe overlay</span><br><span class="line">ExecStart=/usr/local/bin/containerd</span><br><span class="line">Type=notify</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">TasksMax=infinity</span><br><span class="line">OOMScoreAdjust=-999</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-1配置Containerd所需的模块"><a href="#2-1-1配置Containerd所需的模块" class="headerlink" title="2.1.1配置Containerd所需的模块"></a>2.1.1配置Containerd所需的模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2加载模块"><a href="#2-1-2加载模块" class="headerlink" title="2.1.2加载模块"></a>2.1.2加载模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl restart systemd-modules-load.service</span><br></pre></td></tr></table></figure>

<h3 id="2-1-3配置Containerd所需的内核"><a href="#2-1-3配置Containerd所需的内核" class="headerlink" title="2.1.3配置Containerd所需的内核"></a>2.1.3配置Containerd所需的内核</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载内核</span></span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4创建Containerd的配置文件"><a href="#2-1-4创建Containerd的配置文件" class="headerlink" title="2.1.4创建Containerd的配置文件"></a>2.1.4创建Containerd的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改Containerd的配置文件</span><br><span class="line">sed -i &quot;s#SystemdCgroup\ \=\ false#SystemdCgroup\ \=\ true#g&quot; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">cat /etc/containerd/config.toml | grep SystemdCgroup</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到containerd.runtimes.runc.options，在其下加入SystemdCgroup = <span class="literal">true</span></span></span><br><span class="line"></span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">              SystemdCgroup = true</span><br><span class="line">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sandbox_image默认地址改为符合版本地址</span></span><br><span class="line"></span><br><span class="line">    sandbox_image = &quot;registry.cn-hangzhou.aliyuncs.com/chenby/pause:3.6&quot;</span><br></pre></td></tr></table></figure>

<h3 id="2-1-5启动并设置为开机启动"><a href="#2-1-5启动并设置为开机启动" class="headerlink" title="2.1.5启动并设置为开机启动"></a>2.1.5启动并设置为开机启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now containerd</span><br></pre></td></tr></table></figure>

<h3 id="2-1-6配置crictl客户端连接的运行时位置"><a href="#2-1-6配置crictl客户端连接的运行时位置" class="headerlink" title="2.1.6配置crictl客户端连接的运行时位置"></a>2.1.6配置crictl客户端连接的运行时位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.23.0/crictl-v1.23.0-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar xf crictl-v1.23.0-linux-amd64.tar.gz -C /usr/bin/</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">生成配置文件</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/crictl.yaml &lt;&lt;EOF</span><br><span class="line">runtime-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">image-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">timeout: 10</span><br><span class="line">debug: false</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">测试</span></span><br><span class="line">systemctl restart  containerd</span><br><span class="line">crictl info</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2-2-k8s与etcd下载及安装（仅在master01操作）"><a href="#2-2-k8s与etcd下载及安装（仅在master01操作）" class="headerlink" title="2.2.k8s与etcd下载及安装（仅在master01操作）"></a>2.2.k8s与etcd下载及安装（仅在master01操作）</h2><h3 id="2-2-1解压k8s安装包"><a href="#2-2-1解压k8s安装包" class="headerlink" title="2.2.1解压k8s安装包"></a>2.2.1解压k8s安装包</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压k8s安装文件</span></span><br><span class="line">cd cby</span><br><span class="line">tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压etcd安装文件</span></span><br><span class="line">tar -xf etcd-v3.5.4-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.4-linux-amd64/etcd&#123;,ctl&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看/usr/local/bin下内容</span></span><br><span class="line"></span><br><span class="line">ls /usr/local/bin/</span><br><span class="line">etcd  etcdctl  kube-apiserver  kube-controller-manager  kubectl  kubelet  kube-proxy  kube-scheduler</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-2-2查看版本"><a href="#2-2-2查看版本" class="headerlink" title="2.2.2查看版本"></a>2.2.2查看版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubelet --version</span><br><span class="line">Kubernetes v1.24.0</span><br><span class="line">[root@k8s-master01 ~]# etcdctl version</span><br><span class="line">etcdctl version: 3.5.4</span><br><span class="line">API version: 3.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h3 id="2-2-3将组件发送至其他k8s节点"><a href="#2-2-3将组件发送至其他k8s节点" class="headerlink" title="2.2.3将组件发送至其他k8s节点"></a>2.2.3将组件发送至其他k8s节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">Work=&#x27;k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05&#x27;</span><br><span class="line"></span><br><span class="line">for NODE in $Master; do echo $NODE; scp /usr/local/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done</span><br><span class="line"></span><br><span class="line">for NODE in $Work; do     scp /usr/local/bin/kube&#123;let,-proxy&#125; $NODE:/usr/local/bin/ ; done</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/cni/bin</span><br></pre></td></tr></table></figure>

<h2 id="2-3创建证书相关文件"><a href="#2-3创建证书相关文件" class="headerlink" title="2.3创建证书相关文件"></a>2.3创建证书相关文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir pki</span><br><span class="line">cd pki</span><br><span class="line">cat &gt; admin-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; ca-config.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; etcd-ca-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;etcd&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Etcd Security&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; front-proxy-ca-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">     &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">     &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; kubelet-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:node:$NODE&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:nodes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; manager-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; apiserver-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kube-apiserver&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;Kubernetes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; ca-csr.json   &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;Kubernetes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; etcd-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;etcd&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Etcd Security&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; front-proxy-client-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;front-proxy-client&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">     &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">     &quot;size&quot;: 2048</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; kube-proxy-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; scheduler-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir bootstrap</span><br><span class="line">cd bootstrap</span><br><span class="line">cat &gt; bootstrap.secret.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: bootstrap-token-c8ad9c</span><br><span class="line">  namespace: kube-system</span><br><span class="line">type: bootstrap.kubernetes.io/token</span><br><span class="line">stringData:</span><br><span class="line">  description: &quot;The default bootstrap token generated by &#x27;kubelet &#x27;.&quot;</span><br><span class="line">  token-id: c8ad9c</span><br><span class="line">  token-secret: 2e4d610cf3e7426e</span><br><span class="line">  usage-bootstrap-authentication: &quot;true&quot;</span><br><span class="line">  usage-bootstrap-signing: &quot;true&quot;</span><br><span class="line">  auth-extra-groups:  system:bootstrappers:default-node-token,system:bootstrappers:worker,system:bootstrappers:ingress</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubelet-bootstrap</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:bootstrappers:default-node-token</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-autoapprove-bootstrap</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:bootstrappers:default-node-token</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-autoapprove-certificate-rotation</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes/proxy</span><br><span class="line">      - nodes/stats</span><br><span class="line">      - nodes/log</span><br><span class="line">      - nodes/spec</span><br><span class="line">      - nodes/metrics</span><br><span class="line">    verbs:</span><br><span class="line">      - &quot;*&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:kube-apiserver</span><br><span class="line">  namespace: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">subjects:</span><br><span class="line">  - apiGroup: rbac.authorization.k8s.io</span><br><span class="line">    kind: User</span><br><span class="line">    name: kube-apiserver</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir coredns</span><br><span class="line">cd coredns</span><br><span class="line">cat &gt; coredns.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">    - endpoints</span><br><span class="line">    - services</span><br><span class="line">    - pods</span><br><span class="line">    - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - discovery.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">    - endpointslices</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health &#123;</span><br><span class="line">          lameduck 5s</span><br><span class="line">        &#125;</span><br><span class="line">        ready</span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        forward . /etc/resolv.conf &#123;</span><br><span class="line">          max_concurrent 1000</span><br><span class="line">        &#125;</span><br><span class="line">        cache 30</span><br><span class="line">        loop</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">replicas: not specified here:</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">1. Default is 1.</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">2. Will be tuned <span class="keyword">in</span> real time <span class="keyword">if</span> DNS horizontal auto-scaling is turned on.</span></span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: &quot;CriticalAddonsOnly&quot;</span><br><span class="line">          operator: &quot;Exists&quot;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      affinity:</span><br><span class="line">         podAntiAffinity:</span><br><span class="line">           preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">           - weight: 100</span><br><span class="line">             podAffinityTerm:</span><br><span class="line">               labelSelector:</span><br><span class="line">                 matchExpressions:</span><br><span class="line">                   - key: k8s-app</span><br><span class="line">                     operator: In</span><br><span class="line">                     values: [&quot;kube-dns&quot;]</span><br><span class="line">               topologyKey: kubernetes.io/hostname</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: registry.cn-beijing.aliyuncs.com/dotbalo/coredns:1.8.6 </span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 170Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        args: [ &quot;-conf&quot;, &quot;/etc/coredns/Corefile&quot; ]</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/coredns</span><br><span class="line">          readOnly: true</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /ready</span><br><span class="line">            port: 8181</span><br><span class="line">            scheme: HTTP</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: coredns</span><br><span class="line">            items:</span><br><span class="line">            - key: Corefile</span><br><span class="line">              path: Corefile</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: &quot;9153&quot;</span><br><span class="line">    prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir metrics-server</span><br><span class="line">cd metrics-server</span><br><span class="line">cat &gt; metrics-server.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-admin: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot;</span><br><span class="line">  name: system:aggregated-metrics-reader</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - metrics.k8s.io</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes/stats</span><br><span class="line">  - namespaces</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server-auth-reader</span><br><span class="line">  namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: extension-apiserver-authentication-reader</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server:system:auth-delegator</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:auth-delegator</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: https</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - args:</span><br><span class="line">        - --cert-dir=/tmp</span><br><span class="line">        - --secure-port=4443</span><br><span class="line">        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">        - --kubelet-use-node-status-port</span><br><span class="line">        - --metric-resolution=15s</span><br><span class="line">        - --kubelet-insecure-tls</span><br><span class="line">        - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem # change to front-proxy-ca.crt for kubeadm</span><br><span class="line">        - --requestheader-username-headers=X-Remote-User</span><br><span class="line">        - --requestheader-group-headers=X-Remote-Group</span><br><span class="line">        - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">        image: registry.cn-beijing.aliyuncs.com/dotbalo/metrics-server:0.5.0</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        livenessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /livez</span><br><span class="line">            port: https</span><br><span class="line">            scheme: HTTPS</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">        name: metrics-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 4443</span><br><span class="line">          name: https</span><br><span class="line">          protocol: TCP</span><br><span class="line">        readinessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /readyz</span><br><span class="line">            port: https</span><br><span class="line">            scheme: HTTPS</span><br><span class="line">          initialDelaySeconds: 20</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 200Mi</span><br><span class="line">        securityContext:</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">          runAsNonRoot: true</span><br><span class="line">          runAsUser: 1000</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /tmp</span><br><span class="line">          name: tmp-dir</span><br><span class="line">        - name: ca-ssl</span><br><span class="line">          mountPath: /etc/kubernetes/pki</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      volumes:</span><br><span class="line">      - emptyDir: &#123;&#125;</span><br><span class="line">        name: tmp-dir</span><br><span class="line">      - name: ca-ssl</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/kubernetes/pki</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apiregistration.k8s.io/v1</span><br><span class="line">kind: APIService</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: v1beta1.metrics.k8s.io</span><br><span class="line">spec:</span><br><span class="line">  group: metrics.k8s.io</span><br><span class="line">  groupPriorityMinimum: 100</span><br><span class="line">  insecureSkipTLSVerify: true</span><br><span class="line">  service:</span><br><span class="line">    name: metrics-server</span><br><span class="line">    namespace: kube-system</span><br><span class="line">  version: v1beta1</span><br><span class="line">  versionPriority: 100</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="3-相关证书生成"><a href="#3-相关证书生成" class="headerlink" title="3.相关证书生成"></a>3.相关证书生成</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">master01节点下载证书生成工具</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssl</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssljson</span><br><span class="line">chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</span><br></pre></td></tr></table></figure>

<h2 id="3-1-生成etcd证书"><a href="#3-1-生成etcd证书" class="headerlink" title="3.1.生成etcd证书"></a>3.1.生成etcd证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-1-1所有master节点创建证书存放目录"><a href="#3-1-1所有master节点创建证书存放目录" class="headerlink" title="3.1.1所有master节点创建证书存放目录"></a>3.1.1所有master节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/etcd/ssl -p</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2master01节点生成etcd证书"><a href="#3-1-2master01节点生成etcd证书" class="headerlink" title="3.1.2master01节点生成etcd证书"></a>3.1.2master01节点生成etcd证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd pki</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成etcd证书和etcd证书的key（如果你觉得以后可能会扩容，可以在ip那多写几个预留出来）</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,10.0.0.81,10.0.0.82,10.0.0.83,2408:8207:78ce:7561::10,2408:8207:78ce:7561::20,2408:8207:78ce:7561::30 \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</span><br></pre></td></tr></table></figure>

<h3 id="3-1-3将证书复制到其他节点"><a href="#3-1-3将证书复制到其他节点" class="headerlink" title="3.1.3将证书复制到其他节点"></a>3.1.3将证书复制到其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line"></span><br><span class="line">for NODE in $Master; do ssh $NODE &quot;mkdir -p /etc/etcd/ssl&quot;; for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do scp /etc/etcd/ssl/$&#123;FILE&#125; $NODE:/etc/etcd/ssl/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h2 id="3-2-生成k8s相关证书"><a href="#3-2-生成k8s相关证书" class="headerlink" title="3.2.生成k8s相关证书"></a>3.2.生成k8s相关证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-2-1所有k8s节点创建证书存放目录"><a href="#3-2-1所有k8s节点创建证书存放目录" class="headerlink" title="3.2.1所有k8s节点创建证书存放目录"></a>3.2.1所有k8s节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2master01节点生成k8s证书"><a href="#3-2-2master01节点生成k8s证书" class="headerlink" title="3.2.2master01节点生成k8s证书"></a>3.2.2master01节点生成k8s证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成一个根证书</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.96.0.1是service网段的第一个地址，需要计算，10.0.0.89为高可用vip地址</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   \</span><br><span class="line">-ca=/etc/kubernetes/pki/ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-hostname=10.96.0.1,10.0.0.89,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,x.oiox.cn,k.oiox.cn,l.oiox.cn,o.oiox.cn,10.0.0.81,10.0.0.82,10.0.0.83,10.0.0.84,10.0.0.85,10.0.0.86,10.0.0.87,10.0.0.88,10.0.0.80,10.0.0.90,10.0.0.40,10.0.0.41,2408:8207:78ce:7561::10,2408:8207:78ce:7561::20,2408:8207:78ce:7561::30,2408:8207:78ce:7561::40,2408:8207:78ce:7561::50,2408:8207:78ce:7561::60,2408:8207:78ce:7561::70,2408:8207:78ce:7561::80,2408:8207:78ce:7561::90,2408:8207:78ce:7561::100   \</span><br><span class="line">-profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3生成apiserver聚合证书"><a href="#3-2-3生成apiserver聚合证书" class="headerlink" title="3.2.3生成apiserver聚合证书"></a>3.2.3生成apiserver聚合证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有一个警告，可以忽略</span></span><br><span class="line"></span><br><span class="line">cfssl gencert  \</span><br><span class="line">-ca=/etc/kubernetes/pki/front-proxy-ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4生成controller-manage的证书"><a href="#3-2-4生成controller-manage的证书" class="headerlink" title="3.2.4生成controller-manage的证书"></a>3.2.4生成controller-manage的证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个集群项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://10.0.0.89:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个环境项，一个上下文</span></span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=system:kube-controller-manager \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个用户项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置默认环境</span></span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://10.0.0.89:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/scheduler.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/scheduler-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --cluster=kubernetes \</span><br><span class="line">     --user=system:kube-scheduler \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --server=https://10.0.0.89:8443     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes-admin  \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/admin.pem     \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/admin-key.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes    \</span><br><span class="line">  --cluster=kubernetes     \</span><br><span class="line">  --user=kubernetes-admin     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5创建ServiceAccount-Key-——secret"><a href="#3-2-5创建ServiceAccount-Key-——secret" class="headerlink" title="3.2.5创建ServiceAccount Key ——secret"></a>3.2.5创建ServiceAccount Key ——secret</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out /etc/kubernetes/pki/sa.key 2048</span><br><span class="line">openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</span><br></pre></td></tr></table></figure>

<h3 id="3-2-6将证书发送到其他master节点"><a href="#3-2-6将证书发送到其他master节点" class="headerlink" title="3.2.6将证书发送到其他master节点"></a>3.2.6将证书发送到其他master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do  for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do  scp /etc/kubernetes/pki/$&#123;FILE&#125; $NODE:/etc/kubernetes/pki/$&#123;FILE&#125;; done;  for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do  scp /etc/kubernetes/$&#123;FILE&#125; $NODE:/etc/kubernetes/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h3 id="3-2-7查看证书"><a href="#3-2-7查看证书" class="headerlink" title="3.2.7查看证书"></a>3.2.7查看证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /etc/kubernetes/pki/</span><br><span class="line">admin.csr      apiserver-key.pem  ca.pem                      front-proxy-ca.csr      front-proxy-client-key.pem  scheduler.csr</span><br><span class="line">admin-key.pem  apiserver.pem      controller-manager.csr      front-proxy-ca-key.pem  front-proxy-client.pem      scheduler-key.pem</span><br><span class="line">admin.pem      ca.csr             controller-manager-key.pem  front-proxy-ca.pem      sa.key                      scheduler.pem</span><br><span class="line">apiserver.csr  ca-key.pem         controller-manager.pem      front-proxy-client.csr  sa.pub</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一共23个就对了</span></span><br><span class="line"></span><br><span class="line">ls /etc/kubernetes/pki/ |wc -l</span><br><span class="line">23</span><br></pre></td></tr></table></figure>

<h1 id="4-k8s系统组件配置"><a href="#4-k8s系统组件配置" class="headerlink" title="4.k8s系统组件配置"></a>4.k8s系统组件配置</h1><h2 id="4-1-etcd配置"><a href="#4-1-etcd配置" class="headerlink" title="4.1.etcd配置"></a>4.1.etcd配置</h2><h3 id="4-1-1master01配置"><a href="#4-1-1master01配置" class="headerlink" title="4.1.1master01配置"></a>4.1.1master01配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master01&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.81:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.81:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.81:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.81:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.81:2380,k8s-master02=https://10.0.0.82:2380,k8s-master03=https://10.0.0.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2master02配置"><a href="#4-1-2master02配置" class="headerlink" title="4.1.2master02配置"></a>4.1.2master02配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master02&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.82:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.82:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.82:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.82:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.81:2380,k8s-master02=https://10.0.0.82:2380,k8s-master03=https://10.0.0.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3master03配置"><a href="#4-1-3master03配置" class="headerlink" title="4.1.3master03配置"></a>4.1.3master03配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master03&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.83:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.83:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.83:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.83:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.81:2380,k8s-master02=https://10.0.0.82:2380,k8s-master03=https://10.0.0.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="4-2-创建service（所有master节点操作）"><a href="#4-2-创建service（所有master节点操作）" class="headerlink" title="4.2.创建service（所有master节点操作）"></a>4.2.创建service（所有master节点操作）</h2><h3 id="4-2-1创建etcd-service并启动"><a href="#4-2-1创建etcd-service并启动" class="headerlink" title="4.2.1创建etcd.service并启动"></a>4.2.1创建etcd.service并启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2创建etcd证书目录"><a href="#4-2-2创建etcd证书目录" class="headerlink" title="4.2.2创建etcd证书目录"></a>4.2.2创建etcd证书目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/kubernetes/pki/etcd</span><br><span class="line">ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now etcd</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3查看etcd状态"><a href="#4-2-3查看etcd状态" class="headerlink" title="4.2.3查看etcd状态"></a>4.2.3查看etcd状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --endpoints=&quot;10.0.0.83:2379,10.0.0.82:2379,10.0.0.81:2379&quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|    ENDPOINT    |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| 10.0.0.83:2379 | c0c8142615b9523f |   3.5.4 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 10.0.0.82:2379 | de8396604d2c160d |   3.5.4 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 10.0.0.81:2379 | 33c9d6df0037ab97 |   3.5.4 |   20 kB |      true |      false |         2 |          9 |                  9 |        |</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 pki]# </span><br></pre></td></tr></table></figure>

<h1 id="5-高可用配置"><a href="#5-高可用配置" class="headerlink" title="5.高可用配置"></a>5.高可用配置</h1><h2 id="5-1在lb01和lb02两台服务器上操作"><a href="#5-1在lb01和lb02两台服务器上操作" class="headerlink" title="5.1在lb01和lb02两台服务器上操作"></a>5.1在lb01和lb02两台服务器上操作</h2><h3 id="5-1-1安装keepalived和haproxy服务"><a href="#5-1-1安装keepalived和haproxy服务" class="headerlink" title="5.1.1安装keepalived和haproxy服务"></a>5.1.1安装keepalived和haproxy服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br><span class="line"></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum -y install keepalived haproxy</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2修改haproxy配置文件（两台配置文件一样）"><a href="#5-1-2修改haproxy配置文件（两台配置文件一样）" class="headerlink" title="5.1.2修改haproxy配置文件（两台配置文件一样）"></a>5.1.2修改haproxy配置文件（两台配置文件一样）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt;/etc/haproxy/haproxy.cfg&lt;&lt;&quot;EOF&quot;</span><br><span class="line">global</span><br><span class="line"> maxconn 2000</span><br><span class="line"> ulimit-n 16384</span><br><span class="line"> log 127.0.0.1 local0 err</span><br><span class="line"> stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"> log global</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> timeout connect 5000</span><br><span class="line"> timeout client 50000</span><br><span class="line"> timeout server 50000</span><br><span class="line"> timeout http-request 15s</span><br><span class="line"> timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line"> bind *:33305</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line"> bind 0.0.0.0:8443</span><br><span class="line"> bind 127.0.0.1:8443</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> tcp-request inspect-delay 5s</span><br><span class="line"> default_backend k8s-master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> option tcp-check</span><br><span class="line"> balance roundrobin</span><br><span class="line"> default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line"> server  k8s-master01  10.0.0.81:6443 check</span><br><span class="line"> server  k8s-master02  10.0.0.82:6443 check</span><br><span class="line"> server  k8s-master03  10.0.0.83:6443 check</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-3lb01配置keepalived-master节点"><a href="#5-1-3lb01配置keepalived-master节点" class="headerlink" title="5.1.3lb01配置keepalived master节点"></a>5.1.3lb01配置keepalived master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens160</span><br><span class="line">    mcast_src_ip 10.0.0.80</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        10.0.0.89</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4lb02配置keepalived-backup节点"><a href="#5-1-4lb02配置keepalived-backup节点" class="headerlink" title="5.1.4lb02配置keepalived backup节点"></a>5.1.4lb02配置keepalived backup节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens160</span><br><span class="line">    mcast_src_ip 10.0.0.90</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 50</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        10.0.0.89</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-5健康检查脚本配置（两台lb主机）"><a href="#5-1-5健康检查脚本配置（两台lb主机）" class="headerlink" title="5.1.5健康检查脚本配置（两台lb主机）"></a>5.1.5健康检查脚本配置（两台lb主机）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/keepalived/check_apiserver.sh &lt;&lt; EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">err=0</span><br><span class="line">for k in \$(seq 1 3)</span><br><span class="line">do</span><br><span class="line">    check_code=\$(pgrep haproxy)</span><br><span class="line">    if [[ \$check_code == &quot;&quot; ]]; then</span><br><span class="line">        err=\$(expr \$err + 1)</span><br><span class="line">        sleep 1</span><br><span class="line">        continue</span><br><span class="line">    else</span><br><span class="line">        err=0</span><br><span class="line">        break</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ \$err != &quot;0&quot; ]]; then</span><br><span class="line">    echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">    /usr/bin/systemctl stop keepalived</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给脚本授权</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_apiserver.sh</span><br></pre></td></tr></table></figure>

<h3 id="5-1-6启动服务"><a href="#5-1-6启动服务" class="headerlink" title="5.1.6启动服务"></a>5.1.6启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now haproxy</span><br><span class="line">systemctl enable --now keepalived</span><br></pre></td></tr></table></figure>

<h3 id="5-1-7测试高可用"><a href="#5-1-7测试高可用" class="headerlink" title="5.1.7测试高可用"></a>5.1.7测试高可用</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能ping同</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# ping 10.0.0.89</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能telnet访问</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# telnet 10.0.0.89 8443</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭主节点，看vip是否漂移到备节点</span></span><br></pre></td></tr></table></figure>

<h1 id="6-k8s组件配置（区别于第4点）"><a href="#6-k8s组件配置（区别于第4点）" class="headerlink" title="6.k8s组件配置（区别于第4点）"></a>6.k8s组件配置（区别于第4点）</h1><p>所有k8s节点创建以下目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes</span><br></pre></td></tr></table></figure>

<h2 id="6-1-创建apiserver（所有master节点）"><a href="#6-1-创建apiserver（所有master节点）" class="headerlink" title="6.1.创建apiserver（所有master节点）"></a>6.1.创建apiserver（所有master节点）</h2><h3 id="6-1-1master01节点配置"><a href="#6-1-1master01节点配置" class="headerlink" title="6.1.1master01节点配置"></a>6.1.1master01节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.81 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">      --feature-gates=IPv6DualStack=true  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.81:2379,https://10.0.0.82:2379,https://10.0.0.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-2master02节点配置"><a href="#6-1-2master02节点配置" class="headerlink" title="6.1.2master02节点配置"></a>6.1.2master02节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.82 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">			--feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.81:2379,https://10.0.0.82:2379,https://10.0.0.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-3master03节点配置"><a href="#6-1-3master03节点配置" class="headerlink" title="6.1.3master03节点配置"></a>6.1.3master03节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service  &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.83 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">			--feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.81:2379,https://10.0.0.82:2379,https://10.0.0.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-4启动apiserver（所有master节点）"><a href="#6-1-4启动apiserver（所有master节点）" class="headerlink" title="6.1.4启动apiserver（所有master节点）"></a>6.1.4启动apiserver（所有master节点）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl enable --now kube-apiserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意查看状态是否启动正常</span></span><br><span class="line"></span><br><span class="line">systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>

<h2 id="6-2-配置kube-controller-manager-service"><a href="#6-2-配置kube-controller-manager-service" class="headerlink" title="6.2.配置kube-controller-manager service"></a>6.2.配置kube-controller-manager service</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所有master节点配置，且配置相同</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">172.16.0.0/12为pod网段，按需求设置你自己的网段</span></span><br><span class="line"></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --bind-address=127.0.0.1 \</span><br><span class="line">      --root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --use-service-account-credentials=true \</span><br><span class="line">      --node-monitor-grace-period=40s \</span><br><span class="line">      --node-monitor-period=5s \</span><br><span class="line">      --pod-eviction-timeout=2m0s \</span><br><span class="line">      --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">      --allocate-node-cidrs=true \</span><br><span class="line">      --feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108 \</span><br><span class="line">      --cluster-cidr=172.16.0.0/12,fc00::/48 \</span><br><span class="line">      --node-cidr-mask-size-ipv4=24 \</span><br><span class="line">      --node-cidr-mask-size-ipv6=64 \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem </span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-2-1启动kube-controller-manager，并查看状态"><a href="#6-2-1启动kube-controller-manager，并查看状态" class="headerlink" title="6.2.1启动kube-controller-manager，并查看状态"></a>6.2.1启动kube-controller-manager，并查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-controller-manager</span><br><span class="line">systemctl  status kube-controller-manager</span><br></pre></td></tr></table></figure>

<h2 id="6-3-配置kube-scheduler-service"><a href="#6-3-配置kube-scheduler-service" class="headerlink" title="6.3.配置kube-scheduler service"></a>6.3.配置kube-scheduler service</h2><h3 id="6-3-1所有master节点配置，且配置相同"><a href="#6-3-1所有master节点配置，且配置相同" class="headerlink" title="6.3.1所有master节点配置，且配置相同"></a>6.3.1所有master节点配置，且配置相同</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --bind-address=127.0.0.1 \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-3-2启动并查看服务状态"><a href="#6-3-2启动并查看服务状态" class="headerlink" title="6.3.2启动并查看服务状态"></a>6.3.2启动并查看服务状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-scheduler</span><br><span class="line">systemctl status kube-scheduler</span><br></pre></td></tr></table></figure>

<h1 id="7-TLS-Bootstrapping配置"><a href="#7-TLS-Bootstrapping配置" class="headerlink" title="7.TLS Bootstrapping配置"></a>7.TLS Bootstrapping配置</h1><h2 id="7-1在master01上配置"><a href="#7-1在master01上配置" class="headerlink" title="7.1在master01上配置"></a>7.1在master01上配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd bootstrap</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">--certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">--embed-certs=true     --server=https://10.0.0.89:8443     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials tls-bootstrap-token-user     \</span><br><span class="line">--token=c8ad9c.2e4d610cf3e7426e \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context tls-bootstrap-token-user@kubernetes     \</span><br><span class="line">--cluster=kubernetes     \</span><br><span class="line">--user=tls-bootstrap-token-user     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context tls-bootstrap-token-user@kubernetes     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">token的位置在bootstrap.secret.yaml，如果修改的话到这个文件修改</span></span><br><span class="line"></span><br><span class="line">mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config</span><br></pre></td></tr></table></figure>

<h2 id="7-2查看集群状态，没问题的话继续后续操作"><a href="#7-2查看集群状态，没问题的话继续后续操作" class="headerlink" title="7.2查看集群状态，没问题的话继续后续操作"></a>7.2查看集群状态，没问题的话继续后续操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line"></span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE                         ERROR</span><br><span class="line">scheduler            Healthy   ok                              </span><br><span class="line">controller-manager   Healthy   ok                              </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125; </span><br><span class="line"></span><br><span class="line">kubectl create -f bootstrap.secret.yaml</span><br></pre></td></tr></table></figure>

<h1 id="8-node节点配置"><a href="#8-node节点配置" class="headerlink" title="8.node节点配置"></a>8.node节点配置</h1><h2 id="8-1-在master01上将证书复制到node节点"><a href="#8-1-在master01上将证书复制到node节点" class="headerlink" title="8.1.在master01上将证书复制到node节点"></a>8.1.在master01上将证书复制到node节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/kubernetes/</span><br><span class="line"> </span><br><span class="line">for NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do ssh $NODE mkdir -p /etc/kubernetes/pki; for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig; do scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h2 id="8-2-kubelet配置"><a href="#8-2-kubelet配置" class="headerlink" title="8.2.kubelet配置"></a>8.2.kubelet配置</h2><h3 id="8-2-1所有k8s节点创建相关目录"><a href="#8-2-1所有k8s节点创建相关目录" class="headerlink" title="8.2.1所有k8s节点创建相关目录"></a>8.2.1所有k8s节点创建相关目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所有k8s节点配置kubelet service</span></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=containerd.service</span><br><span class="line">Requires=containerd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \</span><br><span class="line">    --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">    --config=/etc/kubernetes/kubelet-conf.yml \</span><br><span class="line">    --container-runtime=remote  \</span><br><span class="line">    --runtime-request-timeout=15m  \</span><br><span class="line">    --container-runtime-endpoint=unix:///run/containerd/containerd.sock  \</span><br><span class="line">    --cgroup-driver=systemd \</span><br><span class="line">    --node-labels=node.kubernetes.io/node=&#x27;&#x27; \</span><br><span class="line">    --feature-gates=IPv6DualStack=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-2所有k8s节点创建kubelet的配置文件"><a href="#8-2-2所有k8s节点创建kubelet的配置文件" class="headerlink" title="8.2.2所有k8s节点创建kubelet的配置文件"></a>8.2.2所有k8s节点创建kubelet的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-3启动kubelet"><a href="#8-2-3启动kubelet" class="headerlink" title="8.2.3启动kubelet"></a>8.2.3启动kubelet</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">systemctl enable --now kubelet</span><br></pre></td></tr></table></figure>

<h3 id="8-2-4查看集群"><a href="#8-2-4查看集群" class="headerlink" title="8.2.4查看集群"></a>8.2.4查看集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-master02   NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-master03   NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-node01     NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-node02     NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-node03     NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-node04     NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-node05     NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">[root@k8s-master01 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="8-3-kube-proxy配置"><a href="#8-3-kube-proxy配置" class="headerlink" title="8.3.kube-proxy配置"></a>8.3.kube-proxy配置</h2><h3 id="8-3-1此配置只在master01操作"><a href="#8-3-1此配置只在master01操作" class="headerlink" title="8.3.1此配置只在master01操作"></a>8.3.1此配置只在master01操作</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp /etc/kubernetes/admin.kubeconfig /etc/kubernetes/kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="8-3-2将kubeconfig发送至其他节点"><a href="#8-3-2将kubeconfig发送至其他节点" class="headerlink" title="8.3.2将kubeconfig发送至其他节点"></a>8.3.2将kubeconfig发送至其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig; done</span><br><span class="line"></span><br><span class="line">for NODE in k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig;  done</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3所有k8s节点添加kube-proxy的配置和service文件"><a href="#8-3-3所有k8s节点添加kube-proxy的配置和service文件" class="headerlink" title="8.3.3所有k8s节点添加kube-proxy的配置和service文件"></a>8.3.3所有k8s节点添加kube-proxy的配置和service文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy.yaml \</span><br><span class="line">  --v=2</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12,fc00::/48 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4启动kube-proxy"><a href="#8-3-4启动kube-proxy" class="headerlink" title="8.3.4启动kube-proxy"></a>8.3.4启动kube-proxy</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kube-proxy</span><br><span class="line">systemctl enable --now kube-proxy</span><br></pre></td></tr></table></figure>

<h1 id="9-安装Calico"><a href="#9-安装Calico" class="headerlink" title="9.安装Calico"></a>9.安装Calico</h1><h2 id="9-1以下步骤只在master01操作"><a href="#9-1以下步骤只在master01操作" class="headerlink" title="9.1以下步骤只在master01操作"></a>9.1以下步骤只在master01操作</h2><h3 id="9-1-1更改calico网段"><a href="#9-1-1更改calico网段" class="headerlink" title="9.1.1更改calico网段"></a>9.1.1更改calico网段</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vim calico.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">calico-config ConfigMap处</span></span><br><span class="line">    &quot;ipam&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;calico-ipam&quot;,</span><br><span class="line">        &quot;assign_ipv4&quot;: &quot;true&quot;,</span><br><span class="line">        &quot;assign_ipv6&quot;: &quot;true&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    - name: IP</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: IP6</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">      value: &quot;172.16.0.0/16&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV6POOL_CIDR</span><br><span class="line">      value: &quot;fc00::/48&quot;</span><br><span class="line"></span><br><span class="line">    - name: FELIX_IPV6SUPPORT</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl apply -f calico.yaml</span></span><br><span class="line">kubectl apply -f calico-ipv6.yaml </span><br></pre></td></tr></table></figure>

<h3 id="9-1-2查看容器状态"><a href="#9-1-2查看容器状态" class="headerlink" title="9.1.2查看容器状态"></a>9.1.2查看容器状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get pod -A</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-kube-controllers-7fb57bc4b5-dwwg8   1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-b8p4z                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-c4lzj                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-dfh2m                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-gbhgn                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-ht6nl                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-lv8bm                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-rm7d4                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-z976w                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-typha-dd885f47-jvgsj                1/1     Running   0          23s</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master02   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master03   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node03     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node04     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node05     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h1 id="10-安装CoreDNS"><a href="#10-安装CoreDNS" class="headerlink" title="10.安装CoreDNS"></a>10.安装CoreDNS</h1><h2 id="10-1以下步骤只在master01操作"><a href="#10-1以下步骤只在master01操作" class="headerlink" title="10.1以下步骤只在master01操作"></a>10.1以下步骤只在master01操作</h2><h3 id="10-1-1修改文件"><a href="#10-1-1修改文件" class="headerlink" title="10.1.1修改文件"></a>10.1.1修改文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd coredns/</span><br><span class="line"></span><br><span class="line">sed -i &quot;s#10.96.0.10#10.96.0.10#g&quot; coredns.yaml</span><br><span class="line"></span><br><span class="line">cat coredns.yaml | grep clusterIP:</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br></pre></td></tr></table></figure>

<h3 id="10-1-2安装"><a href="#10-1-2安装" class="headerlink" title="10.1.2安装"></a>10.1.2安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  create -f coredns.yaml </span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.apps/coredns created</span><br><span class="line">service/kube-dns created</span><br></pre></td></tr></table></figure>

<h1 id="11-安装Metrics-Server"><a href="#11-安装Metrics-Server" class="headerlink" title="11.安装Metrics Server"></a>11.安装Metrics Server</h1><h2 id="11-1以下步骤只在master01操作"><a href="#11-1以下步骤只在master01操作" class="headerlink" title="11.1以下步骤只在master01操作"></a>11.1以下步骤只在master01操作</h2><h3 id="11-1-1安装Metrics-server"><a href="#11-1-1安装Metrics-server" class="headerlink" title="11.1.1安装Metrics-server"></a>11.1.1安装Metrics-server</h3><p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装metrics server</span></span><br><span class="line">cd metrics-server/</span><br><span class="line"></span><br><span class="line">kubectl  apply -f metrics-server.yaml </span><br></pre></td></tr></table></figure>

<h3 id="11-1-2稍等片刻查看状态"><a href="#11-1-2稍等片刻查看状态" class="headerlink" title="11.1.2稍等片刻查看状态"></a>11.1.2稍等片刻查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   154m         1%     1715Mi          21%       </span><br><span class="line">k8s-master02   151m         1%     1274Mi          16%       </span><br><span class="line">k8s-master03   523m         6%     1345Mi          17%       </span><br><span class="line">k8s-node01     84m          1%     671Mi           8%        </span><br><span class="line">k8s-node02     73m          0%     727Mi           9%        </span><br><span class="line">k8s-node03     96m          1%     769Mi           9%        </span><br><span class="line">k8s-node04     68m          0%     673Mi           8%        </span><br><span class="line">k8s-node05     82m          1%     679Mi           8% </span><br></pre></td></tr></table></figure>

<h1 id="12-集群验证"><a href="#12-集群验证" class="headerlink" title="12.集群验证"></a>12.集群验证</h1><h2 id="12-1部署pod资源"><a href="#12-1部署pod资源" class="headerlink" title="12.1部署pod资源"></a>12.1部署pod资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line"></span><br><span class="line">kubectl  get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox   1/1     Running   0          17s</span><br></pre></td></tr></table></figure>

<h2 id="12-2用pod解析默认命名空间中的kubernetes"><a href="#12-2用pod解析默认命名空间中的kubernetes" class="headerlink" title="12.2用pod解析默认命名空间中的kubernetes"></a>12.2用pod解析默认命名空间中的kubernetes</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   17h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl exec  busybox -n default -- nslookup kubernetes</span><br><span class="line">3Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-3测试跨命名空间是否可以解析"><a href="#12-3测试跨命名空间是否可以解析" class="headerlink" title="12.3测试跨命名空间是否可以解析"></a>12.3测试跨命名空间是否可以解析</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl exec  busybox -n default -- nslookup kube-dns.kube-system</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kube-dns.kube-system</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53"><a href="#12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53" class="headerlink" title="12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53"></a>12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">telnet 10.96.0.1 443</span><br><span class="line">Trying 10.96.0.1...</span><br><span class="line">Connected to 10.96.0.1.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line"> telnet 10.96.0.10 53</span><br><span class="line">Trying 10.96.0.10...</span><br><span class="line">Connected to 10.96.0.10.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line">curl 10.96.0.10:53</span><br><span class="line">curl: (52) Empty reply from server</span><br></pre></td></tr></table></figure>

<h2 id="12-5Pod和Pod之前要能通"><a href="#12-5Pod和Pod之前要能通" class="headerlink" title="12.5Pod和Pod之前要能通"></a>12.5Pod和Pod之前要能通</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get po -owide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox   1/1     Running   0          17m   172.27.14.193   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"> kubectl get po -n kube-system -owide</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS      AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-5dffd5886b-4blh6   1/1     Running   0             77m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-fvbdq                          1/1     Running   1 (75m ago)   77m   10.0.0.81     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-g8nqd                          1/1     Running   0             77m   10.0.0.84     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-mdps8                          1/1     Running   0             77m   10.0.0.85     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-nf4nt                          1/1     Running   0             77m   10.0.0.83     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-sq2ml                          1/1     Running   0             77m   10.0.0.82     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-mg6p8              1/1     Running   0             77m   10.0.0.85     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-pxbpj              1/1     Running   0             77m   10.0.0.81     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-tnssl              1/1     Running   0             77m   10.0.0.84     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5db5696c7-67h79                    1/1     Running   0             63m   172.25.92.65     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">metrics-server-6bf7dcd649-5fhrw            1/1     Running   0             61m   172.18.195.1     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入busybox ping其他节点上的pod</span></span><br><span class="line"></span><br><span class="line">kubectl exec -ti busybox -- sh</span><br><span class="line">/ # ping 10.0.0.84</span><br><span class="line">PING 10.0.0.84 (10.0.0.84): 56 data bytes</span><br><span class="line">64 bytes from 10.0.0.84: seq=0 ttl=63 time=0.358 ms</span><br><span class="line">64 bytes from 10.0.0.84: seq=1 ttl=63 time=0.668 ms</span><br><span class="line">64 bytes from 10.0.0.84: seq=2 ttl=63 time=0.637 ms</span><br><span class="line">64 bytes from 10.0.0.84: seq=3 ttl=63 time=0.624 ms</span><br><span class="line">64 bytes from 10.0.0.84: seq=4 ttl=63 time=0.907 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以连通证明这个pod是可以跨命名空间和跨主机通信的</span></span><br></pre></td></tr></table></figure>

<h2 id="12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"><a href="#12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）" class="headerlink" title="12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"></a>12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; deployments.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl  apply -f deployments.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">kubectl  get pod </span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                            1/1     Running   0          6m25s</span><br><span class="line">nginx-deployment-9456bbbf9-4bmvk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-9rcdk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-dqv8s   1/1     Running   0          8s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除nginx</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f deployments.yaml </span><br></pre></td></tr></table></figure>





<h1 id="13-安装dashboard"><a href="#13-安装dashboard" class="headerlink" title="13.安装dashboard"></a>13.安装dashboard</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  apply -f dashboard.yaml</span><br><span class="line">kubectl  apply -f dashboard-user.yaml</span><br></pre></td></tr></table></figure>

<h2 id="13-1更改dashboard的svc为NodePort，如果已是请忽略"><a href="#13-1更改dashboard的svc为NodePort，如果已是请忽略" class="headerlink" title="13.1更改dashboard的svc为NodePort，如果已是请忽略"></a>13.1更改dashboard的svc为NodePort，如果已是请忽略</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure>

<h2 id="13-2查看端口号"><a href="#13-2查看端口号" class="headerlink" title="13.2查看端口号"></a>13.2查看端口号</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.98.201.22   &lt;none&gt;        443:31473/TCP   10m</span><br></pre></td></tr></table></figure>

<h2 id="13-3创建token"><a href="#13-3创建token" class="headerlink" title="13.3创建token"></a>13.3创建token</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl -n kubernetes-dashboard create token admin-user</span><br><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6IlV6b3NRbDRiTll4VEl1a1VGbU53M2Y2X044Wjdfa21mQ0dfYk5BWktHRjAifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjUyNzYzMjUzLCJpYXQiOjE2NTI3NTk2NTMsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiNDYxYjc4MDItNTgzMS00MTNmLTg2M2ItODdlZWVkOTI3MTdiIn19LCJuYmYiOjE2NTI3NTk2NTMsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2VyIn0.nFF729zlDxz4Ed3fcVk5BE8Akc6jod6akf2rksVGJHmfurY7NO1nHP4EekrMx1FRa2JfoPOHTdxcWDVaQAymDC4vgP5aW5RCEOURUY6YdTQUxleRiX-Bgp3eNRHNOcPvdedGm0w7M7gnZqCwy4tsgyiXkIM7zZpvCqdCA1vGJxf_UIck4R8Izua5NSacnG25miIvAmxNzOAEHDD_jDIDHnPVi3iVZzrjBkDwG6spYx_yJbbLy1XbJCYMMH44X4ajuQulV_NS-aiIHj_-PbxfrBRAJCVTZ8L3zD14BraeAAHFqSoiLXohmYHLLjshtraVu4XcvehJDfnRMi8Y4b6sqA</span><br></pre></td></tr></table></figure>

<h2 id="13-3登录dashboard"><a href="#13-3登录dashboard" class="headerlink" title="13.3登录dashboard"></a>13.3登录dashboard</h2><p><a href="https://10.0.0.81:31245/">https://10.0.0.81:31245/</a></p>
<h1 id="14-ingress安装"><a href="#14-ingress安装" class="headerlink" title="14.ingress安装"></a>14.ingress安装</h1><h2 id="14-1写入配置文件，并执行"><a href="#14-1写入配置文件，并执行" class="headerlink" title="14.1写入配置文件，并执行"></a>14.1写入配置文件，并执行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim deploy.yaml</span><br><span class="line">[root@hello ~/yaml]# cat deploy.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-serviceaccount.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">automountServiceAccountToken: true</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-configmap.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">data:</span><br><span class="line">  allow-snippet-annotations: &#x27;true&#x27;</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/clusterrole.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - endpoints</span><br><span class="line">      - nodes</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/clusterrolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-role.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - endpoints</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    resourceNames:</span><br><span class="line">      - ingress-controller-leader</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-rolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-service-webhook.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - name: https-webhook</span><br><span class="line">      port: 443</span><br><span class="line">      targetPort: webhook</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-service.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  externalTrafficPolicy: Local</span><br><span class="line">  ipFamilyPolicy: SingleStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">    - IPv4</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: http</span><br><span class="line">      appProtocol: http</span><br><span class="line">    - name: https</span><br><span class="line">      port: 443</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: https</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-deployment.yaml</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: ingress-nginx</span><br><span class="line">      app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">      app.kubernetes.io/component: controller</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  minReadySeconds: 0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/component: controller</span><br><span class="line">    spec:</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      containers:</span><br><span class="line">        - name: controller</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/controller:v1.1.3 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          lifecycle:</span><br><span class="line">            preStop:</span><br><span class="line">              exec:</span><br><span class="line">                command:</span><br><span class="line">                  - /wait-shutdown</span><br><span class="line">          args:</span><br><span class="line">            - /nginx-ingress-controller</span><br><span class="line">            - --election-id=ingress-controller-leader</span><br><span class="line">            - --controller-class=k8s.io/ingress-nginx</span><br><span class="line">            - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller</span><br><span class="line">            - --validating-webhook=:8443</span><br><span class="line">            - --validating-webhook-certificate=/usr/local/certificates/cert</span><br><span class="line">            - --validating-webhook-key=/usr/local/certificates/key</span><br><span class="line">          securityContext:</span><br><span class="line">            capabilities:</span><br><span class="line">              drop:</span><br><span class="line">                - ALL</span><br><span class="line">              add:</span><br><span class="line">                - NET_BIND_SERVICE</span><br><span class="line">            runAsUser: 101</span><br><span class="line">            allowPrivilegeEscalation: true</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.name</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">            - name: LD_PRELOAD</span><br><span class="line">              value: /usr/local/lib/libmimalloc.so</span><br><span class="line">          livenessProbe:</span><br><span class="line">            failureThreshold: 5</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          readinessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          ports:</span><br><span class="line">            - name: http</span><br><span class="line">              containerPort: 80</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: https</span><br><span class="line">              containerPort: 443</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: webhook</span><br><span class="line">              containerPort: 8443</span><br><span class="line">              protocol: TCP</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: webhook-cert</span><br><span class="line">              mountPath: /usr/local/certificates/</span><br><span class="line">              readOnly: true</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 100m</span><br><span class="line">              memory: 90Mi</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      serviceAccountName: ingress-nginx</span><br><span class="line">      terminationGracePeriodSeconds: 300</span><br><span class="line">      volumes:</span><br><span class="line">        - name: webhook-cert</span><br><span class="line">          secret:</span><br><span class="line">            secretName: ingress-nginx-admission</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-ingressclass.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">We don<span class="string">&#x27;t support namespaced ingressClass yet</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">So a ClusterRole and a ClusterRoleBinding is required</span></span></span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: IngressClass</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  controller: k8s.io/ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/validating-webhook.yaml</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">before changing this value, check the required kubernetes version</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites</span></span></span><br><span class="line">apiVersion: admissionregistration.k8s.io/v1</span><br><span class="line">kind: ValidatingWebhookConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">webhooks:</span><br><span class="line">  - name: validate.nginx.ingress.kubernetes.io</span><br><span class="line">    matchPolicy: Equivalent</span><br><span class="line">    rules:</span><br><span class="line">      - apiGroups:</span><br><span class="line">          - networking.k8s.io</span><br><span class="line">        apiVersions:</span><br><span class="line">          - v1</span><br><span class="line">        operations:</span><br><span class="line">          - CREATE</span><br><span class="line">          - UPDATE</span><br><span class="line">        resources:</span><br><span class="line">          - ingresses</span><br><span class="line">    failurePolicy: Fail</span><br><span class="line">    sideEffects: None</span><br><span class="line">    admissionReviewVersions:</span><br><span class="line">      - v1</span><br><span class="line">    clientConfig:</span><br><span class="line">      service:</span><br><span class="line">        namespace: ingress-nginx</span><br><span class="line">        name: ingress-nginx-controller-admission</span><br><span class="line">        path: /networking/v1/ingresses</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - admissionregistration.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - validatingwebhookconfigurations</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/role.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - create</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-create</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-create</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: create</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - create</span><br><span class="line">            - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-patch</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-patch</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: patch</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - patch</span><br><span class="line">            - --webhook-name=ingress-nginx-admission</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --patch-mutating=false</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">            - --patch-failure-policy=Fail</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="14-2启用后端，写入配置文件执行"><a href="#14-2启用后端，写入配置文件执行" class="headerlink" title="14.2启用后端，写入配置文件执行"></a>14.2启用后端，写入配置文件执行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim backend.yaml</span><br><span class="line">[root@hello ~/yaml]# cat backend.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: default-http-backend</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: default-http-backend</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      containers:</span><br><span class="line">      - name: default-http-backend</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/chenby/defaultbackend-amd64:1.5 </span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /healthz</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="14-3安装测试应用"><a href="#14-3安装测试应用" class="headerlink" title="14.3安装测试应用"></a>14.3安装测试应用</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim ingress-demo-app.yaml</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# cat ingress-demo-app.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello-server</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-server</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-server</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx&quot;  </span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-4执行部署"><a href="#14-4执行部署" class="headerlink" title="14.4执行部署"></a>14.4执行部署</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  apply -f deploy.yaml </span><br><span class="line"></span><br><span class="line">kubectl  apply -f backend.yaml </span><br><span class="line"></span><br><span class="line">kubectl  apply -f ingress-demo-app.yaml </span><br><span class="line"></span><br><span class="line">kubectl  get ingress</span><br><span class="line">NAME               CLASS   HOSTS                            ADDRESS     PORTS   AGE</span><br><span class="line">ingress-host-bar   nginx   hello.chenby.cn,demo.chenby.cn   10.0.0.87   80      7s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-5过滤查看ingress端口"><a href="#14-5过滤查看ingress端口" class="headerlink" title="14.5过滤查看ingress端口"></a>14.5过滤查看ingress端口</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  get svc -A | grep ingress</span><br><span class="line">ingress-nginx          ingress-nginx-controller             NodePort    10.104.231.36    &lt;none&gt;        80:32636/TCP,443:30579/TCP   104s</span><br><span class="line">ingress-nginx          ingress-nginx-controller-admission   ClusterIP   10.101.85.88     &lt;none&gt;        443/TCP                      105s</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="15-IPv6测试"><a href="#15-IPv6测试" class="headerlink" title="15.IPv6测试"></a>15.IPv6测试</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">部署应用</span></span><br><span class="line">[root@k8s-master01 ~]# vim cby.yaml </span><br><span class="line">[root@k8s-master01 ~]# cat cby.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: chenby</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: chenby</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: chenby</span><br><span class="line">        image: nginx</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: &quot;128Mi&quot;</span><br><span class="line">            cpu: &quot;500m&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  ipFamilyPolicy: PreferDualStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">  - IPv6</span><br><span class="line">  - IPv4</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: chenby</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">[root@k8s-master01 ~]# kubectl  apply -f cby.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看端口</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl  get svc</span><br><span class="line">NAME           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">chenby         NodePort    fd00::a29c       &lt;none&gt;        80:30779/TCP   5s</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用内网访问</span></span><br><span class="line">[root@localhost yaml]# curl -I http://[fd00::a29c]</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:35 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# curl -I http://10.0.0.81:30779</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:59 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用公网访问</span></span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# curl -I http://[2408:8207:78ce:7561::10]:30779</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:54 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="16-安装命令行自动补全功能"><a href="#16-安装命令行自动补全功能" class="headerlink" title="16.安装命令行自动补全功能"></a>16.安装命令行自动补全功能</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install bash-completion -y</span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>





<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a>   </p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a>  </p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a>  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a>  </p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a>  </p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a>  </p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a>  </p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a>  </p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a>  </p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a>  </p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>使用kubeadm快速启用一个集群</title>
    <url>/2022/05/06/2022-05-06-%E4%BD%BF%E7%94%A8kubeadm%E5%BF%AB%E9%80%9F%E5%90%AF%E7%94%A8%E4%B8%80%E4%B8%AA%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h1 id="使用kubeadm快速启用一个集群"><a href="#使用kubeadm快速启用一个集群" class="headerlink" title="使用kubeadm快速启用一个集群"></a>使用kubeadm快速启用一个集群</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3c81f8393b0041668964c4ce4bece096~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="CentOS-配置YUM源"><a href="#CentOS-配置YUM源" class="headerlink" title="CentOS 配置YUM源"></a>CentOS 配置YUM源</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=kubernetes</span><br><span class="line">baseurl=https://mirrors.ustc.edu.cn/kubernetes/yum/repos/kubernetes-el7-$basearch</span><br><span class="line">enabled=1</span><br><span class="line">EOF</span><br><span class="line">setenforce 0</span><br><span class="line">yum install -y kubelet kubeadm kubectl</span><br><span class="line">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 将 SELinux 设置为 permissive 模式（相当于将其禁用）</span></span><br><span class="line">sudo setenforce 0</span><br><span class="line">sudo sed -i &#x27;s/^SELINUX=enforcing$/SELINUX=permissive/&#x27; /etc/selinux/config</span><br><span class="line">sudo systemctl enable --now kubelet</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Ubuntu-配置APT源"><a href="#Ubuntu-配置APT源" class="headerlink" title="Ubuntu 配置APT源"></a>Ubuntu 配置APT源</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install -y kubelet kubeadm kubectl</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="配置containerd"><a href="#配置containerd" class="headerlink" title="配置containerd"></a>配置containerd</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar -C / -xzf cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建服务启动文件</span></span><br><span class="line">cat &gt; /etc/systemd/system/containerd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=containerd container runtime</span><br><span class="line">Documentation=https://containerd.io</span><br><span class="line">After=network.target local-fs.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=-/sbin/modprobe overlay</span><br><span class="line">ExecStart=/usr/local/bin/containerd</span><br><span class="line">Type=notify</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">TasksMax=infinity</span><br><span class="line">OOMScoreAdjust=-999</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">sed -i &quot;s#SystemdCgroup\ \=\ false#SystemdCgroup\ \=\ true#g&quot; /etc/containerd/config.toml</span><br><span class="line">sed -i &quot;s#k8s.gcr.io#registry.cn-hangzhou.aliyuncs.com/chenby#g&quot; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now containerd</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="配置基础环境"><a href="#配置基础环境" class="headerlink" title="配置基础环境"></a>配置基础环境</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.all.forwarding = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">modprobe br_netfilter</span><br><span class="line"></span><br><span class="line">sudo sysctl --system</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line"></span><br><span class="line">cat /etc/fstab</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.1.31 k8s-master01</span><br><span class="line">192.168.1.32 k8s-node01</span><br><span class="line">192.168.1.33 k8s-node01</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="初始化安装"><a href="#初始化安装" class="headerlink" title="初始化安装"></a>初始化安装</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@k8s-master01:~# kubeadm config images</span><br><span class="line">missing subcommand; &quot;images&quot; is not meant to be run on its own</span><br><span class="line">To see the stack trace of this error execute with --v=5 or higher</span><br><span class="line">root@k8s-master01:~# kubeadm config images list</span><br><span class="line">k8s.gcr.io/kube-apiserver:v1.24.0</span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.24.0</span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.24.0</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.24.0</span><br><span class="line">k8s.gcr.io/pause:3.7</span><br><span class="line">k8s.gcr.io/etcd:3.5.3-0</span><br><span class="line">k8s.gcr.io/coredns/coredns:v1.8.6</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~# kubeadm init  --image-repository registry.cn-hangzhou.aliyuncs.com/chenby</span><br><span class="line">[init] Using Kubernetes version: v1.24.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &#x27;kubeadm config images pull&#x27;</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.31]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [k8s-master01 localhost] and IPs [192.168.1.31 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [k8s-master01 localhost] and IPs [192.168.1.31 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 9.502219 seconds</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class="line">[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule node-role.kubernetes.io/control-plane:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: nsiavq.637f6t76cbtwckq9</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.1.31:6443 --token nsiavq.637f6t76cbtwckq9 \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:963b47c1d46199eb28c2813c893fcd201cfaa32cfdfd521f6bc78a70c13878c4 </span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~#   mkdir -p $HOME/.kube</span><br><span class="line">root@k8s-master01:~#   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">root@k8s-master01:~#   sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-node01:~# kubeadm join 192.168.1.31:6443 --token nsiavq.637f6t76cbtwckq9 \</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">         --discovery-token-ca-cert-hash sha256:963b47c1d46199eb28c2813c893fcd201cfaa32cfdfd521f6bc78a70c13878c4</span></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">root@k8s-node01:~# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-node02:~# kubeadm join 192.168.1.31:6443 --token nsiavq.637f6t76cbtwckq9 \</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">         --discovery-token-ca-cert-hash sha256:963b47c1d46199eb28c2813c893fcd201cfaa32cfdfd521f6bc78a70c13878c4</span></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">root@k8s-node02:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@k8s-master01:~# kubectl  get node</span><br><span class="line">NAME           STATUS   ROLES           AGE   VERSION</span><br><span class="line">k8s-master01   Ready    control-plane   86s   v1.24.0</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;          42s   v1.24.0</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;          37s   v1.24.0</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~# kubectl  get pod -A</span><br><span class="line">NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-bc77466fc-jxkpv                1/1     Running   0          83s</span><br><span class="line">kube-system   coredns-bc77466fc-nrc9l                1/1     Running   0          83s</span><br><span class="line">kube-system   etcd-k8s-master01                      1/1     Running   0          87s</span><br><span class="line">kube-system   kube-apiserver-k8s-master01            1/1     Running   0          89s</span><br><span class="line">kube-system   kube-controller-manager-k8s-master01   1/1     Running   0          87s</span><br><span class="line">kube-system   kube-proxy-2lgrn                       1/1     Running   0          83s</span><br><span class="line">kube-system   kube-proxy-69p9r                       1/1     Running   0          47s</span><br><span class="line">kube-system   kube-proxy-g58m2                       1/1     Running   0          42s</span><br><span class="line">kube-system   kube-scheduler-k8s-master01            1/1     Running   0          87s</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>部署kubernetes官网博客</title>
    <url>/2022/05/11/2022-05-11-%E9%83%A8%E7%BD%B2kubernetes%E5%AE%98%E7%BD%91%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h1 id="部署kubernetes官网博客"><a href="#部署kubernetes官网博客" class="headerlink" title="部署kubernetes官网博客"></a>部署kubernetes官网博客</h1><p>访问 <a href="https://kubernetes.io/">https://kubernetes.io/</a> 有些时候不问题，部署离线内网使用官网以及博客， 各位尝鲜可以访问 <a href="https://doc.oiox.cn/">https://doc.oiox.cn/</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/706f068caadd43369590a9291605c3fe~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# curl -sSL https://get.daocloud.io/docker | sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Executing docker install script, commit: 0221adedb4bcde0f3d18bddda023544fc56c29d1</span></span><br><span class="line">+ sh -c apt-get update -qq &gt;/dev/null</span><br><span class="line">+ sh -c DEBIAN_FRONTEND=noninteractive apt-get install -y -qq apt-transport-https ca-certificates curl &gt;/dev/null</span><br><span class="line">+ sh -c curl -fsSL &quot;https://download.docker.com/linux/ubuntu/gpg&quot; | gpg --dearmor --yes -o /usr/share/keyrings/docker-archive-keyring.gpg</span><br><span class="line">+ sh -c chmod a+r /usr/share/keyrings/docker-archive-keyring.gpg</span><br><span class="line">+ sh -c echo &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu focal stable&quot; &gt; /etc/apt/sources.list.d/docker.list</span><br><span class="line">+ sh -c apt-get update -qq &gt;/dev/null</span><br><span class="line">+ sh -c DEBIAN_FRONTEND=noninteractive apt-get install -y -qq --no-install-recommends docker-ce docker-ce-cli docker-compose-plugin docker-scan-plugin &gt;/dev/null</span><br><span class="line">+ version_gte 20.10</span><br><span class="line">+ [ -z  ]</span><br><span class="line">+ return 0</span><br><span class="line">+ sh -c DEBIAN_FRONTEND=noninteractive apt-get install -y -qq docker-ce-rootless-extras &gt;/dev/null</span><br><span class="line">+ sh -c docker version</span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           20.10.15</span><br><span class="line"> API version:       1.41</span><br><span class="line"> Go version:        go1.17.9</span><br><span class="line"> Git commit:        fd82621</span><br><span class="line"> Built:             Thu May  5 13:19:23 2022</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Context:           default</span><br><span class="line"> Experimental:      true</span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          20.10.15</span><br><span class="line">  API version:      1.41 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.17.9</span><br><span class="line">  Git commit:       4433bf6</span><br><span class="line">  Built:            Thu May  5 13:17:28 2022</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     false</span><br><span class="line"> containerd:</span><br><span class="line">  Version:          1.6.4</span><br><span class="line">  GitCommit:        212e8b6fa2f44b9c21b2798135fc6fb7c53efc16</span><br><span class="line"> runc:</span><br><span class="line">  Version:          1.1.1</span><br><span class="line">  GitCommit:        v1.1.1-0-g52de29d</span><br><span class="line"> docker-init:</span><br><span class="line">  Version:          0.19.0</span><br><span class="line">  GitCommit:        de40ad0</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"></span><br><span class="line">To run Docker as a non-privileged user, consider setting up the</span><br><span class="line">Docker daemon in rootless mode for your user:</span><br><span class="line"></span><br><span class="line">    dockerd-rootless-setuptool.sh install</span><br><span class="line"></span><br><span class="line">Visit https://docs.docker.com/go/rootless/ to learn about rootless mode.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">To run the Docker daemon as a fully privileged service, but granting non-root</span><br><span class="line">users access, refer to https://docs.docker.com/go/daemon-access/</span><br><span class="line"></span><br><span class="line">WARNING: Access to the remote API on a privileged Docker daemon is equivalent</span><br><span class="line">         to root access on the host. Refer to the &#x27;Docker daemon attack surface&#x27;</span><br><span class="line">         documentation for details: https://docs.docker.com/go/attack-surface/</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"></span><br><span class="line">root@cby:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="克隆库"><a href="#克隆库" class="headerlink" title="克隆库"></a>克隆库</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# git clone https://github.com/kubernetes/website.git</span><br><span class="line">Cloning into &#x27;website&#x27;...</span><br><span class="line">remote: Enumerating objects: 269472, done.</span><br><span class="line">remote: Counting objects: 100% (354/354), done.</span><br><span class="line">remote: Compressing objects: 100% (240/240), done.</span><br><span class="line">remote: Total 269472 (delta 201), reused 221 (delta 112), pack-reused 269118</span><br><span class="line">Receiving objects: 100% (269472/269472), 334.98 MiB | 1.92 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (190520/190520), done.</span><br><span class="line">Updating files: 100% (7124/7124), done.</span><br><span class="line">root@cby:~# cd website</span><br><span class="line">root@cby:~/website# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~/website# git submodule update --init --recursive --depth 1</span><br><span class="line">Submodule &#x27;api-ref-generator&#x27; (https://github.com/kubernetes-sigs/reference-docs) registered for path &#x27;api-ref-generator&#x27;</span><br><span class="line">Submodule &#x27;themes/docsy&#x27; (https://github.com/google/docsy.git) registered for path &#x27;themes/docsy&#x27;</span><br><span class="line">Cloning into &#x27;/root/website/api-ref-generator&#x27;...</span><br><span class="line">Cloning into &#x27;/root/website/themes/docsy&#x27;...</span><br><span class="line">remote: Total 0 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Enumerating objects: 104, done.</span><br><span class="line">remote: Counting objects: 100% (104/104), done.</span><br><span class="line">remote: Compressing objects: 100% (53/53), done.</span><br><span class="line">remote: Total 61 (delta 34), reused 23 (delta 6), pack-reused 0</span><br><span class="line">Unpacking objects: 100% (61/61), 103.64 KiB | 252.00 KiB/s, done.</span><br><span class="line">From https://github.com/kubernetes-sigs/reference-docs</span><br><span class="line"> * branch            55bce686224caba37f93e1e1eb53c0c9fc104ed4 -&gt; FETCH_HEAD</span><br><span class="line">Submodule path &#x27;api-ref-generator&#x27;: checked out &#x27;55bce686224caba37f93e1e1eb53c0c9fc104ed4&#x27;</span><br><span class="line">Submodule &#x27;themes/docsy&#x27; (https://github.com/google/docsy.git) registered for path &#x27;api-ref-generator/themes/docsy&#x27;</span><br><span class="line">Cloning into &#x27;/root/website/api-ref-generator/themes/docsy&#x27;...</span><br><span class="line">remote: Total 0 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Enumerating objects: 251, done.</span><br><span class="line">remote: Counting objects: 100% (251/251), done.</span><br><span class="line">remote: Compressing objects: 100% (119/119), done.</span><br><span class="line">remote: Total 130 (delta 82), reused 34 (delta 3), pack-reused 0</span><br><span class="line">Receiving objects: 100% (130/130), 43.96 KiB | 308.00 KiB/s, done.</span><br><span class="line">Resolving deltas: 100% (82/82), completed with 77 local objects.</span><br><span class="line">From https://github.com/google/docsy</span><br><span class="line"> * branch            6b30513dc837c5937de351f2fb2e4fedb04365c4 -&gt; FETCH_HEAD</span><br><span class="line">Submodule path &#x27;api-ref-generator/themes/docsy&#x27;: checked out &#x27;6b30513dc837c5937de351f2fb2e4fedb04365c4&#x27;</span><br><span class="line">Submodule &#x27;assets/vendor/Font-Awesome&#x27; (https://github.com/FortAwesome/Font-Awesome.git) registered for path &#x27;api-ref-generator/themes/docsy/assets/vendor/Font-Awesome&#x27;</span><br><span class="line">Submodule &#x27;assets/vendor/bootstrap&#x27; (https://github.com/twbs/bootstrap.git) registered for path &#x27;api-ref-generator/themes/docsy/assets/vendor/bootstrap&#x27;</span><br><span class="line">Cloning into &#x27;/root/website/api-ref-generator/themes/docsy/assets/vendor/Font-Awesome&#x27;...</span><br><span class="line">Cloning into &#x27;/root/website/api-ref-generator/themes/docsy/assets/vendor/bootstrap&#x27;...</span><br><span class="line">remote: Total 0 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Enumerating objects: 8924, done.</span><br><span class="line">remote: Counting objects: 100% (8921/8921), done.</span><br><span class="line">remote: Compressing objects: 100% (2868/2868), done.</span><br><span class="line">remote: Total 4847 (delta 3027), reused 2286 (delta 1978), pack-reused 0</span><br><span class="line">Receiving objects: 100% (4847/4847), 5.77 MiB | 4.38 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (3027/3027), completed with 884 local objects.</span><br><span class="line">From https://github.com/FortAwesome/Font-Awesome</span><br><span class="line"> * branch            fcec2d1b01ff069ac10500ac42e4478d20d21f4c -&gt; FETCH_HEAD</span><br><span class="line">Submodule path &#x27;api-ref-generator/themes/docsy/assets/vendor/Font-Awesome&#x27;: checked out &#x27;fcec2d1b01ff069ac10500ac42e4478d20d21f4c&#x27;</span><br><span class="line">remote: Total 0 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Enumerating objects: 701, done.</span><br><span class="line">remote: Counting objects: 100% (701/701), done.</span><br><span class="line">remote: Compressing objects: 100% (511/511), done.</span><br><span class="line">remote: Total 528 (delta 115), reused 186 (delta 13), pack-reused 0</span><br><span class="line">Receiving objects: 100% (528/528), 2.01 MiB | 5.52 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (115/115), completed with 73 local objects.</span><br><span class="line">From https://github.com/twbs/bootstrap</span><br><span class="line"> * branch            a716fb03f965dc0846df479e14388b1b4b93d7ce -&gt; FETCH_HEAD</span><br><span class="line">Submodule path &#x27;api-ref-generator/themes/docsy/assets/vendor/bootstrap&#x27;: checked out &#x27;a716fb03f965dc0846df479e14388b1b4b93d7ce&#x27;</span><br><span class="line">remote: Total 0 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Enumerating objects: 76, done.</span><br><span class="line">remote: Counting objects: 100% (76/76), done.</span><br><span class="line">remote: Compressing objects: 100% (37/37), done.</span><br><span class="line">remote: Total 39 (delta 30), reused 6 (delta 0), pack-reused 0</span><br><span class="line">Unpacking objects: 100% (39/39), 4.48 KiB | 654.00 KiB/s, done.</span><br><span class="line">From https://github.com/google/docsy</span><br><span class="line"> * branch            1c77bb24483946f11c13f882f836a940b55ad019 -&gt; FETCH_HEAD</span><br><span class="line">Submodule path &#x27;themes/docsy&#x27;: checked out &#x27;1c77bb24483946f11c13f882f836a940b55ad019&#x27;</span><br><span class="line">Submodule &#x27;assets/vendor/Font-Awesome&#x27; (https://github.com/FortAwesome/Font-Awesome.git) registered for path &#x27;themes/docsy/assets/vendor/Font-Awesome&#x27;</span><br><span class="line">Submodule &#x27;assets/vendor/bootstrap&#x27; (https://github.com/twbs/bootstrap.git) registered for path &#x27;themes/docsy/assets/vendor/bootstrap&#x27;</span><br><span class="line">Cloning into &#x27;/root/website/themes/docsy/assets/vendor/Font-Awesome&#x27;...</span><br><span class="line">Cloning into &#x27;/root/website/themes/docsy/assets/vendor/bootstrap&#x27;...</span><br><span class="line">remote: Total 0 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Enumerating objects: 8925, done.</span><br><span class="line">remote: Counting objects: 100% (8922/8922), done.</span><br><span class="line">remote: Compressing objects: 100% (2801/2801), done.</span><br><span class="line">remote: Total 4848 (delta 3031), reused 2433 (delta 2046), pack-reused 0</span><br><span class="line">Receiving objects: 100% (4848/4848), 5.65 MiB | 4.21 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (3031/3031), completed with 855 local objects.</span><br><span class="line">From https://github.com/FortAwesome/Font-Awesome</span><br><span class="line"> * branch            7d3d774145ac38663f6d1effc6def0334b68ab7e -&gt; FETCH_HEAD</span><br><span class="line">Submodule path &#x27;themes/docsy/assets/vendor/Font-Awesome&#x27;: checked out &#x27;7d3d774145ac38663f6d1effc6def0334b68ab7e&#x27;</span><br><span class="line">remote: Total 0 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Enumerating objects: 770, done.</span><br><span class="line">remote: Counting objects: 100% (770/770), done.</span><br><span class="line">remote: Compressing objects: 100% (497/497), done.</span><br><span class="line">remote: Total 524 (delta 161), reused 183 (delta 19), pack-reused 0</span><br><span class="line">Receiving objects: 100% (524/524), 2.01 MiB | 2.53 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (161/161), completed with 122 local objects.</span><br><span class="line">From https://github.com/twbs/bootstrap</span><br><span class="line"> * branch            043a03c95a2ad6738f85b65e53b9dbdfb03b8d10 -&gt; FETCH_HEAD</span><br><span class="line">Submodule path &#x27;themes/docsy/assets/vendor/bootstrap&#x27;: checked out &#x27;043a03c95a2ad6738f85b65e53b9dbdfb03b8d10&#x27;</span><br><span class="line">root@cby:~/website# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~/website# make container-image</span><br><span class="line">docker build . \</span><br><span class="line">    --network=host \</span><br><span class="line">    --tag gcr.io/k8s-staging-sig-docs/k8s-website-hugo:v0.87.0-c8ffb2b5979c \</span><br><span class="line">    --build-arg HUGO_VERSION=0.87.0</span><br><span class="line">Sending build context to Docker daemon  4.096kB</span><br><span class="line">Step 1/12 : FROM golang:1.16-alpine</span><br><span class="line">1.16-alpine: Pulling from library/golang</span><br><span class="line">59bf1c3509f3: Pull complete </span><br><span class="line">666ba61612fd: Pull complete </span><br><span class="line">8ed8ca486205: Pull complete </span><br><span class="line">ca4bf87e467a: Pull complete </span><br><span class="line">0435e0963794: Pull complete </span><br><span class="line">Digest: sha256:5616dca835fa90ef13a843824ba58394dad356b7d56198fb7c93cbe76d7d67fe</span><br><span class="line">Status: Downloaded newer image for golang:1.16-alpine</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 7642119cd161</span></span><br><span class="line">Step 2/12 : LABEL maintainer=&quot;Luc Perkins &lt;lperkins@linuxfoundation.org&gt;&quot;</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> f6a8d1fa0c42</span></span><br><span class="line">Removing intermediate container f6a8d1fa0c42</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 291fd45ae748</span></span><br><span class="line">Step 3/12 : RUN apk add --no-cache     curl     gcc     g++     musl-dev     build-base     libc6-compat</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> 209e30a852d3</span></span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.15/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.15/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/25) Installing libgcc (10.3.1_git20211027-r0)</span><br><span class="line">(2/25) Installing libstdc++ (10.3.1_git20211027-r0)</span><br><span class="line">(3/25) Installing binutils (2.37-r3)</span><br><span class="line">(4/25) Installing libmagic (5.41-r0)</span><br><span class="line">(5/25) Installing file (5.41-r0)</span><br><span class="line">(6/25) Installing libgomp (10.3.1_git20211027-r0)</span><br><span class="line">(7/25) Installing libatomic (10.3.1_git20211027-r0)</span><br><span class="line">(8/25) Installing libgphobos (10.3.1_git20211027-r0)</span><br><span class="line">(9/25) Installing gmp (6.2.1-r1)</span><br><span class="line">(10/25) Installing isl22 (0.22-r0)</span><br><span class="line">(11/25) Installing mpfr4 (4.1.0-r0)</span><br><span class="line">(12/25) Installing mpc1 (1.2.1-r0)</span><br><span class="line">(13/25) Installing gcc (10.3.1_git20211027-r0)</span><br><span class="line">(14/25) Installing musl-dev (1.2.2-r7)</span><br><span class="line">(15/25) Installing libc-dev (0.7.2-r3)</span><br><span class="line">(16/25) Installing g++ (10.3.1_git20211027-r0)</span><br><span class="line">(17/25) Installing make (4.3-r0)</span><br><span class="line">(18/25) Installing fortify-headers (1.1-r1)</span><br><span class="line">(19/25) Installing patch (2.7.6-r7)</span><br><span class="line">(20/25) Installing build-base (0.5-r2)</span><br><span class="line">(21/25) Installing brotli-libs (1.0.9-r5)</span><br><span class="line">(22/25) Installing nghttp2-libs (1.46.0-r0)</span><br><span class="line">(23/25) Installing libcurl (7.80.0-r1)</span><br><span class="line">(24/25) Installing curl (7.80.0-r1)</span><br><span class="line">(25/25) Installing libc6-compat (1.2.2-r7)</span><br><span class="line">Executing busybox-1.34.1-r3.trigger</span><br><span class="line">OK: 198 MiB in 40 packages</span><br><span class="line">Removing intermediate container 209e30a852d3</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 83dfeba4ff34</span></span><br><span class="line">Step 4/12 : ARG HUGO_VERSION</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> fdbe162165c2</span></span><br><span class="line">Removing intermediate container fdbe162165c2</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> d6219e970f50</span></span><br><span class="line">Step 5/12 : RUN mkdir $HOME/src &amp;&amp;     cd $HOME/src &amp;&amp;     curl -L https://github.com/gohugoio/hugo/archive/refs/tags/v$&#123;HUGO_VERSION&#125;.tar.gz | tar -xz &amp;&amp;     cd &quot;hugo-$&#123;HUGO_VERSION&#125;&quot; &amp;&amp;     go install --tags extended</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> fe0b26ed3841</span></span><br><span class="line"><span class="meta prompt_">  %</span><span class="language-bash"> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0</span><br><span class="line">100 35.2M    0 35.2M    0     0  2216k      0 --:--:--  0:00:16 --:--:-- 3037k</span><br><span class="line">go: downloading github.com/alecthomas/chroma v0.9.2</span><br><span class="line">go: downloading github.com/bep/debounce v1.2.0</span><br><span class="line">go: downloading github.com/fsnotify/fsnotify v1.4.9</span><br><span class="line">go: downloading github.com/pkg/errors v0.9.1</span><br><span class="line">go: downloading github.com/spf13/afero v1.6.0</span><br><span class="line">go: downloading github.com/spf13/cobra v1.2.1</span><br><span class="line">go: downloading github.com/spf13/fsync v0.9.0</span><br><span class="line">go: downloading github.com/spf13/jwalterweatherman v1.1.0</span><br><span class="line">go: downloading github.com/spf13/pflag v1.0.5</span><br><span class="line">go: downloading golang.org/x/sync v0.0.0-20210220032951-036812b2e83c</span><br><span class="line">go: downloading github.com/pelletier/go-toml v1.9.3</span><br><span class="line">go: downloading github.com/spf13/cast v1.4.0</span><br><span class="line">go: downloading github.com/PuerkitoBio/purell v1.1.1</span><br><span class="line">go: downloading github.com/gobwas/glob v0.2.3</span><br><span class="line">go: downloading github.com/mattn/go-isatty v0.0.13</span><br><span class="line">go: downloading github.com/mitchellh/mapstructure v1.4.1</span><br><span class="line">go: downloading github.com/aws/aws-sdk-go v1.40.8</span><br><span class="line">go: downloading github.com/dustin/go-humanize v1.0.0</span><br><span class="line">go: downloading gocloud.dev v0.20.0</span><br><span class="line">go: downloading github.com/pelletier/go-toml/v2 v2.0.0-beta.3.0.20210727221244-fa0796069526</span><br><span class="line">go: downloading golang.org/x/text v0.3.6</span><br><span class="line">go: downloading google.golang.org/api v0.51.0</span><br><span class="line">go: downloading github.com/jdkato/prose v1.2.1</span><br><span class="line">go: downloading github.com/kyokomi/emoji/v2 v2.2.8</span><br><span class="line">go: downloading github.com/mitchellh/hashstructure v1.1.0</span><br><span class="line">go: downloading github.com/olekukonko/tablewriter v0.0.5</span><br><span class="line">go: downloading github.com/armon/go-radix v1.0.0</span><br><span class="line">go: downloading github.com/gohugoio/locales v0.14.0</span><br><span class="line">go: downloading github.com/gohugoio/localescompressed v0.14.0</span><br><span class="line">go: downloading github.com/gorilla/websocket v1.4.2</span><br><span class="line">go: downloading github.com/rogpeppe/go-internal v1.8.0</span><br><span class="line">go: downloading gopkg.in/yaml.v2 v2.4.0</span><br><span class="line">go: downloading github.com/niklasfasching/go-org v1.5.0</span><br><span class="line">go: downloading github.com/bep/gitmap v1.1.2</span><br><span class="line">go: downloading github.com/gobuffalo/flect v0.2.3</span><br><span class="line">go: downloading golang.org/x/sys v0.0.0-20210630005230-0f9fa26af87c</span><br><span class="line">go: downloading github.com/cpuguy83/go-md2man/v2 v2.0.0</span><br><span class="line">go: downloading github.com/cli/safeexec v1.0.0</span><br><span class="line">go: downloading github.com/dlclark/regexp2 v1.4.0</span><br><span class="line">go: downloading github.com/BurntSushi/locker v0.0.0-20171006230638-a6e239ea1c69</span><br><span class="line">go: downloading github.com/disintegration/gift v1.2.1</span><br><span class="line">go: downloading golang.org/x/image v0.0.0-20210220032944-ac19c3e999fb</span><br><span class="line">go: downloading github.com/PuerkitoBio/urlesc v0.0.0-20170810143723-de5bf2ad4578</span><br><span class="line">go: downloading golang.org/x/net v0.0.0-20210614182718-04defd469f4e</span><br><span class="line">go: downloading go.opencensus.io v0.23.0</span><br><span class="line">go: downloading golang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1</span><br><span class="line">go: downloading github.com/Azure/azure-pipeline-go v0.2.2</span><br><span class="line">go: downloading github.com/Azure/azure-storage-blob-go v0.9.0</span><br><span class="line">go: downloading github.com/google/uuid v1.1.2</span><br><span class="line">go: downloading github.com/google/wire v0.4.0</span><br><span class="line">go: downloading cloud.google.com/go v0.87.0</span><br><span class="line">go: downloading github.com/googleapis/gax-go v2.0.2+incompatible</span><br><span class="line">go: downloading github.com/googleapis/gax-go/v2 v2.0.5</span><br><span class="line">go: downloading cloud.google.com/go/storage v1.10.0</span><br><span class="line">go: downloading golang.org/x/oauth2 v0.0.0-20210628180205-a41e5a781914</span><br><span class="line">go: downloading google.golang.org/genproto v0.0.0-20210716133855-ce7ef5c701ea</span><br><span class="line">go: downloading github.com/mattn/go-runewidth v0.0.9</span><br><span class="line">go: downloading github.com/bep/tmc v0.5.1</span><br><span class="line">go: downloading github.com/rwcarlsen/goexif v0.0.0-20190401172101-9e8deecbddbd</span><br><span class="line">go: downloading github.com/gohugoio/go-i18n/v2 v2.1.3-0.20210430103248-4c28c89f8013</span><br><span class="line">go: downloading github.com/russross/blackfriday v1.5.3-0.20200218234912-41c5fccfd6f6</span><br><span class="line">go: downloading github.com/bep/gowebp v0.1.0</span><br><span class="line">go: downloading github.com/muesli/smartcrop v0.3.0</span><br><span class="line">go: downloading google.golang.org/grpc v1.39.0</span><br><span class="line">go: downloading github.com/mattn/go-ieproxy v0.0.1</span><br><span class="line">go: downloading github.com/russross/blackfriday/v2 v2.0.1</span><br><span class="line">go: downloading google.golang.org/protobuf v1.27.1</span><br><span class="line">go: downloading github.com/danwakefield/fnmatch v0.0.0-20160403171240-cbb64ac3d964</span><br><span class="line">go: downloading github.com/yuin/goldmark v1.4.0</span><br><span class="line">go: downloading github.com/yuin/goldmark-highlighting v0.0.0-20200307114337-60d527fdb691</span><br><span class="line">go: downloading github.com/miekg/mmark v1.3.6</span><br><span class="line">go: downloading github.com/tdewolff/minify/v2 v2.9.21</span><br><span class="line">go: downloading github.com/sanity-io/litter v1.5.1</span><br><span class="line">go: downloading github.com/getkin/kin-openapi v0.68.0</span><br><span class="line">go: downloading github.com/ghodss/yaml v1.0.0</span><br><span class="line">go: downloading github.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e</span><br><span class="line">go: downloading github.com/shurcooL/sanitized_anchor_name v1.0.0</span><br><span class="line">go: downloading github.com/jmespath/go-jmespath v0.4.0</span><br><span class="line">go: downloading github.com/BurntSushi/toml v0.3.1</span><br><span class="line">go: downloading github.com/evanw/esbuild v0.12.17</span><br><span class="line">go: downloading github.com/tdewolff/parse/v2 v2.5.19</span><br><span class="line">go: downloading github.com/bep/godartsass v0.12.0</span><br><span class="line">go: downloading github.com/bep/golibsass v1.0.0</span><br><span class="line">go: downloading github.com/golang/protobuf v1.5.2</span><br><span class="line">go: downloading github.com/google/go-cmp v0.5.6</span><br><span class="line">go: downloading github.com/go-openapi/jsonpointer v0.19.5</span><br><span class="line">go: downloading github.com/go-openapi/swag v0.19.5</span><br><span class="line">go: downloading github.com/mailru/easyjson v0.0.0-20190626092158-b2ccc519800e</span><br><span class="line">Removing intermediate container fe0b26ed3841</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 034cde1adc00</span></span><br><span class="line">Step 6/12 : FROM golang:1.16-alpine</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 7642119cd161</span></span><br><span class="line">Step 7/12 : RUN apk add --no-cache     runuser     git     openssh-client     rsync     npm &amp;&amp;     npm install -D autoprefixer postcss-cli</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> 2af5902e5287</span></span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.15/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.15/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/27) Installing brotli-libs (1.0.9-r5)</span><br><span class="line">(2/27) Installing nghttp2-libs (1.46.0-r0)</span><br><span class="line">(3/27) Installing libcurl (7.80.0-r1)</span><br><span class="line">(4/27) Installing expat (2.4.7-r0)</span><br><span class="line">(5/27) Installing pcre2 (10.39-r0)</span><br><span class="line">(6/27) Installing git (2.34.2-r0)</span><br><span class="line">(7/27) Installing c-ares (1.18.1-r0)</span><br><span class="line">(8/27) Installing libgcc (10.3.1_git20211027-r0)</span><br><span class="line">(9/27) Installing libstdc++ (10.3.1_git20211027-r0)</span><br><span class="line">(10/27) Installing icu-libs (69.1-r1)</span><br><span class="line">(11/27) Installing libuv (1.42.0-r0)</span><br><span class="line">(12/27) Installing nodejs-current (17.9.0-r0)</span><br><span class="line">(13/27) Installing npm (8.1.3-r0)</span><br><span class="line">(14/27) Installing openssh-keygen (8.8_p1-r1)</span><br><span class="line">(15/27) Installing ncurses-terminfo-base (6.3_p20211120-r0)</span><br><span class="line">(16/27) Installing ncurses-libs (6.3_p20211120-r0)</span><br><span class="line">(17/27) Installing libedit (20210910.3.1-r0)</span><br><span class="line">(18/27) Installing openssh-client-common (8.8_p1-r1)</span><br><span class="line">(19/27) Installing openssh-client-default (8.8_p1-r1)</span><br><span class="line">(20/27) Installing libacl (2.2.53-r0)</span><br><span class="line">(21/27) Installing lz4-libs (1.9.3-r1)</span><br><span class="line">(22/27) Installing popt (1.18-r0)</span><br><span class="line">(23/27) Installing zstd-libs (1.5.0-r0)</span><br><span class="line">(24/27) Installing rsync (3.2.3-r5)</span><br><span class="line">(25/27) Installing libeconf (0.4.2-r0)</span><br><span class="line">(26/27) Installing linux-pam (1.5.2-r0)</span><br><span class="line">(27/27) Installing runuser (2.37.4-r0)</span><br><span class="line">Executing busybox-1.34.1-r3.trigger</span><br><span class="line">OK: 106 MiB in 42 packages</span><br><span class="line"></span><br><span class="line">added 73 packages, and audited 74 packages in 15s</span><br><span class="line"></span><br><span class="line">17 packages are looking for funding</span><br><span class="line">  run `npm fund` for details</span><br><span class="line"></span><br><span class="line">found 0 vulnerabilities</span><br><span class="line">Removing intermediate container 2af5902e5287</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 620ef2580a98</span></span><br><span class="line">Step 8/12 : RUN mkdir -p /var/hugo &amp;&amp;     addgroup -Sg 1000 hugo &amp;&amp;     adduser -Sg hugo -u 1000 -h /var/hugo hugo &amp;&amp;     chown -R hugo: /var/hugo &amp;&amp;     runuser -u hugo -- git config --global --add safe.directory /src</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> dc169979de70</span></span><br><span class="line">Removing intermediate container dc169979de70</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 1006a4277115</span></span><br><span class="line">Step 9/12 : COPY --from=0 /go/bin/hugo /usr/local/bin/hugo</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 9bd8581cf0c3</span></span><br><span class="line">Step 10/12 : WORKDIR /src</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> 89fb367fe208</span></span><br><span class="line">Removing intermediate container 89fb367fe208</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> b299d26f87a7</span></span><br><span class="line">Step 11/12 : USER hugo:hugo</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> 353a5aec3b6e</span></span><br><span class="line">Removing intermediate container 353a5aec3b6e</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> ec88a8ce29a5</span></span><br><span class="line">Step 12/12 : EXPOSE 1313</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> Running <span class="keyword">in</span> 2649b06d597f</span></span><br><span class="line">Removing intermediate container 2649b06d597f</span><br><span class="line"><span class="meta prompt_"> ---&gt;</span><span class="language-bash"> 20b483234fde</span></span><br><span class="line">Successfully built 20b483234fde</span><br><span class="line">Successfully tagged gcr.io/k8s-staging-sig-docs/k8s-website-hugo:v0.87.0-c8ffb2b5979c</span><br><span class="line">root@cby:~/website# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="构建容器"><a href="#构建容器" class="headerlink" title="构建容器"></a>构建容器</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~/website# make container-serve</span><br><span class="line">docker run --rm --interactive --tty --volume /root/website:/src --cap-drop=ALL --cap-add=AUDIT_WRITE --read-only --mount type=tmpfs,destination=/tmp,tmpfs-mode=01777 -p 1313:1313 gcr.io/k8s-staging-sig-docs/k8s-website-hugo:v0.87.0-c8ffb2b5979c hugo server --buildFuture --environment development --bind 0.0.0.0 --destination /tmp/hugo --cleanDestinationDir</span><br><span class="line">Start building sites … </span><br><span class="line">hugo v0.87.0+extended linux/amd64 BuildDate=unknown</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">----</span><br><span class="line"></span><br><span class="line">                   |  EN  |  ZH  | KO  | JA  | FR  | IT  | DE  | ES  | PT-BR | ID  | RU  | VI  | PL  | UK   </span><br><span class="line">-------------------+------+------+-----+-----+-----+-----+-----+-----+-------+-----+-----+-----+-----+------</span><br><span class="line">  Pages            | 1453 | 1015 | 539 | 450 | 338 |  71 | 164 | 292 |   186 | 335 | 155 |  77 |  69 |  92  </span><br><span class="line">  Paginator pages  |   43 |    9 |   0 |   0 |   0 |   0 |   0 |   0 |     0 |   0 |   0 |   0 |   0 |   0  </span><br><span class="line">  Non-page files   |  509 |  386 | 200 | 266 |  73 |  20 |  17 |  33 |    30 | 105 |  24 |   8 |   6 |  20  </span><br><span class="line">  Static files     |  838 |  838 | 838 | 838 | 838 | 838 | 838 | 838 |   838 | 838 | 838 | 838 | 838 | 838  </span><br><span class="line">  Processed images |    1 |    1 |   0 |   0 |   0 |   0 |   0 |   0 |     0 |   0 |   0 |   0 |   0 |   0  </span><br><span class="line">  Aliases          |    8 |    2 |   3 |   1 |   0 |   1 |   0 |   0 |     1 |   1 |   1 |   0 |   0 |   0  </span><br><span class="line">  Sitemaps         |    2 |    1 |   1 |   1 |   1 |   1 |   1 |   1 |     1 |   1 |   1 |   1 |   1 |   1  </span><br><span class="line">  Cleaned          |    0 |    0 |   0 |   0 |   0 |   0 |   0 |   0 |     0 |   0 |   0 |   0 |   0 |   0  </span><br><span class="line"></span><br><span class="line">Built in 15926 ms</span><br><span class="line">Watching for changes in /src/&#123;archetypes,assets,content,data,i18n,layouts,package.json,postcss.config.js,static,themes&#125;</span><br><span class="line">Watching for config changes in /src/config.toml, /src/themes/docsy/config.toml, /src/go.mod</span><br><span class="line">Environment: &quot;development&quot;</span><br><span class="line">Serving pages from /tmp/hugo</span><br><span class="line">Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender</span><br><span class="line">Web Server is available at http://localhost:1313/ (bind address 0.0.0.0)</span><br><span class="line">Press Ctrl+C to stop</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="后台启动"><a href="#后台启动" class="headerlink" title="后台启动"></a>后台启动</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# docker images</span><br><span class="line">REPOSITORY                                     TAG                    IMAGE ID       CREATED         SIZE</span><br><span class="line">gcr.io/k8s-staging-sig-docs/k8s-website-hugo   v0.87.0-c8ffb2b5979c   20b483234fde   4 minutes ago   501MB</span><br><span class="line">&lt;none&gt;                                         &lt;none&gt;                 034cde1adc00   4 minutes ago   1.8GB</span><br><span class="line">golang                                         1.16-alpine            7642119cd161   2 months ago    302MB</span><br><span class="line">root@cby:~#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@cby:~/website# docker run --rm --interactive -d --volume /root/website:/src --cap-drop=ALL --cap-add=AUDIT_WRITE --read-only --mount type=tmpfs,destination=/tmp,tmpfs-mode=01777 -p 1313:1313 gcr.io/k8s-staging-sig-docs/k8s-website-hugo:v0.87.0-c8ffb2b5979c hugo server --buildFuture --environment development --bind 0.0.0.0 --destination /tmp/hugo --cleanDestinationDir</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run --rm --interactive -d --volume /root/website:/src --cap-drop=ALL --cap-add=AUDIT_WRITE --read-only --mount type=tmpfs,destination=/tmp,tmpfs-mode=01777 -p 1313:1313 gcr.io/k8s-staging-sig-docs/k8s-website-hugo:v0.87.0-c8ffb2b5979c hugo server --buildFuture --environment development --bind 0.0.0.0 --destination /tmp/hugo --cleanDestinationDir</span><br><span class="line"></span><br><span class="line">root@cby:~/website# docker ps</span><br><span class="line">CONTAINER ID   IMAGE                                                               COMMAND                  CREATED         STATUS         PORTS                                       NAMES</span><br><span class="line">06f34ad73c67   gcr.io/k8s-staging-sig-docs/k8s-website-hugo:v0.87.0-c8ffb2b5979c   &quot;hugo server --build…&quot;   5 seconds ago   Up 4 seconds   0.0.0.0:1313-&gt;1313/tcp, :::1313-&gt;1313/tcp   nervous_kilby</span><br><span class="line">root@cby:~/website# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~/website# git pull</span><br><span class="line">remote: Enumerating objects: 187, done.</span><br><span class="line">remote: Counting objects: 100% (181/181), done.</span><br><span class="line">remote: Compressing objects: 100% (112/112), done.</span><br><span class="line">remote: Total 187 (delta 107), reused 126 (delta 69), pack-reused 6</span><br><span class="line">Receiving objects: 100% (187/187), 154.37 KiB | 403.00 KiB/s, done.</span><br><span class="line">Resolving deltas: 100% (107/107), completed with 35 local objects.</span><br><span class="line">From https://github.com/kubernetes/website</span><br><span class="line">   f559e15074..07e1929b49  main          -&gt; origin/main</span><br><span class="line">   8c980f042b..68e621e794  dev-1.24-ko.1 -&gt; origin/dev-1.24-ko.1</span><br><span class="line">Updating f559e15074..07e1929b49</span><br><span class="line">Fast-forward</span><br><span class="line"> content/en/docs/concepts/cluster-administration/manage-deployment.md                             |   2 +-</span><br><span class="line"> content/en/docs/concepts/containers/runtime-class.md                                             |   2 +-</span><br><span class="line"> content/en/docs/concepts/workloads/pods/init-containers.md                                       |   1 -</span><br><span class="line"> content/en/docs/reference/setup-tools/kubeadm/generated/kubeadm_certs_generate-csr.md            |   3 ---</span><br><span class="line"> content/en/docs/reference/setup-tools/kubeadm/generated/kubeadm_init_phase_preflight.md          |   3 ---</span><br><span class="line"> content/en/docs/reference/setup-tools/kubeadm/generated/kubeadm_init_phase_upload-certs.md       |   3 ---</span><br><span class="line"> content/en/docs/reference/setup-tools/kubeadm/generated/kubeadm_join_phase_control-plane-join.md |   3 ---</span><br><span class="line"> content/en/docs/reference/setup-tools/kubeadm/generated/kubeadm_token.md                         |   3 ---</span><br><span class="line"> content/en/docs/reference/setup-tools/kubeadm/generated/kubeadm_token_create.md                  |   1 -</span><br><span class="line"> content/en/docs/reference/setup-tools/kubeadm/generated/kubeadm_token_delete.md                  |   3 ---</span><br><span class="line"> content/en/docs/reference/setup-tools/kubeadm/generated/kubeadm_version.md                       |   3 ---</span><br><span class="line"> content/en/docs/setup/production-environment/windows/intro-windows-in-kubernetes.md              |   2 +-</span><br><span class="line"> content/en/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes.md                         |   2 +-</span><br><span class="line"> content/en/docs/tasks/configure-pod-container/configure-pod-initialization.md                    |   1 -</span><br><span class="line"> content/en/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume.md              |   2 +-</span><br><span class="line"> content/pt-br/blog/_posts/2022-02-17-updated-dockershim-faq.md                                   |   2 +-</span><br><span class="line"> content/zh/docs/concepts/architecture/nodes.md                                                   | 134 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++---------------</span><br><span class="line"> content/zh/docs/concepts/cluster-administration/system-logs.md                                   | 117 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++---------------------------------------</span><br><span class="line"> content/zh/docs/concepts/containers/runtime-class.md                                             |  62 +++++++++++++++++++++-----------------------------------------</span><br><span class="line"> content/zh/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins.md                | 111 +++++++++++++++++++++------------------------------------------------------------------------------------------</span><br><span class="line"> content/zh/docs/concepts/overview/kubernetes-api.md                                              |  71 +++++++++++++++++++++++++++++++++++++++++++++++++----------------------</span><br><span class="line"> content/zh/docs/reference/setup-tools/kubeadm/generated/kubeadm_certs_generate-csr.md            |  26 ++++++++++++++++++++------</span><br><span class="line"> content/zh/docs/reference/setup-tools/kubeadm/generated/kubeadm_init_phase_preflight.md          |  28 +++++++++++++++++++++++++---</span><br><span class="line"> content/zh/docs/reference/setup-tools/kubeadm/generated/kubeadm_init_phase_upload-certs.md       |  30 +++++++++++++++++++++++++++++-</span><br><span class="line"> content/zh/docs/reference/setup-tools/kubeadm/generated/kubeadm_join_phase_control-plane-join.md |  20 +++++++++++++++++++-</span><br><span class="line"> content/zh/docs/reference/setup-tools/kubeadm/generated/kubeadm_token.md                         |  24 +++++++++++++++++++++++-</span><br><span class="line"> content/zh/docs/reference/setup-tools/kubeadm/generated/kubeadm_token_create.md                  |  51 ++++++++++++++++++++++++++++++++++++++++++++++++++-</span><br><span class="line"> content/zh/docs/reference/setup-tools/kubeadm/generated/kubeadm_token_delete.md                  |  24 +++++++++++++++++++++++-</span><br><span class="line"> content/zh/docs/reference/setup-tools/kubeadm/generated/kubeadm_version.md                       |  24 +++++++++++++++++++++++-</span><br><span class="line"> static/_redirects                                                                                |  48 +++++++++++++++++++++++++++++++++---------------</span><br><span class="line"> 30 files changed, 539 insertions(+), 267 deletions(-)</span><br><span class="line">root@hello:~/website# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/06e685ec4b12465782a405c360dd1348~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>使用kubeadm初始化IPV4/IPV6集群</title>
    <url>/2022/05/12/2022-05-12-%E4%BD%BF%E7%94%A8kubeadm%E5%88%9D%E5%A7%8B%E5%8C%96IPV4_IPV6%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h1 id="使用kubeadm初始化IPV4-x2F-IPV6集群"><a href="#使用kubeadm初始化IPV4-x2F-IPV6集群" class="headerlink" title="使用kubeadm初始化IPV4&#x2F;IPV6集群"></a>使用kubeadm初始化IPV4&#x2F;IPV6集群</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6d3da68f95d943bb9691ea9b660b9d63~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<p>图片</p>
<h1 id="CentOS-配置YUM源"><a href="#CentOS-配置YUM源" class="headerlink" title="CentOS 配置YUM源"></a>CentOS 配置YUM源</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=kubernetes</span><br><span class="line">baseurl=https://mirrors.ustc.edu.cn/kubernetes/yum/repos/kubernetes-el7-$basearch</span><br><span class="line">enabled=1</span><br><span class="line">EOF</span><br><span class="line">setenforce 0</span><br><span class="line">yum install -y kubelet kubeadm kubectl</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 如安装老版本</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> yum install kubelet-1.16.9-0 kubeadm-1.16.9-0 kubectl-1.16.9-0</span></span><br><span class="line"></span><br><span class="line">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 将 SELinux 设置为 permissive 模式（相当于将其禁用）</span></span><br><span class="line">sudo setenforce 0</span><br><span class="line">sudo sed -i &#x27;s/^SELINUX=enforcing$/SELINUX=permissive/&#x27; /etc/selinux/config</span><br><span class="line">sudo systemctl enable --now kubelet</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Ubuntu-配置APT源"><a href="#Ubuntu-配置APT源" class="headerlink" title="Ubuntu 配置APT源"></a>Ubuntu 配置APT源</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install -y kubelet kubeadm kubectl</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 如安装老版本</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> apt install kubelet=1.23.6-00 kubeadm=1.23.6-00 kubectl=1.23.6-00</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="配置containerd"><a href="#配置containerd" class="headerlink" title="配置containerd"></a>配置containerd</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar -C / -xzf cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建服务启动文件</span></span><br><span class="line">cat &gt; /etc/systemd/system/containerd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=containerd container runtime</span><br><span class="line">Documentation=https://containerd.io</span><br><span class="line">After=network.target local-fs.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=-/sbin/modprobe overlay</span><br><span class="line">ExecStart=/usr/local/bin/containerd</span><br><span class="line">Type=notify</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">TasksMax=infinity</span><br><span class="line">OOMScoreAdjust=-999</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">sed -i &quot;s#SystemdCgroup\ \=\ false#SystemdCgroup\ \=\ true#g&quot; /etc/containerd/config.toml</span><br><span class="line">sed -i &quot;s#k8s.gcr.io#registry.cn-hangzhou.aliyuncs.com/chenby#g&quot; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now containerd</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="配置基础环境"><a href="#配置基础环境" class="headerlink" title="配置基础环境"></a>配置基础环境</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.all.forwarding = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">modprobe br_netfilter</span><br><span class="line"></span><br><span class="line">sudo sysctl --system</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line"></span><br><span class="line">cat /etc/fstab</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">2408:8207:78ce:7561::21 k8s-master01</span><br><span class="line">2408:8207:78ce:7561::22 k8s-node01</span><br><span class="line">2408:8207:78ce:7561::23 k8s-node02</span><br><span class="line"></span><br><span class="line">10.0.0.21 k8s-master01</span><br><span class="line">10.0.0.22 k8s-node01</span><br><span class="line">10.0.0.23 k8s-node02</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="初始化安装"><a href="#初始化安装" class="headerlink" title="初始化安装"></a>初始化安装</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@k8s-master01:~# kubeadm config images list --image-repository registry.cn-hangzhou.aliyuncs.com/chenby</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/chenby/kube-apiserver:v1.24.0</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/chenby/kube-controller-manager:v1.24.0</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/chenby/kube-scheduler:v1.24.0</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/chenby/kube-proxy:v1.24.0</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/chenby/pause:3.7</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/chenby/etcd:3.5.3-0</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/chenby/coredns:v1.8.6</span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# vim kubeadm.yaml </span><br><span class="line">root@k8s-master01:~# cat kubeadm.yaml</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: &quot;10.0.0.21&quot;</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  taints:</span><br><span class="line">  - effect: PreferNoSchedule</span><br><span class="line">    key: node-role.kubernetes.io/master</span><br><span class="line">---</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.24.0</span><br><span class="line">imageRepository: registry.cn-hangzhou.aliyuncs.com/chenby</span><br><span class="line">networking:</span><br><span class="line">  podSubnet: 172.16.0.0/12,fc00::/48</span><br><span class="line">  serviceSubnet: 10.96.0.0/12,fd00::/108</span><br><span class="line">root@k8s-master01:~#</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~# kubeadm init --config=kubeadm.yaml </span><br><span class="line">[init] Using Kubernetes version: v1.24.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &#x27;kubeadm config images pull&#x27;</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.0.21]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [k8s-master01 localhost] and IPs [10.0.0.21 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [k8s-master01 localhost] and IPs [10.0.0.21 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 6.504341 seconds</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class="line">[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the taints [node-role.kubernetes.io/master:PreferNoSchedule]</span><br><span class="line">[bootstrap-token] Using token: lnodkp.3n8i4m33sqwg39w2</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 10.0.0.21:6443 --token lnodkp.3n8i4m33sqwg39w2 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:0ed7e18ea2b49bb599bc45e72f764bbe034ef1dce47729f2722467c167754da8 </span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~#   mkdir -p $HOME/.kube</span><br><span class="line">root@k8s-master01:~#   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">root@k8s-master01:~#   sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-node01:~# kubeadm join 10.0.0.21:6443 --token qf3z22.qwtqieutbkik6dy4 \</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash"> --discovery-token-ca-cert-hash sha256:2ade8c834a41cc1960993a600c89fa4bb86e3594f82e09bcd42633d4defbda0d</span></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">root@k8s-node01:~# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-node02:~# kubeadm join 10.0.0.21:6443 --token qf3z22.qwtqieutbkik6dy4 \</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash"> --discovery-token-ca-cert-hash sha256:2ade8c834a41cc1960993a600c89fa4bb86e3594f82e09bcd42633d4defbda0d</span></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">root@k8s-node02:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="查看集群"><a href="#查看集群" class="headerlink" title="查看集群"></a>查看集群</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@k8s-master01:~# kubectl  get node</span><br><span class="line">NAME           STATUS   ROLES           AGE    VERSION</span><br><span class="line">k8s-master01   Ready    control-plane   111s   v1.24.0</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;          82s    v1.24.0</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;          92s    v1.24.0</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~# </span><br><span class="line">root@k8s-master01:~# kubectl  get pod -A</span><br><span class="line">NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-bc77466fc-jxkpv                1/1     Running   0          83s</span><br><span class="line">kube-system   coredns-bc77466fc-nrc9l                1/1     Running   0          83s</span><br><span class="line">kube-system   etcd-k8s-master01                      1/1     Running   0          87s</span><br><span class="line">kube-system   kube-apiserver-k8s-master01            1/1     Running   0          89s</span><br><span class="line">kube-system   kube-controller-manager-k8s-master01   1/1     Running   0          87s</span><br><span class="line">kube-system   kube-proxy-2lgrn                       1/1     Running   0          83s</span><br><span class="line">kube-system   kube-proxy-69p9r                       1/1     Running   0          47s</span><br><span class="line">kube-system   kube-proxy-g58m2                       1/1     Running   0          42s</span><br><span class="line">kube-system   kube-scheduler-k8s-master01            1/1     Running   0          87s</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="配置calico"><a href="#配置calico" class="headerlink" title="配置calico"></a>配置calico</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/cby-chen/Kubernetes/main/yaml/calico-ipv6.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> vim calico-ipv6.yaml</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> calico-config ConfigMap处</span></span><br><span class="line">    &quot;ipam&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;calico-ipam&quot;,</span><br><span class="line">        &quot;assign_ipv4&quot;: &quot;true&quot;,</span><br><span class="line">        &quot;assign_ipv6&quot;: &quot;true&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    - name: IP</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: IP6</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">      value: &quot;172.16.0.0/16&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV6POOL_CIDR</span><br><span class="line">      value: &quot;fc00::/48&quot;</span><br><span class="line"></span><br><span class="line">    - name: FELIX_IPV6SUPPORT</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line"></span><br><span class="line">kubectl  apply -f calico-ipv6.yaml </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="测试IPV6"><a href="#测试IPV6" class="headerlink" title="测试IPV6"></a>测试IPV6</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@k8s-master01:~# cat cby.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: chenby</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: chenby</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: chenby</span><br><span class="line">        image: nginx</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: &quot;128Mi&quot;</span><br><span class="line">            cpu: &quot;500m&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  ipFamilyPolicy: PreferDualStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">  - IPv6</span><br><span class="line">  - IPv4</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: chenby</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line"></span><br><span class="line">kubectl  apply -f cby.yaml </span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# kubectl  get pod </span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">chenby-57479d5997-6pfzg   1/1     Running   0          6m</span><br><span class="line">chenby-57479d5997-jjwpk   1/1     Running   0          6m</span><br><span class="line">chenby-57479d5997-pzrkc   1/1     Running   0          6m</span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# kubectl  get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">chenby       NodePort    fd00::f816   &lt;none&gt;        80:30265/TCP   6m7s</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP        168m</span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# curl -I http://[2408:8207:78ce:7561::21]:30265/</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Wed, 11 May 2022 07:01:43 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# curl -I http://10.0.0.21:30265/</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Wed, 11 May 2022 07:01:54 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
<blockquote>
<p>本文使用 <a href="https://juejin.cn/post/6940875049587097631">文章同步助手</a> 同步</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>kubernetes （k8s） v1.24.0 安装dashboard面板</title>
    <url>/2022/05/17/2022-05-17-kubernetes_%EF%BC%88k8s%EF%BC%89_v1.24.0_%E5%AE%89%E8%A3%85dashboard%E9%9D%A2%E6%9D%BF/</url>
    <content><![CDATA[<h1 id="kubernetes-（k8s）-v1-24-0-安装dashboard面板"><a href="#kubernetes-（k8s）-v1-24-0-安装dashboard面板" class="headerlink" title="kubernetes （k8s） v1.24.0 安装dashboard面板"></a>kubernetes （k8s） v1.24.0 安装dashboard面板</h1><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>v1.24.0 使用之前的安装方式，在安装过程中会有一些异常，此文档已修复已知问题。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7147040ee6a44e2289da8e961a380509~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="下载所需配置"><a href="#下载所需配置" class="headerlink" title="下载所需配置"></a>下载所需配置</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@k8s-master01:~# wget https://raw.githubusercontent.com/cby-chen/Kubernetes/main/yaml/dashboard.yaml</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# kubectl apply -f dashboard.yaml</span><br><span class="line">namespace/kubernetes-dashboard unchanged</span><br><span class="line">serviceaccount/kubernetes-dashboard unchanged</span><br><span class="line">service/kubernetes-dashboard configured</span><br><span class="line">secret/kubernetes-dashboard-certs unchanged</span><br><span class="line">secret/kubernetes-dashboard-csrf configured</span><br><span class="line">Warning: resource secrets/kubernetes-dashboard-key-holder is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.</span><br><span class="line">secret/kubernetes-dashboard-key-holder configured</span><br><span class="line">configmap/kubernetes-dashboard-settings unchanged</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard unchanged</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard unchanged</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard unchanged</span><br><span class="line">deployment.apps/kubernetes-dashboard configured</span><br><span class="line">service/dashboard-metrics-scraper unchanged</span><br><span class="line">deployment.apps/dashboard-metrics-scraper unchanged</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# wget https://raw.githubusercontent.com/cby-chen/Kubernetes/main/yaml/dashboard-user.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# kubectl  apply -f dashboard-user.yaml</span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line">root@k8s-master01:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="修改为nodePort"><a href="#修改为nodePort" class="headerlink" title="修改为nodePort"></a>修改为nodePort</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@k8s-master01:~# kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">service/kubernetes-dashboard edited</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-master01:~# kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.96.221.8   &lt;none&gt;        443:32721/TCP   74s</span><br><span class="line">root@k8s-master01:~#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="创建token"><a href="#创建token" class="headerlink" title="创建token"></a>创建token</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@k8s-master01:~# kubectl -n kubernetes-dashboard create token admin-user</span><br><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6IlV6b3NRbDRiTll4VEl1a1VGbU53M2Y2X044Wjdfa21mQ0dfYk5BWktHRjAifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjUyNzYzMjUzLCJpYXQiOjE2NTI3NTk2NTMsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiNDYxYjc4MDItNTgzMS00MTNmLTg2M2ItODdlZWVkOTI3MTdiIn19LCJuYmYiOjE2NTI3NTk2NTMsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2VyIn0.nFF729zlDxz4Ed3fcVk5BE8Akc6jod6akf2rksVGJHmfurY7NO1nHP4EekrMx1FRa2JfoPOHTdxcWDVaQAymDC4vgP5aW5RCEOURUY6YdTQUxleRiX-Bgp3eNRHNOcPvdedGm0w7M7gnZqCwy4tsgyiXkIM7zZpvCqdCA1vGJxf_UIck4R8Izua5NSacnG25miIvAmxNzOAEHDD_jDIDHnPVi3iVZzrjBkDwG6spYx_yJbbLy1XbJCYMMH44X4ajuQulV_NS-aiIHj_-PbxfrBRAJCVTZ8L3zD14BraeAAHFqSoiLXohmYHLLjshtraVu4XcvehJDfnRMi8Y4b6sqA</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">https://192.168.1.31:32721/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a>  <br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a>  <br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a>  <br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a>  <br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a>  <br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a>  <br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a>  <br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a>  <br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a>  <br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a>  <br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》<br>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>关于</title>
    <url>/2021/12/30/2021-12-30-%E5%85%B3%E4%BA%8E/</url>
    <content><![CDATA[<p>小陈运维，致力于运维技术博客文档分享。互相学习，相互进步。</p>
<p>小陈网站：<br><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br>关于小陈：<a href="https://www.oiox.cn/index.php/start-page.html">https://www.oiox.cn/index.php/start-page.html</a></p>
<p><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a><br><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://weibo.com/u/5982474121">https://weibo.com/u/5982474121</a><br><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://space.bilibili.com/352476552/article">https://space.bilibili.com/352476552/article</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、哔哩哔哩、今日头条、新浪微博、个人博客</p>
<p>全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
]]></content>
  </entry>
  <entry>
    <title>留言</title>
    <url>/2022/05/06/2022-05-06-%E7%95%99%E8%A8%80/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>统计</title>
    <url>/2022/05/06/2022-05-06-%E7%BB%9F%E8%AE%A1/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>直播</title>
    <url>/2022/05/16/2022-05-16-%E7%9B%B4%E6%92%AD/</url>
    <content><![CDATA[<h1 id="建议用电脑网页版打开哟"><a href="#建议用电脑网页版打开哟" class="headerlink" title="建议用电脑网页版打开哟"></a>建议用电脑网页版打开哟</h1><iframe style="width: 700px;height: 400px;" src="https://www.bilibili.com/blackboard/live/live-activity-player.html?cid=15020488&quality=0" frameborder="no"    framespacing="0" scrolling="no" allow="autoplay; encrypted-media" allowfullscreen="true"></iframe>]]></content>
  </entry>
  <entry>
    <title>kubernetes（k8s）常用deploy模板 并验证</title>
    <url>/2022/05/18/2022-05-18-kubernetes%EF%BC%88k8s%EF%BC%89%E5%B8%B8%E7%94%A8deploy%E6%A8%A1%E6%9D%BF_%E5%B9%B6%E9%AA%8C%E8%AF%81/</url>
    <content><![CDATA[<h1 id="kubernetes常用deploy模板，并验证"><a href="#kubernetes常用deploy模板，并验证" class="headerlink" title="kubernetes常用deploy模板，并验证"></a>kubernetes常用deploy模板，并验证</h1><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bcf3087eeb74496cbe982ff78aef0ac3~tplv-k3u1fbpfcp-zoom-1.image" alt="图片"></p>
<h1 id="编写deploy配置文件"><a href="#编写deploy配置文件" class="headerlink" title="编写deploy配置文件"></a>编写deploy配置文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# cat deploy.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata: </span><br><span class="line">  name: hostname-test-cby</span><br><span class="line">  labels:</span><br><span class="line">    name: hostname-test-cby</span><br><span class="line">spec:</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash"> 副本数</span></span><br><span class="line">  replicas: 10</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash"> 标签选择器</span></span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      name: hostname-test-cby</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash"> 更新策略</span></span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 3    # 更新最大数量</span><br><span class="line">      maxUnavailable: 3    #更新时最大不可用数量</span><br><span class="line">    type: RollingUpdate  #滚动更新</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash"> 模板</span></span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: hostname-test-cby</span><br><span class="line">    spec:</span><br><span class="line">      # 配置容器</span><br><span class="line">      containers:</span><br><span class="line">      - name: hostname-test-cby #容器名</span><br><span class="line">        image: nginx #镜像</span><br><span class="line">        imagePullPolicy: IfNotPresent # 拉取策略</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;100m&quot; #CPU限制</span><br><span class="line">            memory: &quot;300M&quot; #内存限制</span><br><span class="line">        # 健康监测</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: / # 探测路径</span><br><span class="line">            port: 80 # 端口</span><br><span class="line">          initialDelaySeconds: 15 # 第一次探测等待</span><br><span class="line">          timeoutSeconds: 3 # 探测的超时后等待多少秒</span><br><span class="line">        # 就绪探测</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: / # 探测路径</span><br><span class="line">            port: 80 # 端口</span><br><span class="line">          initialDelaySeconds: 10 # 第一次探测等待</span><br><span class="line">          timeoutSeconds: 3 # 探测的超时后等待多少秒</span><br><span class="line">        #环境变量</span><br><span class="line">        env:</span><br><span class="line">        - name: cby</span><br><span class="line">          value: chenby</span><br><span class="line">        # 配置容器端口</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">        # 配置挂载到目录</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /usr/share/nginx/html/</span><br><span class="line">          name: data</span><br><span class="line">      # 配置目录挂载</span><br><span class="line">      volumes:</span><br><span class="line">      - name: data</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /html/</span><br><span class="line">          type: Directory</span><br><span class="line">      # 配置指定解析</span><br><span class="line">      hostAliases:</span><br><span class="line">      - ip: &quot;192.168.1.1&quot; #IP地址</span><br><span class="line">        hostnames:</span><br><span class="line">        - &quot;cby&quot; #主机名</span><br><span class="line">        - &quot;cby.chenby.cn&quot; #主机名</span><br><span class="line">      - ip: &quot;192.168.1.10&quot;#IP地址</span><br><span class="line">        hostnames:</span><br><span class="line">        - &quot;chenby&quot; #主机名</span><br><span class="line">        - &quot;chenby.chenby.cn&quot; #主机名</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="执行deploy配置文件"><a href="#执行deploy配置文件" class="headerlink" title="执行deploy配置文件"></a>执行deploy配置文件</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hello:~# kubectl apply -f deploy.yaml </span><br><span class="line">deployment.apps/hostname-test-cby created</span><br><span class="line"></span><br><span class="line">root@hello:~# mkdir /html</span><br><span class="line">root@hello:~# echo 123 &gt; /html/index.html</span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  get pod  -o wide</span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">hostname-test-cby-86df45bf-9fx5n   1/1     Running   0          43s   172.17.125.38   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-cmv2b   1/1     Running   0          43s   172.17.125.37   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-f6drb   1/1     Running   0          43s   172.17.125.41   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-g79x2   1/1     Running   0          43s   172.27.14.232   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-h6blv   1/1     Running   0          43s   172.27.14.233   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-hqjnj   1/1     Running   0          43s   172.17.125.40   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-jt2rz   1/1     Running   0          43s   172.27.14.236   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-s5jjn   1/1     Running   0          43s   172.27.14.235   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-vfkbt   1/1     Running   0          43s   172.17.125.39   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hostname-test-cby-86df45bf-z2x2b   1/1     Running   0          43s   172.27.14.234   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="进入pod进行检查"><a href="#进入pod进行检查" class="headerlink" title="进入pod进行检查"></a>进入pod进行检查</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 访问测试</span></span><br><span class="line">root@hello:~# curl 172.17.125.38</span><br><span class="line">123</span><br><span class="line">root@hello:~# </span><br><span class="line"></span><br><span class="line">root@hello:~# kubectl  exec hostname-test-cby-86df45bf-9fx5n -it -- /bin/bash </span><br><span class="line">root@hostname-test-cby-86df45bf-9fx5n:/# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 查看dns解析</span></span><br><span class="line">root@hostname-test-cby-86df45bf-9fx5n:/# cat /etc/resolv.conf </span><br><span class="line">search default.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line">nameserver 10.96.0.10</span><br><span class="line">options ndots:5</span><br><span class="line">root@hostname-test-cby-86df45bf-9fx5n:/# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 查看host配置已生效</span></span><br><span class="line">root@hostname-test-cby-86df45bf-9fx5n:/# cat /etc/hosts </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Kubernetes-managed hosts file.</span></span><br><span class="line">127.0.0.1       localhost</span><br><span class="line">::1     localhost ip6-localhost ip6-loopback</span><br><span class="line">fe00::0 ip6-localnet</span><br><span class="line">fe00::0 ip6-mcastprefix</span><br><span class="line">fe00::1 ip6-allnodes</span><br><span class="line">fe00::2 ip6-allrouters</span><br><span class="line">172.27.14.197   hostname-test-cby-86df45bf-9fx5n</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> Entries added by HostAliases.</span></span><br><span class="line">192.168.1.1     cby     cby.chenby.cn</span><br><span class="line">192.168.1.10    chenby  chenby.chenby.cn</span><br><span class="line">root@hostname-test-cby-86df45bf-9fx5n:/#</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"> 查看环境变量</span></span><br><span class="line">root@hostname-test-cby-86df45bf-9fx5n:/# echo $cby</span><br><span class="line">chenby</span><br><span class="line">root@hostname-test-cby-86df45bf-9fx5n:/#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》<br>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>友链</title>
    <url>/2022/05/06/2022-05-06-%E5%8F%8B%E9%93%BE/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>关于 ServiceAccounts 及其 Secrets 的重大变化</title>
    <url>/2022/05/25/2022-05-25-%E5%85%B3%E4%BA%8E_ServiceAccounts_%E5%8F%8A%E5%85%B6_Secrets_%E7%9A%84%E9%87%8D%E5%A4%A7%E5%8F%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="关于-ServiceAccounts-及其-Secrets-的重大变化"><a href="#关于-ServiceAccounts-及其-Secrets-的重大变化" class="headerlink" title="关于 ServiceAccounts 及其 Secrets 的重大变化"></a>关于 ServiceAccounts 及其 Secrets 的重大变化</h1><p>kubernetes v1.24.0 更新之后进行创建 ServiceAccount 不会自动生成 Secret 需要对其手动创建</p>
<h2 id="创建-ServiceAccount"><a href="#创建-ServiceAccount" class="headerlink" title="创建 ServiceAccount"></a>创建 ServiceAccount</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: cby</span><br><span class="line">  namespace: default</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h2 id="查看-ServiceAccount"><a href="#查看-ServiceAccount" class="headerlink" title="查看 ServiceAccount"></a>查看 ServiceAccount</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# kubectl get serviceaccounts cby</span><br><span class="line">NAME                     SECRETS   AGE</span><br><span class="line">cby                      0         9s</span><br></pre></td></tr></table></figure>



<h2 id="查看-ServiceAccount-详细详细，没有对-Token-进行创建"><a href="#查看-ServiceAccount-详细详细，没有对-Token-进行创建" class="headerlink" title="查看 ServiceAccount 详细详细，没有对 Token 进行创建"></a>查看 ServiceAccount 详细详细，没有对 Token 进行创建</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# kubectl describe serviceaccounts cby</span><br><span class="line">Name:                cby</span><br><span class="line">Namespace:           default</span><br><span class="line">Labels:              &lt;none&gt;</span><br><span class="line">Annotations:         &lt;none&gt;</span><br><span class="line">Image pull secrets:  &lt;none&gt;</span><br><span class="line">Mountable secrets:   &lt;none&gt;</span><br><span class="line">Tokens:              &lt;none&gt;</span><br><span class="line">Events:              &lt;none&gt;</span><br><span class="line">root@cby:~# </span><br><span class="line"></span><br><span class="line">root@cby:~# kubectl get secrets</span><br><span class="line">No resources found in default namespace.</span><br><span class="line">root@cby:~#</span><br></pre></td></tr></table></figure>



<h2 id="创建-Secret-资源并与-ServiceAccount-关联"><a href="#创建-Secret-资源并与-ServiceAccount-关联" class="headerlink" title="创建 Secret 资源并与 ServiceAccount 关联"></a>创建 Secret 资源并与 ServiceAccount 关联</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">type: kubernetes.io/service-account-token</span><br><span class="line">metadata:</span><br><span class="line">  name: cby</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/service-account.name: &quot;cby&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h2 id="再次查看-ServiceAccount-已对-Secret-关联"><a href="#再次查看-ServiceAccount-已对-Secret-关联" class="headerlink" title="再次查看 ServiceAccount 已对 Secret 关联"></a>再次查看 ServiceAccount 已对 Secret 关联</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# kubectl describe serviceaccounts cby</span><br><span class="line">Name:                cby</span><br><span class="line">Namespace:           default</span><br><span class="line">Labels:              &lt;none&gt;</span><br><span class="line">Annotations:         &lt;none&gt;</span><br><span class="line">Image pull secrets:  &lt;none&gt;</span><br><span class="line">Mountable secrets:   &lt;none&gt;</span><br><span class="line">Tokens:              cby</span><br><span class="line">Events:              &lt;none&gt;</span><br><span class="line">root@cby:~# </span><br></pre></td></tr></table></figure>



<h2 id="查看-Secret-详细详细"><a href="#查看-Secret-详细详细" class="headerlink" title="查看 Secret 详细详细"></a>查看 Secret 详细详细</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# kubectl get secrets cby </span><br><span class="line">NAME   TYPE                                  DATA   AGE</span><br><span class="line">cby    kubernetes.io/service-account-token   3      35s</span><br><span class="line">root@cby:~# </span><br><span class="line"></span><br><span class="line">root@cby:~# kubectl describe secrets cby </span><br><span class="line">Name:         cby</span><br><span class="line">Namespace:    default</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: cby</span><br><span class="line">              kubernetes.io/service-account.uid: c6629b84-1c08-483d-9a12-c2930ac0a2fe</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line"></span><br><span class="line">ca.crt:     1363 bytes</span><br><span class="line">namespace:  7 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IjRwMk02VU9leXU3N3lraUN6UVQ4R3I3Smw3eFhYdEVMX1Z2aTFjU2luSVEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImNieSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJjYnkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjNjYyOWI4NC0xYzA4LTQ4M2QtOWExMi1jMjkzMGFjMGEyZmUiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6ZGVmYXVsdDpjYnkifQ.r0nHVPO-QY-1p0fwKx0p0AfkiCGpTZ8vGzE8ioDtih5cAP1ew3ABnrj01EqeIEn8vhz29i0NHtZfh5XtYttqjU6o_b1IGFtkW5uIwlxYX2gtmm9njsL2NM7YM6lM0BDfQXvYrpKUuWLQUR-8i79h-GH9WFydmEwnthdxit7uSMJIZuyZP0X0ebxWUg1GGHsqNPy514zXEyvTZh8vs4fVl5ROJbKzFuSuQ1TntXMDncHSf8DSJ7iHUZ0pD757ysHvFKH9l6IbGrt8GUvxWxjMvnNjclLozKgfLXQEOVei39VrPU5DtsPp9DU8C04Gn4TWFW_WsyEWM14lGsQEGD-2QA</span><br><span class="line">root@cby:~# </span><br></pre></td></tr></table></figure>



<h2 id="删除-ServiceAccount-随之-Secret-一并自动删除"><a href="#删除-ServiceAccount-随之-Secret-一并自动删除" class="headerlink" title="删除 ServiceAccount 随之 Secret 一并自动删除"></a>删除 ServiceAccount 随之 Secret 一并自动删除</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@cby:~# kubectl delete serviceaccounts cby </span><br><span class="line">serviceaccount &quot;cby&quot; deleted</span><br><span class="line">root@cby:~#</span><br><span class="line"></span><br><span class="line">root@cby:~# kubectl get serviceaccounts</span><br><span class="line">root@cby:~# kubectl get secret</span><br></pre></td></tr></table></figure>



<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》<br>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>修复kube-proxy证书权限过大问题</title>
    <url>/2022/05/26/2022-05-26-%E4%BF%AE%E5%A4%8Dkube-proxy%E8%AF%81%E4%B9%A6%E6%9D%83%E9%99%90%E8%BF%87%E5%A4%A7%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="修复kube-proxy证书权限过大问题"><a href="#修复kube-proxy证书权限过大问题" class="headerlink" title="修复kube-proxy证书权限过大问题"></a>修复kube-proxy证书权限过大问题</h1><p>之前kube-proxy服务都是用admin集群证书，造成权限过大不安全，后续该问题，将在文档中修复</p>
<p>请关注 <a href="https://github.com/cby-chen/Kubernetes">https://github.com/cby-chen/Kubernetes</a></p>
<h2 id="创建生成证书配置文件"><a href="#创建生成证书配置文件" class="headerlink" title="创建生成证书配置文件"></a>创建生成证书配置文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">详细见：https://github.com/cby-chen/Kubernetes#23%E5%88%9B%E5%BB%BA%E8%AF%81%E4%B9%A6%E7%9B%B8%E5%85%B3%E6%96%87%E4%BB%B6</span><br><span class="line"></span><br><span class="line">cat &gt; ca-config.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; kube-proxy-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h2 id="生成-CA-证书和私钥"><a href="#生成-CA-证书和私钥" class="headerlink" title="生成 CA 证书和私钥"></a>生成 CA 证书和私钥</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   kube-proxy-csr.json | cfssljson -bare /etc/kubernetes/pki/kube-proxy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ll /etc/kubernetes/pki/kube-proxy*</span><br><span class="line">-rw-r--r-- 1 root root 1045 May 26 10:21 /etc/kubernetes/pki/kube-proxy.csr</span><br><span class="line">-rw------- 1 root root 1675 May 26 10:21 /etc/kubernetes/pki/kube-proxy-key.pem</span><br><span class="line">-rw-r--r-- 1 root root 1464 May 26 10:21 /etc/kubernetes/pki/kube-proxy.pem</span><br></pre></td></tr></table></figure>

<p>设置集群参数和客户端认证参数时 –embed-certs 都为 true，这会将 certificate-authority、client-certificate 和 client-key 指向的证书文件内容写入到生成的 kube-proxy.kubeconfig 文件中；</p>
<p>kube-proxy.pem 证书中 CN 为 system:kube-proxy，kube-apiserver 预定义的 RoleBinding cluster-admin 将User system:kube-proxy 与 Role system:node-proxier 绑定，该 Role 授予了调用 kube-apiserver Proxy 相关 API 的权限；</p>
<h2 id="创建-kubeconfig-文件"><a href="#创建-kubeconfig-文件" class="headerlink" title="创建 kubeconfig 文件"></a>创建 kubeconfig 文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --server=https://10.0.0.89:8443     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kube-proxy  \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/kube-proxy.pem     \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/kube-proxy-key.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kube-proxy@kubernetes    \</span><br><span class="line">  --cluster=kubernetes     \</span><br><span class="line">  --user=kube-proxy     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kube-proxy@kubernetes  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure>



<h2 id="无法访问-pod资源"><a href="#无法访问-pod资源" class="headerlink" title="无法访问 pod资源"></a>无法访问 pod资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[cby@k8s-master01 ~]$ kubectl  get pod </span><br><span class="line">Error from server (Forbidden): pods is forbidden: User &quot;system:kube-proxy&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;default&quot;</span><br><span class="line">[cby@k8s-master01 ~]$ </span><br></pre></td></tr></table></figure>



<h2 id="可以访问-node资源"><a href="#可以访问-node资源" class="headerlink" title="可以访问 node资源"></a>可以访问 node资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[cby@k8s-master01 ~]$ kubectl  get node</span><br><span class="line">NAME           STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8s-master01   Ready    &lt;none&gt;   2d21h   v1.24.0</span><br><span class="line">k8s-master02   Ready    &lt;none&gt;   2d21h   v1.24.0</span><br><span class="line">k8s-master03   Ready    &lt;none&gt;   2d21h   v1.24.0</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;   2d21h   v1.24.0</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;   2d21h   v1.24.0</span><br><span class="line">[cby@k8s-master01 ~]$ </span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="将配置进行替换"><a href="#将配置进行替换" class="headerlink" title="将配置进行替换"></a>将配置进行替换</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig; done</span><br><span class="line"></span><br><span class="line">for NODE in k8s-node01 k8s-node02; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig;  done</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# cat /etc/kubernetes/kube-proxy.yaml </span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12,fc00::/48 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# systemctl  restart kube-proxy</span><br></pre></td></tr></table></figure>





<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》<br>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>创建用户认证授权的 kubeconfig 文件</title>
    <url>/2022/05/25/2022-05-25-%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83%E7%9A%84_kubeconfig_%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<h1 id="创建用户认证授权的-kubeconfig-文件"><a href="#创建用户认证授权的-kubeconfig-文件" class="headerlink" title="创建用户认证授权的 kubeconfig 文件"></a>创建用户认证授权的 kubeconfig 文件</h1><p>当我们安装好集群后，如果想要把 kubectl 命令交给用户使用，就不得不对用户的身份进行认证和对其权限做出限制。</p>
<p>下面以创建一个 cby 用户并将其绑定到 cby 和 chenby 的 namespace 为例说明。</p>
<h2 id="创建生成证书配置文件"><a href="#创建生成证书配置文件" class="headerlink" title="创建生成证书配置文件"></a>创建生成证书配置文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">详细见：https://github.com/cby-chen/Kubernetes#23%E5%88%9B%E5%BB%BA%E8%AF%81%E4%B9%A6%E7%9B%B8%E5%85%B3%E6%96%87%E4%BB%B6</span><br><span class="line"></span><br><span class="line">cat &gt; ca-config.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; cby-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;cby&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h2 id="生成-CA-证书和私钥"><a href="#生成-CA-证书和私钥" class="headerlink" title="生成 CA 证书和私钥"></a>生成 CA 证书和私钥</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   cby-csr.json | cfssljson -bare /etc/kubernetes/pki/cby</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ll /etc/kubernetes/pki/cby*</span><br><span class="line">-rw-r--r-- 1 root root 1021 May 25 17:36 /etc/kubernetes/pki/cby.csr</span><br><span class="line">-rw------- 1 root root 1679 May 25 17:36 /etc/kubernetes/pki/cby-key.pem</span><br><span class="line">-rw-r--r-- 1 root root 1440 May 25 17:36 /etc/kubernetes/pki/cby.pem</span><br></pre></td></tr></table></figure>



<h2 id="创建-kubeconfig-文件"><a href="#创建-kubeconfig-文件" class="headerlink" title="创建 kubeconfig 文件"></a>创建 kubeconfig 文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --server=https://10.0.0.89:8443     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/cby.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials cby  \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/cby.pem     \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/cby-key.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/cby.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context cby@kubernetes    \</span><br><span class="line">  --cluster=kubernetes     \</span><br><span class="line">  --user=cby     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/cby.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context cby@kubernetes  --kubeconfig=/etc/kubernetes/cby.kubeconfig</span><br></pre></td></tr></table></figure>



<h2 id="添加用户并将配置其用户"><a href="#添加用户并将配置其用户" class="headerlink" title="添加用户并将配置其用户"></a>添加用户并将配置其用户</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">useradd cby</span><br><span class="line">su - cby</span><br><span class="line">mkdir .kube/</span><br><span class="line">exit </span><br><span class="line">cp /etc/kubernetes/cby.kubeconfig  /home/cby/.kube/config</span><br><span class="line">chown cby.cby /home/cby/.kube/config</span><br></pre></td></tr></table></figure>



<h2 id="RoleBinding"><a href="#RoleBinding" class="headerlink" title="RoleBinding"></a>RoleBinding</h2><p>需要使用 RBAC创建角色绑定以将该用户的行为限制在某个或某几个 namespace 空间范围内</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create namespace cby</span><br><span class="line">kubectl create namespace chenby</span><br><span class="line">kubectl create rolebinding cby --clusterrole=cluster-admin --user=cby --namespace=cby</span><br><span class="line">kubectl create rolebinding cby --clusterrole=cluster-admin --user=cby --namespace=chenby</span><br><span class="line"></span><br><span class="line">kubectl  describe -n chenby rolebindings.rbac.authorization.k8s.io cby </span><br><span class="line">Name:         cby</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Role:</span><br><span class="line">  Kind:  ClusterRole</span><br><span class="line">  Name:  cluster-admin</span><br><span class="line">Subjects:</span><br><span class="line">  Kind  Name  Namespace</span><br><span class="line">  ----  ----  ---------</span><br><span class="line">  User  cby   </span><br><span class="line"></span><br><span class="line">kubectl  describe -n cby rolebindings.rbac.authorization.k8s.io cby </span><br><span class="line">Name:         cby</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Role:</span><br><span class="line">  Kind:  ClusterRole</span><br><span class="line">  Name:  cluster-admin</span><br><span class="line">Subjects:</span><br><span class="line">  Kind  Name  Namespace</span><br><span class="line">  ----  ----  ---------</span><br><span class="line">  User  cby   </span><br><span class="line"></span><br><span class="line">su - cby</span><br></pre></td></tr></table></figure>



<h2 id="获取当前的-context"><a href="#获取当前的-context" class="headerlink" title="获取当前的 context"></a>获取当前的 context</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl config get-contexts</span><br><span class="line">CURRENT   NAME                        CLUSTER      AUTHINFO         NAMESPACE</span><br><span class="line"></span><br><span class="line">*         kubernetes-cby@kubernetes   kubernetes   kubernetes-cby   cby</span><br></pre></td></tr></table></figure>



<h2 id="无法访问-default-namespace"><a href="#无法访问-default-namespace" class="headerlink" title="无法访问 default namespace"></a>无法访问 default namespace</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[cby@k8s-master01 ~]$ kubectl get pods --namespace default</span><br><span class="line">Error from server (Forbidden): pods is forbidden: User &quot;cby&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;default&quot;</span><br><span class="line">[cby@k8s-master01 ~]$ </span><br></pre></td></tr></table></figure>



<h2 id="可以访问-cby-namespace"><a href="#可以访问-cby-namespace" class="headerlink" title="可以访问 cby namespace"></a>可以访问 cby namespace</h2><p>这样 cby 用户对 cby 和 chenby 两个 namespace 具有完全访问权限。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[cby@k8s-master01 ~]$ kubectl get pods --namespace cby</span><br><span class="line">No resources found in cby namespace.</span><br><span class="line">[cby@k8s-master01 ~]$ kubectl get pods --namespace chenby</span><br><span class="line">No resources found in chenby namespace.</span><br></pre></td></tr></table></figure>



<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://blog.csdn.net/qq/_33921750">https://blog.csdn.net/qq\_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》<br>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装 Kubernetes（k8s）</title>
    <url>/2022/05/29/2022-05-29-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85_Kubernetes%EF%BC%88k8s%EF%BC%89/</url>
    <content><![CDATA[<h1 id="二进制安装-Kubernetes（k8s）"><a href="#二进制安装-Kubernetes（k8s）" class="headerlink" title="二进制安装 Kubernetes（k8s）"></a>二进制安装 Kubernetes（k8s）</h1><p><a href="https://github.com/cby-chen/Kubernetes">Kubernetes</a> 开源不易，帮忙点个star，谢谢了</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>kubernetes（k8s） 二进制安装</p>
<p>后续尽可能第一时间更新新版本文档</p>
<p>1.23.3 和 1.23.4 和 1.23.5 和 1.23.6 和 1.24.0 和 1.24.1 文档以及安装包已生成。</p>
<p>若不使用IPv6，不对主机进行配置IPv6地址即可，不影响后续，但是集群依旧是IPv6的。</p>
<p>（下载更快）我的网盘共享：<a href="https://pan.oiox.cn/s/PetV">https://pan.oiox.cn/s/PetV</a></p>
<p>手动项目地址：<a href="https://github.com/cby-chen/Kubernetes">https://github.com/cby-chen/Kubernetes</a></p>
<p>脚本项目地址：<a href="https://github.com/cby-chen/Binary_installation_of_Kubernetes">https://github.com/cby-chen/Binary_installation_of_Kubernetes</a></p>
<p>kubernetes 1.24 变化较大，详细见：<a href="https://kubernetes.io/zh/blog/2022/04/07/upcoming-changes-in-kubernetes-1-24/">https://kubernetes.io/zh/blog/2022/04/07/upcoming-changes-in-kubernetes-1-24/</a></p>
<h1 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h1><p>每个版本文档如下链接</p>
<p><a href="https://github.com/cby-chen/Kubernetes/blob/main/v1.23.3-binary-install.md">https://github.com/cby-chen/Kubernetes/blob/main/v1.23.3-binary-install.md</a></p>
<p><a href="https://github.com/cby-chen/Kubernetes/blob/main/v1.23.4-binary-install.md">https://github.com/cby-chen/Kubernetes/blob/main/v1.23.4-binary-install.md</a></p>
<p><a href="https://github.com/cby-chen/Kubernetes/blob/main/v1.23.5-binary-install.md">https://github.com/cby-chen/Kubernetes/blob/main/v1.23.5-binary-install.md</a></p>
<p><a href="https://github.com/cby-chen/Kubernetes/blob/main/v1.23.6-binary-install.md">https://github.com/cby-chen/Kubernetes/blob/main/v1.23.6-binary-install.md</a></p>
<p><a href="https://github.com/cby-chen/Kubernetes/blob/main/v1.24.0-binary-install-IPv6-IPv4.md">https://github.com/cby-chen/Kubernetes/blob/main/v1.24.0-binary-install-IPv6-IPv4.md</a></p>
<p><a href="https://github.com/cby-chen/Kubernetes/blob/main/v1.24.1-binary-install-IPv6-IPv4.md">https://github.com/cby-chen/Kubernetes/blob/main/v1.24.1-binary-install-IPv6-IPv4.md</a></p>
<p><a href="https://github.com/cby-chen/Kubernetes/blob/main/v1.24.0-binary-install-IPv6-IPv4-Three-Masters-Two-Slaves.md">https://github.com/cby-chen/Kubernetes/blob/main/v1.24.0-binary-install-IPv6-IPv4-Three-Masters-Two-Slaves.md</a></p>
<h1 id="安装包"><a href="#安装包" class="headerlink" title="安装包"></a>安装包</h1><p>（下载更快）我自己的网盘：<a href="https://pan.oiox.cn/s/PetV">https://pan.oiox.cn/s/PetV</a></p>
<p>每个初始版本会打上releases，安装包在releases页面</p>
<p><a href="https://github.com/cby-chen/Kubernetes/releases">https://github.com/cby-chen/Kubernetes/releases</a></p>
<p>注意：1.23.3 版本当时没想到会后续更新，所以当时命名不太规范。</p>
<p>wget <a href="https://github.com/cby-chen/Kubernetes/releases/download/cby/Kubernetes.tar">https://github.com/cby-chen/Kubernetes/releases/download/cby/Kubernetes.tar</a></p>
<p>wget <a href="https://github.com/cby-chen/Kubernetes/releases/download/v1.23.4/kubernetes-v1.23.4.tar">https://github.com/cby-chen/Kubernetes/releases/download/v1.23.4/kubernetes-v1.23.4.tar</a></p>
<p>wget <a href="https://github.com/cby-chen/Kubernetes/releases/download/v1.23.5/kubernetes-v1.24.5.tar">https://github.com/cby-chen/Kubernetes/releases/download/v1.23.5/kubernetes-v1.24.5.tar</a></p>
<p>wget <a href="https://github.com/cby-chen/Kubernetes/releases/download/v1.23.6/kubernetes-v1.23.6.tar">https://github.com/cby-chen/Kubernetes/releases/download/v1.23.6/kubernetes-v1.23.6.tar</a></p>
<p>wget <a href="https://github.com/cby-chen/Kubernetes/releases/download/v1.24.0/kubernetes-v1.24.0.tar">https://github.com/cby-chen/Kubernetes/releases/download/v1.24.0/kubernetes-v1.24.0.tar</a></p>
<p>wget <a href="https://github.com/cby-chen/Kubernetes/releases/download/v1.24.1/kubernetes-v1.24.1.tar">https://github.com/cby-chen/Kubernetes/releases/download/v1.24.1/kubernetes-v1.24.1.tar</a></p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul>
<li><p>建议在 <a href="https://github.com/cby-chen/Kubernetes">Kubernetes</a> 查看文档，后续会陆续更新文档</p>
</li>
<li><p>小陈网站：</p>
</li>
</ul>
<ol>
<li><a href="https://blog.oiox.cn/">https://blog.oiox.cn/</a></li>
<li><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></li>
<li><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></li>
<li><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></li>
</ol>
<ul>
<li>关于小陈：<a href="https://www.oiox.cn/index.php/start-page.html">https://www.oiox.cn/index.php/start-page.html</a></li>
</ul>
<p>其他文档请查看如下，欢迎关注微信公众号《Linux运维交流社区》：</p>
<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a>   </p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a>  </p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a>  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a>  </p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a>  </p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a>  </p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a>  </p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a>  </p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a>  </p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a>  </p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>安装 Metrics server</title>
    <url>/2022/06/03/2022-06-03-%E5%AE%89%E8%A3%85_Metrics_server/</url>
    <content><![CDATA[<p>#安装 Metrics server</p>
<p>Metrics Server 是 Kubernetes 内置自动缩放管道的可扩展、高效的容器资源指标来源。</p>
<p>Metrics Server 从 Kubelets 收集资源指标，并通过Metrics API在 Kubernetes apiserver 中公开它们，以供 Horizo​​ntal Pod Autoscaler和Vertical Pod Autoscaler使用。Metrics API 也可以通过 访问kubectl top，从而更容易调试自动缩放管道。</p>
<h2 id="单机版"><a href="#单机版" class="headerlink" title="单机版"></a>单机版</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">单机版 </span><br><span class="line">wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml</span><br><span class="line"></span><br><span class="line">查看镜像地址</span><br><span class="line">grep -rn image components.yaml </span><br><span class="line">140:        image: k8s.gcr.io/metrics-server/metrics-server:v0.6.1</span><br><span class="line">141:        imagePullPolicy: IfNotPresent</span><br><span class="line"></span><br><span class="line">设置镜像地址为阿里云</span><br><span class="line">sed -i &quot;s#k8s.gcr.io/metrics-server#registry.cn-hangzhou.aliyuncs.com/chenby#g&quot; components.yaml</span><br><span class="line"></span><br><span class="line">查看镜像地址已更新</span><br><span class="line">grep -rn image components.yaml </span><br><span class="line">140:        image: registry.cn-hangzhou.aliyuncs.com/chenby/metrics-server:v0.6.1</span><br><span class="line">141:        imagePullPolicy: IfNotPresent</span><br><span class="line"></span><br><span class="line">args添加tls证书配置选项</span><br><span class="line">vim components.yaml</span><br><span class="line"></span><br><span class="line">添加&quot;- --kubelet-insecure-tls&quot;</span><br><span class="line"></span><br><span class="line">例：</span><br><span class="line">	    args:</span><br><span class="line">        - --cert-dir=/tmp</span><br><span class="line">        - --secure-port=4443</span><br><span class="line">        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">        - --kubelet-use-node-status-port</span><br><span class="line">        - --metric-resolution=15s</span><br><span class="line">        - --kubelet-insecure-tls</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/chenby/metrics-server:v0.6.1</span><br><span class="line"></span><br><span class="line">执行配置</span><br><span class="line">kubectl apply -f components.yaml </span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">deployment.apps/metrics-server created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="高可用版本"><a href="#高可用版本" class="headerlink" title="高可用版本"></a>高可用版本</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">高可用版本</span><br><span class="line">wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability.yaml</span><br><span class="line"></span><br><span class="line">查看镜像地址</span><br><span class="line">grep -rn image high-availability.yaml </span><br><span class="line">150:        image: k8s.gcr.io/metrics-server/metrics-server:v0.6.1</span><br><span class="line">151:        imagePullPolicy: IfNotPresent</span><br><span class="line"></span><br><span class="line">设置镜像地址为阿里云</span><br><span class="line">sed -i &quot;s#k8s.gcr.io/metrics-server#registry.cn-hangzhou.aliyuncs.com/chenby#g&quot; high-availability.yaml</span><br><span class="line"></span><br><span class="line">查看镜像地址已更新</span><br><span class="line">grep -rn image high-availability.yaml </span><br><span class="line">150:        image: registry.cn-hangzhou.aliyuncs.com/chenby/metrics-server:v0.6.1</span><br><span class="line">151:        imagePullPolicy: IfNotPresent</span><br><span class="line"></span><br><span class="line">args添加tls证书配置选项</span><br><span class="line">vim high-availability.yaml</span><br><span class="line"></span><br><span class="line">添加&quot;- --kubelet-insecure-tls&quot;</span><br><span class="line"></span><br><span class="line">例：</span><br><span class="line">	    args:</span><br><span class="line">        - --cert-dir=/tmp</span><br><span class="line">        - --secure-port=4443</span><br><span class="line">        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">        - --kubelet-use-node-status-port</span><br><span class="line">        - --metric-resolution=15s</span><br><span class="line">        - --kubelet-insecure-tls</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/chenby/metrics-server:v0.6.1</span><br><span class="line"></span><br><span class="line">执行配置</span><br><span class="line">kubectl apply -f high-availability.yaml</span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">deployment.apps/metrics-server created</span><br><span class="line">Warning: policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget</span><br><span class="line">poddisruptionbudget.policy/metrics-server created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br></pre></td></tr></table></figure>



<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">查看metrics资源</span><br><span class="line">kubectl  get pod -n kube-system | grep metrics</span><br><span class="line">metrics-server-65fb95948b-2bcht            1/1     Running   0             32s</span><br><span class="line">metrics-server-65fb95948b-vqp5s            1/1     Running   0             32s</span><br><span class="line"></span><br><span class="line">查看node资源情况</span><br><span class="line">kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   127m         1%     2439Mi          64%       </span><br><span class="line">k8s-node01     50m          0%     1825Mi          23%       </span><br><span class="line">k8s-node02     53m          0%     1264Mi          16%   </span><br><span class="line"></span><br><span class="line">查看pod资源情况</span><br><span class="line">kubectl  top pod </span><br><span class="line">NAME                      CPU(cores)   MEMORY(bytes)   </span><br><span class="line">chenby-57479d5997-44926   0m           10Mi            </span><br><span class="line">chenby-57479d5997-tbpqc   0m           11Mi            </span><br><span class="line">chenby-57479d5997-w8cp2   0m           6Mi </span><br><span class="line"></span><br></pre></td></tr></table></figure>





<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a><br>https:&#x2F;blog.oiox.cn&#x2F;<br><a href="https://www.chenby.cn/">https://www.chenby.cn/</a><br><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a><br><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a><br><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a><br><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a><br><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a><br><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a><br><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a><br><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a><br><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a><br>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》<br>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装Kubernetes（k8s） v1.24.1 IPv4/IPv6双栈</title>
    <url>/2022/05/29/2022-05-29-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85Kubernetes%EF%BC%88k8s%EF%BC%89_v1.24.1_IPv4_IPv6%E5%8F%8C%E6%A0%88/</url>
    <content><![CDATA[<h1 id="二进制安装Kubernetes（k8s）-v1-24-1-IPv4-x2F-IPv6双栈"><a href="#二进制安装Kubernetes（k8s）-v1-24-1-IPv4-x2F-IPv6双栈" class="headerlink" title="二进制安装Kubernetes（k8s） v1.24.1 IPv4&#x2F;IPv6双栈"></a>二进制安装Kubernetes（k8s） v1.24.1 IPv4&#x2F;IPv6双栈</h1><p><a href="https://github.com/cby-chen/Kubernetes">Kubernetes</a> 开源不易，帮忙点个star，谢谢了</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>kubernetes二进制安装</p>
<p>后续尽可能第一时间更新新版本文档</p>
<p>1.23.3 和 1.23.4 和 1.23.5 和 1.23.6 和 1.24.0 和1.24.1 文档以及安装包已生成。</p>
<p>若不使用IPv6，不对主机进行配置IPv6地址即可，不影响后续，但是集群依旧是支持IPv6的。</p>
<p><a href="https://github.com/cby-chen/Kubernetes/releases">https://github.com/cby-chen/Kubernetes/releases</a></p>
<p>手动项目地址：<a href="https://github.com/cby-chen/Kubernetes">https://github.com/cby-chen/Kubernetes</a></p>
<p>脚本项目地址：<a href="https://github.com/cby-chen/Binary_installation_of_Kubernetes">https://github.com/cby-chen/Binary_installation_of_Kubernetes</a></p>
<p>kubernetes 1.24 变化较大，详细见：<a href="https://kubernetes.io/zh/blog/2022/04/07/upcoming-changes-in-kubernetes-1-24/">https://kubernetes.io/zh/blog/2022/04/07/upcoming-changes-in-kubernetes-1-24/</a></p>
<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1.环境"></a>1.环境</h1><table>
<thead>
<tr>
<th>主机名称</th>
<th>IP地址</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td>Master01</td>
<td>10.0.0.61</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master02</td>
<td>10.0.0.62</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Master03</td>
<td>10.0.0.63</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node01</td>
<td>10.0.0.64</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node02</td>
<td>10.0.0.65</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node03</td>
<td>10.0.0.66</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node04</td>
<td>10.0.0.67</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node05</td>
<td>10.0.0.68</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Lb01</td>
<td>10.0.0.70</td>
<td>Lb01节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td>Lb02</td>
<td>10.0.0.80</td>
<td>Lb02节点</td>
<td>haproxy、keepalived</td>
</tr>
<tr>
<td></td>
<td>10.0.0.69</td>
<td>VIP</td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">软件</th>
<th align="left">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">kernel</td>
<td align="left">5.18.0-1.el8</td>
</tr>
<tr>
<td align="left">CentOS 8</td>
<td align="left">v8 或者 v7</td>
</tr>
<tr>
<td align="left">kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy</td>
<td align="left">v1.24.1</td>
</tr>
<tr>
<td align="left">etcd</td>
<td align="left">v3.5.4</td>
</tr>
<tr>
<td align="left">containerd</td>
<td align="left">v1.5.11</td>
</tr>
<tr>
<td align="left">cfssl</td>
<td align="left">v1.6.1</td>
</tr>
<tr>
<td align="left">cni</td>
<td align="left">v1.1.1</td>
</tr>
<tr>
<td align="left">crictl</td>
<td align="left">v1.24.2</td>
</tr>
<tr>
<td align="left">haproxy</td>
<td align="left">v1.8.27</td>
</tr>
<tr>
<td align="left">keepalived</td>
<td align="left">v2.1.5</td>
</tr>
</tbody></table>
<p>网段</p>
<p>物理主机：10.0.0.0&#x2F;24</p>
<p>service：10.96.0.0&#x2F;12</p>
<p>pod：172.16.0.0&#x2F;12</p>
<p>建议k8s集群与etcd集群分开安装</p>
<p>安装包已经整理好：<a href="https://github.com/cby-chen/Kubernetes/releases/download/v1.24.1/kubernetes-v1.24.1.tar">https://github.com/cby-chen/Kubernetes/releases/download/v1.24.1/kubernetes-v1.24.1.tar</a></p>
<h2 id="1-1-k8s基础系统环境配置"><a href="#1-1-k8s基础系统环境配置" class="headerlink" title="1.1.k8s基础系统环境配置"></a>1.1.k8s基础系统环境配置</h2><h3 id="1-2-配置IP"><a href="#1-2-配置IP" class="headerlink" title="1.2.配置IP"></a>1.2.配置IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@10.0.0.190 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.61/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.146 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.62/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.242 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.63/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.152 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.64/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.124 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.65/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.126 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.66/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.247 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.67/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.207 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.68/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.101 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.70/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.195 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.80/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ssh root@10.0.0.61 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::10; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.62 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::20; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.63 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::30; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.64 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::40; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.65 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::50; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.66 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::60; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.67 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::70; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.68 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::80; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.70 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::90; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.80 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78ca:9fa1::100; nmcli con mod ens160 ipv6.gateway 2408:8207:78ca:9fa1::1; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="1-3-设置主机名"><a href="#1-3-设置主机名" class="headerlink" title="1.3.设置主机名"></a>1.3.设置主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-master02</span><br><span class="line">hostnamectl set-hostname k8s-master03</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br><span class="line">hostnamectl set-hostname k8s-node03</span><br><span class="line">hostnamectl set-hostname k8s-node04</span><br><span class="line">hostnamectl set-hostname k8s-node05</span><br><span class="line">hostnamectl set-hostname lb01</span><br><span class="line">hostnamectl set-hostname lb02</span><br></pre></td></tr></table></figure>

<h3 id="1-4-配置yum源"><a href="#1-4-配置yum源" class="headerlink" title="1.4.配置yum源"></a>1.4.配置yum源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 7</span></span><br><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 8</span></span><br><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于私有仓库</span></span><br><span class="line">sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; -e &#x27;s|^#baseurl=http://mirror.centos.org/\$contentdir|baseurl=http://10.0.0.123/centos|g&#x27; -i.bak  /etc/yum.repos.d/CentOS-*.repo</span><br></pre></td></tr></table></figure>

<h3 id="1-5-安装一些必备工具"><a href="#1-5-安装一些必备工具" class="headerlink" title="1.5.安装一些必备工具"></a>1.5.安装一些必备工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install wget jq psmisc vim net-tools nfs-utils telnet yum-utils device-mapper-persistent-data lvm2 git network-scripts tar curl -y</span><br></pre></td></tr></table></figure>

<h3 id="1-6-选择性下载需要工具"><a href="#1-6-选择性下载需要工具" class="headerlink" title="1.6.选择性下载需要工具"></a>1.6.选择性下载需要工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1.下载kubernetes1.24.+的二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md</span><br><span class="line"></span><br><span class="line">wget https://dl.k8s.io/v1.24.1/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">2.下载etcdctl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/etcd-io/etcd/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.5.4/etcd-v3.5.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">3.docker-ce二进制包下载地址</span><br><span class="line">二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><br><span class="line"></span><br><span class="line">这里需要下载20.10.+版本</span><br><span class="line"></span><br><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-20.10.14.tgz</span><br><span class="line"></span><br><span class="line">4.containerd二进制包下载</span><br><span class="line">github下载地址：https://github.com/containerd/containerd/releases</span><br><span class="line"></span><br><span class="line">containerd下载时下载带cni插件的二进制包。</span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">5.下载cfssl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/cloudflare/cfssl/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.1_linux_amd64</span><br><span class="line"></span><br><span class="line">6.cni插件下载</span><br><span class="line">github下载地址：https://github.com/containernetworking/plugins/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span><br><span class="line"></span><br><span class="line">7.crictl客户端二进制下载</span><br><span class="line">github下载：https://github.com/kubernetes-sigs/cri-tools/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.24.2/crictl-v1.24.2-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="1-7-关闭防火墙"><a href="#1-7-关闭防火墙" class="headerlink" title="1.7.关闭防火墙"></a>1.7.关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br></pre></td></tr></table></figure>

<h3 id="1-8-关闭SELinux"><a href="#1-8-关闭SELinux" class="headerlink" title="1.8.关闭SELinux"></a>1.8.关闭SELinux</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure>

<h3 id="1-9-关闭交换分区"><a href="#1-9-关闭交换分区" class="headerlink" title="1.9.关闭交换分区"></a>1.9.关闭交换分区</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line"></span><br><span class="line">cat /etc/fstab</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>

<h3 id="1-10-关闭NetworkManager-并启用-network-lb除外"><a href="#1-10-关闭NetworkManager-并启用-network-lb除外" class="headerlink" title="1.10.关闭NetworkManager 并启用 network (lb除外)"></a>1.10.关闭NetworkManager 并启用 network (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now NetworkManager</span><br><span class="line">systemctl start network &amp;&amp; systemctl enable network</span><br></pre></td></tr></table></figure>

<h3 id="1-11-进行时间同步-lb除外"><a href="#1-11-进行时间同步-lb除外" class="headerlink" title="1.11.进行时间同步 (lb除外)"></a>1.11.进行时间同步 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">服务端</span></span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">cat &gt; /etc/chrony.conf &lt;&lt; EOF </span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">allow 10.0.0.0/24</span><br><span class="line">local stratum 10</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd</span><br><span class="line">systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">客户端</span></span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool 10.0.0.61 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">客户端安装一条命令</span></span><br><span class="line">yum install chrony -y ; sed -i &quot;s#2.centos.pool.ntp.org#10.0.0.61#g&quot; /etc/chrony.conf ; systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用客户端进行验证</span></span><br><span class="line">chronyc sources -v</span><br></pre></td></tr></table></figure>

<h3 id="1-12-配置ulimit"><a href="#1-12-配置ulimit" class="headerlink" title="1.12.配置ulimit"></a>1.12.配置ulimit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -SHn 65535</span><br><span class="line">cat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOF</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* seft memlock unlimited</span><br><span class="line">* hard memlock unlimitedd</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="1-13-配置免密登录"><a href="#1-13-配置免密登录" class="headerlink" title="1.13.配置免密登录"></a>1.13.配置免密登录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br><span class="line">ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;</span><br><span class="line">export IP=&quot;10.0.0.61 10.0.0.62 10.0.0.63 10.0.0.64 10.0.0.65 10.0.0.66 10.0.0.67 10.0.0.68 10.0.0.70 10.0.0.60&quot;</span><br><span class="line">export SSHPASS=123123</span><br><span class="line">for HOST in $IP;do</span><br><span class="line">     sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $HOST</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="1-14-添加启用源-lb除外"><a href="#1-14-添加启用源-lb除外" class="headerlink" title="1.14.添加启用源 (lb除外)"></a>1.14.添加启用源 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为 RHEL-8或 CentOS-8配置源</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为 RHEL-7 SL-7 或 CentOS-7 安装 ELRepo</span> </span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看可用安装包</span></span><br><span class="line">yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available</span><br></pre></td></tr></table></figure>

<h3 id="1-15-升级内核至4-18版本以上-lb除外"><a href="#1-15-升级内核至4-18版本以上-lb除外" class="headerlink" title="1.15.升级内核至4.18版本以上 (lb除外)"></a>1.15.升级内核至4.18版本以上 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装最新的内核</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我这里选择的是稳定版kernel-ml   如需更新长期维护版本kernel-lt</span>  </span><br><span class="line">yum  --enablerepo=elrepo-kernel  install  kernel-ml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看已安装那些内核</span></span><br><span class="line">rpm -qa | grep kernel</span><br><span class="line">kernel-core-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-core-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-ml-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-modules-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-libs-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-modules-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看默认内核</span></span><br><span class="line">grubby --default-kernel</span><br><span class="line">/boot/vmlinuz-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">若不是最新的使用命令设置</span></span><br><span class="line">grubby --set-default /boot/vmlinuz-「您的内核版本」.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启生效</span></span><br><span class="line">reboot</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">v8 整合命令为：</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --default-kernel ; reboot</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">v7 整合命令为：</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --set-default \$(ls /boot/vmlinuz-* | grep elrepo) ; grubby --default-kernel</span><br></pre></td></tr></table></figure>

<h3 id="1-16-安装ipvsadm-lb除外"><a href="#1-16-安装ipvsadm-lb除外" class="headerlink" title="1.16.安装ipvsadm (lb除外)"></a>1.16.安装ipvsadm (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;EOF </span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">ip_tables</span><br><span class="line">ip_set</span><br><span class="line">xt_set</span><br><span class="line">ipt_set</span><br><span class="line">ipt_rpfilter</span><br><span class="line">ipt_REJECT</span><br><span class="line">ipip</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart systemd-modules-load.service</span><br><span class="line"></span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack</span><br><span class="line">ip_vs_sh               16384  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          176128  1 ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure>

<h3 id="1-17-修改内核参数-lb除外"><a href="#1-17-修改内核参数-lb除外" class="headerlink" title="1.17.修改内核参数 (lb除外)"></a>1.17.修改内核参数 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line"></span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.all.forwarding = 0</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="1-18-所有节点配置hosts本地解析"><a href="#1-18-所有节点配置hosts本地解析" class="headerlink" title="1.18.所有节点配置hosts本地解析"></a>1.18.所有节点配置hosts本地解析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">2408:8207:78ca:9fa1::10 k8s-master01</span><br><span class="line">2408:8207:78ca:9fa1::20 k8s-master02</span><br><span class="line">2408:8207:78ca:9fa1::30 k8s-master03</span><br><span class="line">2408:8207:78ca:9fa1::40 k8s-node01</span><br><span class="line">2408:8207:78ca:9fa1::50 k8s-node02</span><br><span class="line">2408:8207:78ca:9fa1::60 k8s-node03</span><br><span class="line">2408:8207:78ca:9fa1::70 k8s-node04</span><br><span class="line">2408:8207:78ca:9fa1::80 k8s-node05</span><br><span class="line">2408:8207:78ca:9fa1::90 lb01</span><br><span class="line">2408:8207:78ca:9fa1::100 lb02</span><br><span class="line"></span><br><span class="line">10.0.0.61 k8s-master01</span><br><span class="line">10.0.0.62 k8s-master02</span><br><span class="line">10.0.0.63 k8s-master03</span><br><span class="line">10.0.0.64 k8s-node01</span><br><span class="line">10.0.0.65 k8s-node02</span><br><span class="line">10.0.0.66 k8s-node03</span><br><span class="line">10.0.0.67 k8s-node04</span><br><span class="line">10.0.0.68 k8s-node05</span><br><span class="line">10.0.0.70 lb01</span><br><span class="line">10.0.0.60 lb02</span><br><span class="line">10.0.0.69 lb-vip</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="2-k8s基本组件安装"><a href="#2-k8s基本组件安装" class="headerlink" title="2.k8s基本组件安装"></a>2.k8s基本组件安装</h1><h2 id="2-1-所有k8s节点安装Containerd作为Runtime"><a href="#2-1-所有k8s节点安装Containerd作为Runtime" class="headerlink" title="2.1.所有k8s节点安装Containerd作为Runtime"></a>2.1.所有k8s节点安装Containerd作为Runtime</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建cni插件所需目录</span></span><br><span class="line">mkdir -p /etc/cni/net.d /opt/cni/bin </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压cni二进制包</span></span><br><span class="line">tar xf cni-plugins-linux-amd64-v1.1.1.tgz -C /opt/cni/bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar -C / -xzf cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建服务启动文件</span></span><br><span class="line">cat &gt; /etc/systemd/system/containerd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=containerd container runtime</span><br><span class="line">Documentation=https://containerd.io</span><br><span class="line">After=network.target local-fs.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=-/sbin/modprobe overlay</span><br><span class="line">ExecStart=/usr/local/bin/containerd</span><br><span class="line">Type=notify</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">TasksMax=infinity</span><br><span class="line">OOMScoreAdjust=-999</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-1配置Containerd所需的模块"><a href="#2-1-1配置Containerd所需的模块" class="headerlink" title="2.1.1配置Containerd所需的模块"></a>2.1.1配置Containerd所需的模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2加载模块"><a href="#2-1-2加载模块" class="headerlink" title="2.1.2加载模块"></a>2.1.2加载模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl restart systemd-modules-load.service</span><br></pre></td></tr></table></figure>

<h3 id="2-1-3配置Containerd所需的内核"><a href="#2-1-3配置Containerd所需的内核" class="headerlink" title="2.1.3配置Containerd所需的内核"></a>2.1.3配置Containerd所需的内核</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载内核</span></span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4创建Containerd的配置文件"><a href="#2-1-4创建Containerd的配置文件" class="headerlink" title="2.1.4创建Containerd的配置文件"></a>2.1.4创建Containerd的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改Containerd的配置文件</span><br><span class="line">sed -i &quot;s#SystemdCgroup\ \=\ false#SystemdCgroup\ \=\ true#g&quot; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">cat /etc/containerd/config.toml | grep SystemdCgroup</span><br><span class="line"></span><br><span class="line">sed -i &quot;s#k8s.gcr.io#registry.cn-hangzhou.aliyuncs.com/chenby#g&quot; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">cat /etc/containerd/config.toml | grep sandbox_image</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到containerd.runtimes.runc.options，在其下加入SystemdCgroup = <span class="literal">true</span></span></span><br><span class="line"></span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">              SystemdCgroup = true</span><br><span class="line">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sandbox_image默认地址改为符合版本地址</span></span><br><span class="line"></span><br><span class="line">    sandbox_image = &quot;registry.cn-hangzhou.aliyuncs.com/chenby/pause:3.6&quot;</span><br></pre></td></tr></table></figure>

<h3 id="2-1-5启动并设置为开机启动"><a href="#2-1-5启动并设置为开机启动" class="headerlink" title="2.1.5启动并设置为开机启动"></a>2.1.5启动并设置为开机启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now containerd</span><br></pre></td></tr></table></figure>

<h3 id="2-1-6配置crictl客户端连接的运行时位置"><a href="#2-1-6配置crictl客户端连接的运行时位置" class="headerlink" title="2.1.6配置crictl客户端连接的运行时位置"></a>2.1.6配置crictl客户端连接的运行时位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.24.2/crictl-v1.24.2-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar xf crictl-v1.24.2-linux-amd64.tar.gz -C /usr/bin/</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">生成配置文件</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/crictl.yaml &lt;&lt;EOF</span><br><span class="line">runtime-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">image-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">timeout: 10</span><br><span class="line">debug: false</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">测试</span></span><br><span class="line">systemctl restart  containerd</span><br><span class="line">crictl info</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2-2-k8s与etcd下载及安装（仅在master01操作）"><a href="#2-2-k8s与etcd下载及安装（仅在master01操作）" class="headerlink" title="2.2.k8s与etcd下载及安装（仅在master01操作）"></a>2.2.k8s与etcd下载及安装（仅在master01操作）</h2><h3 id="2-2-1解压k8s安装包"><a href="#2-2-1解压k8s安装包" class="headerlink" title="2.2.1解压k8s安装包"></a>2.2.1解压k8s安装包</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载安装包</span></span><br><span class="line">wget https://dl.k8s.io/v1.24.1/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.5.4/etcd-v3.5.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压k8s安装文件</span></span><br><span class="line">cd cby</span><br><span class="line">tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压etcd安装文件</span></span><br><span class="line">tar -xf etcd-v3.5.4-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.4-linux-amd64/etcd&#123;,ctl&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看/usr/local/bin下内容</span></span><br><span class="line"></span><br><span class="line">ls /usr/local/bin/</span><br><span class="line">etcd  etcdctl  kube-apiserver  kube-controller-manager  kubectl  kubelet  kube-proxy  kube-scheduler</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-2-2查看版本"><a href="#2-2-2查看版本" class="headerlink" title="2.2.2查看版本"></a>2.2.2查看版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubelet --version</span><br><span class="line">Kubernetes v1.24.1</span><br><span class="line">[root@k8s-master01 ~]# etcdctl version</span><br><span class="line">etcdctl version: 3.5.4</span><br><span class="line">API version: 3.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h3 id="2-2-3将组件发送至其他k8s节点"><a href="#2-2-3将组件发送至其他k8s节点" class="headerlink" title="2.2.3将组件发送至其他k8s节点"></a>2.2.3将组件发送至其他k8s节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">Work=&#x27;k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05&#x27;</span><br><span class="line"></span><br><span class="line">for NODE in $Master; do echo $NODE; scp /usr/local/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done</span><br><span class="line"></span><br><span class="line">for NODE in $Work; do     scp /usr/local/bin/kube&#123;let,-proxy&#125; $NODE:/usr/local/bin/ ; done</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/cni/bin</span><br></pre></td></tr></table></figure>

<h2 id="2-3创建证书相关文件"><a href="#2-3创建证书相关文件" class="headerlink" title="2.3创建证书相关文件"></a>2.3创建证书相关文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir pki</span><br><span class="line">cd pki</span><br><span class="line">cat &gt; admin-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; ca-config.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; etcd-ca-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;etcd&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Etcd Security&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; front-proxy-ca-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">     &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">     &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; kubelet-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:node:$NODE&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:nodes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; manager-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; apiserver-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kube-apiserver&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;Kubernetes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; ca-csr.json   &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;Kubernetes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; etcd-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;etcd&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Etcd Security&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; front-proxy-client-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;front-proxy-client&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">     &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">     &quot;size&quot;: 2048</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; kube-proxy-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; scheduler-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir bootstrap</span><br><span class="line">cd bootstrap</span><br><span class="line">cat &gt; bootstrap.secret.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: bootstrap-token-c8ad9c</span><br><span class="line">  namespace: kube-system</span><br><span class="line">type: bootstrap.kubernetes.io/token</span><br><span class="line">stringData:</span><br><span class="line">  description: &quot;The default bootstrap token generated by &#x27;kubelet &#x27;.&quot;</span><br><span class="line">  token-id: c8ad9c</span><br><span class="line">  token-secret: 2e4d610cf3e7426e</span><br><span class="line">  usage-bootstrap-authentication: &quot;true&quot;</span><br><span class="line">  usage-bootstrap-signing: &quot;true&quot;</span><br><span class="line">  auth-extra-groups:  system:bootstrappers:default-node-token,system:bootstrappers:worker,system:bootstrappers:ingress</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubelet-bootstrap</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:bootstrappers:default-node-token</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-autoapprove-bootstrap</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:bootstrappers:default-node-token</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-autoapprove-certificate-rotation</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes/proxy</span><br><span class="line">      - nodes/stats</span><br><span class="line">      - nodes/log</span><br><span class="line">      - nodes/spec</span><br><span class="line">      - nodes/metrics</span><br><span class="line">    verbs:</span><br><span class="line">      - &quot;*&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:kube-apiserver</span><br><span class="line">  namespace: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">subjects:</span><br><span class="line">  - apiGroup: rbac.authorization.k8s.io</span><br><span class="line">    kind: User</span><br><span class="line">    name: kube-apiserver</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir coredns</span><br><span class="line">cd coredns</span><br><span class="line">cat &gt; coredns.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">    - endpoints</span><br><span class="line">    - services</span><br><span class="line">    - pods</span><br><span class="line">    - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - discovery.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">    - endpointslices</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health &#123;</span><br><span class="line">          lameduck 5s</span><br><span class="line">        &#125;</span><br><span class="line">        ready</span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        forward . /etc/resolv.conf &#123;</span><br><span class="line">          max_concurrent 1000</span><br><span class="line">        &#125;</span><br><span class="line">        cache 30</span><br><span class="line">        loop</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">replicas: not specified here:</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">1. Default is 1.</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">2. Will be tuned <span class="keyword">in</span> real time <span class="keyword">if</span> DNS horizontal auto-scaling is turned on.</span></span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: &quot;CriticalAddonsOnly&quot;</span><br><span class="line">          operator: &quot;Exists&quot;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      affinity:</span><br><span class="line">         podAntiAffinity:</span><br><span class="line">           preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">           - weight: 100</span><br><span class="line">             podAffinityTerm:</span><br><span class="line">               labelSelector:</span><br><span class="line">                 matchExpressions:</span><br><span class="line">                   - key: k8s-app</span><br><span class="line">                     operator: In</span><br><span class="line">                     values: [&quot;kube-dns&quot;]</span><br><span class="line">               topologyKey: kubernetes.io/hostname</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: registry.cn-beijing.aliyuncs.com/dotbalo/coredns:1.8.6 </span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 170Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        args: [ &quot;-conf&quot;, &quot;/etc/coredns/Corefile&quot; ]</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/coredns</span><br><span class="line">          readOnly: true</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /ready</span><br><span class="line">            port: 8181</span><br><span class="line">            scheme: HTTP</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: coredns</span><br><span class="line">            items:</span><br><span class="line">            - key: Corefile</span><br><span class="line">              path: Corefile</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: &quot;9153&quot;</span><br><span class="line">    prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir metrics-server</span><br><span class="line">cd metrics-server</span><br><span class="line">cat &gt; metrics-server.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-admin: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot;</span><br><span class="line">  name: system:aggregated-metrics-reader</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - metrics.k8s.io</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes/stats</span><br><span class="line">  - namespaces</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server-auth-reader</span><br><span class="line">  namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: extension-apiserver-authentication-reader</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server:system:auth-delegator</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:auth-delegator</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: https</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - args:</span><br><span class="line">        - --cert-dir=/tmp</span><br><span class="line">        - --secure-port=4443</span><br><span class="line">        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">        - --kubelet-use-node-status-port</span><br><span class="line">        - --metric-resolution=15s</span><br><span class="line">        - --kubelet-insecure-tls</span><br><span class="line">        - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem # change to front-proxy-ca.crt for kubeadm</span><br><span class="line">        - --requestheader-username-headers=X-Remote-User</span><br><span class="line">        - --requestheader-group-headers=X-Remote-Group</span><br><span class="line">        - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">        image: registry.cn-beijing.aliyuncs.com/dotbalo/metrics-server:0.5.0</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        livenessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /livez</span><br><span class="line">            port: https</span><br><span class="line">            scheme: HTTPS</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">        name: metrics-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 4443</span><br><span class="line">          name: https</span><br><span class="line">          protocol: TCP</span><br><span class="line">        readinessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /readyz</span><br><span class="line">            port: https</span><br><span class="line">            scheme: HTTPS</span><br><span class="line">          initialDelaySeconds: 20</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 200Mi</span><br><span class="line">        securityContext:</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">          runAsNonRoot: true</span><br><span class="line">          runAsUser: 1000</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /tmp</span><br><span class="line">          name: tmp-dir</span><br><span class="line">        - name: ca-ssl</span><br><span class="line">          mountPath: /etc/kubernetes/pki</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      volumes:</span><br><span class="line">      - emptyDir: &#123;&#125;</span><br><span class="line">        name: tmp-dir</span><br><span class="line">      - name: ca-ssl</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/kubernetes/pki</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apiregistration.k8s.io/v1</span><br><span class="line">kind: APIService</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: v1beta1.metrics.k8s.io</span><br><span class="line">spec:</span><br><span class="line">  group: metrics.k8s.io</span><br><span class="line">  groupPriorityMinimum: 100</span><br><span class="line">  insecureSkipTLSVerify: true</span><br><span class="line">  service:</span><br><span class="line">    name: metrics-server</span><br><span class="line">    namespace: kube-system</span><br><span class="line">  version: v1beta1</span><br><span class="line">  versionPriority: 100</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="3-相关证书生成"><a href="#3-相关证书生成" class="headerlink" title="3.相关证书生成"></a>3.相关证书生成</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">master01节点下载证书生成工具</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssl</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssljson</span><br><span class="line">chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</span><br></pre></td></tr></table></figure>

<h2 id="3-1-生成etcd证书"><a href="#3-1-生成etcd证书" class="headerlink" title="3.1.生成etcd证书"></a>3.1.生成etcd证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-1-1所有master节点创建证书存放目录"><a href="#3-1-1所有master节点创建证书存放目录" class="headerlink" title="3.1.1所有master节点创建证书存放目录"></a>3.1.1所有master节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/etcd/ssl -p</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2master01节点生成etcd证书"><a href="#3-1-2master01节点生成etcd证书" class="headerlink" title="3.1.2master01节点生成etcd证书"></a>3.1.2master01节点生成etcd证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd pki</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成etcd证书和etcd证书的key（如果你觉得以后可能会扩容，可以在ip那多写几个预留出来）</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,10.0.0.61,10.0.0.62,10.0.0.63,2408:8207:78ca:9fa1::10,2408:8207:78ca:9fa1::20,2408:8207:78ca:9fa1::30 \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</span><br></pre></td></tr></table></figure>

<h3 id="3-1-3将证书复制到其他节点"><a href="#3-1-3将证书复制到其他节点" class="headerlink" title="3.1.3将证书复制到其他节点"></a>3.1.3将证书复制到其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line"></span><br><span class="line">for NODE in $Master; do ssh $NODE &quot;mkdir -p /etc/etcd/ssl&quot;; for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do scp /etc/etcd/ssl/$&#123;FILE&#125; $NODE:/etc/etcd/ssl/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h2 id="3-2-生成k8s相关证书"><a href="#3-2-生成k8s相关证书" class="headerlink" title="3.2.生成k8s相关证书"></a>3.2.生成k8s相关证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-2-1所有k8s节点创建证书存放目录"><a href="#3-2-1所有k8s节点创建证书存放目录" class="headerlink" title="3.2.1所有k8s节点创建证书存放目录"></a>3.2.1所有k8s节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2master01节点生成k8s证书"><a href="#3-2-2master01节点生成k8s证书" class="headerlink" title="3.2.2master01节点生成k8s证书"></a>3.2.2master01节点生成k8s证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成一个根证书 ，多写了一些IP作为预留IP，为将来添加node做准备</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.96.0.1是service网段的第一个地址，需要计算，10.0.0.69为高可用vip地址</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   \</span><br><span class="line">-ca=/etc/kubernetes/pki/ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-hostname=10.96.0.1,10.0.0.69,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,x.oiox.cn,k.oiox.cn,l.oiox.cn,o.oiox.cn,10.0.0.61,10.0.0.62,10.0.0.63,10.0.0.64,10.0.0.65,10.0.0.66,10.0.0.67,10.0.0.68,10.0.0.80,10.0.0.60,10.0.0.40,10.0.0.41,2408:8207:78ca:9fa1::10,2408:8207:78ca:9fa1::20,2408:8207:78ca:9fa1::30,2408:8207:78ca:9fa1::40,2408:8207:78ca:9fa1::50,2408:8207:78ca:9fa1::60,2408:8207:78ca:9fa1::70,2408:8207:78ca:9fa1::80,2408:8207:78ca:9fa1::90,2408:8207:78ca:9fa1::100   \</span><br><span class="line">-profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3生成apiserver聚合证书"><a href="#3-2-3生成apiserver聚合证书" class="headerlink" title="3.2.3生成apiserver聚合证书"></a>3.2.3生成apiserver聚合证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有一个警告，可以忽略</span></span><br><span class="line"></span><br><span class="line">cfssl gencert  \</span><br><span class="line">-ca=/etc/kubernetes/pki/front-proxy-ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4生成controller-manage的证书"><a href="#3-2-4生成controller-manage的证书" class="headerlink" title="3.2.4生成controller-manage的证书"></a>3.2.4生成controller-manage的证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个集群项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://10.0.0.69:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个环境项，一个上下文</span></span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=system:kube-controller-manager \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个用户项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置默认环境</span></span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://10.0.0.69:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/scheduler.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/scheduler-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --cluster=kubernetes \</span><br><span class="line">     --user=system:kube-scheduler \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --server=https://10.0.0.69:8443     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes-admin  \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/admin.pem     \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/admin-key.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes    \</span><br><span class="line">  --cluster=kubernetes     \</span><br><span class="line">  --user=kubernetes-admin     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5创建kube-proxy证书"><a href="#3-2-5创建kube-proxy证书" class="headerlink" title="3.2.5创建kube-proxy证书"></a>3.2.5创建kube-proxy证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   kube-proxy-csr.json | cfssljson -bare /etc/kubernetes/pki/kube-proxy</span><br><span class="line">   </span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --server=https://10.0.0.69:8443     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kube-proxy  \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/kube-proxy.pem     \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/kube-proxy-key.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kube-proxy@kubernetes    \</span><br><span class="line">  --cluster=kubernetes     \</span><br><span class="line">  --user=kube-proxy     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kube-proxy@kubernetes  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure>



<h3 id="3-2-5创建ServiceAccount-Key-——secret"><a href="#3-2-5创建ServiceAccount-Key-——secret" class="headerlink" title="3.2.5创建ServiceAccount Key ——secret"></a>3.2.5创建ServiceAccount Key ——secret</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out /etc/kubernetes/pki/sa.key 2048</span><br><span class="line">openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</span><br></pre></td></tr></table></figure>

<h3 id="3-2-6将证书发送到其他master节点"><a href="#3-2-6将证书发送到其他master节点" class="headerlink" title="3.2.6将证书发送到其他master节点"></a>3.2.6将证书发送到其他master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">其他节点创建目录</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mkdir</span>  /etc/kubernetes/pki/ -p</span></span><br><span class="line"></span><br><span class="line">for NODE in k8s-master02 k8s-master03; do  for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do  scp /etc/kubernetes/pki/$&#123;FILE&#125; $NODE:/etc/kubernetes/pki/$&#123;FILE&#125;; done;  for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do  scp /etc/kubernetes/$&#123;FILE&#125; $NODE:/etc/kubernetes/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h3 id="3-2-7查看证书"><a href="#3-2-7查看证书" class="headerlink" title="3.2.7查看证书"></a>3.2.7查看证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /etc/kubernetes/pki/</span><br><span class="line">admin.csr          ca.csr                      front-proxy-ca.csr          kube-proxy.csr      scheduler-key.pem</span><br><span class="line">admin-key.pem      ca-key.pem                  front-proxy-ca-key.pem      kube-proxy-key.pem  scheduler.pem</span><br><span class="line">admin.pem          ca.pem                      front-proxy-ca.pem          kube-proxy.pem</span><br><span class="line">apiserver.csr      controller-manager.csr      front-proxy-client.csr      sa.key</span><br><span class="line">apiserver-key.pem  controller-manager-key.pem  front-proxy-client-key.pem  sa.pub</span><br><span class="line">apiserver.pem      controller-manager.pem      front-proxy-client.pem      scheduler.csr</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一共23个就对了</span></span><br><span class="line"></span><br><span class="line">ls /etc/kubernetes/pki/ |wc -l</span><br><span class="line">26</span><br></pre></td></tr></table></figure>

<h1 id="4-k8s系统组件配置"><a href="#4-k8s系统组件配置" class="headerlink" title="4.k8s系统组件配置"></a>4.k8s系统组件配置</h1><h2 id="4-1-etcd配置"><a href="#4-1-etcd配置" class="headerlink" title="4.1.etcd配置"></a>4.1.etcd配置</h2><h3 id="4-1-1master01配置"><a href="#4-1-1master01配置" class="headerlink" title="4.1.1master01配置"></a>4.1.1master01配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master01&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.61:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.61:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.61:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.61:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.61:2380,k8s-master02=https://10.0.0.62:2380,k8s-master03=https://10.0.0.63:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2master02配置"><a href="#4-1-2master02配置" class="headerlink" title="4.1.2master02配置"></a>4.1.2master02配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master02&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.62:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.62:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.62:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.62:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.61:2380,k8s-master02=https://10.0.0.62:2380,k8s-master03=https://10.0.0.63:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3master03配置"><a href="#4-1-3master03配置" class="headerlink" title="4.1.3master03配置"></a>4.1.3master03配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master03&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.63:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.63:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.63:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.63:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.61:2380,k8s-master02=https://10.0.0.62:2380,k8s-master03=https://10.0.0.63:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="4-2-创建service（所有master节点操作）"><a href="#4-2-创建service（所有master节点操作）" class="headerlink" title="4.2.创建service（所有master节点操作）"></a>4.2.创建service（所有master节点操作）</h2><h3 id="4-2-1创建etcd-service并启动"><a href="#4-2-1创建etcd-service并启动" class="headerlink" title="4.2.1创建etcd.service并启动"></a>4.2.1创建etcd.service并启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2创建etcd证书目录"><a href="#4-2-2创建etcd证书目录" class="headerlink" title="4.2.2创建etcd证书目录"></a>4.2.2创建etcd证书目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/kubernetes/pki/etcd</span><br><span class="line">ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now etcd</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3查看etcd状态"><a href="#4-2-3查看etcd状态" class="headerlink" title="4.2.3查看etcd状态"></a>4.2.3查看etcd状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --endpoints=&quot;10.0.0.63:2379,10.0.0.62:2379,10.0.0.61:2379&quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|    ENDPOINT    |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| 10.0.0.63:2379 | c0c8142615b9523f |   3.5.4 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 10.0.0.62:2379 | de8396604d2c160d |   3.5.4 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 10.0.0.61:2379 | 33c9d6df0037ab97 |   3.5.4 |   20 kB |      true |      false |         2 |          9 |                  9 |        |</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 pki]# </span><br></pre></td></tr></table></figure>

<h1 id="5-高可用配置"><a href="#5-高可用配置" class="headerlink" title="5.高可用配置"></a>5.高可用配置</h1><h2 id="5-1在lb01和lb02两台服务器上操作"><a href="#5-1在lb01和lb02两台服务器上操作" class="headerlink" title="5.1在lb01和lb02两台服务器上操作"></a>5.1在lb01和lb02两台服务器上操作</h2><h3 id="5-1-1安装keepalived和haproxy服务"><a href="#5-1-1安装keepalived和haproxy服务" class="headerlink" title="5.1.1安装keepalived和haproxy服务"></a>5.1.1安装keepalived和haproxy服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br><span class="line"></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br><span class="line"></span><br><span class="line">yum -y install keepalived haproxy</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2修改haproxy配置文件（两台配置文件一样）"><a href="#5-1-2修改haproxy配置文件（两台配置文件一样）" class="headerlink" title="5.1.2修改haproxy配置文件（两台配置文件一样）"></a>5.1.2修改haproxy配置文件（两台配置文件一样）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt;/etc/haproxy/haproxy.cfg&lt;&lt;&quot;EOF&quot;</span><br><span class="line">global</span><br><span class="line"> maxconn 2000</span><br><span class="line"> ulimit-n 16384</span><br><span class="line"> log 127.0.0.1 local0 err</span><br><span class="line"> stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"> log global</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> timeout connect 5000</span><br><span class="line"> timeout client 50000</span><br><span class="line"> timeout server 50000</span><br><span class="line"> timeout http-request 15s</span><br><span class="line"> timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line"> bind *:33305</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line"> bind 0.0.0.0:8443</span><br><span class="line"> bind 127.0.0.1:8443</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> tcp-request inspect-delay 5s</span><br><span class="line"> default_backend k8s-master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> option tcp-check</span><br><span class="line"> balance roundrobin</span><br><span class="line"> default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line"> server  k8s-master01  10.0.0.61:6443 check</span><br><span class="line"> server  k8s-master02  10.0.0.62:6443 check</span><br><span class="line"> server  k8s-master03  10.0.0.63:6443 check</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-3lb01配置keepalived-master节点"><a href="#5-1-3lb01配置keepalived-master节点" class="headerlink" title="5.1.3lb01配置keepalived master节点"></a>5.1.3lb01配置keepalived master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens160</span><br><span class="line">    mcast_src_ip 10.0.0.70</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        10.0.0.69</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4lb02配置keepalived-backup节点"><a href="#5-1-4lb02配置keepalived-backup节点" class="headerlink" title="5.1.4lb02配置keepalived backup节点"></a>5.1.4lb02配置keepalived backup节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens160</span><br><span class="line">    mcast_src_ip 10.0.0.80</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 50</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        10.0.0.69</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-5健康检查脚本配置（两台lb主机）"><a href="#5-1-5健康检查脚本配置（两台lb主机）" class="headerlink" title="5.1.5健康检查脚本配置（两台lb主机）"></a>5.1.5健康检查脚本配置（两台lb主机）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/keepalived/check_apiserver.sh &lt;&lt; EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">err=0</span><br><span class="line">for k in \$(seq 1 3)</span><br><span class="line">do</span><br><span class="line">    check_code=\$(pgrep haproxy)</span><br><span class="line">    if [[ \$check_code == &quot;&quot; ]]; then</span><br><span class="line">        err=\$(expr \$err + 1)</span><br><span class="line">        sleep 1</span><br><span class="line">        continue</span><br><span class="line">    else</span><br><span class="line">        err=0</span><br><span class="line">        break</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ \$err != &quot;0&quot; ]]; then</span><br><span class="line">    echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">    /usr/bin/systemctl stop keepalived</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给脚本授权</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_apiserver.sh</span><br></pre></td></tr></table></figure>

<h3 id="5-1-6启动服务"><a href="#5-1-6启动服务" class="headerlink" title="5.1.6启动服务"></a>5.1.6启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now haproxy</span><br><span class="line">systemctl enable --now keepalived</span><br></pre></td></tr></table></figure>

<h3 id="5-1-7测试高可用"><a href="#5-1-7测试高可用" class="headerlink" title="5.1.7测试高可用"></a>5.1.7测试高可用</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能ping同</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# ping 10.0.0.69</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能telnet访问</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# telnet 10.0.0.69 8443</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭主节点，看vip是否漂移到备节点</span></span><br></pre></td></tr></table></figure>

<h1 id="6-k8s组件配置（区别于第4点）"><a href="#6-k8s组件配置（区别于第4点）" class="headerlink" title="6.k8s组件配置（区别于第4点）"></a>6.k8s组件配置（区别于第4点）</h1><p>所有k8s节点创建以下目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes</span><br></pre></td></tr></table></figure>

<h2 id="6-1-创建apiserver（所有master节点）"><a href="#6-1-创建apiserver（所有master节点）" class="headerlink" title="6.1.创建apiserver（所有master节点）"></a>6.1.创建apiserver（所有master节点）</h2><h3 id="6-1-1master01节点配置"><a href="#6-1-1master01节点配置" class="headerlink" title="6.1.1master01节点配置"></a>6.1.1master01节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.61 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">      --feature-gates=IPv6DualStack=true  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.61:2379,https://10.0.0.62:2379,https://10.0.0.63:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-2master02节点配置"><a href="#6-1-2master02节点配置" class="headerlink" title="6.1.2master02节点配置"></a>6.1.2master02节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.62 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">			--feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.61:2379,https://10.0.0.62:2379,https://10.0.0.63:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-3master03节点配置"><a href="#6-1-3master03节点配置" class="headerlink" title="6.1.3master03节点配置"></a>6.1.3master03节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service  &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.63 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">			--feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.61:2379,https://10.0.0.62:2379,https://10.0.0.63:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-4启动apiserver（所有master节点）"><a href="#6-1-4启动apiserver（所有master节点）" class="headerlink" title="6.1.4启动apiserver（所有master节点）"></a>6.1.4启动apiserver（所有master节点）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl enable --now kube-apiserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意查看状态是否启动正常</span></span><br><span class="line"></span><br><span class="line">systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>

<h2 id="6-2-配置kube-controller-manager-service"><a href="#6-2-配置kube-controller-manager-service" class="headerlink" title="6.2.配置kube-controller-manager service"></a>6.2.配置kube-controller-manager service</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所有master节点配置，且配置相同</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">172.16.0.0/12为pod网段，按需求设置你自己的网段</span></span><br><span class="line"></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --bind-address=127.0.0.1 \</span><br><span class="line">      --root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --use-service-account-credentials=true \</span><br><span class="line">      --node-monitor-grace-period=40s \</span><br><span class="line">      --node-monitor-period=5s \</span><br><span class="line">      --pod-eviction-timeout=2m0s \</span><br><span class="line">      --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">      --allocate-node-cidrs=true \</span><br><span class="line">      --feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108 \</span><br><span class="line">      --cluster-cidr=172.16.0.0/12,fc00::/48 \</span><br><span class="line">      --node-cidr-mask-size-ipv4=24 \</span><br><span class="line">      --node-cidr-mask-size-ipv6=64 \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem </span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-2-1启动kube-controller-manager，并查看状态"><a href="#6-2-1启动kube-controller-manager，并查看状态" class="headerlink" title="6.2.1启动kube-controller-manager，并查看状态"></a>6.2.1启动kube-controller-manager，并查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-controller-manager</span><br><span class="line">systemctl  status kube-controller-manager</span><br></pre></td></tr></table></figure>

<h2 id="6-3-配置kube-scheduler-service"><a href="#6-3-配置kube-scheduler-service" class="headerlink" title="6.3.配置kube-scheduler service"></a>6.3.配置kube-scheduler service</h2><h3 id="6-3-1所有master节点配置，且配置相同"><a href="#6-3-1所有master节点配置，且配置相同" class="headerlink" title="6.3.1所有master节点配置，且配置相同"></a>6.3.1所有master节点配置，且配置相同</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --bind-address=127.0.0.1 \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-3-2启动并查看服务状态"><a href="#6-3-2启动并查看服务状态" class="headerlink" title="6.3.2启动并查看服务状态"></a>6.3.2启动并查看服务状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-scheduler</span><br><span class="line">systemctl status kube-scheduler</span><br></pre></td></tr></table></figure>

<h1 id="7-TLS-Bootstrapping配置"><a href="#7-TLS-Bootstrapping配置" class="headerlink" title="7.TLS Bootstrapping配置"></a>7.TLS Bootstrapping配置</h1><h2 id="7-1在master01上配置"><a href="#7-1在master01上配置" class="headerlink" title="7.1在master01上配置"></a>7.1在master01上配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd bootstrap</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">--certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">--embed-certs=true     --server=https://10.0.0.69:8443     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials tls-bootstrap-token-user     \</span><br><span class="line">--token=c8ad9c.2e4d610cf3e7426e \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context tls-bootstrap-token-user@kubernetes     \</span><br><span class="line">--cluster=kubernetes     \</span><br><span class="line">--user=tls-bootstrap-token-user     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context tls-bootstrap-token-user@kubernetes     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">token的位置在bootstrap.secret.yaml，如果修改的话到这个文件修改</span></span><br><span class="line"></span><br><span class="line">mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config</span><br></pre></td></tr></table></figure>

<h2 id="7-2查看集群状态，没问题的话继续后续操作"><a href="#7-2查看集群状态，没问题的话继续后续操作" class="headerlink" title="7.2查看集群状态，没问题的话继续后续操作"></a>7.2查看集群状态，没问题的话继续后续操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line"></span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE                         ERROR</span><br><span class="line">scheduler            Healthy   ok                              </span><br><span class="line">controller-manager   Healthy   ok                              </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125; </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切记执行，别忘记！！！</span></span><br><span class="line"></span><br><span class="line">kubectl create -f bootstrap.secret.yaml</span><br></pre></td></tr></table></figure>

<h1 id="8-node节点配置"><a href="#8-node节点配置" class="headerlink" title="8.node节点配置"></a>8.node节点配置</h1><h2 id="8-1-在master01上将证书复制到node节点"><a href="#8-1-在master01上将证书复制到node节点" class="headerlink" title="8.1.在master01上将证书复制到node节点"></a>8.1.在master01上将证书复制到node节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/kubernetes/</span><br><span class="line"> </span><br><span class="line">for NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do ssh $NODE mkdir -p /etc/kubernetes/pki; for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig kube-proxy.kubeconfig; do scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h2 id="8-2-kubelet配置"><a href="#8-2-kubelet配置" class="headerlink" title="8.2.kubelet配置"></a>8.2.kubelet配置</h2><h3 id="8-2-1所有k8s节点创建相关目录"><a href="#8-2-1所有k8s节点创建相关目录" class="headerlink" title="8.2.1所有k8s节点创建相关目录"></a>8.2.1所有k8s节点创建相关目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所有k8s节点配置kubelet service</span></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=containerd.service</span><br><span class="line">Requires=containerd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \</span><br><span class="line">    --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">    --config=/etc/kubernetes/kubelet-conf.yml \</span><br><span class="line">    --container-runtime=remote  \</span><br><span class="line">    --runtime-request-timeout=15m  \</span><br><span class="line">    --container-runtime-endpoint=unix:///run/containerd/containerd.sock  \</span><br><span class="line">    --cgroup-driver=systemd \</span><br><span class="line">    --node-labels=node.kubernetes.io/node=&#x27;&#x27; \</span><br><span class="line">    --feature-gates=IPv6DualStack=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-2所有k8s节点创建kubelet的配置文件"><a href="#8-2-2所有k8s节点创建kubelet的配置文件" class="headerlink" title="8.2.2所有k8s节点创建kubelet的配置文件"></a>8.2.2所有k8s节点创建kubelet的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-3启动kubelet"><a href="#8-2-3启动kubelet" class="headerlink" title="8.2.3启动kubelet"></a>8.2.3启动kubelet</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">systemctl enable --now kubelet</span><br></pre></td></tr></table></figure>

<h3 id="8-2-4查看集群"><a href="#8-2-4查看集群" class="headerlink" title="8.2.4查看集群"></a>8.2.4查看集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   Ready   &lt;none&gt;   12s   v1.24.1</span><br><span class="line">k8s-master02   Ready   &lt;none&gt;   12s   v1.24.1</span><br><span class="line">k8s-master03   Ready   &lt;none&gt;   12s   v1.24.1</span><br><span class="line">k8s-node01     Ready   &lt;none&gt;   12s   v1.24.1</span><br><span class="line">k8s-node02     Ready   &lt;none&gt;   12s   v1.24.1</span><br><span class="line">k8s-node03     Ready   &lt;none&gt;   12s   v1.24.1</span><br><span class="line">k8s-node04     Ready   &lt;none&gt;   12s   v1.24.1</span><br><span class="line">k8s-node05     Ready   &lt;none&gt;   12s   v1.24.1</span><br><span class="line">[root@k8s-master01 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="8-3-kube-proxy配置"><a href="#8-3-kube-proxy配置" class="headerlink" title="8.3.kube-proxy配置"></a>8.3.kube-proxy配置</h2><h3 id="8-3-1将kubeconfig发送至其他节点"><a href="#8-3-1将kubeconfig发送至其他节点" class="headerlink" title="8.3.1将kubeconfig发送至其他节点"></a>8.3.1将kubeconfig发送至其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig; done</span><br><span class="line"></span><br><span class="line">for NODE in k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig;  done</span><br></pre></td></tr></table></figure>

<h3 id="8-3-2所有k8s节点添加kube-proxy的service文件"><a href="#8-3-2所有k8s节点添加kube-proxy的service文件" class="headerlink" title="8.3.2所有k8s节点添加kube-proxy的service文件"></a>8.3.2所有k8s节点添加kube-proxy的service文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy.yaml \</span><br><span class="line">  --v=2</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3所有k8s节点添加kube-proxy的配置"><a href="#8-3-3所有k8s节点添加kube-proxy的配置" class="headerlink" title="8.3.3所有k8s节点添加kube-proxy的配置"></a>8.3.3所有k8s节点添加kube-proxy的配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12,fc00::/48 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4启动kube-proxy"><a href="#8-3-4启动kube-proxy" class="headerlink" title="8.3.4启动kube-proxy"></a>8.3.4启动kube-proxy</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kube-proxy</span><br><span class="line">systemctl enable --now kube-proxy</span><br></pre></td></tr></table></figure>

<h1 id="9-安装Calico"><a href="#9-安装Calico" class="headerlink" title="9.安装Calico"></a>9.安装Calico</h1><h2 id="9-1以下步骤只在master01操作"><a href="#9-1以下步骤只在master01操作" class="headerlink" title="9.1以下步骤只在master01操作"></a>9.1以下步骤只在master01操作</h2><h3 id="9-1-1更改calico网段"><a href="#9-1-1更改calico网段" class="headerlink" title="9.1.1更改calico网段"></a>9.1.1更改calico网段</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vim calico.yaml</span></span><br><span class="line">vim calico-ipv6.yaml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">calico-config ConfigMap处</span></span><br><span class="line">    &quot;ipam&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;calico-ipam&quot;,</span><br><span class="line">        &quot;assign_ipv4&quot;: &quot;true&quot;,</span><br><span class="line">        &quot;assign_ipv6&quot;: &quot;true&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    - name: IP</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: IP6</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">      value: &quot;172.16.0.0/16&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV6POOL_CIDR</span><br><span class="line">      value: &quot;fc00::/48&quot;</span><br><span class="line"></span><br><span class="line">    - name: FELIX_IPV6SUPPORT</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl apply -f calico.yaml</span></span><br><span class="line">kubectl apply -f calico-ipv6.yaml </span><br></pre></td></tr></table></figure>

<h3 id="9-1-2查看容器状态"><a href="#9-1-2查看容器状态" class="headerlink" title="9.1.2查看容器状态"></a>9.1.2查看容器状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get pod -A</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-kube-controllers-7fb57bc4b5-dwwg8   1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-b8p4z                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-c4lzj                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-dfh2m                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-gbhgn                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-ht6nl                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-lv8bm                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-rm7d4                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-z976w                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-typha-dd885f47-jvgsj                1/1     Running   0          23s</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h1 id="10-安装CoreDNS"><a href="#10-安装CoreDNS" class="headerlink" title="10.安装CoreDNS"></a>10.安装CoreDNS</h1><h2 id="10-1以下步骤只在master01操作"><a href="#10-1以下步骤只在master01操作" class="headerlink" title="10.1以下步骤只在master01操作"></a>10.1以下步骤只在master01操作</h2><h3 id="10-1-1修改文件"><a href="#10-1-1修改文件" class="headerlink" title="10.1.1修改文件"></a>10.1.1修改文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd coredns/</span><br><span class="line"></span><br><span class="line">sed -i &quot;s#10.96.0.10#10.96.0.10#g&quot; coredns.yaml</span><br><span class="line"></span><br><span class="line">cat coredns.yaml | grep clusterIP:</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br></pre></td></tr></table></figure>

<h3 id="10-1-2安装"><a href="#10-1-2安装" class="headerlink" title="10.1.2安装"></a>10.1.2安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  create -f coredns.yaml </span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.apps/coredns created</span><br><span class="line">service/kube-dns created</span><br></pre></td></tr></table></figure>

<h1 id="11-安装Metrics-Server"><a href="#11-安装Metrics-Server" class="headerlink" title="11.安装Metrics Server"></a>11.安装Metrics Server</h1><h2 id="11-1以下步骤只在master01操作"><a href="#11-1以下步骤只在master01操作" class="headerlink" title="11.1以下步骤只在master01操作"></a>11.1以下步骤只在master01操作</h2><h3 id="11-1-1安装Metrics-server"><a href="#11-1-1安装Metrics-server" class="headerlink" title="11.1.1安装Metrics-server"></a>11.1.1安装Metrics-server</h3><p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装metrics server</span></span><br><span class="line">cd metrics-server/</span><br><span class="line"></span><br><span class="line">kubectl  apply -f metrics-server.yaml </span><br></pre></td></tr></table></figure>

<h3 id="11-1-2稍等片刻查看状态"><a href="#11-1-2稍等片刻查看状态" class="headerlink" title="11.1.2稍等片刻查看状态"></a>11.1.2稍等片刻查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   154m         1%     1715Mi          21%       </span><br><span class="line">k8s-master02   151m         1%     1274Mi          16%       </span><br><span class="line">k8s-master03   523m         6%     1345Mi          17%       </span><br><span class="line">k8s-node01     84m          1%     671Mi           8%        </span><br><span class="line">k8s-node02     73m          0%     727Mi           9%        </span><br><span class="line">k8s-node03     96m          1%     769Mi           9%        </span><br><span class="line">k8s-node04     68m          0%     673Mi           8%        </span><br><span class="line">k8s-node05     82m          1%     679Mi           8% </span><br></pre></td></tr></table></figure>

<h1 id="12-集群验证"><a href="#12-集群验证" class="headerlink" title="12.集群验证"></a>12.集群验证</h1><h2 id="12-1部署pod资源"><a href="#12-1部署pod资源" class="headerlink" title="12.1部署pod资源"></a>12.1部署pod资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line"></span><br><span class="line">kubectl  get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox   1/1     Running   0          17s</span><br></pre></td></tr></table></figure>

<h2 id="12-2用pod解析默认命名空间中的kubernetes"><a href="#12-2用pod解析默认命名空间中的kubernetes" class="headerlink" title="12.2用pod解析默认命名空间中的kubernetes"></a>12.2用pod解析默认命名空间中的kubernetes</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   17h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl exec  busybox -n default -- nslookup kubernetes</span><br><span class="line">3Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-3测试跨命名空间是否可以解析"><a href="#12-3测试跨命名空间是否可以解析" class="headerlink" title="12.3测试跨命名空间是否可以解析"></a>12.3测试跨命名空间是否可以解析</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl exec  busybox -n default -- nslookup kube-dns.kube-system</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kube-dns.kube-system</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53"><a href="#12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53" class="headerlink" title="12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53"></a>12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">telnet 10.96.0.1 443</span><br><span class="line">Trying 10.96.0.1...</span><br><span class="line">Connected to 10.96.0.1.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line"> telnet 10.96.0.10 53</span><br><span class="line">Trying 10.96.0.10...</span><br><span class="line">Connected to 10.96.0.10.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line">curl 10.96.0.10:53</span><br><span class="line">curl: (52) Empty reply from server</span><br></pre></td></tr></table></figure>

<h2 id="12-5Pod和Pod之前要能通"><a href="#12-5Pod和Pod之前要能通" class="headerlink" title="12.5Pod和Pod之前要能通"></a>12.5Pod和Pod之前要能通</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get po -owide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox   1/1     Running   0          17m   172.27.14.193   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"> kubectl get po -n kube-system -owide</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS      AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-5dffd5886b-4blh6   1/1     Running   0             77m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-fvbdq                          1/1     Running   1 (75m ago)   77m   10.0.0.61     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-g8nqd                          1/1     Running   0             77m   10.0.0.64     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-mdps8                          1/1     Running   0             77m   10.0.0.65     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-nf4nt                          1/1     Running   0             77m   10.0.0.63     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-sq2ml                          1/1     Running   0             77m   10.0.0.62     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-mg6p8              1/1     Running   0             77m   10.0.0.65     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-pxbpj              1/1     Running   0             77m   10.0.0.61     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-tnssl              1/1     Running   0             77m   10.0.0.64     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5db5696c7-67h79                    1/1     Running   0             63m   172.25.92.65     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">metrics-server-6bf7dcd649-5fhrw            1/1     Running   0             61m   172.18.195.1     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入busybox ping其他节点上的pod</span></span><br><span class="line"></span><br><span class="line">kubectl exec -ti busybox -- sh</span><br><span class="line">/ # ping 10.0.0.64</span><br><span class="line">PING 10.0.0.64 (10.0.0.64): 56 data bytes</span><br><span class="line">64 bytes from 10.0.0.64: seq=0 ttl=63 time=0.358 ms</span><br><span class="line">64 bytes from 10.0.0.64: seq=1 ttl=63 time=0.668 ms</span><br><span class="line">64 bytes from 10.0.0.64: seq=2 ttl=63 time=0.637 ms</span><br><span class="line">64 bytes from 10.0.0.64: seq=3 ttl=63 time=0.624 ms</span><br><span class="line">64 bytes from 10.0.0.64: seq=4 ttl=63 time=0.907 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以连通证明这个pod是可以跨命名空间和跨主机通信的</span></span><br></pre></td></tr></table></figure>

<h2 id="12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"><a href="#12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）" class="headerlink" title="12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"></a>12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; deployments.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl  apply -f deployments.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">kubectl  get pod </span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                            1/1     Running   0          6m25s</span><br><span class="line">nginx-deployment-9456bbbf9-4bmvk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-9rcdk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-dqv8s   1/1     Running   0          8s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除nginx</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f deployments.yaml </span><br></pre></td></tr></table></figure>





<h1 id="13-安装dashboard"><a href="#13-安装dashboard" class="headerlink" title="13.安装dashboard"></a>13.安装dashboard</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/cby-chen/Kubernetes/main/yaml/dashboard.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/cby-chen/Kubernetes/main/yaml/dashboard-user.yaml</span><br><span class="line"></span><br><span class="line">kubectl  apply -f dashboard.yaml</span><br><span class="line">kubectl  apply -f dashboard-user.yaml</span><br></pre></td></tr></table></figure>

<h2 id="13-1更改dashboard的svc为NodePort，如果已是请忽略"><a href="#13-1更改dashboard的svc为NodePort，如果已是请忽略" class="headerlink" title="13.1更改dashboard的svc为NodePort，如果已是请忽略"></a>13.1更改dashboard的svc为NodePort，如果已是请忽略</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure>

<h2 id="13-2查看端口号"><a href="#13-2查看端口号" class="headerlink" title="13.2查看端口号"></a>13.2查看端口号</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.108.120.110   &lt;none&gt;        443:30034/TCP   34s</span><br></pre></td></tr></table></figure>

<h2 id="13-3创建token"><a href="#13-3创建token" class="headerlink" title="13.3创建token"></a>13.3创建token</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl -n kubernetes-dashboard create token admin-user</span><br><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6ImxkV1hHaHViN2d3STVLTkxtbFkyaUZPdnhWa0s2NjUzRGVrNmJhMjVpRmsifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjUzODMwMTUwLCJpYXQiOjE2NTM4MjY1NTAsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiZDZlOTI2YWUtNDExYS00YTU3LTk3NWUtOWI4ZTEyMzYyZjg1In19LCJuYmYiOjE2NTM4MjY1NTAsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2VyIn0.ZSGJmGQc0F1jeJp8SwgZQ0a9ynTYi-y1JNUBJBhjRVStS9KphVK5MLpRxV4KqzhzGt8pR20nNZGop3na6EgIXVJ8XNrlQQO8kZV_I11ylw_mqL7sjCK_UsxJODOOvoRzOJMN3Qd9ONLB3cPjge9zIGeRvaEwpQulOWALScyQvO__1LkSjqz2DPQM7aDh0Gt6VZ2-JoVgTlEBy--nF-Okb0qyHMI8KEcqv7BnI1rJw5rETL7JrYBM3YIWY8_Ft71w6dKn7UhEbB9tPVMi0ymGTpUVja2M2ypsDymrMlcd4doRUn98F_i0iGW4ZN3CweRDFnkwwIUODjTn1fdp1uPXnQ</span><br></pre></td></tr></table></figure>

<h2 id="13-3登录dashboard"><a href="#13-3登录dashboard" class="headerlink" title="13.3登录dashboard"></a>13.3登录dashboard</h2><p><a href="https://10.0.0.61:30034/">https://10.0.0.61:30034/</a></p>
<h1 id="14-ingress安装"><a href="#14-ingress安装" class="headerlink" title="14.ingress安装"></a>14.ingress安装</h1><h2 id="14-1写入配置文件，并执行"><a href="#14-1写入配置文件，并执行" class="headerlink" title="14.1写入配置文件，并执行"></a>14.1写入配置文件，并执行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim deploy.yaml</span><br><span class="line">[root@hello ~/yaml]# cat deploy.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-serviceaccount.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">automountServiceAccountToken: true</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-configmap.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">data:</span><br><span class="line">  allow-snippet-annotations: &#x27;true&#x27;</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/clusterrole.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - endpoints</span><br><span class="line">      - nodes</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/clusterrolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-role.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - endpoints</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    resourceNames:</span><br><span class="line">      - ingress-controller-leader</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-rolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-service-webhook.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - name: https-webhook</span><br><span class="line">      port: 443</span><br><span class="line">      targetPort: webhook</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-service.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  externalTrafficPolicy: Local</span><br><span class="line">  ipFamilyPolicy: SingleStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">    - IPv4</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: http</span><br><span class="line">      appProtocol: http</span><br><span class="line">    - name: https</span><br><span class="line">      port: 443</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: https</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-deployment.yaml</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: ingress-nginx</span><br><span class="line">      app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">      app.kubernetes.io/component: controller</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  minReadySeconds: 0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/component: controller</span><br><span class="line">    spec:</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      containers:</span><br><span class="line">        - name: controller</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/controller:v1.2.0 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          lifecycle:</span><br><span class="line">            preStop:</span><br><span class="line">              exec:</span><br><span class="line">                command:</span><br><span class="line">                  - /wait-shutdown</span><br><span class="line">          args:</span><br><span class="line">            - /nginx-ingress-controller</span><br><span class="line">            - --election-id=ingress-controller-leader</span><br><span class="line">            - --controller-class=k8s.io/ingress-nginx</span><br><span class="line">            - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller</span><br><span class="line">            - --validating-webhook=:8443</span><br><span class="line">            - --validating-webhook-certificate=/usr/local/certificates/cert</span><br><span class="line">            - --validating-webhook-key=/usr/local/certificates/key</span><br><span class="line">          securityContext:</span><br><span class="line">            capabilities:</span><br><span class="line">              drop:</span><br><span class="line">                - ALL</span><br><span class="line">              add:</span><br><span class="line">                - NET_BIND_SERVICE</span><br><span class="line">            runAsUser: 101</span><br><span class="line">            allowPrivilegeEscalation: true</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.name</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">            - name: LD_PRELOAD</span><br><span class="line">              value: /usr/local/lib/libmimalloc.so</span><br><span class="line">          livenessProbe:</span><br><span class="line">            failureThreshold: 5</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          readinessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          ports:</span><br><span class="line">            - name: http</span><br><span class="line">              containerPort: 80</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: https</span><br><span class="line">              containerPort: 443</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: webhook</span><br><span class="line">              containerPort: 8443</span><br><span class="line">              protocol: TCP</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: webhook-cert</span><br><span class="line">              mountPath: /usr/local/certificates/</span><br><span class="line">              readOnly: true</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 100m</span><br><span class="line">              memory: 90Mi</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      serviceAccountName: ingress-nginx</span><br><span class="line">      terminationGracePeriodSeconds: 300</span><br><span class="line">      volumes:</span><br><span class="line">        - name: webhook-cert</span><br><span class="line">          secret:</span><br><span class="line">            secretName: ingress-nginx-admission</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-ingressclass.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">We don<span class="string">&#x27;t support namespaced ingressClass yet</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">So a ClusterRole and a ClusterRoleBinding is required</span></span></span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: IngressClass</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  controller: k8s.io/ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/validating-webhook.yaml</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">before changing this value, check the required kubernetes version</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites</span></span></span><br><span class="line">apiVersion: admissionregistration.k8s.io/v1</span><br><span class="line">kind: ValidatingWebhookConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">webhooks:</span><br><span class="line">  - name: validate.nginx.ingress.kubernetes.io</span><br><span class="line">    matchPolicy: Equivalent</span><br><span class="line">    rules:</span><br><span class="line">      - apiGroups:</span><br><span class="line">          - networking.k8s.io</span><br><span class="line">        apiVersions:</span><br><span class="line">          - v1</span><br><span class="line">        operations:</span><br><span class="line">          - CREATE</span><br><span class="line">          - UPDATE</span><br><span class="line">        resources:</span><br><span class="line">          - ingresses</span><br><span class="line">    failurePolicy: Fail</span><br><span class="line">    sideEffects: None</span><br><span class="line">    admissionReviewVersions:</span><br><span class="line">      - v1</span><br><span class="line">    clientConfig:</span><br><span class="line">      service:</span><br><span class="line">        namespace: ingress-nginx</span><br><span class="line">        name: ingress-nginx-controller-admission</span><br><span class="line">        path: /networking/v1/ingresses</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - admissionregistration.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - validatingwebhookconfigurations</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/role.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - create</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-create</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-create</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: create</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.2.0 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - create</span><br><span class="line">            - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-patch</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-patch</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: patch</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - patch</span><br><span class="line">            - --webhook-name=ingress-nginx-admission</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --patch-mutating=false</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">            - --patch-failure-policy=Fail</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="14-2启用后端，写入配置文件执行"><a href="#14-2启用后端，写入配置文件执行" class="headerlink" title="14.2启用后端，写入配置文件执行"></a>14.2启用后端，写入配置文件执行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim backend.yaml</span><br><span class="line">[root@hello ~/yaml]# cat backend.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: default-http-backend</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: default-http-backend</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      containers:</span><br><span class="line">      - name: default-http-backend</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/chenby/defaultbackend-amd64:1.5 </span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /healthz</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="14-3安装测试应用"><a href="#14-3安装测试应用" class="headerlink" title="14.3安装测试应用"></a>14.3安装测试应用</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim ingress-demo-app.yaml</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# cat ingress-demo-app.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello-server</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-server</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-server</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx&quot;  </span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-4执行部署"><a href="#14-4执行部署" class="headerlink" title="14.4执行部署"></a>14.4执行部署</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  apply -f deploy.yaml </span><br><span class="line"></span><br><span class="line">kubectl  apply -f backend.yaml </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">等创建完成后在执行：</span></span><br><span class="line">kubectl  apply -f ingress-demo-app.yaml </span><br><span class="line"></span><br><span class="line">kubectl  get ingress</span><br><span class="line">NAME               CLASS   HOSTS                            ADDRESS     PORTS   AGE</span><br><span class="line">ingress-host-bar   nginx   hello.chenby.cn,demo.chenby.cn   10.0.0.62   80      7s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-5过滤查看ingress端口"><a href="#14-5过滤查看ingress端口" class="headerlink" title="14.5过滤查看ingress端口"></a>14.5过滤查看ingress端口</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  get svc -A | grep ingress</span><br><span class="line">ingress-nginx          ingress-nginx-controller             NodePort    10.104.231.36    &lt;none&gt;        80:32636/TCP,443:30579/TCP   104s</span><br><span class="line">ingress-nginx          ingress-nginx-controller-admission   ClusterIP   10.101.85.88     &lt;none&gt;        443/TCP                      105s</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="15-IPv6测试"><a href="#15-IPv6测试" class="headerlink" title="15.IPv6测试"></a>15.IPv6测试</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">部署应用</span></span><br><span class="line">[root@k8s-master01 ~]# vim cby.yaml </span><br><span class="line">[root@k8s-master01 ~]# cat cby.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: chenby</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: chenby</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: chenby</span><br><span class="line">        image: nginx</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: &quot;128Mi&quot;</span><br><span class="line">            cpu: &quot;500m&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  ipFamilyPolicy: PreferDualStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">  - IPv6</span><br><span class="line">  - IPv4</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: chenby</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">[root@k8s-master01 ~]# kubectl  apply -f cby.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看端口</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl  get svc</span><br><span class="line">NAME           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">chenby         NodePort    fd00::a29c       &lt;none&gt;        80:30779/TCP   5s</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用内网访问</span></span><br><span class="line">[root@localhost yaml]# curl -I http://[fd00::a29c]</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:35 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# curl -I http://10.0.0.61:30779</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:59 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用公网访问</span></span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# curl -I http://[2408:8207:78ca:9fa1::10]:30779</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:54 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="16-安装命令行自动补全功能"><a href="#16-安装命令行自动补全功能" class="headerlink" title="16.安装命令行自动补全功能"></a>16.安装命令行自动补全功能</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install bash-completion -y</span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>





<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a></p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a></p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a></p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a></p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a></p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a></p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a></p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a></p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a></p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a></p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>二进制安装Kubernetes（k8s） v1.24.0 IPv4/IPv6双栈 （三主俩从）</title>
    <url>/2022/05/24/2022-05-24-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85Kubernetes%EF%BC%88k8s%EF%BC%89_v1.24.0_IPv4_IPv6%E5%8F%8C%E6%A0%88_%EF%BC%88%E4%B8%89%E4%B8%BB%E4%BF%A9%E4%BB%8E%EF%BC%89/</url>
    <content><![CDATA[<h1 id="二进制安装Kubernetes（k8s）-v1-24-0-IPv4-x2F-IPv6双栈-（三主俩从）"><a href="#二进制安装Kubernetes（k8s）-v1-24-0-IPv4-x2F-IPv6双栈-（三主俩从）" class="headerlink" title="二进制安装Kubernetes（k8s） v1.24.0 IPv4&#x2F;IPv6双栈 （三主俩从）"></a>二进制安装Kubernetes（k8s） v1.24.0 IPv4&#x2F;IPv6双栈 （三主俩从）</h1><p><a href="https://github.com/cby-chen/Kubernetes">Kubernetes</a> 开源不易，帮忙点个star，谢谢了</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>kubernetes二进制安装</p>
<p>后续尽可能第一时间更新新版本文档</p>
<p>1.23.3 和 1.23.4 和 1.23.5 和 1.23.6 和 1.24.0 文档以及安装包已生成。</p>
<p>若不使用IPv6，不对主机进行配置IPv6地址即可，不影响后续，但是集群依旧是IPv6的。</p>
<p><a href="https://github.com/cby-chen/Kubernetes/releases">https://github.com/cby-chen/Kubernetes/releases</a></p>
<p>手动项目地址：<a href="https://github.com/cby-chen/Kubernetes">https://github.com/cby-chen/Kubernetes</a></p>
<p>脚本项目地址：<a href="https://github.com/cby-chen/Binary_installation_of_Kubernetes">https://github.com/cby-chen/Binary_installation_of_Kubernetes</a></p>
<p>kubernetes 1.24 变化较大，详细见：<a href="https://kubernetes.io/zh/blog/2022/04/07/upcoming-changes-in-kubernetes-1-24/">https://kubernetes.io/zh/blog/2022/04/07/upcoming-changes-in-kubernetes-1-24/</a></p>
<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1.环境"></a>1.环境</h1><table>
<thead>
<tr>
<th>主机名称</th>
<th>IP地址</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td>Master01</td>
<td>10.0.0.81</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client、haproxy、keepalived</td>
</tr>
<tr>
<td>Master02</td>
<td>10.0.0.82</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client、haproxy、keepalived</td>
</tr>
<tr>
<td>Master03</td>
<td>10.0.0.83</td>
<td>master节点</td>
<td>kube-apiserver、kube-controller-manager、kube-scheduler、etcd、<br />kubelet、kube-proxy、nfs-client、haproxy、keepalived</td>
</tr>
<tr>
<td>Node01</td>
<td>10.0.0.84</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td>Node02</td>
<td>10.0.0.85</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nfs-client</td>
</tr>
<tr>
<td></td>
<td>10.0.0.89</td>
<td>VIP</td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">软件</th>
<th align="left">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">内核</td>
<td align="left">5.17.9-1.el8.elrepo</td>
</tr>
<tr>
<td align="left">CentOS 8</td>
<td align="left">v8 或者 v7</td>
</tr>
<tr>
<td align="left">kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy</td>
<td align="left">v1.24.0</td>
</tr>
<tr>
<td align="left">etcd</td>
<td align="left">v3.5.4</td>
</tr>
<tr>
<td align="left">containerd</td>
<td align="left">v1.5.11</td>
</tr>
<tr>
<td align="left">cfssl</td>
<td align="left">v1.6.1</td>
</tr>
<tr>
<td align="left">cni</td>
<td align="left">v1.1.1</td>
</tr>
<tr>
<td align="left">crictl</td>
<td align="left">v1.23.0</td>
</tr>
<tr>
<td align="left">haproxy</td>
<td align="left">v1.8.27</td>
</tr>
<tr>
<td align="left">keepalived</td>
<td align="left">v2.1.5</td>
</tr>
</tbody></table>
<p>网段</p>
<p>物理主机：10.0.0.0&#x2F;24</p>
<p>service：10.96.0.0&#x2F;12</p>
<p>pod：172.16.0.0&#x2F;12</p>
<p>建议k8s集群与etcd集群分开安装</p>
<p>安装包已经整理好：<a href="https://github.com/cby-chen/Kubernetes/releases/download/v1.24.0/kubernetes-v1.24.0.tar">https://github.com/cby-chen/Kubernetes/releases/download/v1.24.0/kubernetes-v1.24.0.tar</a></p>
<h2 id="1-1-k8s基础系统环境配置"><a href="#1-1-k8s基础系统环境配置" class="headerlink" title="1.1.k8s基础系统环境配置"></a>1.1.k8s基础系统环境配置</h2><h3 id="1-2-配置IP"><a href="#1-2-配置IP" class="headerlink" title="1.2.配置IP"></a>1.2.配置IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@10.0.0.168 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.81/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.130 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.82/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.191 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.83/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.154 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.84/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.173 &quot;nmcli con mod ens160 ipv4.addresses 10.0.0.85/24; nmcli con mod ens160 ipv4.gateway 10.0.0.1; nmcli con mod ens160 ipv4.method manual; nmcli con mod ens160 ipv4.dns &quot;8.8.8.8&quot;; nmcli con up ens160&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ssh root@10.0.0.81 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78c5:29a1::10; nmcli con mod ens160 ipv6.gateway 2408:8207:78c5:29a1::3; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.82 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78c5:29a1::20; nmcli con mod ens160 ipv6.gateway 2408:8207:78c5:29a1::3; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.83 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78c5:29a1::30; nmcli con mod ens160 ipv6.gateway 2408:8207:78c5:29a1::3; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.84 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78c5:29a1::40; nmcli con mod ens160 ipv6.gateway 2408:8207:78c5:29a1::3; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line">ssh root@10.0.0.85 &quot;nmcli con mod ens160 ipv6.addresses 2408:8207:78c5:29a1::50; nmcli con mod ens160 ipv6.gateway 2408:8207:78c5:29a1::3; nmcli con mod ens160 ipv6.method manual; nmcli con mod ens160 ipv6.dns &quot;2001:4860:4860::8888&quot;; nmcli con up ens160&quot;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="1-3-设置主机名"><a href="#1-3-设置主机名" class="headerlink" title="1.3.设置主机名"></a>1.3.设置主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname k8s-master01</span><br><span class="line">hostnamectl set-hostname k8s-master02</span><br><span class="line">hostnamectl set-hostname k8s-master03</span><br><span class="line">hostnamectl set-hostname k8s-node01</span><br><span class="line">hostnamectl set-hostname k8s-node02</span><br></pre></td></tr></table></figure>

<h3 id="1-4-配置yum源"><a href="#1-4-配置yum源" class="headerlink" title="1.4.配置yum源"></a>1.4.配置yum源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 7</span></span><br><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 8</span></span><br><span class="line">sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \</span><br><span class="line">         -e &#x27;s|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos|g&#x27; \</span><br><span class="line">         -i.bak \</span><br><span class="line">         /etc/yum.repos.d/CentOS-*.repo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于私有仓库</span></span><br><span class="line">sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; -e &#x27;s|^#baseurl=http://mirror.centos.org/\$contentdir|baseurl=http://10.0.0.123/centos|g&#x27; -i.bak  /etc/yum.repos.d/CentOS-*.repo</span><br></pre></td></tr></table></figure>

<h3 id="1-5-安装一些必备工具"><a href="#1-5-安装一些必备工具" class="headerlink" title="1.5.安装一些必备工具"></a>1.5.安装一些必备工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install wget jq psmisc vim net-tools nfs-utils telnet yum-utils device-mapper-persistent-data lvm2 git network-scripts tar curl -y</span><br></pre></td></tr></table></figure>

<h3 id="1-6-选择性下载需要工具"><a href="#1-6-选择性下载需要工具" class="headerlink" title="1.6.选择性下载需要工具"></a>1.6.选择性下载需要工具</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1.下载kubernetes1.24.+的二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md</span><br><span class="line"></span><br><span class="line">wget https://dl.k8s.io/v1.24.0/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">2.下载etcdctl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/etcd-io/etcd/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.5.4/etcd-v3.5.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">3.docker-ce二进制包下载地址</span><br><span class="line">二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><br><span class="line"></span><br><span class="line">这里需要下载20.10.+版本</span><br><span class="line"></span><br><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-20.10.14.tgz</span><br><span class="line"></span><br><span class="line">4.containerd二进制包下载</span><br><span class="line">github下载地址：https://github.com/containerd/containerd/releases</span><br><span class="line"></span><br><span class="line">containerd下载时下载带cni插件的二进制包。</span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">5.下载cfssl二进制包</span><br><span class="line">github二进制包下载地址：https://github.com/cloudflare/cfssl/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64</span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.1_linux_amd64</span><br><span class="line"></span><br><span class="line">6.cni插件下载</span><br><span class="line">github下载地址：https://github.com/containernetworking/plugins/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span><br><span class="line"></span><br><span class="line">7.crictl客户端二进制下载</span><br><span class="line">github下载：https://github.com/kubernetes-sigs/cri-tools/releases</span><br><span class="line"></span><br><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.23.0/crictl-v1.23.0-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="1-7-关闭防火墙"><a href="#1-7-关闭防火墙" class="headerlink" title="1.7.关闭防火墙"></a>1.7.关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now firewalld</span><br></pre></td></tr></table></figure>

<h3 id="1-8-关闭SELinux"><a href="#1-8-关闭SELinux" class="headerlink" title="1.8.关闭SELinux"></a>1.8.关闭SELinux</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure>

<h3 id="1-9-关闭交换分区"><a href="#1-9-关闭交换分区" class="headerlink" title="1.9.关闭交换分区"></a>1.9.关闭交换分区</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line"></span><br><span class="line">cat /etc/fstab</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>

<h3 id="1-10-关闭NetworkManager-并启用-network-lb除外"><a href="#1-10-关闭NetworkManager-并启用-network-lb除外" class="headerlink" title="1.10.关闭NetworkManager 并启用 network (lb除外)"></a>1.10.关闭NetworkManager 并启用 network (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable --now NetworkManager</span><br><span class="line">systemctl start network &amp;&amp; systemctl enable network</span><br></pre></td></tr></table></figure>

<h3 id="1-11-进行时间同步-lb除外"><a href="#1-11-进行时间同步-lb除外" class="headerlink" title="1.11.进行时间同步 (lb除外)"></a>1.11.进行时间同步 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">服务端</span></span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">cat &gt; /etc/chrony.conf &lt;&lt; EOF </span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">allow 10.0.0.0/24</span><br><span class="line">local stratum 10</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd</span><br><span class="line">systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">客户端</span></span><br><span class="line"></span><br><span class="line">yum install chrony -y</span><br><span class="line">vim /etc/chrony.conf</span><br><span class="line">cat /etc/chrony.conf | grep -v  &quot;^#&quot; | grep -v &quot;^$&quot;</span><br><span class="line">pool 10.0.0.81 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line">leapsectz right/UTC</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line">systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">客户端安装一条命令</span></span><br><span class="line">yum install chrony -y ; sed -i &quot;s#2.centos.pool.ntp.org#10.0.0.81#g&quot; /etc/chrony.conf ; systemctl restart chronyd ; systemctl enable chronyd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用客户端进行验证</span></span><br><span class="line">chronyc sources -v</span><br></pre></td></tr></table></figure>

<h3 id="1-12-配置ulimit"><a href="#1-12-配置ulimit" class="headerlink" title="1.12.配置ulimit"></a>1.12.配置ulimit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -SHn 65535</span><br><span class="line">cat &gt;&gt; /etc/security/limits.conf &lt;&lt;EOF</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* seft memlock unlimited</span><br><span class="line">* hard memlock unlimitedd</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="1-13-配置免密登录"><a href="#1-13-配置免密登录" class="headerlink" title="1.13.配置免密登录"></a>1.13.配置免密登录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br><span class="line">ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;</span><br><span class="line">export IP=&quot;10.0.0.81 10.0.0.82 10.0.0.83 10.0.0.84 10.0.0.85&quot;</span><br><span class="line">export SSHPASS=123123</span><br><span class="line">for HOST in $IP;do</span><br><span class="line">     sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $HOST</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="1-14-添加启用源-lb除外"><a href="#1-14-添加启用源-lb除外" class="headerlink" title="1.14.添加启用源 (lb除外)"></a>1.14.添加启用源 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为 RHEL-8或 CentOS-8配置源</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为 RHEL-7 SL-7 或 CentOS-7 安装 ELRepo</span> </span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看可用安装包</span></span><br><span class="line">yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available</span><br></pre></td></tr></table></figure>

<h3 id="1-15-升级内核至4-18版本以上-lb除外"><a href="#1-15-升级内核至4-18版本以上-lb除外" class="headerlink" title="1.15.升级内核至4.18版本以上 (lb除外)"></a>1.15.升级内核至4.18版本以上 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装最新的内核</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我这里选择的是稳定版kernel-ml   如需更新长期维护版本kernel-lt</span>  </span><br><span class="line">yum  --enablerepo=elrepo-kernel  install  kernel-ml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看已安装那些内核</span></span><br><span class="line">rpm -qa | grep kernel</span><br><span class="line">kernel-core-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-core-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-ml-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line">kernel-modules-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-tools-libs-4.18.0-358.el8.x86_64</span><br><span class="line">kernel-ml-modules-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看默认内核</span></span><br><span class="line">grubby --default-kernel</span><br><span class="line">/boot/vmlinuz-5.16.7-1.el8.elrepo.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">若不是最新的使用命令设置</span></span><br><span class="line">grubby --set-default /boot/vmlinuz-「您的内核版本」.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启生效</span></span><br><span class="line">reboot</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">v8 整合命令为：</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --default-kernel ; reboot</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">v7 整合命令为：</span></span><br><span class="line">yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm -y ; yum  --disablerepo=&quot;*&quot;  --enablerepo=&quot;elrepo-kernel&quot;  list  available -y ; yum  --enablerepo=elrepo-kernel  install  kernel-ml -y ; grubby --set-default \$(ls /boot/vmlinuz-* | grep elrepo) ; grubby --default-kernel</span><br></pre></td></tr></table></figure>

<h3 id="1-16-安装ipvsadm-lb除外"><a href="#1-16-安装ipvsadm-lb除外" class="headerlink" title="1.16.安装ipvsadm (lb除外)"></a>1.16.安装ipvsadm (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;EOF </span><br><span class="line">ip_vs</span><br><span class="line">ip_vs_rr</span><br><span class="line">ip_vs_wrr</span><br><span class="line">ip_vs_sh</span><br><span class="line">nf_conntrack</span><br><span class="line">ip_tables</span><br><span class="line">ip_set</span><br><span class="line">xt_set</span><br><span class="line">ipt_set</span><br><span class="line">ipt_rpfilter</span><br><span class="line">ipt_REJECT</span><br><span class="line">ipip</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart systemd-modules-load.service</span><br><span class="line"></span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack</span><br><span class="line">ip_vs_sh               16384  0</span><br><span class="line">ip_vs_wrr              16384  0</span><br><span class="line">ip_vs_rr               16384  0</span><br><span class="line">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          176128  1 ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure>

<h3 id="1-17-修改内核参数-lb除外"><a href="#1-17-修改内核参数-lb除外" class="headerlink" title="1.17.修改内核参数 (lb除外)"></a>1.17.修改内核参数 (lb除外)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line"></span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.all.forwarding = 0</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="1-18-所有节点配置hosts本地解析"><a href="#1-18-所有节点配置hosts本地解析" class="headerlink" title="1.18.所有节点配置hosts本地解析"></a>1.18.所有节点配置hosts本地解析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">2408:8207:78c5:29a1::10 k8s-master01</span><br><span class="line">2408:8207:78c5:29a1::20 k8s-master02</span><br><span class="line">2408:8207:78c5:29a1::30 k8s-master03</span><br><span class="line">2408:8207:78c5:29a1::40 k8s-node01</span><br><span class="line">2408:8207:78c5:29a1::50 k8s-node02</span><br><span class="line">2408:8207:78c5:29a1::90 lb01</span><br><span class="line">2408:8207:78c5:29a1::100 lb02</span><br><span class="line"></span><br><span class="line">10.0.0.81 k8s-master01</span><br><span class="line">10.0.0.82 k8s-master02</span><br><span class="line">10.0.0.83 k8s-master03</span><br><span class="line">10.0.0.84 k8s-node01</span><br><span class="line">10.0.0.85 k8s-node02</span><br><span class="line">10.0.0.80 lb01</span><br><span class="line">10.0.0.90 lb02</span><br><span class="line">10.0.0.89 lb-vip</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="2-k8s基本组件安装"><a href="#2-k8s基本组件安装" class="headerlink" title="2.k8s基本组件安装"></a>2.k8s基本组件安装</h1><h2 id="2-1-所有k8s节点安装Containerd作为Runtime"><a href="#2-1-所有k8s节点安装Containerd作为Runtime" class="headerlink" title="2.1.所有k8s节点安装Containerd作为Runtime"></a>2.1.所有k8s节点安装Containerd作为Runtime</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建cni插件所需目录</span></span><br><span class="line">mkdir -p /etc/cni/net.d /opt/cni/bin </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压cni二进制包</span></span><br><span class="line">tar xf cni-plugins-linux-amd64-v1.1.1.tgz -C /opt/cni/bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar -C / -xzf cri-containerd-cni-1.6.4-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建服务启动文件</span></span><br><span class="line">cat &gt; /etc/systemd/system/containerd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=containerd container runtime</span><br><span class="line">Documentation=https://containerd.io</span><br><span class="line">After=network.target local-fs.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=-/sbin/modprobe overlay</span><br><span class="line">ExecStart=/usr/local/bin/containerd</span><br><span class="line">Type=notify</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">TasksMax=infinity</span><br><span class="line">OOMScoreAdjust=-999</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-1配置Containerd所需的模块"><a href="#2-1-1配置Containerd所需的模块" class="headerlink" title="2.1.1配置Containerd所需的模块"></a>2.1.1配置Containerd所需的模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2加载模块"><a href="#2-1-2加载模块" class="headerlink" title="2.1.2加载模块"></a>2.1.2加载模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl restart systemd-modules-load.service</span><br></pre></td></tr></table></figure>

<h3 id="2-1-3配置Containerd所需的内核"><a href="#2-1-3配置Containerd所需的内核" class="headerlink" title="2.1.3配置Containerd所需的内核"></a>2.1.3配置Containerd所需的内核</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载内核</span></span><br><span class="line"></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4创建Containerd的配置文件"><a href="#2-1-4创建Containerd的配置文件" class="headerlink" title="2.1.4创建Containerd的配置文件"></a>2.1.4创建Containerd的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | tee /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改Containerd的配置文件</span><br><span class="line">sed -i &quot;s#SystemdCgroup\ \=\ false#SystemdCgroup\ \=\ true#g&quot; /etc/containerd/config.toml</span><br><span class="line"></span><br><span class="line">cat /etc/containerd/config.toml | grep SystemdCgroup</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到containerd.runtimes.runc.options，在其下加入SystemdCgroup = <span class="literal">true</span></span></span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">              SystemdCgroup = true</span><br><span class="line">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sandbox_image默认地址改为符合版本地址</span></span><br><span class="line">    sandbox_image = &quot;registry.cn-hangzhou.aliyuncs.com/chenby/pause:3.6&quot;</span><br></pre></td></tr></table></figure>

<h3 id="2-1-5启动并设置为开机启动"><a href="#2-1-5启动并设置为开机启动" class="headerlink" title="2.1.5启动并设置为开机启动"></a>2.1.5启动并设置为开机启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now containerd</span><br></pre></td></tr></table></figure>

<h3 id="2-1-6配置crictl客户端连接的运行时位置"><a href="#2-1-6配置crictl客户端连接的运行时位置" class="headerlink" title="2.1.6配置crictl客户端连接的运行时位置"></a>2.1.6配置crictl客户端连接的运行时位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.23.0/crictl-v1.23.0-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar xf crictl-v1.23.0-linux-amd64.tar.gz -C /usr/bin/</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">生成配置文件</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/crictl.yaml &lt;&lt;EOF</span><br><span class="line">runtime-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">image-endpoint: unix:///run/containerd/containerd.sock</span><br><span class="line">timeout: 10</span><br><span class="line">debug: false</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">测试</span></span><br><span class="line">systemctl restart  containerd</span><br><span class="line">crictl info</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2-2-k8s与etcd下载及安装（仅在master01操作）"><a href="#2-2-k8s与etcd下载及安装（仅在master01操作）" class="headerlink" title="2.2.k8s与etcd下载及安装（仅在master01操作）"></a>2.2.k8s与etcd下载及安装（仅在master01操作）</h2><h3 id="2-2-1解压k8s安装包"><a href="#2-2-1解压k8s安装包" class="headerlink" title="2.2.1解压k8s安装包"></a>2.2.1解压k8s安装包</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压k8s安装文件</span></span><br><span class="line">cd cby</span><br><span class="line">tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压etcd安装文件</span></span><br><span class="line">tar -xf etcd-v3.5.4-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.4-linux-amd64/etcd&#123;,ctl&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看/usr/local/bin下内容</span></span><br><span class="line"></span><br><span class="line">ls /usr/local/bin/</span><br><span class="line">etcd  etcdctl  kube-apiserver  kube-controller-manager  kubectl  kubelet  kube-proxy  kube-scheduler</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-2-2查看版本"><a href="#2-2-2查看版本" class="headerlink" title="2.2.2查看版本"></a>2.2.2查看版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubelet --version</span><br><span class="line">Kubernetes v1.24.0</span><br><span class="line">[root@k8s-master01 ~]# etcdctl version</span><br><span class="line">etcdctl version: 3.5.4</span><br><span class="line">API version: 3.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h3 id="2-2-3将组件发送至其他k8s节点"><a href="#2-2-3将组件发送至其他k8s节点" class="headerlink" title="2.2.3将组件发送至其他k8s节点"></a>2.2.3将组件发送至其他k8s节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line">Work=&#x27;k8s-node01 k8s-node02&#x27;</span><br><span class="line"></span><br><span class="line">for NODE in $Master; do echo $NODE; scp /usr/local/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done</span><br><span class="line"></span><br><span class="line">for NODE in $Work; do     scp /usr/local/bin/kube&#123;let,-proxy&#125; $NODE:/usr/local/bin/ ; done</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/cni/bin</span><br></pre></td></tr></table></figure>

<h2 id="2-3创建证书相关文件"><a href="#2-3创建证书相关文件" class="headerlink" title="2.3创建证书相关文件"></a>2.3创建证书相关文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir pki</span><br><span class="line">cd pki</span><br><span class="line">cat &gt; admin-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; ca-config.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; etcd-ca-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;etcd&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Etcd Security&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; front-proxy-ca-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">     &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">     &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; kubelet-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:node:$NODE&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:nodes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; manager-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; apiserver-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kube-apiserver&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;Kubernetes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; ca-csr.json   &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;Kubernetes&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; etcd-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;etcd&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Etcd Security&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; front-proxy-client-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;front-proxy-client&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">     &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">     &quot;size&quot;: 2048</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; kube-proxy-csr.json  &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; scheduler-csr.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir bootstrap</span><br><span class="line">cd bootstrap</span><br><span class="line">cat &gt; bootstrap.secret.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: bootstrap-token-c8ad9c</span><br><span class="line">  namespace: kube-system</span><br><span class="line">type: bootstrap.kubernetes.io/token</span><br><span class="line">stringData:</span><br><span class="line">  description: &quot;The default bootstrap token generated by &#x27;kubelet &#x27;.&quot;</span><br><span class="line">  token-id: c8ad9c</span><br><span class="line">  token-secret: 2e4d610cf3e7426e</span><br><span class="line">  usage-bootstrap-authentication: &quot;true&quot;</span><br><span class="line">  usage-bootstrap-signing: &quot;true&quot;</span><br><span class="line">  auth-extra-groups:  system:bootstrappers:default-node-token,system:bootstrappers:worker,system:bootstrappers:ingress</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubelet-bootstrap</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:bootstrappers:default-node-token</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-autoapprove-bootstrap</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:bootstrappers:default-node-token</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-autoapprove-certificate-rotation</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes/proxy</span><br><span class="line">      - nodes/stats</span><br><span class="line">      - nodes/log</span><br><span class="line">      - nodes/spec</span><br><span class="line">      - nodes/metrics</span><br><span class="line">    verbs:</span><br><span class="line">      - &quot;*&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:kube-apiserver</span><br><span class="line">  namespace: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">subjects:</span><br><span class="line">  - apiGroup: rbac.authorization.k8s.io</span><br><span class="line">    kind: User</span><br><span class="line">    name: kube-apiserver</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir coredns</span><br><span class="line">cd coredns</span><br><span class="line">cat &gt; coredns.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">    - endpoints</span><br><span class="line">    - services</span><br><span class="line">    - pods</span><br><span class="line">    - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - discovery.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">    - endpointslices</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health &#123;</span><br><span class="line">          lameduck 5s</span><br><span class="line">        &#125;</span><br><span class="line">        ready</span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        forward . /etc/resolv.conf &#123;</span><br><span class="line">          max_concurrent 1000</span><br><span class="line">        &#125;</span><br><span class="line">        cache 30</span><br><span class="line">        loop</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">replicas: not specified here:</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">1. Default is 1.</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">2. Will be tuned <span class="keyword">in</span> real time <span class="keyword">if</span> DNS horizontal auto-scaling is turned on.</span></span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: &quot;CriticalAddonsOnly&quot;</span><br><span class="line">          operator: &quot;Exists&quot;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      affinity:</span><br><span class="line">         podAntiAffinity:</span><br><span class="line">           preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">           - weight: 100</span><br><span class="line">             podAffinityTerm:</span><br><span class="line">               labelSelector:</span><br><span class="line">                 matchExpressions:</span><br><span class="line">                   - key: k8s-app</span><br><span class="line">                     operator: In</span><br><span class="line">                     values: [&quot;kube-dns&quot;]</span><br><span class="line">               topologyKey: kubernetes.io/hostname</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: registry.cn-beijing.aliyuncs.com/dotbalo/coredns:1.8.6 </span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 170Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        args: [ &quot;-conf&quot;, &quot;/etc/coredns/Corefile&quot; ]</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/coredns</span><br><span class="line">          readOnly: true</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /ready</span><br><span class="line">            port: 8181</span><br><span class="line">            scheme: HTTP</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: coredns</span><br><span class="line">            items:</span><br><span class="line">            - key: Corefile</span><br><span class="line">              path: Corefile</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: &quot;9153&quot;</span><br><span class="line">    prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line">mkdir metrics-server</span><br><span class="line">cd metrics-server</span><br><span class="line">cat &gt; metrics-server.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-admin: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot;</span><br><span class="line">  name: system:aggregated-metrics-reader</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - metrics.k8s.io</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes/stats</span><br><span class="line">  - namespaces</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server-auth-reader</span><br><span class="line">  namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: extension-apiserver-authentication-reader</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server:system:auth-delegator</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:auth-delegator</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: https</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - args:</span><br><span class="line">        - --cert-dir=/tmp</span><br><span class="line">        - --secure-port=4443</span><br><span class="line">        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">        - --kubelet-use-node-status-port</span><br><span class="line">        - --metric-resolution=15s</span><br><span class="line">        - --kubelet-insecure-tls</span><br><span class="line">        - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem # change to front-proxy-ca.crt for kubeadm</span><br><span class="line">        - --requestheader-username-headers=X-Remote-User</span><br><span class="line">        - --requestheader-group-headers=X-Remote-Group</span><br><span class="line">        - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">        image: registry.cn-beijing.aliyuncs.com/dotbalo/metrics-server:0.5.0</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        livenessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /livez</span><br><span class="line">            port: https</span><br><span class="line">            scheme: HTTPS</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">        name: metrics-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 4443</span><br><span class="line">          name: https</span><br><span class="line">          protocol: TCP</span><br><span class="line">        readinessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /readyz</span><br><span class="line">            port: https</span><br><span class="line">            scheme: HTTPS</span><br><span class="line">          initialDelaySeconds: 20</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 200Mi</span><br><span class="line">        securityContext:</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">          runAsNonRoot: true</span><br><span class="line">          runAsUser: 1000</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /tmp</span><br><span class="line">          name: tmp-dir</span><br><span class="line">        - name: ca-ssl</span><br><span class="line">          mountPath: /etc/kubernetes/pki</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      volumes:</span><br><span class="line">      - emptyDir: &#123;&#125;</span><br><span class="line">        name: tmp-dir</span><br><span class="line">      - name: ca-ssl</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/kubernetes/pki</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apiregistration.k8s.io/v1</span><br><span class="line">kind: APIService</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  name: v1beta1.metrics.k8s.io</span><br><span class="line">spec:</span><br><span class="line">  group: metrics.k8s.io</span><br><span class="line">  groupPriorityMinimum: 100</span><br><span class="line">  insecureSkipTLSVerify: true</span><br><span class="line">  service:</span><br><span class="line">    name: metrics-server</span><br><span class="line">    namespace: kube-system</span><br><span class="line">  version: v1beta1</span><br><span class="line">  versionPriority: 100</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h1 id="3-相关证书生成"><a href="#3-相关证书生成" class="headerlink" title="3.相关证书生成"></a>3.相关证书生成</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">master01节点下载证书生成工具</span></span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssl</span><br><span class="line">wget &quot;https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64&quot; -O /usr/local/bin/cfssljson</span><br><span class="line">chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</span><br></pre></td></tr></table></figure>

<h2 id="3-1-生成etcd证书"><a href="#3-1-生成etcd证书" class="headerlink" title="3.1.生成etcd证书"></a>3.1.生成etcd证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-1-1所有master节点创建证书存放目录"><a href="#3-1-1所有master节点创建证书存放目录" class="headerlink" title="3.1.1所有master节点创建证书存放目录"></a>3.1.1所有master节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/etcd/ssl -p</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2master01节点生成etcd证书"><a href="#3-1-2master01节点生成etcd证书" class="headerlink" title="3.1.2master01节点生成etcd证书"></a>3.1.2master01节点生成etcd证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd pki</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成etcd证书和etcd证书的key（如果你觉得以后可能会扩容，可以在ip那多写几个预留出来）</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,10.0.0.81,10.0.0.82,10.0.0.83,2408:8207:78c5:29a1::10,2408:8207:78c5:29a1::20,2408:8207:78c5:29a1::30 \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</span><br></pre></td></tr></table></figure>

<h3 id="3-1-3将证书复制到其他节点"><a href="#3-1-3将证书复制到其他节点" class="headerlink" title="3.1.3将证书复制到其他节点"></a>3.1.3将证书复制到其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Master=&#x27;k8s-master02 k8s-master03&#x27;</span><br><span class="line"></span><br><span class="line">for NODE in $Master; do ssh $NODE &quot;mkdir -p /etc/etcd/ssl&quot;; for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do scp /etc/etcd/ssl/$&#123;FILE&#125; $NODE:/etc/etcd/ssl/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h2 id="3-2-生成k8s相关证书"><a href="#3-2-生成k8s相关证书" class="headerlink" title="3.2.生成k8s相关证书"></a>3.2.生成k8s相关证书</h2><p>特别说明除外，以下操作在所有master节点操作</p>
<h3 id="3-2-1所有k8s节点创建证书存放目录"><a href="#3-2-1所有k8s节点创建证书存放目录" class="headerlink" title="3.2.1所有k8s节点创建证书存放目录"></a>3.2.1所有k8s节点创建证书存放目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/pki</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2master01节点生成k8s证书"><a href="#3-2-2master01节点生成k8s证书" class="headerlink" title="3.2.2master01节点生成k8s证书"></a>3.2.2master01节点生成k8s证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成一个根证书</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.96.0.1是service网段的第一个地址，需要计算，10.0.0.89为高可用vip地址</span></span><br><span class="line"></span><br><span class="line">cfssl gencert   \</span><br><span class="line">-ca=/etc/kubernetes/pki/ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-hostname=10.96.0.1,10.0.0.89,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,x.oiox.cn,k.oiox.cn,l.oiox.cn,o.oiox.cn,10.0.0.81,10.0.0.82,10.0.0.83,10.0.0.84,10.0.0.85,10.0.0.86,10.0.0.87,10.0.0.88,10.0.0.80,10.0.0.90,10.0.0.40,10.0.0.41,2408:8207:78c5:29a1::10,2408:8207:78c5:29a1::20,2408:8207:78c5:29a1::30,2408:8207:78c5:29a1::40,2408:8207:78c5:29a1::50,2408:8207:78c5:29a1::60,2408:8207:78c5:29a1::70,2408:8207:78c5:29a1::80,2408:8207:78c5:29a1::90,2408:8207:78c5:29a1::100   \</span><br><span class="line">-profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3生成apiserver聚合证书"><a href="#3-2-3生成apiserver聚合证书" class="headerlink" title="3.2.3生成apiserver聚合证书"></a>3.2.3生成apiserver聚合证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有一个警告，可以忽略</span></span><br><span class="line"></span><br><span class="line">cfssl gencert  \</span><br><span class="line">-ca=/etc/kubernetes/pki/front-proxy-ca.pem   \</span><br><span class="line">-ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   \</span><br><span class="line">-config=ca-config.json   \</span><br><span class="line">-profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4生成controller-manage的证书"><a href="#3-2-4生成controller-manage的证书" class="headerlink" title="3.2.4生成controller-manage的证书"></a>3.2.4生成controller-manage的证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个集群项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://10.0.0.89:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个环境项，一个上下文</span></span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=system:kube-controller-manager \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置一个用户项</span></span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置默认环境</span></span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">     --certificate-authority=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --server=https://10.0.0.89:8443 \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">     --client-certificate=/etc/kubernetes/pki/scheduler.pem \</span><br><span class="line">     --client-key=/etc/kubernetes/pki/scheduler-key.pem \</span><br><span class="line">     --embed-certs=true \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --cluster=kubernetes \</span><br><span class="line">     --user=system:kube-scheduler \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes \</span><br><span class="line">     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">cfssl gencert \</span><br><span class="line">   -ca=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">   -ca-key=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">   -config=ca-config.json \</span><br><span class="line">   -profile=kubernetes \</span><br><span class="line">   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --server=https://10.0.0.89:8443     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubernetes-admin  \</span><br><span class="line">  --client-certificate=/etc/kubernetes/pki/admin.pem     \</span><br><span class="line">  --client-key=/etc/kubernetes/pki/admin-key.pem     \</span><br><span class="line">  --embed-certs=true     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes    \</span><br><span class="line">  --cluster=kubernetes     \</span><br><span class="line">  --user=kubernetes-admin     \</span><br><span class="line">  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes  --kubeconfig=/etc/kubernetes/admin.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5创建ServiceAccount-Key-——secret"><a href="#3-2-5创建ServiceAccount-Key-——secret" class="headerlink" title="3.2.5创建ServiceAccount Key ——secret"></a>3.2.5创建ServiceAccount Key ——secret</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out /etc/kubernetes/pki/sa.key 2048</span><br><span class="line">openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</span><br></pre></td></tr></table></figure>

<h3 id="3-2-6将证书发送到其他master节点"><a href="#3-2-6将证书发送到其他master节点" class="headerlink" title="3.2.6将证书发送到其他master节点"></a>3.2.6将证书发送到其他master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do  for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do  scp /etc/kubernetes/pki/$&#123;FILE&#125; $NODE:/etc/kubernetes/pki/$&#123;FILE&#125;; done;  for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do  scp /etc/kubernetes/$&#123;FILE&#125; $NODE:/etc/kubernetes/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h3 id="3-2-7查看证书"><a href="#3-2-7查看证书" class="headerlink" title="3.2.7查看证书"></a>3.2.7查看证书</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls /etc/kubernetes/pki/</span><br><span class="line">admin.csr      apiserver-key.pem  ca.pem                      front-proxy-ca.csr      front-proxy-client-key.pem  scheduler.csr</span><br><span class="line">admin-key.pem  apiserver.pem      controller-manager.csr      front-proxy-ca-key.pem  front-proxy-client.pem      scheduler-key.pem</span><br><span class="line">admin.pem      ca.csr             controller-manager-key.pem  front-proxy-ca.pem      sa.key                      scheduler.pem</span><br><span class="line">apiserver.csr  ca-key.pem         controller-manager.pem      front-proxy-client.csr  sa.pub</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一共23个就对了</span></span><br><span class="line"></span><br><span class="line">ls /etc/kubernetes/pki/ |wc -l</span><br><span class="line">23</span><br></pre></td></tr></table></figure>

<h1 id="4-k8s系统组件配置"><a href="#4-k8s系统组件配置" class="headerlink" title="4.k8s系统组件配置"></a>4.k8s系统组件配置</h1><h2 id="4-1-etcd配置"><a href="#4-1-etcd配置" class="headerlink" title="4.1.etcd配置"></a>4.1.etcd配置</h2><h3 id="4-1-1master01配置"><a href="#4-1-1master01配置" class="headerlink" title="4.1.1master01配置"></a>4.1.1master01配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master01&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.81:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.81:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.81:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.81:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.81:2380,k8s-master02=https://10.0.0.82:2380,k8s-master03=https://10.0.0.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2master02配置"><a href="#4-1-2master02配置" class="headerlink" title="4.1.2master02配置"></a>4.1.2master02配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master02&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.82:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.82:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.82:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.82:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.81:2380,k8s-master02=https://10.0.0.82:2380,k8s-master03=https://10.0.0.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3master03配置"><a href="#4-1-3master03配置" class="headerlink" title="4.1.3master03配置"></a>4.1.3master03配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">cat &gt; /etc/etcd/etcd.config.yml &lt;&lt; EOF </span><br><span class="line">name: &#x27;k8s-master03&#x27;</span><br><span class="line">data-dir: /var/lib/etcd</span><br><span class="line">wal-dir: /var/lib/etcd/wal</span><br><span class="line">snapshot-count: 5000</span><br><span class="line">heartbeat-interval: 100</span><br><span class="line">election-timeout: 1000</span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line">listen-peer-urls: &#x27;https://10.0.0.83:2380&#x27;</span><br><span class="line">listen-client-urls: &#x27;https://10.0.0.83:2379,http://127.0.0.1:2379&#x27;</span><br><span class="line">max-snapshots: 3</span><br><span class="line">max-wals: 5</span><br><span class="line">cors:</span><br><span class="line">initial-advertise-peer-urls: &#x27;https://10.0.0.83:2380&#x27;</span><br><span class="line">advertise-client-urls: &#x27;https://10.0.0.83:2379&#x27;</span><br><span class="line">discovery:</span><br><span class="line">discovery-fallback: &#x27;proxy&#x27;</span><br><span class="line">discovery-proxy:</span><br><span class="line">discovery-srv:</span><br><span class="line">initial-cluster: &#x27;k8s-master01=https://10.0.0.81:2380,k8s-master02=https://10.0.0.82:2380,k8s-master03=https://10.0.0.83:2380&#x27;</span><br><span class="line">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><br><span class="line">initial-cluster-state: &#x27;new&#x27;</span><br><span class="line">strict-reconfig-check: false</span><br><span class="line">enable-v2: true</span><br><span class="line">enable-pprof: true</span><br><span class="line">proxy: &#x27;off&#x27;</span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><br><span class="line">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><br><span class="line">  peer-client-cert-auth: true</span><br><span class="line">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><br><span class="line">  auto-tls: true</span><br><span class="line">debug: false</span><br><span class="line">log-package-levels:</span><br><span class="line">log-outputs: [default]</span><br><span class="line">force-new-cluster: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="4-2-创建service（所有master节点操作）"><a href="#4-2-创建service（所有master节点操作）" class="headerlink" title="4.2.创建service（所有master节点操作）"></a>4.2.创建service（所有master节点操作）</h2><h3 id="4-2-1创建etcd-service并启动"><a href="#4-2-1创建etcd-service并启动" class="headerlink" title="4.2.1创建etcd.service并启动"></a>4.2.1创建etcd.service并启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2创建etcd证书目录"><a href="#4-2-2创建etcd证书目录" class="headerlink" title="4.2.2创建etcd证书目录"></a>4.2.2创建etcd证书目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /etc/kubernetes/pki/etcd</span><br><span class="line">ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now etcd</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3查看etcd状态"><a href="#4-2-3查看etcd状态" class="headerlink" title="4.2.3查看etcd状态"></a>4.2.3查看etcd状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果要用IPv6那么把IPv4地址修改为IPv6即可</span></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --endpoints=&quot;10.0.0.83:2379,10.0.0.82:2379,10.0.0.81:2379&quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">|    ENDPOINT    |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line">| 10.0.0.83:2379 | c0c8142615b9523f |   3.5.4 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 10.0.0.82:2379 | de8396604d2c160d |   3.5.4 |   20 kB |     false |      false |         2 |          9 |                  9 |        |</span><br><span class="line">| 10.0.0.81:2379 | 33c9d6df0037ab97 |   3.5.4 |   20 kB |      true |      false |         2 |          9 |                  9 |        |</span><br><span class="line">+----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 pki]# </span><br></pre></td></tr></table></figure>

<h1 id="5-高可用配置"><a href="#5-高可用配置" class="headerlink" title="5.高可用配置"></a>5.高可用配置</h1><h2 id="5-1在master01和master02和master03服务器上操作"><a href="#5-1在master01和master02和master03服务器上操作" class="headerlink" title="5.1在master01和master02和master03服务器上操作"></a>5.1在master01和master02和master03服务器上操作</h2><h3 id="5-1-1安装keepalived和haproxy服务"><a href="#5-1-1安装keepalived和haproxy服务" class="headerlink" title="5.1.1安装keepalived和haproxy服务"></a>5.1.1安装keepalived和haproxy服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install keepalived haproxy</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2修改haproxy配置文件（配置文件一样）"><a href="#5-1-2修改haproxy配置文件（配置文件一样）" class="headerlink" title="5.1.2修改haproxy配置文件（配置文件一样）"></a>5.1.2修改haproxy配置文件（配置文件一样）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt;/etc/haproxy/haproxy.cfg&lt;&lt;&quot;EOF&quot;</span><br><span class="line">global</span><br><span class="line"> maxconn 2000</span><br><span class="line"> ulimit-n 16384</span><br><span class="line"> log 127.0.0.1 local0 err</span><br><span class="line"> stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"> log global</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> timeout connect 5000</span><br><span class="line"> timeout client 50000</span><br><span class="line"> timeout server 50000</span><br><span class="line"> timeout http-request 15s</span><br><span class="line"> timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line"> bind *:33305</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line"> bind 0.0.0.0:8443</span><br><span class="line"> bind 127.0.0.1:8443</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> tcp-request inspect-delay 5s</span><br><span class="line"> default_backend k8s-master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> option tcp-check</span><br><span class="line"> balance roundrobin</span><br><span class="line"> default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line"> server  k8s-master01  10.0.0.81:6443 check</span><br><span class="line"> server  k8s-master02  10.0.0.82:6443 check</span><br><span class="line"> server  k8s-master03  10.0.0.83:6443 check</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-3master01配置keepalived-master节点"><a href="#5-1-3master01配置keepalived-master节点" class="headerlink" title="5.1.3master01配置keepalived master节点"></a>5.1.3master01配置keepalived master节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens160</span><br><span class="line">    mcast_src_ip 10.0.0.81</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        10.0.0.89</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4master02配置keepalived-backup节点"><a href="#5-1-4master02配置keepalived-backup节点" class="headerlink" title="5.1.4master02配置keepalived backup节点"></a>5.1.4master02配置keepalived backup节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens160</span><br><span class="line">    mcast_src_ip 10.0.0.82</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 80</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        10.0.0.89</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4master03配置keepalived-backup节点"><a href="#5-1-4master03配置keepalived-backup节点" class="headerlink" title="5.1.4master03配置keepalived backup节点"></a>5.1.4master03配置keepalived backup节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span></span><br><span class="line"></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_apiserver &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_apiserver.sh&quot;</span><br><span class="line">    interval 5 </span><br><span class="line">    weight -5</span><br><span class="line">    fall 2</span><br><span class="line">    rise 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens160</span><br><span class="line">    mcast_src_ip 10.0.0.83</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 50</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        10.0.0.89</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">      chk_apiserver </span><br><span class="line">&#125; &#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h3 id="5-1-5健康检查脚本配置（两台lb主机）"><a href="#5-1-5健康检查脚本配置（两台lb主机）" class="headerlink" title="5.1.5健康检查脚本配置（两台lb主机）"></a>5.1.5健康检查脚本配置（两台lb主机）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /etc/keepalived/check_apiserver.sh &lt;&lt; EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">err=0</span><br><span class="line">for k in \$(seq 1 3)</span><br><span class="line">do</span><br><span class="line">    check_code=\$(pgrep haproxy)</span><br><span class="line">    if [[ \$check_code == &quot;&quot; ]]; then</span><br><span class="line">        err=\$(expr \$err + 1)</span><br><span class="line">        sleep 1</span><br><span class="line">        continue</span><br><span class="line">    else</span><br><span class="line">        err=0</span><br><span class="line">        break</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ \$err != &quot;0&quot; ]]; then</span><br><span class="line">    echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">    /usr/bin/systemctl stop keepalived</span><br><span class="line">    exit 1</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给脚本授权</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_apiserver.sh</span><br></pre></td></tr></table></figure>

<h3 id="5-1-6启动服务"><a href="#5-1-6启动服务" class="headerlink" title="5.1.6启动服务"></a>5.1.6启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now haproxy</span><br><span class="line">systemctl enable --now keepalived</span><br></pre></td></tr></table></figure>

<h3 id="5-1-7测试高可用"><a href="#5-1-7测试高可用" class="headerlink" title="5.1.7测试高可用"></a>5.1.7测试高可用</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能ping同</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# ping 10.0.0.89</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">能telnet访问</span></span><br><span class="line"></span><br><span class="line">[root@k8s-node02 ~]# telnet 10.0.0.89 8443</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭主节点，看vip是否漂移到备节点</span></span><br></pre></td></tr></table></figure>

<h1 id="6-k8s组件配置（区别于第4点）"><a href="#6-k8s组件配置（区别于第4点）" class="headerlink" title="6.k8s组件配置（区别于第4点）"></a>6.k8s组件配置（区别于第4点）</h1><p>所有k8s节点创建以下目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes</span><br></pre></td></tr></table></figure>

<h2 id="6-1-创建apiserver（所有master节点）"><a href="#6-1-创建apiserver（所有master节点）" class="headerlink" title="6.1.创建apiserver（所有master节点）"></a>6.1.创建apiserver（所有master节点）</h2><h3 id="6-1-1master01节点配置"><a href="#6-1-1master01节点配置" class="headerlink" title="6.1.1master01节点配置"></a>6.1.1master01节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.81 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">      --feature-gates=IPv6DualStack=true  \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.81:2379,https://10.0.0.82:2379,https://10.0.0.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-2master02节点配置"><a href="#6-1-2master02节点配置" class="headerlink" title="6.1.2master02节点配置"></a>6.1.2master02节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.82 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">			--feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.81:2379,https://10.0.0.82:2379,https://10.0.0.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line">      # --token-auth-file=/etc/kubernetes/token.csv</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-3master03节点配置"><a href="#6-1-3master03节点配置" class="headerlink" title="6.1.3master03节点配置"></a>6.1.3master03节点配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service  &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \</span><br><span class="line">      --v=2  \</span><br><span class="line">      --logtostderr=true  \</span><br><span class="line">      --allow-privileged=true  \</span><br><span class="line">      --bind-address=0.0.0.0  \</span><br><span class="line">      --secure-port=6443  \</span><br><span class="line">      --advertise-address=10.0.0.83 \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108  \</span><br><span class="line">			--feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-node-port-range=30000-32767  \</span><br><span class="line">      --etcd-servers=https://10.0.0.81:2379,https://10.0.0.82:2379,https://10.0.0.83:2379 \</span><br><span class="line">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \</span><br><span class="line">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \</span><br><span class="line">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \</span><br><span class="line">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \</span><br><span class="line">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \</span><br><span class="line">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><br><span class="line">      --authorization-mode=Node,RBAC  \</span><br><span class="line">      --enable-bootstrap-token-auth=true  \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \</span><br><span class="line">      --requestheader-allowed-names=aggregator  \</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group  \</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \</span><br><span class="line">      --requestheader-username-headers=X-Remote-User \</span><br><span class="line">      --enable-aggregator-routing=true</span><br><span class="line"></span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-1-4启动apiserver（所有master节点）"><a href="#6-1-4启动apiserver（所有master节点）" class="headerlink" title="6.1.4启动apiserver（所有master节点）"></a>6.1.4启动apiserver（所有master节点）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl enable --now kube-apiserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意查看状态是否启动正常</span></span><br><span class="line"></span><br><span class="line">systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>

<h2 id="6-2-配置kube-controller-manager-service"><a href="#6-2-配置kube-controller-manager-service" class="headerlink" title="6.2.配置kube-controller-manager service"></a>6.2.配置kube-controller-manager service</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所有master节点配置，且配置相同</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">172.16.0.0/12为pod网段，按需求设置你自己的网段</span></span><br><span class="line"></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --bind-address=127.0.0.1 \</span><br><span class="line">      --root-ca-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \</span><br><span class="line">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \</span><br><span class="line">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --use-service-account-credentials=true \</span><br><span class="line">      --node-monitor-grace-period=40s \</span><br><span class="line">      --node-monitor-period=5s \</span><br><span class="line">      --pod-eviction-timeout=2m0s \</span><br><span class="line">      --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">      --allocate-node-cidrs=true \</span><br><span class="line">      --feature-gates=IPv6DualStack=true \</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12,fd00::/108 \</span><br><span class="line">      --cluster-cidr=172.16.0.0/12,fc00::/48 \</span><br><span class="line">      --node-cidr-mask-size-ipv4=24 \</span><br><span class="line">      --node-cidr-mask-size-ipv6=64 \</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem </span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-2-1启动kube-controller-manager，并查看状态"><a href="#6-2-1启动kube-controller-manager，并查看状态" class="headerlink" title="6.2.1启动kube-controller-manager，并查看状态"></a>6.2.1启动kube-controller-manager，并查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-controller-manager</span><br><span class="line">systemctl  status kube-controller-manager</span><br></pre></td></tr></table></figure>

<h2 id="6-3-配置kube-scheduler-service"><a href="#6-3-配置kube-scheduler-service" class="headerlink" title="6.3.配置kube-scheduler service"></a>6.3.配置kube-scheduler service</h2><h3 id="6-3-1所有master节点配置，且配置相同"><a href="#6-3-1所有master节点配置，且配置相同" class="headerlink" title="6.3.1所有master节点配置，且配置相同"></a>6.3.1所有master节点配置，且配置相同</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \</span><br><span class="line">      --v=2 \</span><br><span class="line">      --logtostderr=true \</span><br><span class="line">      --bind-address=127.0.0.1 \</span><br><span class="line">      --leader-elect=true \</span><br><span class="line">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="6-3-2启动并查看服务状态"><a href="#6-3-2启动并查看服务状态" class="headerlink" title="6.3.2启动并查看服务状态"></a>6.3.2启动并查看服务状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now kube-scheduler</span><br><span class="line">systemctl status kube-scheduler</span><br></pre></td></tr></table></figure>

<h1 id="7-TLS-Bootstrapping配置"><a href="#7-TLS-Bootstrapping配置" class="headerlink" title="7.TLS Bootstrapping配置"></a>7.TLS Bootstrapping配置</h1><h2 id="7-1在master01上配置"><a href="#7-1在master01上配置" class="headerlink" title="7.1在master01上配置"></a>7.1在master01上配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd bootstrap</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes     \</span><br><span class="line">--certificate-authority=/etc/kubernetes/pki/ca.pem     \</span><br><span class="line">--embed-certs=true     --server=https://10.0.0.89:8443     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials tls-bootstrap-token-user     \</span><br><span class="line">--token=c8ad9c.2e4d610cf3e7426e \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context tls-bootstrap-token-user@kubernetes     \</span><br><span class="line">--cluster=kubernetes     \</span><br><span class="line">--user=tls-bootstrap-token-user     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context tls-bootstrap-token-user@kubernetes     \</span><br><span class="line">--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">token的位置在bootstrap.secret.yaml，如果修改的话到这个文件修改</span></span><br><span class="line"></span><br><span class="line">mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config</span><br></pre></td></tr></table></figure>

<h2 id="7-2查看集群状态，没问题的话继续后续操作"><a href="#7-2查看集群状态，没问题的话继续后续操作" class="headerlink" title="7.2查看集群状态，没问题的话继续后续操作"></a>7.2查看集群状态，没问题的话继续后续操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line"></span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE                         ERROR</span><br><span class="line">scheduler            Healthy   ok                              </span><br><span class="line">controller-manager   Healthy   ok                              </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;,&quot;reason&quot;:&quot;&quot;&#125; </span><br><span class="line"></span><br><span class="line">kubectl create -f bootstrap.secret.yaml</span><br></pre></td></tr></table></figure>

<h1 id="8-node节点配置"><a href="#8-node节点配置" class="headerlink" title="8.node节点配置"></a>8.node节点配置</h1><h2 id="8-1-在master01上将证书复制到node节点"><a href="#8-1-在master01上将证书复制到node节点" class="headerlink" title="8.1.在master01上将证书复制到node节点"></a>8.1.在master01上将证书复制到node节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/kubernetes/</span><br><span class="line"> </span><br><span class="line">for NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02; do ssh $NODE mkdir -p /etc/kubernetes/pki; for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig; do scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&#123;FILE&#125;; done; done</span><br></pre></td></tr></table></figure>

<h2 id="8-2-kubelet配置"><a href="#8-2-kubelet配置" class="headerlink" title="8.2.kubelet配置"></a>8.2.kubelet配置</h2><h3 id="8-2-1所有k8s节点创建相关目录"><a href="#8-2-1所有k8s节点创建相关目录" class="headerlink" title="8.2.1所有k8s节点创建相关目录"></a>8.2.1所有k8s节点创建相关目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所有k8s节点配置kubelet service</span></span><br><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=containerd.service</span><br><span class="line">Requires=containerd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \</span><br><span class="line">    --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \</span><br><span class="line">    --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="line">    --config=/etc/kubernetes/kubelet-conf.yml \</span><br><span class="line">    --container-runtime=remote  \</span><br><span class="line">    --runtime-request-timeout=15m  \</span><br><span class="line">    --container-runtime-endpoint=unix:///run/containerd/containerd.sock  \</span><br><span class="line">    --cgroup-driver=systemd \</span><br><span class="line">    --node-labels=node.kubernetes.io/node=&#x27;&#x27; \</span><br><span class="line">    --feature-gates=IPv6DualStack=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-2所有k8s节点创建kubelet的配置文件"><a href="#8-2-2所有k8s节点创建kubelet的配置文件" class="headerlink" title="8.2.2所有k8s节点创建kubelet的配置文件"></a>8.2.2所有k8s节点创建kubelet的配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">port: 10250</span><br><span class="line">readOnlyPort: 10255</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-2-3启动kubelet"><a href="#8-2-3启动kubelet" class="headerlink" title="8.2.3启动kubelet"></a>8.2.3启动kubelet</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">systemctl enable --now kubelet</span><br></pre></td></tr></table></figure>

<h3 id="8-2-4查看集群"><a href="#8-2-4查看集群" class="headerlink" title="8.2.4查看集群"></a>8.2.4查看集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-master02   NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-master03   NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-node01     NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">k8s-node02     NotReady   &lt;none&gt;   12s   v1.24.0</span><br><span class="line">[root@k8s-master01 ~]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="8-3-kube-proxy配置"><a href="#8-3-kube-proxy配置" class="headerlink" title="8.3.kube-proxy配置"></a>8.3.kube-proxy配置</h2><h3 id="8-3-1此配置只在master01操作"><a href="#8-3-1此配置只在master01操作" class="headerlink" title="8.3.1此配置只在master01操作"></a>8.3.1此配置只在master01操作</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp /etc/kubernetes/admin.kubeconfig /etc/kubernetes/kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="8-3-2将kubeconfig发送至其他节点"><a href="#8-3-2将kubeconfig发送至其他节点" class="headerlink" title="8.3.2将kubeconfig发送至其他节点"></a>8.3.2将kubeconfig发送至其他节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for NODE in k8s-master02 k8s-master03; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig; done</span><br><span class="line"></span><br><span class="line">for NODE in k8s-node01 k8s-node02 ; do scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig;  done</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3所有k8s节点添加kube-proxy的配置和service文件"><a href="#8-3-3所有k8s节点添加kube-proxy的配置和service文件" class="headerlink" title="8.3.3所有k8s节点添加kube-proxy的配置和service文件"></a>8.3.3所有k8s节点添加kube-proxy的配置和service文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt;  /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube Proxy</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \</span><br><span class="line">  --config=/etc/kubernetes/kube-proxy.yaml \</span><br><span class="line">  --v=2</span><br><span class="line"></span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line">clusterCIDR: 172.16.0.0/12,fc00::/48 </span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  masqueradeAll: true</span><br><span class="line">  minSyncPeriod: 5s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4启动kube-proxy"><a href="#8-3-4启动kube-proxy" class="headerlink" title="8.3.4启动kube-proxy"></a>8.3.4启动kube-proxy</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kube-proxy</span><br><span class="line">systemctl enable --now kube-proxy</span><br></pre></td></tr></table></figure>

<h1 id="9-安装Calico"><a href="#9-安装Calico" class="headerlink" title="9.安装Calico"></a>9.安装Calico</h1><h2 id="9-1以下步骤只在master01操作"><a href="#9-1以下步骤只在master01操作" class="headerlink" title="9.1以下步骤只在master01操作"></a>9.1以下步骤只在master01操作</h2><h3 id="9-1-1更改calico网段"><a href="#9-1-1更改calico网段" class="headerlink" title="9.1.1更改calico网段"></a>9.1.1更改calico网段</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim calico-ipv6.yaml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vim calico.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">calico-config ConfigMap处</span></span><br><span class="line">    &quot;ipam&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;calico-ipam&quot;,</span><br><span class="line">        &quot;assign_ipv4&quot;: &quot;true&quot;,</span><br><span class="line">        &quot;assign_ipv6&quot;: &quot;true&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    - name: IP</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: IP6</span><br><span class="line">      value: &quot;autodetect&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">      value: &quot;172.16.0.0/16&quot;</span><br><span class="line"></span><br><span class="line">    - name: CALICO_IPV6POOL_CIDR</span><br><span class="line">      value: &quot;fc00::/48&quot;</span><br><span class="line"></span><br><span class="line">    - name: FELIX_IPV6SUPPORT</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl apply -f calico.yaml</span></span><br><span class="line">kubectl apply -f calico-ipv6.yaml </span><br></pre></td></tr></table></figure>

<h3 id="9-1-2查看容器状态"><a href="#9-1-2查看容器状态" class="headerlink" title="9.1.2查看容器状态"></a>9.1.2查看容器状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl  get pod -A</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-kube-controllers-7fb57bc4b5-dwwg8   1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-b8p4z                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-c4lzj                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-dfh2m                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-gbhgn                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-node-ht6nl                          1/1     Running   0          23s</span><br><span class="line">kube-system   calico-typha-dd885f47-jvgsj                1/1     Running   0          23s</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl  get node</span><br><span class="line">NAME           STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master01   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master02   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-master03   Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;   14h   v1.23.5</span><br><span class="line">[root@k8s-master01 ~]# </span><br></pre></td></tr></table></figure>

<h1 id="10-安装CoreDNS"><a href="#10-安装CoreDNS" class="headerlink" title="10.安装CoreDNS"></a>10.安装CoreDNS</h1><h2 id="10-1以下步骤只在master01操作"><a href="#10-1以下步骤只在master01操作" class="headerlink" title="10.1以下步骤只在master01操作"></a>10.1以下步骤只在master01操作</h2><h3 id="10-1-1修改文件"><a href="#10-1-1修改文件" class="headerlink" title="10.1.1修改文件"></a>10.1.1修改文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd coredns/</span><br><span class="line"></span><br><span class="line">sed -i &quot;s#10.96.0.10#10.96.0.10#g&quot; coredns.yaml</span><br><span class="line"></span><br><span class="line">cat coredns.yaml | grep clusterIP:</span><br><span class="line">  clusterIP: 10.96.0.10 </span><br></pre></td></tr></table></figure>

<h3 id="10-1-2安装"><a href="#10-1-2安装" class="headerlink" title="10.1.2安装"></a>10.1.2安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  create -f coredns.yaml </span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.apps/coredns created</span><br><span class="line">service/kube-dns created</span><br></pre></td></tr></table></figure>

<h1 id="11-安装Metrics-Server"><a href="#11-安装Metrics-Server" class="headerlink" title="11.安装Metrics Server"></a>11.安装Metrics Server</h1><h2 id="11-1以下步骤只在master01操作"><a href="#11-1以下步骤只在master01操作" class="headerlink" title="11.1以下步骤只在master01操作"></a>11.1以下步骤只在master01操作</h2><h3 id="11-1-1安装Metrics-server"><a href="#11-1-1安装Metrics-server" class="headerlink" title="11.1.1安装Metrics-server"></a>11.1.1安装Metrics-server</h3><p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装metrics server</span></span><br><span class="line">cd metrics-server/</span><br><span class="line"></span><br><span class="line">kubectl  apply -f metrics-server.yaml </span><br></pre></td></tr></table></figure>

<h3 id="11-1-2稍等片刻查看状态"><a href="#11-1-2稍等片刻查看状态" class="headerlink" title="11.1.2稍等片刻查看状态"></a>11.1.2稍等片刻查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   415m         10%    1112Mi          29%       </span><br><span class="line">k8s-master02   232m         5%     940Mi           24%       </span><br><span class="line">k8s-master03   578m         14%    1183Mi          31%       </span><br><span class="line">k8s-node01     110m         2%     592Mi           15%       </span><br><span class="line">k8s-node02     114m         2%     617Mi           16%  </span><br></pre></td></tr></table></figure>

<h1 id="12-集群验证"><a href="#12-集群验证" class="headerlink" title="12.集群验证"></a>12.集群验证</h1><h2 id="12-1部署pod资源"><a href="#12-1部署pod资源" class="headerlink" title="12.1部署pod资源"></a>12.1部署pod资源</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat&lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line"></span><br><span class="line">kubectl  get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox   1/1     Running   0          17s</span><br></pre></td></tr></table></figure>

<h2 id="12-2用pod解析默认命名空间中的kubernetes"><a href="#12-2用pod解析默认命名空间中的kubernetes" class="headerlink" title="12.2用pod解析默认命名空间中的kubernetes"></a>12.2用pod解析默认命名空间中的kubernetes</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   17h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl exec  busybox -n default -- nslookup kubernetes</span><br><span class="line">3Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-3测试跨命名空间是否可以解析"><a href="#12-3测试跨命名空间是否可以解析" class="headerlink" title="12.3测试跨命名空间是否可以解析"></a>12.3测试跨命名空间是否可以解析</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl exec  busybox -n default -- nslookup kube-dns.kube-system</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kube-dns.kube-system</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br></pre></td></tr></table></figure>

<h2 id="12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53"><a href="#12-4每个节点都必须要能访问Kubernetes的kubernetes-svc-443和kube-dns的service-53" class="headerlink" title="12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53"></a>12.4每个节点都必须要能访问Kubernetes的kubernetes svc 443和kube-dns的service 53</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">telnet 10.96.0.1 443</span><br><span class="line">Trying 10.96.0.1...</span><br><span class="line">Connected to 10.96.0.1.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line"> telnet 10.96.0.10 53</span><br><span class="line">Trying 10.96.0.10...</span><br><span class="line">Connected to 10.96.0.10.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line"></span><br><span class="line">curl 10.96.0.10:53</span><br><span class="line">curl: (52) Empty reply from server</span><br></pre></td></tr></table></figure>

<h2 id="12-5Pod和Pod之前要能通"><a href="#12-5Pod和Pod之前要能通" class="headerlink" title="12.5Pod和Pod之前要能通"></a>12.5Pod和Pod之前要能通</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get po -owide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox   1/1     Running   0          17m   172.27.14.193   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"> kubectl get po -n kube-system -owide</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS      AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-5dffd5886b-4blh6   1/1     Running   0             77m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-fvbdq                          1/1     Running   1 (75m ago)   77m   10.0.0.81     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-g8nqd                          1/1     Running   0             77m   10.0.0.84     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-mdps8                          1/1     Running   0             77m   10.0.0.85     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-nf4nt                          1/1     Running   0             77m   10.0.0.83     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-sq2ml                          1/1     Running   0             77m   10.0.0.82     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-mg6p8              1/1     Running   0             77m   10.0.0.85     k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-pxbpj              1/1     Running   0             77m   10.0.0.81     k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-8445487f56-tnssl              1/1     Running   0             77m   10.0.0.84     k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5db5696c7-67h79                    1/1     Running   0             63m   172.25.92.65     k8s-master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">metrics-server-6bf7dcd649-5fhrw            1/1     Running   0             61m   172.18.195.1     k8s-master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入busybox ping其他节点上的pod</span></span><br><span class="line"></span><br><span class="line">kubectl exec -ti busybox -- sh</span><br><span class="line">/ # ping 10.0.0.84</span><br><span class="line">PING 10.0.0.84 (10.0.0.84): 56 data bytes</span><br><span class="line">64 bytes from 10.0.0.84: seq=0 ttl=63 time=0.358 ms</span><br><span class="line">64 bytes from 10.0.0.84: seq=1 ttl=63 time=0.668 ms</span><br><span class="line">64 bytes from 10.0.0.84: seq=2 ttl=63 time=0.637 ms</span><br><span class="line">64 bytes from 10.0.0.84: seq=3 ttl=63 time=0.624 ms</span><br><span class="line">64 bytes from 10.0.0.84: seq=4 ttl=63 time=0.907 ms</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以连通证明这个pod是可以跨命名空间和跨主机通信的</span></span><br></pre></td></tr></table></figure>

<h2 id="12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"><a href="#12-6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）" class="headerlink" title="12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）"></a>12.6创建三个副本，可以看到3个副本分布在不同的节点上（用完可以删了）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; deployments.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl  apply -f deployments.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">kubectl  get pod </span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                            1/1     Running   0          6m25s</span><br><span class="line">nginx-deployment-9456bbbf9-4bmvk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-9rcdk   1/1     Running   0          8s</span><br><span class="line">nginx-deployment-9456bbbf9-dqv8s   1/1     Running   0          8s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除nginx</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f deployments.yaml </span><br></pre></td></tr></table></figure>





<h1 id="13-安装dashboard"><a href="#13-安装dashboard" class="headerlink" title="13.安装dashboard"></a>13.安装dashboard</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/cby-chen/Kubernetes/main/yaml/dashboard.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/cby-chen/Kubernetes/main/yaml/dashboard-user.yaml</span><br><span class="line"></span><br><span class="line">kubectl  apply -f dashboard.yaml</span><br><span class="line">kubectl  apply -f dashboard-user.yaml</span><br></pre></td></tr></table></figure>

<h2 id="13-1更改dashboard的svc为NodePort，如果已是请忽略"><a href="#13-1更改dashboard的svc为NodePort，如果已是请忽略" class="headerlink" title="13.1更改dashboard的svc为NodePort，如果已是请忽略"></a>13.1更改dashboard的svc为NodePort，如果已是请忽略</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure>

<h2 id="13-2查看端口号"><a href="#13-2查看端口号" class="headerlink" title="13.2查看端口号"></a>13.2查看端口号</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get svc kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.98.201.22   &lt;none&gt;        443:31473/TCP   10m</span><br></pre></td></tr></table></figure>

<h2 id="13-3创建token"><a href="#13-3创建token" class="headerlink" title="13.3创建token"></a>13.3创建token</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl -n kubernetes-dashboard create token admin-user</span><br><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6IlV6b3NRbDRiTll4VEl1a1VGbU53M2Y2X044Wjdfa21mQ0dfYk5BWktHRjAifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjUyNzYzMjUzLCJpYXQiOjE2NTI3NTk2NTMsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiNDYxYjc4MDItNTgzMS00MTNmLTg2M2ItODdlZWVkOTI3MTdiIn19LCJuYmYiOjE2NTI3NTk2NTMsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2VyIn0.nFF729zlDxz4Ed3fcVk5BE8Akc6jod6akf2rksVGJHmfurY7NO1nHP4EekrMx1FRa2JfoPOHTdxcWDVaQAymDC4vgP5aW5RCEOURUY6YdTQUxleRiX-Bgp3eNRHNOcPvdedGm0w7M7gnZqCwy4tsgyiXkIM7zZpvCqdCA1vGJxf_UIck4R8Izua5NSacnG25miIvAmxNzOAEHDD_jDIDHnPVi3iVZzrjBkDwG6spYx_yJbbLy1XbJCYMMH44X4ajuQulV_NS-aiIHj_-PbxfrBRAJCVTZ8L3zD14BraeAAHFqSoiLXohmYHLLjshtraVu4XcvehJDfnRMi8Y4b6sqA</span><br></pre></td></tr></table></figure>

<h2 id="13-3登录dashboard"><a href="#13-3登录dashboard" class="headerlink" title="13.3登录dashboard"></a>13.3登录dashboard</h2><p><a href="https://10.0.0.81:31245/">https://10.0.0.81:31245/</a></p>
<h1 id="14-ingress安装"><a href="#14-ingress安装" class="headerlink" title="14.ingress安装"></a>14.ingress安装</h1><h2 id="14-1写入配置文件，并执行"><a href="#14-1写入配置文件，并执行" class="headerlink" title="14.1写入配置文件，并执行"></a>14.1写入配置文件，并执行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim deploy.yaml</span><br><span class="line">[root@hello ~/yaml]# cat deploy.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-serviceaccount.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">automountServiceAccountToken: true</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-configmap.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">data:</span><br><span class="line">  allow-snippet-annotations: &#x27;true&#x27;</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/clusterrole.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - endpoints</span><br><span class="line">      - nodes</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/clusterrolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-role.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">      - pods</span><br><span class="line">      - secrets</span><br><span class="line">      - endpoints</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses/status</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - networking.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - ingressclasses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    resourceNames:</span><br><span class="line">      - ingress-controller-leader</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - configmaps</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - events</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - patch</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-rolebinding.yaml</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-service-webhook.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - name: https-webhook</span><br><span class="line">      port: 443</span><br><span class="line">      targetPort: webhook</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-service.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  externalTrafficPolicy: Local</span><br><span class="line">  ipFamilyPolicy: SingleStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">    - IPv4</span><br><span class="line">  ports:</span><br><span class="line">    - name: http</span><br><span class="line">      port: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: http</span><br><span class="line">      appProtocol: http</span><br><span class="line">    - name: https</span><br><span class="line">      port: 443</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: https</span><br><span class="line">      appProtocol: https</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-deployment.yaml</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: ingress-nginx-controller</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: ingress-nginx</span><br><span class="line">      app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">      app.kubernetes.io/component: controller</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  minReadySeconds: 0</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/component: controller</span><br><span class="line">    spec:</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      containers:</span><br><span class="line">        - name: controller</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/controller:v1.1.3 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          lifecycle:</span><br><span class="line">            preStop:</span><br><span class="line">              exec:</span><br><span class="line">                command:</span><br><span class="line">                  - /wait-shutdown</span><br><span class="line">          args:</span><br><span class="line">            - /nginx-ingress-controller</span><br><span class="line">            - --election-id=ingress-controller-leader</span><br><span class="line">            - --controller-class=k8s.io/ingress-nginx</span><br><span class="line">            - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller</span><br><span class="line">            - --validating-webhook=:8443</span><br><span class="line">            - --validating-webhook-certificate=/usr/local/certificates/cert</span><br><span class="line">            - --validating-webhook-key=/usr/local/certificates/key</span><br><span class="line">          securityContext:</span><br><span class="line">            capabilities:</span><br><span class="line">              drop:</span><br><span class="line">                - ALL</span><br><span class="line">              add:</span><br><span class="line">                - NET_BIND_SERVICE</span><br><span class="line">            runAsUser: 101</span><br><span class="line">            allowPrivilegeEscalation: true</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.name</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">            - name: LD_PRELOAD</span><br><span class="line">              value: /usr/local/lib/libmimalloc.so</span><br><span class="line">          livenessProbe:</span><br><span class="line">            failureThreshold: 5</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          readinessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /healthz</span><br><span class="line">              port: 10254</span><br><span class="line">              scheme: HTTP</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          ports:</span><br><span class="line">            - name: http</span><br><span class="line">              containerPort: 80</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: https</span><br><span class="line">              containerPort: 443</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - name: webhook</span><br><span class="line">              containerPort: 8443</span><br><span class="line">              protocol: TCP</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: webhook-cert</span><br><span class="line">              mountPath: /usr/local/certificates/</span><br><span class="line">              readOnly: true</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 100m</span><br><span class="line">              memory: 90Mi</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      serviceAccountName: ingress-nginx</span><br><span class="line">      terminationGracePeriodSeconds: 300</span><br><span class="line">      volumes:</span><br><span class="line">        - name: webhook-cert</span><br><span class="line">          secret:</span><br><span class="line">            secretName: ingress-nginx-admission</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source: ingress-nginx/templates/controller-ingressclass.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">We don<span class="string">&#x27;t support namespaced ingressClass yet</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">So a ClusterRole and a ClusterRoleBinding is required</span></span></span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: IngressClass</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: controller</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">spec:</span><br><span class="line">  controller: k8s.io/ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/validating-webhook.yaml</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">before changing this value, check the required kubernetes version</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites</span></span></span><br><span class="line">apiVersion: admissionregistration.k8s.io/v1</span><br><span class="line">kind: ValidatingWebhookConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">webhooks:</span><br><span class="line">  - name: validate.nginx.ingress.kubernetes.io</span><br><span class="line">    matchPolicy: Equivalent</span><br><span class="line">    rules:</span><br><span class="line">      - apiGroups:</span><br><span class="line">          - networking.k8s.io</span><br><span class="line">        apiVersions:</span><br><span class="line">          - v1</span><br><span class="line">        operations:</span><br><span class="line">          - CREATE</span><br><span class="line">          - UPDATE</span><br><span class="line">        resources:</span><br><span class="line">          - ingresses</span><br><span class="line">    failurePolicy: Fail</span><br><span class="line">    sideEffects: None</span><br><span class="line">    admissionReviewVersions:</span><br><span class="line">      - v1</span><br><span class="line">    clientConfig:</span><br><span class="line">      service:</span><br><span class="line">        namespace: ingress-nginx</span><br><span class="line">        name: ingress-nginx-controller-admission</span><br><span class="line">        path: /networking/v1/ingresses</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - admissionregistration.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">      - validatingwebhookconfigurations</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/role.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &#x27;&#x27;</span><br><span class="line">    resources:</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - create</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml</span></span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: ingress-nginx-admission</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: ingress-nginx-admission</span><br><span class="line">    namespace: ingress-nginx</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-create</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: pre-install,pre-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-create</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: create</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - create</span><br><span class="line">            - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Source: ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml</span></span></span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-admission-patch</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    helm.sh/hook: post-install,post-upgrade</span><br><span class="line">    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded</span><br><span class="line">  labels:</span><br><span class="line">    helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">    app.kubernetes.io/version: 1.1.0</span><br><span class="line">    app.kubernetes.io/managed-by: Helm</span><br><span class="line">    app.kubernetes.io/component: admission-webhook</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: ingress-nginx-admission-patch</span><br><span class="line">      labels:</span><br><span class="line">        helm.sh/chart: ingress-nginx-4.0.10</span><br><span class="line">        app.kubernetes.io/name: ingress-nginx</span><br><span class="line">        app.kubernetes.io/instance: ingress-nginx</span><br><span class="line">        app.kubernetes.io/version: 1.1.0</span><br><span class="line">        app.kubernetes.io/managed-by: Helm</span><br><span class="line">        app.kubernetes.io/component: admission-webhook</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: patch</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/chenby/kube-webhook-certgen:v1.1.1 </span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - patch</span><br><span class="line">            - --webhook-name=ingress-nginx-admission</span><br><span class="line">            - --namespace=$(POD_NAMESPACE)</span><br><span class="line">            - --patch-mutating=false</span><br><span class="line">            - --secret-name=ingress-nginx-admission</span><br><span class="line">            - --patch-failure-policy=Fail</span><br><span class="line">          env:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">      restartPolicy: OnFailure</span><br><span class="line">      serviceAccountName: ingress-nginx-admission</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      securityContext:</span><br><span class="line">        runAsNonRoot: true</span><br><span class="line">        runAsUser: 2000</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="14-2启用后端，写入配置文件执行"><a href="#14-2启用后端，写入配置文件执行" class="headerlink" title="14.2启用后端，写入配置文件执行"></a>14.2启用后端，写入配置文件执行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim backend.yaml</span><br><span class="line">[root@hello ~/yaml]# cat backend.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: default-http-backend</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: default-http-backend</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      containers:</span><br><span class="line">      - name: default-http-backend</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/chenby/defaultbackend-amd64:1.5 </span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /healthz</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 20Mi</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: default-http-backend</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: default-http-backend</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="14-3安装测试应用"><a href="#14-3安装测试应用" class="headerlink" title="14.3安装测试应用"></a>14.3安装测试应用</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# vim ingress-demo-app.yaml</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line">[root@hello ~/yaml]# cat ingress-demo-app.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello-server</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-server</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-server</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.chenby.cn&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx&quot;  </span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-4执行部署"><a href="#14-4执行部署" class="headerlink" title="14.4执行部署"></a>14.4执行部署</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl  apply -f deploy.yaml </span><br><span class="line"></span><br><span class="line">kubectl  apply -f backend.yaml </span><br><span class="line"></span><br><span class="line">kubectl  apply -f ingress-demo-app.yaml </span><br><span class="line"></span><br><span class="line">kubectl  get ingress</span><br><span class="line">NAME               CLASS   HOSTS                            ADDRESS     PORTS   AGE</span><br><span class="line">ingress-host-bar   nginx   hello.chenby.cn,demo.chenby.cn   10.0.0.87   80      7s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-5过滤查看ingress端口"><a href="#14-5过滤查看ingress端口" class="headerlink" title="14.5过滤查看ingress端口"></a>14.5过滤查看ingress端口</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hello ~/yaml]# kubectl  get svc -A | grep ingress</span><br><span class="line">ingress-nginx          ingress-nginx-controller             NodePort    10.104.231.36    &lt;none&gt;        80:32636/TCP,443:30579/TCP   104s</span><br><span class="line">ingress-nginx          ingress-nginx-controller-admission   ClusterIP   10.101.85.88     &lt;none&gt;        443/TCP                      105s</span><br><span class="line">[root@hello ~/yaml]#</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="15-IPv6测试"><a href="#15-IPv6测试" class="headerlink" title="15.IPv6测试"></a>15.IPv6测试</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">部署应用</span></span><br><span class="line">[root@k8s-master01 ~]# vim cby.yaml </span><br><span class="line">[root@k8s-master01 ~]# cat cby.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: chenby</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: chenby</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: chenby</span><br><span class="line">        image: nginx</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: &quot;128Mi&quot;</span><br><span class="line">            cpu: &quot;500m&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: chenby</span><br><span class="line">spec:</span><br><span class="line">  ipFamilyPolicy: PreferDualStack</span><br><span class="line">  ipFamilies:</span><br><span class="line">  - IPv6</span><br><span class="line">  - IPv4</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: chenby</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">[root@k8s-master01 ~]# kubectl  apply -f cby.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看端口</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl  get svc</span><br><span class="line">NAME           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">chenby         NodePort    fd00::a29c       &lt;none&gt;        80:30779/TCP   5s</span><br><span class="line">[root@k8s-master01 ~]# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用内网访问</span></span><br><span class="line">[root@localhost yaml]# curl -I http://[fd00::a29c]</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:35 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# curl -I http://10.0.0.81:30779</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:59 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">使用公网访问</span></span><br><span class="line"></span><br><span class="line">[root@localhost yaml]# curl -I http://[2408:8207:78c5:29a1::10]:30779</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.6</span><br><span class="line">Date: Thu, 05 May 2022 10:20:54 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 25 Jan 2022 15:03:52 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: &quot;61f01158-267&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="16-安装命令行自动补全功能"><a href="#16-安装命令行自动补全功能" class="headerlink" title="16.安装命令行自动补全功能"></a>16.安装命令行自动补全功能</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install bash-completion -y</span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>





<blockquote>
<p><a href="https://www.oiox.cn/">https://www.oiox.cn/</a>   </p>
<p><a href="https://www.chenby.cn/">https://www.chenby.cn/</a>  </p>
<p><a href="https://cby-chen.github.io/">https://cby-chen.github.io/</a>  </p>
<p><a href="https://blog.csdn.net/qq_33921750">https://blog.csdn.net/qq_33921750</a>  </p>
<p><a href="https://my.oschina.net/u/3981543">https://my.oschina.net/u/3981543</a>  </p>
<p><a href="https://www.zhihu.com/people/chen-bu-yun-2">https://www.zhihu.com/people/chen-bu-yun-2</a>  </p>
<p><a href="https://segmentfault.com/u/hppyvyv6/articles">https://segmentfault.com/u/hppyvyv6/articles</a>  </p>
<p><a href="https://juejin.cn/user/3315782802482007">https://juejin.cn/user/3315782802482007</a>  </p>
<p><a href="https://cloud.tencent.com/developer/column/93230">https://cloud.tencent.com/developer/column/93230</a>  </p>
<p><a href="https://www.jianshu.com/u/0f894314ae2c">https://www.jianshu.com/u/0f894314ae2c</a>  </p>
<p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/">https://www.toutiao.com/c/user/token/MS4wLjABAAAAeqOrhjsoRZSj7iBJbjLJyMwYT5D0mLOgCoo4pEmpr4A/</a></p>
<p>CSDN、GitHub、知乎、开源中国、思否、掘金、简书、腾讯云、今日头条、个人博客、全网可搜《小陈运维》</p>
<p>文章主要发布于微信公众号：《Linux运维交流社区》</p>
</blockquote>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
</search>
